<doc id="624" url="https://en.wikipedia.org/wiki?curid=624" title="Alaska">
Alaska

Alaska () is a U.S. state situated in the northwest extremity of the Americas. The Canadian administrative divisions of British Columbia and Yukon border the state to the east; its most extreme western part is Attu Island; it has a maritime border with Russia to the west across the Bering Strait. To the north are the Chukchi and Beaufort seas–the southern parts of the Arctic Ocean. The Pacific Ocean lies to the south and southwest. Alaska is the largest state in the United States by area, the 3rd least populous and the least densely populated of the 50 United States. Approximately half of Alaska's residents (the total estimated at 738,432 by the U.S. Census Bureau in 2015) live within the Anchorage metropolitan area. Alaska's economy is dominated by the fishing, natural gas, and oil industries, resources which it has in abundance. Military bases and tourism are also a significant part of the economy.
The United States purchased Alaska from the Russian Empire on March 30, 1867, for 7.2 million U.S. dollars at approximately two cents per acre ($4.74/km). The area went through several administrative changes before becoming organized as a territory on May 11, 1912. It was admitted as the 49th state of the U.S. on January 3, 1959.
<h2>Etymology.</h2>
The name "Alaska" (Аляска) was introduced in the Russian colonial period when it was used to refer to the peninsula. It was derived from an Aleut, or Unangam idiom, which figuratively refers to the mainland of Alaska. Literally, it means "object to which the action of the sea is directed". It is also known as "Alyeska," the "great land", an Aleut word derived from the same root.
<h2>Geography.</h2>
Alaska is the northernmost and westernmost state in the United States and has the most easterly longitude in the United States because the Aleutian Islands extend into the Eastern Hemisphere. Alaska is the only non-contiguous U.S. state on continental North America; about of British Columbia (Canada) separates Alaska from Washington. It is technically part of the continental U.S., but is sometimes not included in colloquial use; Alaska is not part of the contiguous U.S., often called "the Lower 48". The capital city, Juneau, is situated on the mainland of the North American continent but is not connected by road to the rest of the North American highway system.
The state is bordered by Yukon and British Columbia in Canada, to the east, the Gulf of Alaska and the Pacific Ocean to the south and southwest, the Bering Sea, Bering Strait, and Chukchi Sea to the west and the Arctic Ocean to the north. Alaska's territorial waters touch Russia's territorial waters in the Bering Strait, as the Russian Big Diomede Island and Alaskan Little Diomede Island are only apart. Alaska has a longer coastline than all the other U.S. states combined.
Alaska is the largest state in the United States in land area at , over twice the size of Texas, the next largest state. Alaska is larger than all but 18 sovereign countries. Counting territorial waters, Alaska is larger than the combined area of the next three largest states: Texas, California, and Montana. It is also larger than the combined area of the 22 smallest U.S. states.
<h3>Regions.</h3>
There are no officially defined borders demarcating the various regions of Alaska, but there are six widely accepted regions:
<h4>South Central.</h4>
The most populous region of Alaska, containing Anchorage, the Matanuska-Susitna Valley and the Kenai Peninsula. Rural, mostly unpopulated areas south of the Alaska Range and west of the Wrangell Mountains also fall within the definition of South Central, as do the Prince William Sound area and the communities of Cordova and Valdez.
<h4>Southeast.</h4>
Also referred to as the Panhandle or Inside Passage, this is the region of Alaska closest to the rest of the United States. As such, this was where most of the initial non-indigenous settlement occurred in the years following the Alaska Purchase. The region is dominated by the Alexander Archipelago as well as the Tongass National Forest, the largest national forest in the United States. It contains the state capital Juneau, the former capital Sitka, and Ketchikan, at one time Alaska's largest city. The Alaska Marine Highway provides a vital surface transportation link throughout the area, as only three communities (Haines, Hyder and Skagway) enjoy direct connections to the contiguous North American road system.
<h4>Interior.</h4>
The Interior is the largest region of Alaska; much of it is uninhabited wilderness. Fairbanks is the only large city in the region. Denali National Park and Preserve is located here. "Denali" is the highest mountain in North America.
<h4>Southwest.</h4>
Southwest Alaska is a sparsely inhabited region stretching some inland from the Bering Sea. Most of the population lives along the coast. Kodiak Island is also located in Southwest. The massive Yukon–Kuskokwim Delta, one of the largest river deltas in the world, is here. Portions of the Alaska Peninsula are considered part of Southwest, with the remaining portions included with the Aleutian Islands (see below).
<h4>North Slope.</h4>
The North Slope is mostly tundra peppered with small villages. The area is known for its massive reserves of crude oil, and contains both the National Petroleum Reserve–Alaska and the Prudhoe Bay Oil Field. Barrow, the northernmost city in the United States, is located here. The Northwest Arctic area, anchored by Kotzebue and also containing the Kobuk River valley, is often regarded as being part of this region. However, the respective Inupiat of the North Slope and of the Northwest Arctic seldom consider themselves to be one people.
<h4>Aleutian Islands.</h4>
More than 300 small volcanic islands make up this chain, which stretches over into the Pacific Ocean. Some of these islands fall in the Eastern Hemisphere, but the International Date Line was drawn west of 180° to keep the whole state, and thus the entire North American continent, within the same legal day. Two of the islands, Attu and Kiska, were occupied by Japanese forces during World War II.
<h3>Natural features.</h3>
With its myriad islands, Alaska has nearly of tidal shoreline. The Aleutian Islands chain extends west from the southern tip of the Alaska Peninsula. Many active volcanoes are found in the Aleutians and in coastal regions. Unimak Island, for example, is home to Mount Shishaldin, which is an occasionally smoldering volcano that rises to above the North Pacific. It is the most perfect volcanic cone on Earth, even more symmetrical than Japan's Mount Fuji. The chain of volcanoes extends to Mount Spurr, west of Anchorage on the mainland. Geologists have identified Alaska as part of Wrangellia, a large region consisting of multiple states and Canadian provinces in the Pacific Northwest, which is actively undergoing continent building.
One of the world's largest tides occurs in Turnagain Arm, just south of Anchorage – tidal differences can be more than .
Alaska has more than three million lakes. Marshlands and wetland permafrost cover (mostly in northern, western and southwest flatlands). Glacier ice covers some of land and of tidal zone. The Bering Glacier complex near the southeastern border with Yukon covers alone. With over 100,000 glaciers, Alaska has half of all in the world.
<h3>Land ownership.</h3>
According to an October 1998 report by the United States Bureau of Land Management, approximately 65% of Alaska is owned and managed by the U.S. federal government as public lands, including a multitude of national forests, national parks, and national wildlife refuges. Of these, the Bureau of Land Management manages , or 23.8% of the state. The Arctic National Wildlife Refuge is managed by the United States Fish and Wildlife Service. It is the world's largest wildlife refuge, comprising .
Of the remaining land area, the state of Alaska owns , its entitlement under the Alaska Statehood Act. A portion of that acreage is occasionally ceded to organized boroughs, under the statutory provisions pertaining to newly formed boroughs. Smaller portions are set aside for rural subdivisions and other homesteading-related opportunities. These are not very popular due to the often remote and roadless locations. The University of Alaska, as a land grant university, also owns substantial acreage which it manages independently.
Another are owned by 12 regional, and scores of local, Native corporations created under the Alaska Native Claims Settlement Act (ANCSA) of 1971. Regional Native corporation Doyon, Limited often promotes itself as the largest private landowner in Alaska in advertisements and other communications. Provisions of ANCSA allowing the corporations' land holdings to be sold on the open market starting in 1991 were repealed before they could take effect. Effectively, the corporations hold title (including subsurface title in many cases, a privilege denied to individual Alaskans) but cannot sell the land. Individual Native allotments can be and are sold on the open market, however.
Various private interests own the remaining land, totaling about one percent of the state. Alaska is, by a large margin, the state with the smallest percentage of private land ownership when Native corporation holdings are excluded.
<h3>Climate.</h3>
The climate in Southeast Alaska is a mid-latitude oceanic climate (Köppen climate classification: "Cfb") in the southern sections and a subarctic oceanic climate (Köppen "Cfc") in the northern parts. On an annual basis, Southeast is both the wettest and warmest part of Alaska with milder temperatures in the winter and high precipitation throughout the year. Juneau averages over of precipitation a year, and Ketchikan averages over . This is also the only region in Alaska in which the average daytime high temperature is above freezing during the winter months.
The climate of Anchorage and south central Alaska is mild by Alaskan standards due to the region's proximity to the seacoast. While the area gets less rain than southeast Alaska, it gets more snow, and days tend to be clearer. On average, Anchorage receives of precipitation a year, with around of snow, although there are areas in the south central which receive far more snow. It is a subarctic climate () due to its brief, cool summers.
The climate of Western Alaska is determined in large part by the Bering Sea and the Gulf of Alaska. It is a subarctic oceanic climate in the southwest and a continental subarctic climate farther north. The temperature is somewhat moderate considering how far north the area is. This region has a tremendous amount of variety in precipitation. An area stretching from the northern side of the Seward Peninsula to the Kobuk River valley (i. e., the region around Kotzebue Sound) is technically a desert, with portions receiving less than of precipitation annually. On the other extreme, some locations between Dillingham and Bethel average around of precipitation.
The climate of the interior of Alaska is subarctic. Some of the highest and lowest temperatures in Alaska occur around the area near Fairbanks. The summers may have temperatures reaching into the 90s °F (the low-to-mid 30s °C), while in the winter, the temperature can fall below . Precipitation is sparse in the Interior, often less than a year, but what precipitation falls in the winter tends to stay the entire winter.
The highest and lowest recorded temperatures in Alaska are both in the Interior. The highest is in Fort Yukon (which is just inside the arctic circle) on June 27, 1915, making Alaska tied with Hawaii as the state with the lowest high temperature in the United States. The lowest official Alaska temperature is in Prospect Creek on January 23, 1971, one degree above the lowest temperature recorded in continental North America (in Snag, Yukon, Canada).
The climate in the extreme north of Alaska is Arctic () with long, very cold winters and short, cool summers. Even in July, the average low temperature in Barrow is . Precipitation is light in this part of Alaska, with many places averaging less than per year, mostly as snow which stays on the ground almost the entire year.
<h2>History.</h2>
<h3>Alaska Natives.</h3>
Numerous indigenous peoples occupied Alaska for thousands of years before the arrival of European peoples to the area. Linguistic and DNA studies done here have provided evidence for the settlement of North America by way of the Bering land bridge. The Tlingit people developed a society with a matrilineal kinship system of property inheritance and descent in what is today Southeast Alaska, along with parts of British Columbia and the Yukon. Also in Southeast were the Haida, now well known for their unique arts. The Tsimshian people came to Alaska from British Columbia in 1887, when President Grover Cleveland, and later the U.S. Congress, granted them permission to settle on Annette Island and found the town of Metlakatla. All three of these peoples, as well as other indigenous peoples of the Pacific Northwest Coast, experienced smallpox outbreaks from the late 18th through the mid-19th century, with the most devastating epidemics occurring in the 1830s and 1860s, resulting in high fatalities and social disruption.
The Aleutian Islands are still home to the Aleut people's seafaring society, although they were the first Native Alaskans to be exploited by Russians. Western and Southwestern Alaska are home to the Yup'ik, while their cousins the Alutiiq ~ Sugpiaq lived in what is now Southcentral Alaska. The Gwich'in people of the northern Interior region are Athabaskan and primarily known today for their dependence on the caribou within the much-contested Arctic National Wildlife Refuge. The North Slope and Little Diomede Island are occupied by the widespread Inupiat people.
<h3>Colonization.</h3>
Some researchers believe that the first Russian settlement in Alaska was established in the 17th century. According to this hypothesis, in 1648 several koches of Semyon Dezhnyov's expedition came ashore in Alaska by storm and founded this settlement. This hypothesis is based on the testimony of Chukchi geographer Nikolai Daurkin, who had visited Alaska in 1764–1765 and who had reported on a village on the Kheuveren River, populated by "bearded men" who "pray to the icons". Some modern researchers associate Kheuveren with Koyuk River.
The first European vessel to reach Alaska is generally held to be the "St. Gabriel" under the authority of the surveyor M. S. Gvozdev and assistant navigator I. Fyodorov on August 21, 1732 during an expedition of Siberian cossak A. F. Shestakov and Belorussian explorer Dmitry Pavlutsky (1729—1735).
Another European contact with Alaska occurred in 1741, when Vitus Bering led an expedition for the Russian Navy aboard the "St. Peter". After his crew returned to Russia with sea otter pelts judged to be the finest fur in the world, small associations of fur traders began to sail from the shores of Siberia toward the Aleutian Islands. The first permanent European settlement was founded in 1784.
Between 1774 and 1800, Spain sent several expeditions to Alaska in order to assert its claim over the Pacific Northwest. In 1789 a Spanish settlement and fort were built in Nootka Sound. These expeditions gave names to places such as Valdez, Bucareli Sound, and Cordova. Later, the Russian-American Company carried out an expanded colonization program during the early-to-mid-19th century.
Sitka, renamed New Archangel from 1804 to 1867, on Baranof Island in the Alexander Archipelago in what is now Southeast Alaska, became the capital of Russian America. It remained the capital after the colony was transferred to the United States. The Russians never fully colonized Alaska, and the colony was never very profitable. Evidence of Russian settlement in names and churches survive throughout southeast Alaska.
William H. Seward, the United States Secretary of State, negotiated the Alaska Purchase (also known as Seward's Folly) with the Russians in 1867 for $7.2 million. Alaska was loosely governed by the military initially, and was administered as a district starting in 1884, with a governor appointed by the President of the United States. A federal district court was headquartered in Sitka.
For most of Alaska's first decade under the United States flag, Sitka was the only community inhabited by American settlers. They organized a "provisional city government," which was Alaska's first municipal government, but not in a legal sense. Legislation allowing Alaskan communities to legally incorporate as cities did not come about until 1900, and home rule for cities was extremely limited or unavailable until statehood took effect in 1959.
<h3>U.S. Territory.</h3>
Starting in the 1890s and stretching in some places to the early 1910s, gold rushes in Alaska and the nearby Yukon Territory brought thousands of miners and settlers to Alaska. Alaska was officially incorporated as an organized territory in 1912. Alaska's capital, which had been in Sitka until 1906, was moved north to Juneau. Construction of the Alaska Governor's Mansion began that same year. European immigrants from Norway and Sweden also settled in southeast Alaska, where they entered the fishing and logging industries.
During World War II, the Aleutian Islands Campaign focused on the three outer Aleutian Islands – Attu, Agattu and Kiska – that were invaded by Japanese troops and occupied between June 1942 and August 1943. During the occupation, one Alaskan civilian was killed by Japanese troops and nearly fifty were interned in Japan, where about half of them died. Unalaska/Dutch Harbor became a significant base for the U.S. Army Air Forces and Navy submariners.
The U.S. Lend-Lease program involved the flying of American warplanes through Canada to Fairbanks and thence Nome; Soviet pilots took possession of these aircraft, ferrying them to fight the German invasion of the Soviet Union. The construction of military bases contributed to the population growth of some Alaskan cities.
<h3>Statehood.</h3>
Statehood for Alaska was an important cause of James Wickersham early in his tenure as a congressional delegate. Decades later, the statehood movement gained its first real momentum following a territorial referendum in 1946. The Alaska Statehood Committee and Alaska's Constitutional Convention would soon follow. Statehood supporters also found themselves fighting major battles against political foes, mostly in the U.S. Congress but also within Alaska. Statehood was approved by Congress on July 7, 1958. Alaska was officially proclaimed a state on January 3, 1959.
In 1960, the Census Bureau reported Alaska's population as 77.2% White, 3% Black, and 18.8% American Indian and Alaska Native.
On March 27, 1964, the massive Good Friday earthquake killed 133 people and destroyed several villages and portions of large coastal communities, mainly by the resultant tsunamis and landslides. It was the second-most-powerful earthquake in the recorded history of the world, with a moment magnitude of 9.2. It was over one thousand times more powerful than the 1989 San Francisco earthquake. The time of day (5:36 pm), time of year and location of the epicenter were all cited as factors in potentially sparing thousands of lives, particularly in Anchorage.
The 1968 discovery of oil at Prudhoe Bay and the 1977 completion of the Trans-Alaska Pipeline System led to an oil boom. Royalty revenues from oil have funded large state budgets from 1980 onward. That same year, not coincidentally, Alaska repealed its state income tax.
In 1989, the "Exxon Valdez" hit a reef in the Prince William Sound, spilling over of crude oil over of coastline. Today, the battle between philosophies of development and conservation is seen in the contentious debate over oil drilling in the Arctic National Wildlife Refuge and the proposed Pebble Mine.
<h3>Alaska Heritage Resources Survey.</h3>
The Alaska Heritage Resources Survey (AHRS) is a restricted inventory of all reported historic and prehistoric sites within the state of Alaska; it is maintained by the Office of History and Archaeology. The survey's inventory of cultural resources includes objects, structures, buildings, sites, districts, and travel ways, with a general provision that they are over 50 years old. As of January 31, 2012, over 35,000 sites have been reported.
<h2>Demographics.</h2>
The United States Census Bureau estimates that the population of Alaska was 738,432 on July 1, 2015, a 3.97% increase since the 2010 United States Census.
In 2010, Alaska ranked as the 47th state by population, ahead of North Dakota, Vermont, and Wyoming (and Washington, D.C.) Alaska is the least densely populated state, and one of the most sparsely populated areas in the world, at , with the next state, Wyoming, at . Alaska is the largest U.S. state by area, and the tenth wealthiest (per capita income). As of November 2014, the state's unemployment rate was 6.6%.
<h3>Race and ancestry.</h3>
According to the 2010 United States Census, Alaska had a population of 710,231. In terms of race and ethnicity, the state was 66.7% White (64.1% Non-Hispanic White), 14.8% American Indian and Alaska Native, 5.4% Asian, 3.3% Black or African American, 1.0% Native Hawaiian and Other Pacific Islander, 1.6% from Some Other Race, and 7.3% from Two or More Races. Hispanics or Latinos of any race made up 5.5% of the population.
, 50.7% of Alaska's population younger than one year of age belonged to minority groups (i.e., did not have two parents of non-Hispanic white ancestry).
<h3>Languages.</h3>
According to the 2011 American Community Survey, 83.4% of people over the age of five speak only English at home. About 3.5% speak Spanish at home. About 2.2% speak another Indo-European language at home and about 4.3% speak an Asian language at home. About 5.3% speak other languages at home.
The Alaska Native Language Center at the University of Alaska Fairbanks claims that at least 20 Alaskan native languages exist and there are also some languages with different dialects. Most of Alaska's native languages belong to either the Eskimo–Aleut or Na-Dene language families however some languages are thought to be isolates (e.g. Haida) or have not yet been classified (e.g. Tsimshianic).
A total of 5.2% of Alaskans speak one of the state's 20 indigenous languages, known locally as "native languages".
In October 2014, the governor of Alaska signed a bill declaring the state's 20 indigenous languages as official languages. This bill gave the languages symbolic recognition as official languages, though they have not been adopted for official use within the government. The 20 languages that were included in the bill are:
<h3>Religion.</h3>
According to statistics collected by the Association of Religion Data Archives from 2010, about 34% of Alaska residents were members of religious congregations. 100,960 people identified as Evangelical Protestants, 50,866 as Roman Catholic, and 32,550 as mainline Protestants. Roughly 4% are Mormon, 0.5% are Jewish, 1% are Muslim, 0.5% are Buddhist, and 0.5% are Hindu. The largest religious denominations in Alaska were the Catholic Church with 50,866 adherents, non-denominational Evangelical Protestants with 38,070 adherents, The Church of Jesus Christ of Latter-day Saints with 32,170 adherents, and the Southern Baptist Convention with 19,891 adherents. Alaska has been identified, along with Pacific Northwest states Washington and Oregon, as being the least religious states of the USA, in terms of church membership.
In 1795, the First Russian Orthodox Church was established in Kodiak. Intermarriage with Alaskan Natives helped the Russian immigrants integrate into society. As a result, an increasing number of Russian Orthodox churches gradually became established within Alaska. Alaska also has the largest Quaker population (by percentage) of any state. In 2009 there were 6,000 Jews in Alaska (for whom observance of halakha may pose special problems). Alaskan Hindus often share venues and celebrations with members of other Asian religious communities, including Sikhs and Jains.
Estimates for the number of Muslims in Alaska range from 2,000 to 5,000. The Islamic Community Center of Anchorage began efforts in the late 1990s to construct a mosque in Anchorage. They broke ground on a building in south Anchorage in 2010 and were nearing completion in late 2014. When completed, the mosque will be the first in the state and one of the northernmost mosques in the world.
<h2>Economy.</h2>
The 2007 gross state product was $44.9 billion, 45th in the nation. Its per capita personal income for 2007 was $40,042, ranking 15th in the nation. According to a 2013 study by Phoenix Marketing International, Alaska had the fifth-largest number of millionaires per capita in the United States, with a ratio of 6.75 percent. The oil and gas industry dominates the Alaskan economy, with more than 80% of the state's revenues derived from petroleum extraction. Alaska's main export product (excluding oil and natural gas) is seafood, primarily salmon, cod, Pollock and crab.
Agriculture represents a very small fraction of the Alaskan economy. Agricultural production is primarily for consumption within the state and includes nursery stock, dairy products, vegetables, and livestock. Manufacturing is limited, with most foodstuffs and general goods imported from elsewhere.
Employment is primarily in government and industries such as natural resource extraction, shipping, and transportation. Military bases are a significant component of the economy in the Fairbanks North Star, Anchorage and Kodiak Island boroughs, as well as Kodiak. Federal subsidies are also an important part of the economy, allowing the state to keep taxes low. Its industrial outputs are crude petroleum, natural gas, coal, gold, precious metals, zinc and other mining, seafood processing, timber and wood products. There is also a growing service and tourism sector. Tourists have contributed to the economy by supporting local lodging.
<h3>Energy.</h3>
Alaska has vast energy resources, although its oil reserves have been largely depleted. Major oil and gas reserves were found in the Alaska North Slope (ANS) and Cook Inlet basins, but according to the Energy Information Administration, by February 2014 Alaska had fallen to fourth place in the nation in crude oil production after Texas, North Dakota, and California. Prudhoe Bay on Alaska's North Slope is still the second highest-yielding oil field in the United States, typically producing about , although by early 2014 North Dakota's Bakken Formation was producing over . Prudhoe Bay was the largest conventional oil field ever discovered in North America, but was much smaller than Canada's enormous Athabasca oil sands field, which by 2014 was producing about of unconventional oil, and had hundreds of years of producible reserves at that rate.
The Trans-Alaska Pipeline can transport and pump up to of crude oil per day, more than any other crude oil pipeline in the United States. Additionally, substantial coal deposits are found in Alaska's bituminous, sub-bituminous, and lignite coal basins. The United States Geological Survey estimates that there are of undiscovered, technically recoverable gas from natural gas hydrates on the Alaskan North Slope. Alaska also offers some of the highest hydroelectric power potential in the country from its numerous rivers. Large swaths of the Alaskan coastline offer wind and geothermal energy potential as well.
Alaska's economy depends heavily on increasingly expensive diesel fuel for heating, transportation, electric power and light. Though wind and hydroelectric power are abundant and underdeveloped, proposals for statewide energy systems (e.g. with special low-cost electric interties) were judged uneconomical (at the time of the report, 2001) due to low (less than 50¢/gal) fuel prices, long distances and low population. The cost of a gallon of gas in urban Alaska today is usually 30–60¢ higher than the national average; prices in rural areas are generally significantly higher but vary widely depending on transportation costs, seasonal usage peaks, nearby petroleum development infrastructure and many other factors.
<h4>Permanent Fund.</h4>
The Alaska Permanent Fund is a constitutionally authorized appropriation of oil revenues, established by voters in 1976 to manage a surplus in state petroleum revenues from oil, largely in anticipation of the then recently constructed Trans-Alaska Pipeline System. The fund was originally proposed by Governor Keith Miller on the eve of the 1969 Prudhoe Bay lease sale, out of fear that the legislature would spend the entire proceeds of the sale (which amounted to $900 million) at once. It was later championed by Governor Jay Hammond and Kenai state representative Hugh Malone. It has served as an attractive political prospect ever since, diverting revenues which would normally be deposited into the general fund.
The Alaska Constitution was written so as to discourage dedicating state funds for a particular purpose. The Permanent Fund has become the rare exception to this, mostly due to the political climate of distrust existing during the time of its creation. From its initial principal of $734,000, the fund has grown to $50 billion as a result of oil royalties and capital investment programs. Most if not all the principal is invested conservatively outside Alaska. This has led to frequent calls by Alaskan politicians for the Fund to make investments within Alaska, though such a stance has never gained momentum.
Starting in 1982, dividends from the fund's annual growth have been paid out each year to eligible Alaskans, ranging from an initial $1,000 in 1982 (equal to three years' payout, as the distribution of payments was held up in a lawsuit over the distribution scheme) to $3,269 in 2008 (which included a one-time $1,200 "Resource Rebate"). Every year, the state legislature takes out 8% from the earnings, puts 3% back into the principal for inflation proofing, and the remaining 5% is distributed to all qualifying Alaskans. To qualify for the Permanent Fund Dividend, one must have lived in the state for a minimum of 12 months, maintain constant residency subject to allowable absences, and not be subject to court judgments or criminal convictions which fall under various disqualifying classifications or may subject the payment amount to civil garnishment.
The Permanent Fund is often considered to be one of the leading examples of a "Basic Income" policy in the world.
<h3>Cost of living.</h3>
The cost of goods in Alaska has long been higher than in the contiguous 48 states. Federal government employees, particularly United States Postal Service (USPS) workers and active-duty military members, receive a Cost of Living Allowance usually set at 25% of base pay because, while the cost of living has gone down, it is still one of the highest in the country.
Rural Alaska suffers from extremely high prices for food and consumer goods compared to the rest of the country, due to the relatively limited transportation infrastructure.
<h3>Agriculture and fishing.</h3>
Due to the northern climate and short growing season, relatively little farming occurs in Alaska. Most farms are in either the Matanuska Valley, about northeast of Anchorage, or on the Kenai Peninsula, about southwest of Anchorage. The short 100-day growing season limits the crops that can be grown, but the long sunny summer days make for productive growing seasons. The primary crops are potatoes, carrots, lettuce, and cabbage.
The Tanana Valley is another notable agricultural locus, especially the Delta Junction area, about southeast of Fairbanks, with a sizable concentration of farms growing agronomic crops; these farms mostly lie north and east of Fort Greely. This area was largely set aside and developed under a state program spearheaded by Hammond during his second term as governor. Delta-area crops consist predominately of barley and hay. West of Fairbanks lies another concentration of small farms catering to restaurants, the hotel and tourist industry, and community-supported agriculture.
Alaskan agriculture has experienced a surge in growth of market gardeners, small farms and farmers' markets in recent years, with the highest percentage increase (46%) in the nation in growth in farmers' markets in 2011, compared to 17% nationwide. The peony industry has also taken off, as the growing season allows farmers to harvest during a gap in supply elsewhere in the world, thereby filling a niche in the flower market.
Alaska, with no counties, lacks county fairs. However, a small assortment of state and local fairs (with the Alaska State Fair in Palmer the largest), are held mostly in the late summer. The fairs are mostly located in communities with historic or current agricultural activity, and feature local farmers exhibiting produce in addition to more high-profile commercial activities such as carnival rides, concerts and food. "Alaska Grown" is used as an agricultural slogan.
Alaska has an abundance of seafood, with the primary fisheries in the Bering Sea and the North Pacific. Seafood is one of the few food items that is often cheaper within the state than outside it. Many Alaskans take advantage of salmon seasons to harvest portions of their household diet while fishing for subsistence, as well as sport. This includes fish taken by hook, net or wheel.
Hunting for subsistence, primarily caribou, moose, and Dall sheep is still common in the state, particularly in remote Bush communities. An example of a traditional native food is Akutaq, the Eskimo ice cream, which can consist of reindeer fat, seal oil, dried fish meat and local berries.
Alaska's reindeer herding is concentrated on Seward Peninsula, where wild caribou can be prevented from mingling and migrating with the domesticated reindeer.
Most food in Alaska is transported into the state from "Outside", and shipping costs make food in the cities relatively expensive. In rural areas, subsistence hunting and gathering is an essential activity because imported food is prohibitively expensive. Though most small towns and villages in Alaska lie along the coastline, the cost of importing food to remote villages can be high, because of the terrain and difficult road conditions, which change dramatically, due to varying climate and precipitation changes. The cost of transport can reach as high as 50¢ per pound ($1.10/kg) or more in some remote areas, during the most difficult times, if these locations can be reached at all during such inclement weather and terrain conditions. The cost of delivering a of milk is about $3.50 in many villages where per capita income can be $20,000 or less. Fuel cost per gallon is routinely 20–30¢ higher than the continental United States average, with only Hawaii having higher prices.
<h2>Transportation.</h2>
<h3>Roads.</h3>
Alaska has few road connections compared to the rest of the U.S. The state's road system covers a relatively small area of the state, linking the central population centers and the Alaska Highway, the principal route out of the state through Canada. The state capital, Juneau, is not accessible by road, only a car ferry, which has spurred several debates over the decades about moving the capital to a city on the road system, or building a road connection from Haines. The western part of Alaska has no road system connecting the communities with the rest of Alaska.
One unique feature of the Alaska Highway system is the Anton Anderson Memorial Tunnel, an active Alaska Railroad tunnel recently upgraded to provide a paved roadway link with the isolated community of Whittier on Prince William Sound to the Seward Highway about southeast of Anchorage at Portage. At , the tunnel was the longest road tunnel in North America until 2007. The tunnel is the longest combination road and rail tunnel in North America.
<h3>Rail.</h3>
Built around 1915, the Alaska Railroad (ARR) played a key role in the development of Alaska through the 20th century. It links north Pacific shipping through providing critical infrastructure with tracks that run from Seward to Interior Alaska by way of South Central Alaska, passing through Anchorage, Eklutna, Wasilla, Talkeetna, Denali, and Fairbanks, with spurs to Whittier, Palmer and North Pole. The cities, towns, villages, and region served by ARR tracks are known statewide as "The Railbelt". In recent years, the ever-improving paved highway system began to eclipse the railroad's importance in Alaska's economy.
The railroad played a vital role in Alaska's development, moving freight into Alaska while transporting natural resources southward (i.e., coal from the Usibelli coal mine near Healy to Seward and gravel from the Matanuska Valley to Anchorage). It is well known for its summertime tour passenger service.
The Alaska Railroad was one of the last railroads in North America to use cabooses in regular service and still uses them on some gravel trains. It continues to offer one of the last flag stop routes in the country. A stretch of about of track along an area north of Talkeetna remains inaccessible by road; the railroad provides the only transportation to rural homes and cabins in the area. Until construction of the Parks Highway in the 1970s, the railroad provided the only land access to most of the region along its entire route.
In northern Southeast Alaska, the White Pass and Yukon Route also partly runs through the state from Skagway northwards into Canada (British Columbia and Yukon Territory), crossing the border at White Pass Summit. This line is now mainly used by tourists, often arriving by cruise liner at Skagway. It was featured in the 1983 BBC television series "Great Little Railways."
The Alaska Rail network is not connected to Outside. In 2000, the U.S. Congress authorized $6 million to study the feasibility of a rail link between Alaska, Canada, and the lower 48.
Alaska Rail Marine provides car float service between Whittier and Seattle.
<h3>Marine transport.</h3>
Many cities, towns and villages in the state do not have road or highway access; the only modes of access involve travel by air, river, or the sea.
Alaska's well-developed state-owned ferry system (known as the Alaska Marine Highway) serves the cities of southeast, the Gulf Coast and the Alaska Peninsula. The ferries transport vehicles as well as passengers. The system also operates a ferry service from Bellingham, Washington and Prince Rupert, British Columbia in Canada through the Inside Passage to Skagway. The Inter-Island Ferry Authority also serves as an important marine link for many communities in the Prince of Wales Island region of Southeast and works in concert with the Alaska Marine Highway.
In recent years, cruise lines have created a summertime tourism market, mainly connecting the Pacific Northwest to Southeast Alaska and, to a lesser degree, towns along Alaska's gulf coast. The population of Ketchikan may rise by over 10,000 people on many days during the summer, as up to four large cruise ships at a time can dock, debarking thousands of passengers.
<h3>Air transport.</h3>
Cities not served by road, sea, or river can be reached only by air, foot, dogsled, or snowmachine, accounting for Alaska's extremely well developed bush air services—an Alaskan novelty. Anchorage and, to a lesser extent Fairbanks, is served by many major airlines. Because of limited highway access, air travel remains the most efficient form of transportation in and out of the state. Anchorage recently completed extensive remodeling and construction at Ted Stevens Anchorage International Airport to help accommodate the upsurge in tourism (in 2012-2013, Alaska received almost 2 million visitors).
Regular flights to most villages and towns within the state that are commercially viable are challenging to provide, so they are heavily subsidized by the federal government through the Essential Air Service program. Alaska Airlines is the only major airline offering in-state travel with jet service (sometimes in combination cargo and passenger Boeing 737-400s) from Anchorage and Fairbanks to regional hubs like Bethel, Nome, Kotzebue, Dillingham, Kodiak, and other larger communities as well as to major Southeast and Alaska Peninsula communities.
The bulk of remaining commercial flight offerings come from small regional commuter airlines such as Ravn Alaska, PenAir, and Frontier Flying Service. The smallest towns and villages must rely on scheduled or chartered bush flying services using general aviation aircraft such as the Cessna Caravan, the most popular aircraft in use in the state. Much of this service can be attributed to the Alaska bypass mail program which subsidizes bulk mail delivery to Alaskan rural communities. The program requires 70% of that subsidy to go to carriers who offer passenger service to the communities.
Many communities have small air taxi services. These operations originated from the demand for customized transport to remote areas. Perhaps the most quintessentially Alaskan plane is the bush seaplane. The world's busiest seaplane base is Lake Hood, located next to Ted Stevens Anchorage International Airport, where flights bound for remote villages without an airstrip carry passengers, cargo, and many items from stores and warehouse clubs. In 2006 Alaska had the highest number of pilots per capita of any U.S. state.
<h3>Other transport.</h3>
Another Alaskan transportation method is the dogsled. In modern times (that is, any time after the mid-late 1920s), dog mushing is more of a sport than a true means of transportation. Various races are held around the state, but the best known is the Iditarod Trail Sled Dog Race, a trail from Anchorage to Nome (although the distance varies from year to year, the official distance is set at ). The race commemorates the famous 1925 serum run to Nome in which mushers and dogs like Togo and Balto took much-needed medicine to the diphtheria-stricken community of Nome when all other means of transportation had failed. Mushers from all over the world come to Anchorage each March to compete for cash, prizes, and prestige. The "Serum Run" is another sled dog race that more accurately follows the route of the famous 1925 relay, leaving from the community of Nenana (southwest of Fairbanks) to Nome.
In areas not served by road or rail, primary transportation in summer is by all-terrain vehicle and in winter by snowmobile or "snow machine," as it is commonly referred to in Alaska.
<h3>Data transport.</h3>
Alaska's internet and other data transport systems are provided largely through the two major telecommunications companies: GCI and Alaska Communications. GCI owns and operates what it calls the Alaska United Fiber Optic system and as of late 2011 Alaska Communications advertised that it has "two fiber optic paths to the lower 48 and two more across Alaska. In January 2011, it was reported that a $1 billion project to run connect Asia and rural Alaska was being planned, aided in part by $350 million in stimulus from the federal government.
<h2>Law and government.</h2>
<h3>State government.</h3>
Like all other U.S. states, Alaska is governed as a republic, with three branches of government: an executive branch consisting of the Governor of Alaska and the other independently elected constitutional officers; a legislative branch consisting of the Alaska House of Representatives and Alaska Senate; and a judicial branch consisting of the Alaska Supreme Court and lower courts.
The state of Alaska employs approximately 16,000 people statewide.
The Alaska Legislature consists of a 40-member House of Representatives and a 20-member Senate. Senators serve four-year terms and House members two. The Governor of Alaska serves four-year terms. The lieutenant governor runs separately from the governor in the primaries, but during the general election, the nominee for governor and nominee for lieutenant governor run together on the same ticket.
Alaska's court system has four levels: the Alaska Supreme Court, the Alaska Court of Appeals, the superior courts and the district courts. The superior and district courts are trial courts. Superior courts are courts of general jurisdiction, while district courts only hear certain types of cases, including misdemeanor criminal cases and civil cases valued up to $100,000.
The Supreme Court and the Court of Appeals are appellate courts. The Court of Appeals is required to hear appeals from certain lower-court decisions, including those regarding criminal prosecutions, juvenile delinquency, and habeas corpus. The Supreme Court hears civil appeals and may in its discretion hear criminal appeals.
<h3>State politics.</h3>
Although in its early years of statehood Alaska was a Democratic state, since the early 1970s it has been characterized as Republican-leaning. Local political communities have often worked on issues related to land use development, fishing, tourism, and individual rights. Alaska Natives, while organized in and around their communities, have been active within the Native corporations. These have been given ownership over large tracts of land, which require stewardship.
Alaska was formerly the only state in which possession of one ounce or less of marijuana in one's home was completely legal under state law, though the federal law remains in force.
The state has an independence movement favoring a vote on secession from the United States, with the Alaskan Independence Party.
Six Republicans and four Democrats have served as governor of Alaska. In addition, Republican Governor Wally Hickel was elected to the office for a second term in 1990 after leaving the Republican party and briefly joining the Alaskan Independence Party ticket just long enough to be reelected. He subsequently officially rejoined the Republican party in 1994.
Alaska's voter initiative making marijuana legal takes effect 24 February 2015, placing Alaska alongside Colorado and Washington as the three U.S. states where recreational marijuana is legal. The new law means people over age 21 can consume small amounts of pot — if they can find it. Commercial sales await implementation of Alaska Measure 2 (2014).
<h3>Taxes.</h3>
To finance state government operations, Alaska depends primarily on petroleum revenues and federal subsidies. This allows it to have the lowest individual tax burden in the United States. It is one of five states with no state sales tax, one of seven states that do not levy an individual income tax, and one of the two states that has neither. The Department of Revenue Tax Division reports regularly on the state's revenue sources. The Department also issues an annual summary of its operations, including new state laws that directly affect the tax division.
While Alaska has no state sales tax, 89 municipalities collect a local sales tax, from 1.0–7.5%, typically 3–5%. Other local taxes levied include raw fish taxes, hotel, motel, and bed-and-breakfast 'bed' taxes, severance taxes, liquor and tobacco taxes, gaming (pull tabs) taxes, tire taxes and fuel transfer taxes. A part of the revenue collected from certain state taxes and license fees (such as petroleum, aviation motor fuel, telephone cooperative) is shared with municipalities in Alaska.
Fairbanks has one of the highest property taxes in the state as no sales or income taxes are assessed in the Fairbanks North Star Borough (FNSB). A sales tax for the FNSB has been voted on many times, but has yet to be approved, leading law makers to increase taxes dramatically on goods such as liquor and tobacco.
In 2014 the Tax Foundation ranked Alaska as having the fourth most "business friendly" tax policy, behind only Wyoming, South Dakota, and Nevada.
<h3>Federal politics.</h3>
Alaska regularly supports Republicans in presidential elections and has done so since statehood. Republicans have won the state's electoral college votes in all but one election that it has participated in (1964). No state has voted for a Democratic presidential candidate fewer times. Alaska was carried by Democratic nominee Lyndon B. Johnson during his landslide election in 1964, while the 1960 and 1968 elections were close. Since 1972, however, Republicans have carried the state by large margins. In 2008, Republican John McCain defeated Democrat Barack Obama in Alaska, 59.49% to 37.83%. McCain's running mate was Sarah Palin, the state's governor and the first Alaskan on a major party ticket. Obama lost Alaska again in 2012, but he captured 40% of the state's vote in that election, making him the first Democrat to do so since 1968.
The Alaska Bush, central Juneau, midtown and downtown Anchorage, and the areas surrounding the University of Alaska Fairbanks campus and Ester have been strongholds of the Democratic Party. The Matanuska-Susitna Borough, the majority of Fairbanks (including North Pole and the military base), and South Anchorage typically have the strongest Republican showing. , well over half of all registered voters have chosen "Non-Partisan" or "Undeclared" as their affiliation, despite recent attempts to close primaries to unaffiliated voters.
Because of its population relative to other U.S. states, Alaska has only one member in the U.S. House of Representatives. This seat is held by Republican Don Young, who was re-elected to his 21st consecutive term in 2012. Alaska's At-large congressional district is one of the largest parliamentary constituencies in the world.
In 2008, Governor Sarah Palin became the first Republican woman to run on a national ticket when she became John McCain's running mate. She continued to be a prominent national figure even after resigning from the governor's job in July 2009.
Alaska's United States Senators belong to Class 2 and Class 3. In 2008, Democrat Mark Begich, mayor of Anchorage, defeated long-time Republican senator Ted Stevens. Stevens had been convicted on seven felony counts of failing to report gifts on Senate financial discloser forms one week before the election. The conviction was set aside in April 2009 after evidence of prosecutorial misconduct emerged.
Republican Frank Murkowski held the state's other senatorial position. After being elected governor in 2002, he resigned from the Senate and appointed his daughter, State Representative Lisa Murkowski as his successor. She won full six-year terms in 2004 and 2010.
<h2>Cities, towns and boroughs.</h2>
Alaska is not divided into counties, as most of the other U.S. states, but it is divided into "boroughs". Many of the more densely populated parts of the state are part of Alaska's 16 boroughs, which function somewhat similarly to counties in other states. However, unlike county-equivalents in the other 49 states, the boroughs do not cover the entire land area of the state. The area not part of any borough is referred to as the Unorganized Borough.
The Unorganized Borough has no government of its own, but the U.S. Census Bureau in cooperation with the state divided the Unorganized Borough into 11 census areas solely for the purposes of statistical analysis and presentation. A "recording district" is a mechanism for administration of the public record in Alaska. The state is divided into 34 recording districts which are centrally administered under a State Recorder. All recording districts use the same acceptance criteria, fee schedule, etc., for accepting documents into the public record.
Whereas many U.S. states use a three-tiered system of decentralization—state/county/township—most of Alaska uses only two tiers—state/borough. Owing to the low population density, most of the land is located in the Unorganized Borough. As the name implies, it has no intermediate borough government but is administered directly by the state government. In 2000, 57.71% of Alaska's area has this status, with 13.05% of the population.
Anchorage merged the city government with the Greater Anchorage Area Borough in 1975 to form the Municipality of Anchorage, containing the city proper and the communities of Eagle River, Chugiak, Peters Creek, Girdwood, Bird, and Indian. Fairbanks has a separate borough (the Fairbanks North Star Borough) and municipality (the City of Fairbanks).
The state's most populous city is Anchorage, home to 278,700 people in 2006, 225,744 of whom live in the urbanized area. The richest location in Alaska by per capita income is Halibut Cove ($89,895). Yakutat City, Sitka, Juneau, and Anchorage are the four largest cities in the U.S. by area.
<h3>Cities and census-designated places (by population).</h3>
As reflected in the 2010 United States Census, Alaska has a total of 355 incorporated cities and census-designated places (CDPs). The tally of cities includes four unified municipalities, essentially the equivalent of a consolidated city–county. The majority of these communities are located in the rural expanse of Alaska known as "The Bush" and are unconnected to the contiguous North American road network. The table at the bottom of this section lists the 100 largest cities and census-designated places in Alaska, in population order.
Of Alaska's 2010 Census population figure of 710,231, 20,429 people, or 2.88% of the population, did not live in an incorporated city or census-designated place. Approximately three-quarters of that figure were people who live in urban and suburban neighborhoods on the outskirts of the city limits of Ketchikan, Kodiak, Palmer and Wasilla. CDPs have not been established for these areas by the United States Census Bureau, except that seven CDPs were established for the Ketchikan-area neighborhoods in the 1980 Census (Clover Pass, Herring Cove, Ketchikan East, Mountain Point, North Tongass Highway, Pennock Island and Saxman East), but have not been used since. The remaining population was scattered throughout Alaska, both within organized boroughs and in the Unorganized Borough, in largely remote areas.
<h2>Education.</h2>
The Alaska Department of Education and Early Development administers many school districts in Alaska. In addition, the state operates a boarding school, Mt. Edgecumbe High School in Sitka, and provides partial funding for other boarding schools, including Nenana Student Living Center in Nenana and The Galena Interior Learning Academy in Galena.
There are more than a dozen colleges and universities in Alaska. Accredited universities in Alaska include the University of Alaska Anchorage, University of Alaska Fairbanks, University of Alaska Southeast, and Alaska Pacific University. Alaska is the only state that has no institutions that are part of the NCAA Division I.
The Alaska Department of Labor and Workforce Development operates AVTEC, Alaska's Institute of Technology. Campuses in Seward and Anchorage offer 1 week to 11-month training programs in areas as diverse as Information Technology, Welding, Nursing, and Mechanics.
Alaska has had a problem with a "brain drain". Many of its young people, including most of the highest academic achievers, leave the state after high school graduation and do not return. , Alaska did not have a law school or medical school. The University of Alaska has attempted to combat this by offering partial four-year scholarships to the top 10% of Alaska high school graduates, via the Alaska Scholars Program.
<h2>Public health and public safety.</h2>
The Alaska State Troopers are Alaska's statewide police force. They have a long and storied history, but were not an official organization until 1941. Before the force was officially organized, law enforcement in Alaska was handled by various federal agencies. Larger towns usually have their own local police and some villages rely on "Public Safety Officers" who have police training but do not carry firearms. In much of the state, the troopers serve as the only police force available. In addition to enforcing traffic and criminal law, wildlife Troopers enforce hunting and fishing regulations. Due to the varied terrain and wide scope of the Troopers' duties, they employ a wide variety of land, air, and water patrol vehicles.
Many rural communities in Alaska are considered "dry," having outlawed the importation of alcoholic beverages. Suicide rates for rural residents are higher than urban.
Domestic abuse and other violent crimes are also at high levels in the state; this is in part linked to alcohol abuse. Alaska has the highest rate of sexual assault in the nation, especially in rural areas. The average age of sexually assaulted victims is 16 years old. In four out of five cases, the suspects were relatives, friends or acquaintances.
<h2>Culture.</h2>
Some of Alaska's popular annual events are the Iditarod Trail Sled Dog Race that starts in Anchorage and ends in Nome, World Ice Art Championships in Fairbanks, the Blueberry Festival and Alaska Hummingbird Festival in Ketchikan, the Sitka Whale Fest, and the Stikine River Garnet Fest in Wrangell. The Stikine River attracts the largest springtime concentration of American bald eagles in the world.
The Alaska Native Heritage Center celebrates the rich heritage of Alaska's 11 cultural groups. Their purpose is to encourage cross-cultural exchanges among all people and enhance self-esteem among Native people. The Alaska Native Arts Foundation promotes and markets Native art from all regions and cultures in the State, using the internet.
<h3>Music.</h3>
Influences on music in Alaska include the traditional music of Alaska Natives as well as folk music brought by later immigrants from Russia and Europe. Prominent musicians from Alaska include singer Jewel, traditional Aleut flautist Mary Youngblood, folk singer-songwriter Libby Roderick, Christian music singer/songwriter Lincoln Brewster, metal/post hardcore band 36 Crazyfists and the groups Pamyua and Portugal. The Man.
There are many established music festivals in Alaska, including the Alaska Folk Festival, the Fairbanks Summer Arts Festival, the Anchorage Folk Festival, the Athabascan Old-Time Fiddling Festival, the Sitka Jazz Festival, and the Sitka Summer Music Festival. The most prominent orchestra in Alaska is the Anchorage Symphony Orchestra, though the Fairbanks Symphony Orchestra and Juneau Symphony are also notable. The Anchorage Opera is currently the state's only professional opera company, though there are several volunteer and semi-professional organizations in the state as well.
The official state song of Alaska is "Alaska's Flag", which was adopted in 1955; it celebrates the flag of Alaska.
<h3>Alaska in film and on television.</h3>
Alaska's first independent picture entirely made in Alaska was "The Chechahcos", produced by Alaskan businessman Austin E. Lathrop and filmed in and around Anchorage. Released in 1924 by the Alaska Moving Picture Corporation, it was the only film the company made.
One of the most prominent movies filmed in Alaska is MGM's "Eskimo/Mala The Magnificent", starring Alaska Native Ray Mala. In 1932 an expedition set out from MGM's studios in Hollywood to Alaska to film what was then billed as "The Biggest Picture Ever Made." Upon arriving in Alaska, they set up "Camp Hollywood" in Northwest Alaska, where they lived during the duration of the filming. Louis B. Mayer spared no expense in spite of the remote location, going so far as to hire the chef from the Hotel Roosevelt in Hollywood to prepare meals.
When "Eskimo" premiered at the Astor Theatre in New York City, the studio received the largest amount of feedback in its history to that point. "Eskimo" was critically acclaimed and released worldwide; as a result, Mala became an international movie star. "Eskimo" won the first Oscar for Best Film Editing at the Academy Awards, and showcased and preserved aspects of Inupiat culture on film.
The 1983 Disney movie "Never Cry Wolf" was at least partially shot in Alaska. The 1991 film "White Fang", based on Jack London's novel and starring Ethan Hawke, was filmed in and around Haines. Steven Seagal's 1994 "On Deadly Ground", starring Michael Caine, was filmed in part at the Worthington Glacier near Valdez. The 1999 John Sayles film "Limbo", starring David Strathairn, Mary Elizabeth Mastrantonio, and Kris Kristofferson, was filmed in Juneau.
The psychological thriller "Insomnia", starring Al Pacino and Robin Williams, was shot in Canada, but was set in Alaska. The 2007 film directed by Sean Penn, "Into The Wild", was partially filmed and set in Alaska. The film, which is based on the novel of the same name, follows the adventures of Christopher McCandless, who died in a remote abandoned bus along the Stampede Trail west of Healy in 1992.
Many films and television shows set in Alaska are not filmed there; for example, "Northern Exposure", set in the fictional town of Cicely, Alaska, was filmed in Roslyn, Washington. The 2007 horror feature "30 Days of Night" is set in Barrow, but was filmed in New Zealand.
Many reality television shows are filmed in Alaska. In 2011 the "Anchorage Daily News" found ten set in the state.

</doc>
<doc id="627" url="https://en.wikipedia.org/wiki?curid=627" title="Agriculture">
Agriculture

Agriculture is the cultivation of animals, plants and fungi for food, fiber, biofuel, medicinal plants and other products used to sustain and enhance human life. Agriculture was the key development in the rise of sedentary human civilization, whereby farming of domesticated species created food surpluses that nurtured the development of civilization. The study of agriculture is known as agricultural science. The history of agriculture dates back thousands of years, and its development has been driven and defined by greatly different climates, cultures, and technologies. Industrial agriculture based on large-scale monoculture farming has become the dominant agricultural methodology.
Modern agronomy, plant breeding, agrochemicals such as pesticides and fertilizers, and technological developments have in many cases sharply increased yields from cultivation, but at the same time have caused widespread ecological damage and negative human health effects. Selective breeding and modern practices in animal husbandry have similarly increased the output of meat, but have raised concerns about animal welfare and the health effects of the antibiotics, growth hormones, and other chemicals commonly used in industrial meat production. Genetically modified organisms are an increasing component of agriculture, although they are banned in several countries. Agricultural food production and water management are increasingly becoming global issues that are fostering debate on a number of fronts. Significant degradation of land and water resources, including the depletion of aquifers, has been observed in recent decades, and the effects of global warming on agriculture and of agriculture on global warming are still not fully understood.
The major agricultural products can be broadly grouped into foods, fibers, fuels, and raw materials. Specific foods include cereals (grains), vegetables, fruits, oils, meats and spices. Fibers include cotton, wool, hemp, silk and flax. Raw materials include lumber and bamboo. Other useful materials are also produced by plants, such as resins, dyes, drugs, perfumes, biofuels and ornamental products such as cut flowers and nursery plants. Over one third of the world's workers are employed in agriculture, second only to the service sector, although the percentages of agricultural workers in developed countries has decreased significantly over the past several centuries.
<h2>Etymology and terminology.</h2>
The word "agriculture" is a late Middle English adaptation of Latin "agricultūra", from "ager", "field", and "cultūra", "cultivation" or "growing". Agriculture usually refers to human activities, although it is also observed in certain species of ant, termite and ambrosia beetle. To practice agriculture means to use natural resources to "produce commodities which maintain life, including food, fiber, forest products, horticultural crops, and their related services." This definition includes arable farming or agronomy, and horticulture, all terms for the growing of plants, animal husbandry and forestry. A distinction is sometimes made between forestry and agriculture, based on the former's longer management rotations, extensive versus intensive management practices and development mainly by nature, rather than by man. Even then, it is acknowledged that there is a large amount of knowledge transfer and overlap between silviculture (the management of forests) and agriculture. In traditional farming, the two are often combined even on small landholdings, leading to the term agroforestry.
<h2>History.</h2>
Agriculture began independently in different parts of the globe, and included a diverse range of taxa. At least 11 separate regions of the Old and New World were involved as independent centers of origin. Wild grains were collected and eaten from at least 105,000 years ago. Pigs were domesticated in Mesopotamia around 15,000 years ago. Rice was domesticated in China between 13,500 and 8,200 years ago, followed by mung, soy and azuki beans. Sheep were domesticated in Mesopotamia between 13,000 and 11,000 years ago. From around 11,500 years ago, the eight Neolithic founder crops, emmer and einkorn wheat, hulled barley, peas, lentils, bitter vetch, chick peas and flax were cultivated in the Levant. Cattle were domesticated from the wild aurochs in the areas of modern Turkey and Pakistan some 10,500 years ago. In the Andes of South America, the potato was domesticated between 10,000 and 7,000 years ago, along with beans, coca, llamas, alpacas, and guinea pigs. Sugarcane and some root vegetables were domesticated in New Guinea around 9,000 years ago. Sorghum was domesticated in the Sahel region of Africa by 7,000 years ago. Cotton was domesticated in Peru by 5,600 years ago, and was independently domesticated in Eurasia at an unknown time. In Mesoamerica, wild teosinte was domesticated to maize by 6,000 years ago. 
In the Middle Ages, both in the Islamic world and in Europe, agriculture was transformed with improved techniques and the diffusion of crop plants, including the introduction of sugar, rice, cotton and fruit trees such as the orange to Europe by way of Al-Andalus. After 1492, the Columbian exchange brought New World crops such as maize, potatoes, sweet potatoes and manioc to Europe, and Old World crops such as wheat, barley, rice and turnips, and livestock including horses, cattle, sheep and goats to the Americas.
Irrigation, crop rotation, and fertilizers were introduced soon after the Neolithic Revolution and developed much further in the past 200 years, starting with the British Agricultural Revolution. Since 1900, agriculture in the developed nations, and to a lesser extent in the developing world, has seen large rises in productivity as human labor has been replaced by mechanization, and assisted by synthetic fertilizers, pesticides, and selective breeding. The Haber-Bosch method allowed the synthesis of ammonium nitrate fertilizer on an industrial scale, greatly increasing crop yields. Modern agriculture has raised political issues including water pollution, biofuels, genetically modified organisms, tariffs and farm subsidies, leading to alternative approaches such as the organic movement.
<h2>Agriculture and civilization.</h2>
Civilization was the product of the Agricultural Neolithic Revolution. In the course of history, civilization coincided in space with fertile areas such as The Fertile Crescent, and states formed mainly in circumscribed agricultural lands. The Great Wall of China and the Roman empire's "limes" (borders) demarcated the same northern frontier of cereal agriculture. This cereal belt fed the civilizations formed in the Axial Age and connected by the Silk Road.
Ancient Egyptians, whose agriculture depended exclusively on the Nile, deified the river, worshipped, and exalted it in a great hymn. The Chinese imperial court issued numerous edicts, stating: "Agriculture is the foundation of this Empire." Egyptian, Mesopotamian, Chinese, and Inca Emperors themselves plowed ceremonial fields in order to show personal example to everyone.
Ancient strategists, Chinese Guan Zhong and Shang Yang and Indian Kautilya, drew doctrines linking agriculture with military power. Agriculture defined the limits on how large and for how long an army could be mobilized. Shang Yang called agriculture and war the "One". In the vast human pantheon of agricultural deities there are several deities who combined the functions of agriculture and war.
As the Neolithic Agricultural Revolution produced civilization, the modern Agricultural Revolution, begun in Britain (British Agricultural Revolution), made possible the Industrial civilization. The first precondition for industry was greater yields by less manpower, resulting in greater percentage of manpower available for non-agricultural sectors.
<h2>Types of agriculture.</h2>
Pastoralism involves managing domesticated animals. In nomadic pastoralism, herds of livestock are moved from place to place in search of pasture, fodder, and water. This type of farming is practised in arid and semi-arid regions of Sahara, Central Asia and some parts of India.
In shifting cultivation, a small area of a forest is cleared by cutting down all the trees and the area is burned. The land is then used for growing crops for several years. When the soil becomes less fertile, the area is then abandoned. Another patch of land is selected and the process is repeated. This type of farming is practiced mainly in areas with abundant rainfall where the forest regenerates quickly. This practice is used in Northeast India, Southeast Asia, and the Amazon Basin.
Subsistence farming is practiced to satisfy family or local needs alone, with little left over for transport elsewhere. It is intensively practiced in Monsoon Asia and South-East Asia.
In intensive farming, the crops are cultivated for commercial purpose i.e., for selling. The main motive of the farmer is to make profit, with a low fallow ratio and a high use of inputs. This type of farming is mainly practiced in highly developed countries.
<h2>Contemporary agriculture.</h2>
In the past century, agriculture has been characterized by increased productivity, the substitution of synthetic fertilizers and pesticides for labor, water pollution, and farm subsidies. In recent years there has been a backlash against the external environmental effects of conventional agriculture, resulting in the organic and sustainable agriculture movements. One of the major forces behind this movement has been the European Union, which first certified organic food in 1991 and began reform of its Common Agricultural Policy (CAP) in 2005 to phase out commodity-linked farm subsidies, also known as decoupling. The growth of organic farming has renewed research in alternative technologies such as integrated pest management and selective breeding. Recent mainstream technological developments include genetically modified food.
In 2007, higher incentives for farmers to grow non-food biofuel crops combined with other factors, such as over development of former farm lands, rising transportation costs, climate change, growing consumer demand in China and India, and population growth, caused food shortages in Asia, the Middle East, Africa, and Mexico, as well as rising food prices around the globe. As of December 2007, 37 countries faced food crises, and 20 had imposed some sort of food-price controls. Some of these shortages resulted in food riots and even deadly stampedes. The International Fund for Agricultural Development posits that an increase in smallholder agriculture may be part of the solution to concerns about food prices and overall food security. They in part base this on the experience of Vietnam, which went from a food importer to large food exporter and saw a significant drop in poverty, due mainly to the development of smallholder agriculture in the country.
Disease and land degradation are two of the major concerns in agriculture today. For example, an epidemic of stem rust on wheat caused by the Ug99 lineage is currently spreading across Africa and into Asia and is causing major concerns due to crop losses of 70% or more under some conditions. Approximately 40% of the world's agricultural land is seriously degraded. In Africa, if current trends of soil degradation continue, the continent might be able to feed just 25% of its population by 2025, according to United Nations University's Ghana-based Institute for Natural Resources in Africa.
Agrarian structure is a long-term structure in the Braudelian understanding of the concept. On a larger scale the agrarian structure is more dependent on the regional, social, cultural and historical factors than on the state’s undertaken activities. Like in Poland, where despite running an intense agrarian policy for many years, the agrarian structure in 2002 has much in common with that found in 1921 soon after the partitions period.
In 2009, the agricultural output of China was the largest in the world, followed by the European Union, India and the United States, according to the International Monetary Fund ("see below"). Economists measure the total factor productivity of agriculture and by this measure agriculture in the United States is roughly 1.7 times more productive than it was in 1948.
<h2>Workforce.</h2>
, the International Labour Organization states that approximately one billion people, or over 1/3 of the available work force, are employed in the global agricultural sector. Agriculture constitutes approximately 70% of the global employment of children, and in many countries employs the largest percentage of women of any industry. The service sector only overtook the agricultural sector as the largest global employer in 2007. Between 1997 and 2007, the percentage of people employed in agriculture fell by over four percentage points, a trend that is expected to continue. The number of people employed in agriculture varies widely on a per-country basis, ranging from less than 2% in countries like the US and Canada to over 80% in many African nations. In developed countries, these figures are significantly lower than in previous centuries. During the 16th century in Europe, for example, between 55 and 75 percent of the population was engaged in agriculture, depending on the country. By the 19th century in Europe, this had dropped to between 35 and 65 percent. In the same countries today, the figure is less than 10%.
<h3>Safety.</h3>
Agriculture, specifically farming, remains a hazardous industry, and farmers worldwide remain at high risk of work-related injuries, lung disease, noise-induced hearing loss, skin diseases, as well as certain cancers related to chemical use and prolonged sun exposure. On industrialized farms, injuries frequently involve the use of agricultural machinery, and a common cause of fatal agricultural injuries in developed countries is tractor rollovers. Pesticides and other chemicals used in farming can also be hazardous to worker health, and workers exposed to pesticides may experience illness or have children with birth defects. As an industry in which families commonly share in work and live on the farm itself, entire families can be at risk for injuries, illness, and death. Common causes of fatal injuries among young farm workers include drowning, machinery and motor vehicle-related accidents.
The International Labour Organization considers agriculture "one of the most hazardous of all economic sectors." It estimates that the annual work-related death toll among agricultural employees is at least 170,000, twice the average rate of other jobs. In addition, incidences of death, injury and illness related to agricultural activities often go unreported. The organization has developed the Safety and Health in Agriculture Convention, 2001, which covers the range of risks in the agriculture occupation, the prevention of these risks and the role that individuals and organizations engaged in agriculture should play.
<h2>Agricultural production systems.</h2>
<h3>Crop cultivation systems.</h3>
Cropping systems vary among farms depending on the available resources and constraints; geography and climate of the farm; government policy; economic, social and political pressures; and the philosophy and culture of the farmer.
Shifting cultivation (or slash and burn) is a system in which forests are burnt, releasing nutrients to support cultivation of annual and then perennial crops for a period of several years. Then the plot is left fallow to regrow forest, and the farmer moves to a new plot, returning after many more years (10 – 20). This fallow period is shortened if population density grows, requiring the input of nutrients (fertilizer or manure) and some manual pest control. Annual cultivation is the next phase of intensity in which there is no fallow period. This requires even greater nutrient and pest control inputs.
Further industrialization led to the use of monocultures, when one cultivar is planted on a large acreage. Because of the low biodiversity, nutrient use is uniform and pests tend to build up, necessitating the greater use of pesticides and fertilizers. Multiple cropping, in which several crops are grown sequentially in one year, and intercropping, when several crops are grown at the same time, are other kinds of annual cropping systems known as polycultures.
In subtropical and arid environments, the timing and extent of agriculture may be limited by rainfall, either not allowing multiple annual crops in a year, or requiring irrigation. In all of these environments perennial crops are grown (coffee, chocolate) and systems are practiced such as agroforestry. In temperate environments, where ecosystems were predominantly grassland or prairie, highly productive annual farming is the dominant agricultural system.
<h4>Crop statistics.</h4>
Important categories of crops include cereals and pseudocereals, pulses (legumes), forage, and fruits and vegetables. Specific crops are cultivated in distinct growing regions throughout the world. In millions of metric tons, based on FAO estimate.
<h3>Livestock production systems.</h3>
Animals, including horses, mules, oxen, water buffalo, camels, llamas, alpacas, donkeys, and dogs, are often used to help cultivate fields, harvest crops, wrangle other animals, and transport farm products to buyers. Animal husbandry not only refers to the breeding and raising of animals for meat or to harvest animal products (like milk, eggs, or wool) on a continual basis, but also to the breeding and care of species for work and companionship.
Livestock production systems can be defined based on feed source, as grassland-based, mixed, and landless. , 30% of Earth's ice- and water-free area was used for producing livestock, with the sector employing approximately 1.3 billion people. Between the 1960s and the 2000s, there was a significant increase in livestock production, both by numbers and by carcass weight, especially among beef, pigs and chickens, the latter of which had production increased by almost a factor of 10. Non-meat animals, such as milk cows and egg-producing chickens, also showed significant production increases. Global cattle, sheep and goat populations are expected to continue to increase sharply through 2050. Aquaculture or fish farming, the production of fish for human consumption in confined operations, is one of the fastest growing sectors of food production, growing at an average of 9% a year between 1975 and 2007.
During the second half of the 20th century, producers using selective breeding focused on creating livestock breeds and crossbreeds that increased production, while mostly disregarding the need to preserve genetic diversity. This trend has led to a significant decrease in genetic diversity and resources among livestock breeds, leading to a corresponding decrease in disease resistance and local adaptations previously found among traditional breeds.
Grassland based livestock production relies upon plant material such as shrubland, rangeland, and pastures for feeding ruminant animals. Outside nutrient inputs may be used, however manure is returned directly to the grassland as a major nutrient source. This system is particularly important in areas where crop production is not feasible because of climate or soil, representing 30 – 40 million pastoralists. Mixed production systems use grassland, fodder crops and grain feed crops as feed for ruminant and monogastric (one stomach; mainly chickens and pigs) livestock. Manure is typically recycled in mixed systems as a fertilizer for crops.
Landless systems rely upon feed from outside the farm, representing the de-linking of crop and livestock production found more prevalently in Organisation for Economic Co-operation and Development(OECD) member countries. Synthetic fertilizers are more heavily relied upon for crop production and manure utilization becomes a challenge as well as a source for pollution. Industrialized countries use these operations to produce much of the global supplies of poultry and pork. Scientists estimate that 75% of the growth in livestock production between 2003 and 2030 will be in confined animal feeding operations, sometimes called factory farming. Much of this growth is happening in developing countries in Asia, with much smaller amounts of growth in Africa. Some of the practices used in commercial livestock production, including the usage of growth hormones, are controversial.
<h2>Production practices.</h2>
Farming is the practice of agriculture by specialized labor in an area primarily devoted to agricultural processes, in service of a dislocated population usually in a city.
Tillage is the practice of plowing soil to prepare for planting or for nutrient incorporation or for pest control. Tillage varies in intensity from conventional to no-till. It may improve productivity by warming the soil, incorporating fertilizer and controlling weeds, but also renders soil more prone to erosion, triggers the decomposition of organic matter releasing CO, and reduces the abundance and diversity of soil organisms.
Pest control includes the management of weeds, insects, mites, and diseases. Chemical (pesticides), biological (biocontrol), mechanical (tillage), and cultural practices are used. Cultural practices include crop rotation, culling, cover crops, intercropping, composting, avoidance, and resistance. Integrated pest management attempts to use all of these methods to keep pest populations below the number which would cause economic loss, and recommends pesticides as a last resort.
Nutrient management includes both the source of nutrient inputs for crop and livestock production, and the method of utilization of manure produced by livestock. Nutrient inputs can be chemical inorganic fertilizers, manure, green manure, compost and mined minerals. Crop nutrient use may also be managed using cultural techniques such as crop rotation or a fallow period. Manure is used either by holding livestock where the feed crop is growing, such as in managed intensive rotational grazing, or by spreading either dry or liquid formulations of manure on cropland or pastures.
Water management is needed where rainfall is insufficient or variable, which occurs to some degree in most regions of the world. Some farmers use irrigation to supplement rainfall. In other areas such as the Great Plains in the U.S. and Canada, farmers use a fallow year to conserve soil moisture to use for growing a crop in the following year. Agriculture represents 70% of freshwater use worldwide.
According to a report by the International Food Policy Research Institute, agricultural technologies will have the greatest impact on food production if adopted in combination with each other; using a model that assessed how eleven technologies could impact agricultural productivity, food security and trade by 2050, the International Food Policy Research Institute found that the number of people at risk from hunger could be reduced by as much as 40% and food prices could be reduced by almost half.
"Payment for ecosystem services (PES) can further incentivise efforts to green the agriculture sector. This is an approach that verifies values and rewards the benefits of ecosystem services provided by green agricultural practices." "Innovative PES measures could include reforestation payments made by cities to upstream communities in rural areas of shared watersheds for improved quantities and quality of fresh water for municipal users. Ecoservice payments by farmers to upstream forest stewards for properly managing the flow of soil nutrients, and methods to monetise the carbon sequestration and emission reduction credit benefits of green agriculture practices in order to compensate farmers for their efforts to restore and build SOM and employ other practices."
<h2>Crop alteration and biotechnology.</h2>
Crop alteration has been practiced by humankind for thousands of years, since the beginning of civilization. Altering crops through breeding practices changes the genetic make-up of a plant to develop crops with more beneficial characteristics for humans, for example, larger fruits or seeds, drought-tolerance, or resistance to pests. Significant advances in plant breeding ensued after the work of geneticist Gregor Mendel. His work on dominant and recessive alleles, although initially largely ignored for almost 50 years, gave plant breeders a better understanding of genetics and breeding techniques. Crop breeding includes techniques such as plant selection with desirable traits, self-pollination and cross-pollination, and molecular techniques that genetically modify the organism.
Domestication of plants has, over the centuries increased yield, improved disease resistance and drought tolerance, eased harvest and improved the taste and nutritional value of crop plants. Careful selection and breeding have had enormous effects on the characteristics of crop plants. Plant selection and breeding in the 1920s and 1930s improved pasture (grasses and clover) in New Zealand. Extensive X-ray and ultraviolet induced mutagenesis efforts (i.e. primitive genetic engineering) during the 1950s produced the modern commercial varieties of grains such as wheat, corn (maize) and barley.
The Green Revolution popularized the use of conventional hybridization to sharply increase yield by creating "high-yielding varieties". For example, average yields of corn (maize) in the USA have increased from around 2.5 tons per hectare (t/ha) (40 bushels per acre) in 1900 to about 9.4 t/ha (150 bushels per acre) in 2001. Similarly, worldwide average wheat yields have increased from less than 1 t/ha in 1900 to more than 2.5 t/ha in 1990. South American average wheat yields are around 2 t/ha, African under 1 t/ha, and Egypt and Arabia up to 3.5 to 4 t/ha with irrigation. In contrast, the average wheat yield in countries such as France is over 8 t/ha. Variations in yields are due mainly to variation in climate, genetics, and the level of intensive farming techniques (use of fertilizers, chemical pest control, growth control to avoid lodging).
<h3>Genetic engineering.</h3>
Genetically modified organisms (GMO) are organisms whose genetic material has been altered by genetic engineering techniques generally known as recombinant DNA technology. Genetic engineering has expanded the genes available to breeders to utilize in creating desired germlines for new crops. Increased durability, nutritional content, insect and virus resistance and herbicide tolerance are a few of the attributes bred into crops through genetic engineering. For some, GMO crops cause food safety and food labeling concerns. Numerous countries have placed restrictions on the production, import or use of GMO foods and crops, which have been put in place due to concerns over potential health issues, declining agricultural diversity and contamination of non-GMO crops. Currently a global treaty, the Biosafety Protocol, regulates the trade of GMOs. There is ongoing discussion regarding the labeling of foods made from GMOs, and while the EU currently requires all GMO foods to be labeled, the US does not.
Herbicide-resistant seed has a gene implanted into its genome that allows the plants to tolerate exposure to herbicides, including glyphosates. These seeds allow the farmer to grow a crop that can be sprayed with herbicides to control weeds without harming the resistant crop. Herbicide-tolerant crops are used by farmers worldwide. With the increasing use of herbicide-tolerant crops, comes an increase in the use of glyphosate-based herbicide sprays. In some areas glyphosate resistant weeds have developed, causing farmers to switch to other herbicides. Some studies also link widespread glyphosate usage to iron deficiencies in some crops, which is both a crop production and a nutritional quality concern, with potential economic and health implications.
Other GMO crops used by growers include insect-resistant crops, which have a gene from the soil bacterium "Bacillus thuringiensis" (Bt), which produces a toxin specific to insects. These crops protect plants from damage by insects. Some believe that similar or better pest-resistance traits can be acquired through traditional breeding practices, and resistance to various pests can be gained through hybridization or cross-pollination with wild species. In some cases, wild species are the primary source of resistance traits; some tomato cultivars that have gained resistance to at least 19 diseases did so through crossing with wild populations of tomatoes.
<h2>Environmental impact.</h2>
Agriculture, as implemented through the method of farming, imposes external costs upon society through pesticides, nutrient runoff, excessive water usage, loss of natural environment and assorted other problems. A 2000 assessment of agriculture in the UK determined total external costs for 1996 of £2,343 million, or £208 per hectare. A 2005 analysis of these costs in the USA concluded that cropland imposes approximately $5 to 16 billion ($30 to $96 per hectare), while livestock production imposes $714 million. Both studies, which focused solely on the fiscal impacts, concluded that more should be done to internalize external costs. Neither included subsidies in their analysis, but they noted that subsidies also influence the cost of agriculture to society. In 2010, the International Resource Panel of the United Nations Environment Programme published a report assessing the environmental impacts of consumption and production. The study found that agriculture and food consumption are two of the most important drivers of environmental pressures, particularly habitat change, climate change, water use and toxic emissions. The 2011 UNEP Green Economy report states that "[a]gricultural operations, excluding land use changes, produce approximately 13 per cent of anthropogenic global GHG emissions. This includes GHGs emitted by the use of inorganic fertilisers agro-chemical pesticides and herbicides; (GHG emissions resulting from production of these inputs are included in industrial emissions); and fossil fuel-energy inputs. "On average we find that the total amount of fresh residues from agricultural and forestry production for second- generation biofuel production amounts to 3.8 billion tonnes per year between 2011 and 2050 (with an average annual growth rate of 11 per cent throughout the period analysed, accounting for higher growth during early years, 48 per cent for 2011–2020 and an average 2 per cent annual expansion after 2020)."
<h3>Livestock issues.</h3>
A senior UN official and co-author of a UN report detailing this problem, Henning Steinfeld, said "Livestock are one of the most significant contributors to today's most serious environmental problems". Livestock production occupies 70% of all land used for agriculture, or 30% of the land surface of the planet. It is one of the largest sources of greenhouse gases, responsible for 18% of the world's greenhouse gas emissions as measured in CO equivalents. By comparison, all transportation emits 13.5% of the CO. It produces 65% of human-related nitrous oxide (which has 296 times the global warming potential of CO) and 37% of all human-induced methane (which is 23 times as warming as CO.) It also generates 64% of the ammonia emission. Livestock expansion is cited as a key factor driving deforestation; in the Amazon basin 70% of previously forested area is now occupied by pastures and the remainder used for feedcrops. Through deforestation and land degradation, livestock is also driving reductions in biodiversity. Furthermore, the UNEP states that "methane emissions from global livestock are projected to increase by 60 per cent by 2030 under current practices and consumption patterns."
<h3>Land and water issues.</h3>
Land transformation, the use of land to yield goods and services, is the most substantial way humans alter the Earth's ecosystems, and is considered the driving force in the loss of biodiversity. Estimates of the amount of land transformed by humans vary from 39 to 50%. Land degradation, the long-term decline in ecosystem function and productivity, is estimated to be occurring on 24% of land worldwide, with cropland overrepresented. The UN-FAO report cites land management as the driving factor behind degradation and reports that 1.5 billion people rely upon the degrading land. Degradation can be deforestation, desertification, soil erosion, mineral depletion, or chemical degradation (acidification and salinization).
Eutrophication, excessive nutrients in aquatic ecosystems resulting in algal blooms and anoxia, leads to fish kills, loss of biodiversity, and renders water unfit for drinking and other industrial uses. Excessive fertilization and manure application to cropland, as well as high livestock stocking densities cause nutrient (mainly nitrogen and phosphorus) runoff and leaching from agricultural land. These nutrients are major nonpoint pollutants contributing to eutrophication of aquatic ecosystems.
Agriculture accounts for 70 percent of withdrawals of freshwater resources. Agriculture is a major draw on water from aquifers, and currently draws from those underground water sources at an unsustainable rate. It is long known that aquifers in areas as diverse as northern China, the Upper Ganges and the western US are being depleted, and new research extends these problems to aquifers in Iran, Mexico and Saudi Arabia. Increasing pressure is being placed on water resources by industry and urban areas, meaning that water scarcity is increasing and agriculture is facing the challenge of producing more food for the world's growing population with reduced water resources. Agricultural water usage can also cause major environmental problems, including the destruction of natural wetlands, the spread of water-borne diseases, and land degradation through salinization and waterlogging, when irrigation is performed incorrectly.
<h3>Pesticides.</h3>
Pesticide use has increased since 1950 to 2.5million short tons annually worldwide, yet crop loss from pests has remained relatively constant. The World Health Organization estimated in 1992 that 3million pesticide poisonings occur annually, causing 220,000 deaths. Pesticides select for pesticide resistance in the pest population, leading to a condition termed the "pesticide treadmill" in which pest resistance warrants the development of a new pesticide.
An alternative argument is that the way to "save the environment" and prevent famine is by using pesticides and intensive high yield farming, a view exemplified by a quote heading the Center for Global Food Issues website: 'Growing more per acre leaves more land for nature'. However, critics argue that a trade-off between the environment and a need for food is not inevitable, and that pesticides simply replace good agronomic practices such as crop rotation. The UNEP introduces the Push–pull agricultural pest management technique which involves intercropping that uses plant aromas to repel or push away pests while pulling in or attracting the right insects. "The implementation of push-pull in eastern Africa has significantly increased maize yields and the combined cultivation of N-fixing forage crops has enriched the soil and has also provided farmers with feed for livestock. With increased livestock operations, the farmers are able to produce meat, milk and other dairy products and they use the manure as organic fertiliser that returns nutrients to the fields."
<h3>Climate change.</h3>
Climate change has the potential to affect agriculture through changes in temperature, rainfall (timing and quantity), CO, solar radiation and the interaction of these elements. Extreme events, such as droughts and floods, are forecast to increase as climate change takes hold. Agriculture is among sectors most vulnerable to the impacts of climate change; water supply for example, will be critical to sustain agricultural production and provide the increase in food output required to sustain the world's growing population. Fluctuations in the flow of rivers are likely to increase in the twenty-first century. Based on the experience of countries in the Nile river basin (Ethiopia, Kenya and Sudan) and other developing countries, depletion of water resources during seasons crucial for agriculture can lead to a decline in yield by up to 50%. Transformational approaches will be needed to manage natural resources in the future. For example, policies, practices and tools promoting climate-smart agriculture will be important, as will better use of scientific information on climate for assessing risks and vulnerability. Planners and policy-makers will need to help create suitable policies that encourage funding for such agricultural transformation.
Agriculture in its many forms can both mitigate or worsen global warming. Some of the increase in CO in the atmosphere comes from the decomposition of organic matter in the soil, and much of the methane emitted into the atmosphere is caused by the decomposition of organic matter in wet soils such as rice paddy fields, as well as the normal digestive activities of farm animals. Further, wet or anaerobic soils also lose nitrogen through denitrification, releasing the greenhouse gases nitric oxide and nitrous oxide. Changes in management can reduce the release of these greenhouse gases, and soil can further be used to sequester some of the CO in the atmosphere. Informed by the UNEP, "[a]griculture also produces about 58 per cent of global nitrous oxide emissions and about 47 per cent of global methane emissions. Cattle and rice farms release methane, fertilized fields release nitrous oxide, and the cutting down of rainforests to grow crops or raise livestock releases carbon dioxide. Both of these gases have a far greater global warming potential per tonne than CO2 (298 times and 25 times respectively)."
There are several factors within the field of agriculture that contribute to the large amount of CO2 emissions. The diversity of the sources ranges from the production of farming tools to the transport of harvested produce. Approximately 8% of the national carbon footprint is due to agricultural sources. Of that, 75% is of the carbon emissions released from the production of crop assisting chemicals. Factories producing insecticides, herbicides, fungicides, and fertilizers are a major culprit of the greenhouse gas. Productivity on the farm itself and the use of machinery is another source of the carbon emission. Almost all the industrial machines used in modern farming are powered by fossil fuels. These instruments are burning fossil fuels from the beginning of the process to the end. Tractors are the root of this source. The tractor is going to burn fuel and release CO2 just to run. The amount of emissions from the machinery increase with the attachment of different units and need for more power. During the soil preparation stage tillers and plows will be used to disrupt the soil. During growth watering pumps and sprayers are used to keep the crops hydrated. And when the crops are ready for picking a forage or combine harvester is used. These types of machinery all require additional energy which leads to increased carbon dioxide emissions from the basic tractors. The final major contribution to CO2 emissions in agriculture is in the final transport of produce. Local farming suffered a decline over the past century due to large amounts of farm subsidies. The majority of crops are shipped hundreds of miles to various processing plants before ending up in the grocery store. These shipments are made using fossil fuel burning modes of transportation. Inevitably these transport adds to carbon dioxide emissions.
<h3>Sustainability.</h3>
Some major organizations are hailing farming within agroecosystems as the way forward for mainstream agriculture. Current farming methods have resulted in over-stretched water resources, high levels of erosion and reduced soil fertility. According to a report by the International Water Management Institute and UNEP, there is not enough water to continue farming using current practices; therefore how critical water, land, and ecosystem resources are used to boost crop yields must be reconsidered. The report suggested assigning value to ecosystems, recognizing environmental and livelihood tradeoffs, and balancing the rights of a variety of users and interests. Inequities that result when such measures are adopted would need to be addressed, such as the reallocation of water from poor to rich, the clearing of land to make way for
more productive farmland, or the preservation of a wetland system that limits fishing rights.
Technological advancements help provide farmers with tools and resources to make farming more sustainable. New technologies have given rise to innovations like conservation tillage, a farming process which helps prevent land loss to erosion, water pollution and enhances carbon sequestration.
According to a report by the International Food Policy Research Institute (IFPRI), agricultural technologies will have the greatest impact on food production if adopted in combination with each other; using a model that assessed how eleven technologies could impact agricultural productivity, food security and trade by 2050, IFPRI found that the number of people at risk from hunger could be reduced by as much as 40% and food prices could be reduced by almost half.
<h2>Agricultural economics.</h2>
Agricultural economics refers to economics as it relates to the "production, distribution and consumption of [agricultural] goods and services". Combining agricultural production with general theories of marketing and business as a discipline of study began in the late 1800s, and grew significantly through the 20th century. Although the study of agricultural economics is relatively recent, major trends in agriculture have significantly affected national and international economies throughout history, ranging from tenant farmers and sharecropping in the post-American Civil War Southern United States to the European feudal system of manorialism. In the United States, and elsewhere, food costs attributed to food processing, distribution, and agricultural marketing, sometimes referred to as the value chain, have risen while the costs attributed to farming have declined. This is related to the greater efficiency of farming, combined with the increased level of value addition (e.g. more highly processed products) provided by the supply chain. Market concentration has increased in the sector as well, and although the total effect of the increased market concentration is likely increased efficiency, the changes redistribute economic surplus from producers (farmers) and consumers, and may have negative implications for rural communities.
National government policies can significantly change the economic marketplace for agricultural products, in the form of taxation, subsidies, tariffs and other measures. Since at least the 1960s, a combination of import/export restrictions, exchange rate policies and subsidies have affected farmers in both the developing and developed world. In the 1980s, it was clear that non-subsidized farmers in developing countries were experiencing adverse effects from national policies that created artificially low global prices for farm products. Between the mid-1980s and the early 2000s, several international agreements were put into place that limited agricultural tariffs, subsidies and other trade restrictions.
However, , there was still a significant amount of policy-driven distortion in global agricultural product prices. The three agricultural products with the greatest amount of trade distortion were sugar, milk and rice, mainly due to taxation. Among the oilseeds, sesame had the greatest amount of taxation, but overall, feed grains and oilseeds had much lower levels of taxation than livestock products. Since the 1980s, policy-driven distortions have seen a greater decrease among livestock products than crops during the worldwide reforms in agricultural policy. Despite this progress, certain crops, such as cotton, still see subsidies in developed countries artificially deflating global prices, causing hardship in developing countries with non-subsidized farmers. Unprocessed commodities (i.e. corn, soybeans, cows) are generally graded to indicate quality. The quality affects the price the producer receives. Commodities are generally reported by production quantities, such as volume, number or weight.
<h2>Energy and agriculture.</h2>
Since the 1940s, agricultural productivity has increased dramatically, due largely to the increased use of energy-intensive mechanization, fertilizers and pesticides. The vast majority of this energy input comes from fossil fuel sources. Between the 1960–65 measuring cycle and the cycle from 1986 to 1990, the Green Revolution transformed agriculture around the globe, with world grain production increasing significantly (between 70% and 390% for wheat and 60% to 150% for rice, depending on geographic area) as world population doubled. Modern agriculture's heavy reliance on petrochemicals and mechanization has raised concerns that oil shortages could increase costs and reduce agricultural output, causing food shortages.
Modern or industrialized agriculture is dependent on fossil fuels in two fundamental ways: 1. direct consumption on the farm and 2. indirect consumption to manufacture inputs used on the farm. Direct consumption includes the use of lubricants and fuels to operate farm vehicles and machinery; and use of gasoline, liquid propane, and electricity to power dryers, pumps, lights, heaters, and coolers. American farms directly consumed about 1.2 exajoules (1.1 quadrillion BTU) in 2002, or just over 1% of the nation's total energy.
Indirect consumption is mainly oil and natural gas used to manufacture fertilizers and pesticides, which accounted for 0.6 exajoules (0.6 quadrillion BTU) in 2002. The natural gas and coal consumed by the production of nitrogen fertilizer can account for over half of the agricultural energy usage. China utilizes mostly coal in the production of nitrogen fertilizer, while most of Europe uses large amounts of natural gas and small amounts of coal. According to a 2010 report published by The Royal Society, agriculture is increasingly dependent on the direct and indirect input of fossil fuels. Overall, the fuels used in agriculture vary based on several factors, including crop, production system and location. The energy used to manufacture farm machinery is also a form of indirect agricultural energy consumption. Together, direct and indirect consumption by US farms accounts for about 2% of the nation's energy use. Direct and indirect energy consumption by U.S. farms peaked in 1979, and has gradually declined over the past 30 years. Food systems encompass not just agricultural production, but also off-farm processing, packaging, transporting, marketing, consumption, and disposal of food and food-related items. Agriculture accounts for less than one-fifth of food system energy use in the US.
In the event of a petroleum shortage (see peak oil for global concerns), organic agriculture can be more attractive than conventional practices that use petroleum-based pesticides, herbicides, or fertilizers. Some studies using modern organic-farming methods have reported yields equal to or higher than those available from conventional farming. In the aftermath of the fall of the Soviet Union, with shortages of conventional petroleum-based inputs, Cuba made use of mostly organic practices, including biopesticides, plant-based pesticides and sustainable cropping practices, to feed its populace. However, organic farming may be more labor-intensive and would require a shift of the workforce from urban to rural areas. The reconditioning of soil to restore organic matter lost during the use of monoculture agriculture techniques is important to provide a reservoir of plant-available nutrients, to maintain texture, and to minimize erosion.
It has been suggested that rural communities might obtain fuel from the biochar and synfuel process, which uses agricultural "waste" to provide charcoal fertilizer, some fuel "and" food, instead of the normal food vs. fuel debate. As the synfuel would be used on-site, the process would be more efficient and might just provide enough fuel for a new organic-agriculture fusion.
It has been suggested that some transgenic plants may some day be developed which would allow for maintaining or increasing yields while requiring fewer fossil-fuel-derived inputs than conventional crops. The possibility of success of these programs is questioned by ecologists and economists concerned with unsustainable GMO practices such as terminator seeds. While there has been some research on sustainability using GMO crops, at least one prominent multi-year attempt by Monsanto Company has been unsuccessful, though during the same period traditional breeding techniques yielded a more sustainable variety of the same crop.
<h2>Policy.</h2>
Agricultural policy is the set of government decisions and actions relating to domestic agriculture and imports of foreign agricultural products. Governments usually implement agricultural policies with the goal of achieving a specific outcome in the domestic agricultural product markets. Some overarching themes include risk management and adjustment (including policies related to climate change, food safety and natural disasters), economic stability (including policies related to taxes), natural resources and environmental sustainability (especially water policy), research and development, and market access for domestic commodities (including relations with global organizations and agreements with other countries). Agricultural policy can also touch on food quality, ensuring that the food supply is of a consistent and known quality, food security, ensuring that the food supply meets the population's needs, and conservation. Policy programs can range from financial programs, such as subsidies, to encouraging producers to enroll in voluntary quality assurance programs.
There are many influences on the creation of agricultural policy, including consumers, agribusiness, trade lobbies and other groups. Agribusiness interests hold a large amount of influence over policy making, in the form of lobbying and campaign contributions. Political action groups, including those interested in environmental issues and labor unions, also provide influence, as do lobbying organizations representing individual agricultural commodities. The Food and Agriculture Organization of the United Nations (FAO) leads international efforts to defeat hunger and provides a forum for the negotiation of global agricultural regulations and agreements. Dr. Samuel Jutzi, director of FAO's animal production and health division, states that lobbying by large corporations has stopped reforms that would improve human health and the environment. For example, proposals in 2010 for a voluntary code of conduct for the livestock industry that would have provided incentives for improving standards for health, and environmental regulations, such as the number of animals an area of land can support without long-term damage, were successfully defeated due to large food company pressure.

</doc>
<doc id="628" url="https://en.wikipedia.org/wiki?curid=628" title="Aldous Huxley">
Aldous Huxley

Aldous Leonard Huxley (; 26 July 1894 – 22 November 1963) was an English writer, novelist, philosopher, and prominent member of the Huxley family. He graduated from Balliol College, Oxford, with a first in English literature.
He was best known for his novels including "Brave New World", set in a dystopian London; for non-fiction books, such as "The Doors of Perception", which recalls experiences when taking a psychedelic drug; and a wide-ranging output of essays. Early in his career Huxley edited the magazine "Oxford Poetry" and published short stories and poetry. Mid career and later, he published travel writing, film stories, and scripts. He spent the later part of his life in the U.S., living in Los Angeles from 1937 until his death. In 1962, a year before his death, he was elected Companion of Literature by the Royal Society of Literature.
Huxley was a humanist, pacifist, and satirist. He later became interested in spiritual subjects such as parapsychology and philosophical mysticism, in particular universalism. By the end of his life, Huxley was widely acknowledged as one of the pre-eminent intellectuals of his time. He was nominated for the Nobel Prize in Literature in seven different years.
<h2>Early life.</h2>
Huxley was born in Godalming, Surrey, England, in 1894. He was the third son of the writer and schoolmaster Leonard Huxley, who edited "Cornhill Magazine", and his first wife, Julia Arnold, who founded Prior's Field School. Julia was the niece of poet and critic Matthew Arnold and the sister of Mrs. Humphrey Ward. Aldous was the grandson of Thomas Henry Huxley, the zoologist, agnostic, and controversialist ("Darwin's Bulldog"). His brother Julian Huxley and half-brother Andrew Huxley also became outstanding biologists. Aldous had another brother, Noel Trevelyan Huxley (1891–1914), who committed suicide after a period of clinical depression.
As a child, Huxley's nickname was "Ogie", short for "Ogre". He was described by his brother, Julian, as someone who frequently "[contemplated] the strangeness of things". According to his cousin and contemporary, Gervas Huxley, he had an early interest in drawing.
Huxley's education began in his father's well-equipped botanical laboratory, after which he enrolled at Hillside School, Malvern. He was taught there by his own mother for several years until she became terminally ill. After Hillside, he went on to Eton College. His mother died in 1908 when he was 14. In 1911 he contracted the eye disease (keratitis punctata) which "left [him] practically blind for two to three years". This "ended his early dreams of becoming a doctor." In October 1913, Huxley went up to Balliol College, Oxford, where he read English Literature. In January 1916, he volunteered to join the British Army in the Great War, but was rejected on health grounds, being half-blind in one eye. His eyesight later partly recovered. In 1916 he edited "Oxford Poetry" and in June of that year graduated BA with First Class honours. His brother Julian wrote:
Following his years at Balliol, Huxley, being financially indebted to his father, decided to find employment. From April to July 1917, he was in charge of ordering supplies at the Air Ministry for the Royal Air Force. He taught French for a year at Eton, where Eric Blair (who was to take the pen name George Orwell) and Steven Runciman were among his pupils. He was mainly remembered as being an incompetent schoolmaster unable to keep order in class. Nevertheless, Blair and others spoke highly of his brilliant command of language.
Significantly, Huxley also worked for a time during the 1920s at Brunner and Mond, a high-tech chemical plant in Billingham, North East England. According to the introduction to the latest edition of his great science fiction novel "Brave New World" (1932), the experience he had there of "an ordered universe in a world of planless incoherence" was an important source for the novel.
<h2>Career.</h2>
Huxley completed his first (unpublished) novel at the age of 17 and began writing seriously in his early 20s, establishing himself as a successful writer and social satirist. His first published novels were social satires, "Crome Yellow" (1921), "Antic Hay" (1923), "Those Barren Leaves" (1925), and "Point Counter Point" (1928). "Brave New World" was Huxley's fifth novel and first dystopian work. In the 1920s he was also a contributor to "Vanity Fair" and British "Vogue" magazines.
<h3>Bloomsbury Set.</h3>
During World War I, Huxley spent much of his time at Garsington Manor near Oxford, home of Lady Ottoline Morrell, working as a farm labourer. There he met several Bloomsbury figures, including Bertrand Russell, Alfred North Whitehead, and Clive Bell. Later, in "Crome Yellow" (1921) he caricatured the Garsington lifestyle. Jobs were very scarce, but in 1919 John Middleton Murry was reorganising the "Athenaeum" and invited Huxley to join the staff. He accepted immediately, and quickly married the Belgian refugee Maria Nys, also at Garsington. They lived with their young son in Italy part of the time during the 1920s, where Huxley would visit his friend D. H. Lawrence. Following Lawrence's death in 1930, Huxley edited Lawrence's letters (1932).
Works of this period included important novels on the dehumanising aspects of scientific progress, most famously "Brave New World", and on pacifist themes (for example, "Eyeless in Gaza"). In "Brave New World", set in a dystopian London, Huxley portrays a society operating on the principles of mass production and Pavlovian conditioning. Huxley was strongly influenced by F. Matthias Alexander and included him as a character in "Eyeless in Gaza".
Starting from this period, Huxley began to write and edit non-fiction works on pacifist issues, including "Ends and Means", "An Encyclopedia of Pacifism", and "Pacifism and Philosophy", and was an active member of the Peace Pledge Union.
<h3>United States.</h3>
In 1937, Huxley moved to Hollywood with his wife Maria, son Matthew, and friend Gerald Heard. He lived in the US, mainly in southern California, until his death, but also for a time in Taos, New Mexico, where he wrote "Ends and Means" (published in 1937). The book contains illuminating tracts on war, religion, nationalism and ethics.
Heard introduced Huxley to Vedanta (Upanishad-centered philosophy), meditation, and vegetarianism through the principle of ahimsa. In 1938, Huxley befriended Jiddu Krishnamurti, whose teachings he greatly admired. He also became a Vedantist in the circle of Hindu Swami Prabhavananda, and introduced Christopher Isherwood to this circle. Not long after, Huxley wrote his book on widely held spiritual values and ideas, "The Perennial Philosophy", which discussed the teachings of renowned mystics of the world. Huxley's book affirmed a sensibility that insists there are realities beyond the generally accepted "five senses" and that there is genuine meaning for humans beyond both sensual satisfactions and sentimentalities.
Huxley became a close friend of Remsen Bird, president of Occidental College. He spent much time at the college, which is in the Eagle Rock neighbourhood of Los Angeles. The college appears as "Tarzana College" in his satirical novel "After Many a Summer" (1939). The novel won Huxley a British literary award, the 1939 James Tait Black Memorial Prize for fiction. Huxley also incorporated Bird into the novel.
During this period, Huxley earned a substantial income as a Hollywood screenwriter; Christopher Isherwood, in his autobiography "My Guru and His Disciple", states that Huxley earned more than $3,000 per week (an enormous sum in those days) as a screenwriter, and that he used much of it to transport Jewish and left-wing writer and artist refugees from Hitler's Germany to the U.S. In March 1938, his friend Anita Loos, a novelist and screenwriter, put him in touch with Metro-Goldwyn-Mayer who hired Huxley for "Madame Curie", which was originally to star Greta Garbo and be directed by George Cukor. (Eventually, the film was completed by MGM in 1943 with a different director and cast.) Huxley received screen credit for "Pride and Prejudice" (1940) and was paid for his work on a number of other films, including "Jane Eyre" (1944). Huxley was commissioned by Walt Disney in 1945 to write a script based on "Alice's Adventures in Wonderland" and the biography of the story's author, Lewis Carroll. The script was not used, however.
Huxley wrote an introduction to the posthumous publication of J. D. Unwin's 1940 book "Hopousia or The Sexual and Economic Foundations of a New Society".
On 21 October 1949, Huxley wrote to George Orwell, author of "Nineteen Eighty-Four", congratulating him on "how fine and how profoundly important the book is". In his letter to Orwell, he predicted:
Huxley had deeply felt apprehensions about the future the developed world might make for itself. From these, he made some warnings in his writings and talks. In a 1958 televised interview conducted by journalist Mike Wallace, Huxley outlined several major concerns: the difficulties and dangers of world overpopulation; the tendency toward distinctly hierarchical social organisation; the crucial importance of evaluating the use of technology in mass societies susceptible to wily persuasion; the tendency to promote modern politicians, to a naive public, as well-marketed commodities.
<h3>Post World War II.</h3>
After World War II, Huxley applied for United States citizenship. His application was continuously deferred on the grounds that he would not say he would take up arms to defend the U.S. He claimed a philosophical, rather than a religious objection, and therefore was not exempt under the McCarran Act. He withdrew his application. Nevertheless, he remained in the country; and in 1959 he turned down an offer of a Knight Bachelor by the Macmillan government.
<h2>Association with Vedanta.</h2>
Beginning in 1939 and continuing until his death in 1963, Huxley had an extensive association with the Vedanta Society of Southern California, founded and headed by Swami Prabhavananda. Together with Gerald Heard, Christopher Isherwood, and other followers he was initiated by the Swami and was taught meditation and spiritual practices.
In 1944, Huxley wrote the introduction to the "Bhagavad Gita: The Song of God", translated by Swami Prabhavanada and Christopher Isherwood, which was published by The Vedanta Society of Southern California.
From 1941 until 1960, Huxley contributed 48 articles to "Vedanta and the West", published by the society. He also served on the editorial board with Isherwood, Heard, and playwright John van Druten from 1951 through 1962.
Huxley also occasionally lectured at the Hollywood and Santa Barbara Vedanta temples. Two of those lectures have been released on CD: "Knowledge and Understanding" and "Who Are We?" from 1955. Nonetheless, Huxley's agnosticism, together with his speculative propensity, made it difficult for him to fully embrace any form of institutionalized religion. In spring of 1953, Huxley had his first, supervised, experience with psychedelic drugs (in this case, mescaline). After the publication of "The Doors of Perception", in which he recounted this experience, Huxley and Swami Prabhavanada disagreed about the meaning and importance of the psychedelic drug experience, which may have caused the relationship to cool, but Huxley continued to write articles for the society's journal, lecture at the temple, and attend social functions.
<h2>Eyesight.</h2>
There are differing accounts about the details of the quality of Huxley's eyesight at specific points in his life. About 1939, Huxley encountered the Bates method for better eyesight, and a teacher, Margaret Darst Corbett, who was able to teach the method to him. In 1940, Huxley relocated from Hollywood to a "ranchito" in the high desert hamlet of Llano, California, in northernmost Los Angeles County. Huxley then said that his sight improved dramatically with the Bates Method and the extreme and pure natural lighting of the southwestern American desert. He reported that, for the first time in more than 25 years, he was able to read without glasses and without strain. He even tried driving a car along the dirt road beside the ranch. He wrote a book about his successes with the Bates Method, "The Art of Seeing", which was published in 1942 (U.S.), 1943 (UK). The book contained some generally disputed theories, and its publication created a growing degree of popular controversy about Huxley's eyesight.
It was, and is, widely believed that Huxley was nearly blind since the illness in his teens, despite the partial recovery that had enabled him to study at Oxford. For example, some ten years after publication of "The Art of Seeing", in 1952, Bennett Cerf was present when Huxley spoke at a Hollywood banquet, wearing no glasses and apparently reading his paper from the lectern without difficulty: "Then suddenly he faltered — and the disturbing truth became obvious. He wasn't reading his address at all. He had learned it by heart. To refresh his memory he brought the paper closer and closer to his eyes. When it was only an inch or so away he still couldn't read it, and had to fish for a magnifying glass in his pocket to make the typing visible to him. It was an agonising moment."
On the other hand, Huxley's second wife, Laura Archera Huxley, would later emphasise in her biographical account, "This Timeless Moment": "One of the great achievements of his life: that of having regained his sight." After revealing a letter she wrote to the "Los Angeles Times" disclaiming the label of Huxley as a "poor fellow who can hardly see" by Walter C. Alvarez, she tempered this: "Although I feel it was an injustice to treat Aldous as though he were blind, it is true there were many indications of his impaired vision. For instance, although Aldous did not wear glasses, he would quite often use a magnifying lens." Laura Huxley proceeded to elaborate a few nuances of inconsistency peculiar to Huxley's vision. Her account, in this respect, is discernibly congruent with the following sample of Huxley's own words from "The Art of Seeing": "The most characteristic fact about the functioning of the total organism, or any part of the organism, is that it is not constant, but highly variable." Nevertheless, the topic of Huxley's eyesight continues to endure similar, significant controversy, regardless of how trivial a subject matter it might initially appear.
American popular science author Steven Johnson, in his book "Mind Wide Open", quotes Huxley about his difficulties with visual encoding: "I am and, for as long as I can remember, I have always been a poor visualizer. Words, even the pregnant words of poets, do not evoke pictures in my mind. No hypnagogic visions greet me on the verge of sleep. When I recall something, the memory does not present itself to me as a vividly seen event or object. By an effort of the will, I can evoke a not very vivid image of what happened yesterday afternoon ..."
<h2>Personal life.</h2>
Huxley married Maria Nys (10 September 1899 – 12 February 1955), a Belgian he met at Garsington, Oxfordshire, in 1919. They had one child, Matthew Huxley (19 April 1920 – 10 February 2005), who had a career as an author, anthropologist, and prominent epidemiologist. In 1955, Maria died of cancer.
In 1956, Huxley married Laura Archera (1911–2007), also an author as well as a violinist and psychotherapist. She wrote "This Timeless Moment", a biography of Huxley. Laura felt inspired to illuminate the story of their marriage through Mary Ann Braubach's 2010 documentary, "Huxley on Huxley".
In 1960, Huxley was diagnosed with laryngeal cancer and, in the years that followed, with his health deteriorating, he wrote the Utopian novel "Island", and gave lectures on "Human Potentialities" both at the University of California's San Francisco Medical Center and at the Esalen Institute. These lectures were fundamental to the beginning of the Human Potential Movement.
Huxley was a close friend of Jiddu Krishnamurti and Rosalind Rajagopal and was involved in the creation of the Happy Valley School (now Besant Hill School of Happy Valley) in Ojai, California.
The most substantial collection of Huxley's few remaining papers (following the destruction of most in a fire) is at the Library of the University of California, Los Angeles. Some are also at the Stanford University Libraries.
On 9 April 1962, Huxley was informed he was elected Companion of Literature by the Royal Society of Literature, the senior literary organisation in Britain, and he accepted the title via letter on 28 April 1962. The correspondence between Huxley and the society are kept at the Cambridge University Library. The society invited Huxley to appear at a banquet and give a lecture at Somerset House, London in June 1963. Huxley wrote a draft of the speech he intended to give at the society; however, his deteriorating health meant he would not be able to attend.
<h2>Death.</h2>
On his deathbed, unable to speak due to advanced laryngeal cancer, Huxley made a written request to his wife Laura for "LSD, 100 µg, intramuscular". According to her account of his death in "This Timeless Moment", she obliged with an injection at 11:20 a.m. and a second dose an hour later; Huxley died aged 69, at 5:20 p.m. (Los Angeles time), on 22 November 1963.
Media coverage of Huxley's passing — as with that of the author C. S. Lewis – was overshadowed by the assassination of U.S. President John F. Kennedy on the same day. This coincidence served as the basis for Peter Kreeft's book "Between Heaven and Hell: A Dialog Somewhere Beyond Death with John F. Kennedy, C. S. Lewis, & Aldous Huxley", which imagines a conversation among the three men taking place in Purgatory following their deaths.
Huxley's memorial service took place in London in December 1963 which was led by his older brother Julian, and his ashes were interred in the family grave at the Watts Cemetery, home of the Watts Mortuary Chapel in Compton, a village near Guildford, Surrey, England.
Huxley had been a long-time friend of Russian composer Igor Stravinsky, who later dedicated his last orchestral composition to Huxley. Stravinsky began "Variations" in Santa Fé, New Mexico, in July 1963, and completed the composition in Hollywood on 28 October 1964. It was first performed in Chicago on 17 April 1965, by the Chicago Symphony Orchestra conducted by Robert Craft.

</doc>
<doc id="630" url="https://en.wikipedia.org/wiki?curid=630" title="Ada">
Ada

Ada may refer to:

</doc>
<doc id="632" url="https://en.wikipedia.org/wiki?curid=632" title="Aberdeen (disambiguation)">
Aberdeen (disambiguation)

Aberdeen is a city in Scotland, United Kingdom.
Aberdeen may also refer to:

</doc>
<doc id="633" url="https://en.wikipedia.org/wiki?curid=633" title="Algae">
Algae

Algae (; singular "alga" ) is an informal term for a large, diverse group of photosynthetic organisms which are not necessarily closely related, thus are polyphyletic. Included organisms range from unicellular genera, such as "Chlorella" and the diatoms, to multicellular forms, such as the giant kelp, a large brown alga which may grow up to 50 m in length. Most are aquatic and autotrophic and lack many of the distinct cell and tissue types, such as stomata, xylem, and phloem, which are found in land plants. The largest and most complex marine algae are called seaweeds, while the most complex freshwater forms are the Charophyta, a division of green algae which includes, for example, "Spirogyra" and the stoneworts.
No definition of algae is generally accepted. One definition is that algae "have chlorophyll as their primary photosynthetic pigment and lack a sterile covering of cells around their reproductive cells". Some authors exclude all prokaryotes thus do not consider cyanobacteria (blue-green algae) as algae.
Algae constitute a polyphyletic group since they do not include a common ancestor, and although their plastids seem to have a single origin, from cyanobacteria, they were acquired in different ways. Green algae are examples of algae that have primary chloroplasts derived from endosymbiotic cyanobacteria. Diatoms and brown algae are examples of algae with secondary chloroplasts derived from an endosymbiotic red alga.
Algae exhibit a wide range of reproductive strategies, from simple asexual cell division to complex forms of sexual reproduction.
Algae lack the various structures that characterize land plants, such as the phyllids (leaf-like structures) of bryophytes, rhizoids in nonvascular plants, and the roots, leaves, and other organs found in tracheophytes (vascular plants). Most are phototrophic, although some are mixotrophic, deriving energy both from photosynthesis and uptake of organic carbon either by osmotrophy, myzotrophy, or phagotrophy. Some unicellular species of green algae, many golden algae, euglenids, dinoflagellates, and other algae have become heterotrophs (also called colorless or apochlorotic algae), sometimes parasitic, relying entirely on external energy sources and have limited or no photosynthetic apparatus. Some other heterotrophic organisms, such as the apicomplexans, are also derived from cells whose ancestors possessed plastids, but are not traditionally considered as algae. Algae have photosynthetic machinery ultimately derived from cyanobacteria that produce oxygen as a by-product of photosynthesis, unlike other photosynthetic bacteria such as purple and green sulfur bacteria. Fossilized filamentous algae from the Vindhya basin have been dated back to 1.6 to 1.7 billion years ago.
<h2>Etymology and study.</h2>
The singular "alga" is the Latin word for "seaweed" and retains that meaning in English. The etymology is obscure. Although some speculate that it is related to Latin "algēre", "be cold", no reason is known to associate seaweed with temperature. A more likely source is "alliga", "binding, entwining".
The Ancient Greek word for seaweed was φῦκος ("fūkos" or "phykos"), which could mean either the seaweed (probably red algae) or a red dye derived from it. The Latinization, "fūcus", meant primarily the cosmetic rouge. The etymology is uncertain, but a strong candidate has long been some word related to the Biblical פוך ("pūk"), "paint" (if not that word itself), a cosmetic eye-shadow used by the ancient Egyptians and other inhabitants of the eastern Mediterranean. It could be any color: black, red, green, or blue.
Accordingly, the modern study of marine and freshwater algae is called either phycology or algology, depending on whether the Greek or Latin root is used. The name "Fucus" appears in a number of taxa.
<h2>Classification.</h2>
Most algae contain chloroplasts that are similar in structure to cyanobacteria. Chloroplasts contain circular DNA like that in cyanobacteria and presumably represent reduced endosymbiotic cyanobacteria. However, the exact origin of the chloroplasts is different among separate lineages of algae, reflecting their acquisition during different endosymbiotic events. The table below describes the composition of the three major groups of algae. Their lineage relationships are shown in the figure in the upper right. Many of these groups contain some members that are no longer photosynthetic. Some retain plastids, but not chloroplasts, while others have lost plastids entirely.
Phylogeny based on plastid not nucleocytoplasmic genealogy:
Linnaeus, in "Species Plantarum" (1753), the starting point for modern botanical nomenclature, recognized 14 genera of algae, of which only four are currently considered among algae. In "Systema Naturae", Linnaeus described the genera "Volvox" and "Corallina", and a species of "Acetabularia" (as "Madrepora"), among the animals.
In 1768, Samuel Gottlieb Gmelin (1744–1774) published the "Historia Fucorum", the first work dedicated to marine algae and the first book on marine biology to use the then new binomial nomenclature of Linnaeus. It included elaborate illustrations of seaweed and marine algae on folded leaves.
W.H.Harvey (1811—1866) and Lamouroux (1813) were the first to divide macroscopic algae into four divisions based on their pigmentation. This is the first use of a biochemical criterion in plant systematics. Harvey's four divisions are: red algae (Rhodospermae), brown algae (Melanospermae), green algae (Chlorospermae), and Diatomaceae.
At this time, microscopic algae were discovered and reported by a different group of workers (e.g., O. F. Müller and Ehrenberg) studying the Infusoria (microscopic organisms). Unlike macroalgae, which were clearly viewed as plants, microalgae were frequently considered animals because they are often motile. Even the nonmotile (coccoid) microalgae were sometimes merely seen as stages of the lifecycle of plants, macroalgae, or animals.
Although used as a taxonomic category in some pre-Darwinian classifications, e.g., Linnaeus (1753), de Jussieu (1789), Horaninow (1843), Agassiz (1859), Wilson & Cassin (1864), in further classifications, the "algae" are seen as an artificial, polyphyletic group.
Throughout the 20th century, most classifications treated the following groups as divisions or classes of algae: cyanophytes, rhodophytes, chrysophytes, xanthophytes, bacillariophytes, phaeophytes, pyrrhophytes (cryptophytes and dinophytes), euglenophytes, and chlorophytes. Later, many new groups were discovered (e.g., Bolidophyceae), and others were splintered from older groups: charophytes and glaucophytes (from chlorophytes), many heterokontophytes (e.g., synurophytes from chrysophytes, or eustigmatophytes from xanthophytes), haptophytes (from chrysophytes), and chlorarachniophytes (from xanthophytes).
With the abandonment of plant-animal dichotomous classification, most groups of algae (sometimes all) were included in Protista, later also abandoned in favour of Eukaryota. However, as a legacy of the older plant life scheme, some groups that were also treated as protozoans in the past still have duplicated classifications (see ambiregnal protists).
Some parasitic algae (e.g., the green algae "Prototheca" and "Helicosporidium", parasites of metazoans, or "Cephaleuros", parasites of plants) were originally classified as fungi, sporozoans, or protistans of "incertae sedis", while others (e.g., the green algae "Phyllosiphon" and "Rhodochytrium", parasites of plants, or the red algae "Pterocladiophila" and "Gelidiocolax mammillatus", parasites of other red algae, or the dinoflagellates "Oodinium", parasites of fish) had their relationship with algae conjectured early. In other cases, some groups were originally characterized as parasitic algae (e.g., "Chlorochytrium"), but later were seen as endophytic algae. Some filamentous bacteria (e.g., "Beggiatoa") were originally seen as algae. Furthermore, groups like the apicomplexans are also parasites derived from ancestors that possessed plastids, but are not included in any group traditionally seen as algae.
<h2>Relationship to land plants.</h2>
The first land plants probably evolved from shallow freshwater charophyte algae much like "Chara" almost 500 million years ago. These probably had an isomorphic alternation of generations and were probably filamentous. Fossils of isolated land plant spores suggest land plants may have been around as long as 475 million years ago.
<h2>Morphology.</h2>
A range of algal morphologies is exhibited, and convergence of features in unrelated groups is common. The only groups to exhibit three-dimensional multicellular thalli are the reds and browns, and some chlorophytes. Apical growth is constrained to subsets of these groups: the florideophyte reds, various browns, and the charophytes. The form of charophytes is quite different from those of reds and browns, because they have distinct nodes, separated by internode 'stems'; whorls of branches reminiscent of the horsetails occur at the nodes. Conceptacles are another polyphyletic trait; they appear in the coralline algae and the Hildenbrandiales, as well as the browns.
Most of the simpler algae are unicellular flagellates or amoeboids, but colonial and nonmotile forms have developed independently among several of the groups. Some of the more common organizational levels, more than one of which may occur in the lifecycle of a species, are
In three lines, even higher levels of organization have been reached, with full tissue differentiation. These are the brown algae,—some of which may reach 50 m in length (kelps)—the red algae, and the green algae. The most complex forms are found among the green algae (see Charales and Charophyta), in a lineage that eventually led to the higher land plants. The point where these nonalgal plants begin and algae stop is usually taken to be the presence of reproductive organs with protective cell layers, a characteristic not found in the other algal groups.
<h2>Physiology.</h2>
Many algae, particularly members of the Characeae, have served as model experimental organisms to understand the mechanisms of the water permeability of membranes, osmoregulation, turgor regulation, salt tolerance, cytoplasmic streaming, and the generation of action potentials.
Phytohormones are found not only in higher plants, but in algae, too.
<h2>Symbiotic algae.</h2>
Some species of algae form symbiotic relationships with other organisms. In these symbioses, the algae supply photosynthates (organic substances) to the host organism providing protection to the algal cells. The host organism derives some or all of its energy requirements from the algae. Examples are:
<h3>Lichens.</h3>
Lichens are defined by the International Association for Lichenology to be "an association of a fungus and a photosynthetic symbiont resulting in a stable vegetative body having a specific structure." The fungi, or mycobionts, are mainly from the Ascomycota with a few from the Basidiomycota. They are not found alone in nature; but when they began to associate is not known. One mycobiont associates with the same phycobiont species, rarely two, from the green algae, except that alternatively, the mycobiont may associate with a species of cyanobacteria (hence "photobiont" is the more accurate term). A photobiont may be associated with many different mycobionts or may live independently; accordingly, lichens are named and classified as fungal species. The association is termed a morphogenesis because the lichen has a form and capabilities not possessed by the symbiont species alone (they can be experimentally isolated). The photobiont possibly triggers otherwise latent genes in the mycobiont.
<h3>Coral reefs.</h3>
 Coral reefs are accumulated from the calcareous exoskeletons of marine invertebrates of the order Scleractinia (stony corals). These animals metabolize sugar and oxygen to obtain energy for their cell-building processes, including secretion of the exoskeleton, with water and carbon dioxide as byproducts. Dinoflagellates (algal protists) are often endosymbionts in the cells of the coral-forming marine invertebrates, where they accelerate host-cell metabolism by generating immediately available sugar and oxygen through photosynthesis using incident light and the carbon dioxide produced by the host. Reef-building stony corals (hermatypic corals) require endosymbiotic algae from the genus "Symbiodinium" to be in a healthy condition. The loss of "Symbiodinium" from the host is known as coral bleaching, a condition which leads to the deterioration of a reef.
<h3>Sea sponges.</h3>
Green algae live close to the surface of some sponges, for example, breadcrumb sponge ("Halichondria panicea"). The alga is thus protected from predators; the sponge is provided with oxygen and sugars which can account for 50 to 80% of sponge growth in some species.
<h2>Lifecycle.</h2>
Rhodophyta, Chlorophyta, and Heterokontophyta, the three main algal divisions, have lifecycles which show considerable variation and complexity. In general, an asexual phase exists where the seaweed's cells are diploid, a sexual phase where the cells are haploid, followed by fusion of the male and female gametes. Asexual reproduction permits efficient population increases, but less variation is possible. Commonly, in sexual reproduction of unicellular and colonial algae, two specialized, sexually compatible, haploid gametes make physical contact and fuse to form a zygote. To ensure a successful mating, the development and release of gametes is highly synchronized and regulated; pheromones may play a key role in these processes. Sexual reproduction allows for more variation and provides the benefit of efficient recombinational repair of DNA damages during meiosis, a key stage of the sexual cycle. However, sexual reproduction is more costly than asexual reproduction. Meiosis has been shown to occur in many different species of algae.
<h2>Numbers.</h2>
The "Algal Collection of the US National Herbarium" (located in the National Museum of Natural History) consists of approximately 320,500 dried specimens, which, although not exhaustive (no exhaustive collection exists), gives an idea of the order of magnitude of the number of algal species (that number remains unknown). Estimates vary widely. For example, according to one standard textbook, in the British Isles the "UK Biodiversity Steering Group Report" estimated there to be 20000 algal species in the UK. Another checklist reports only about 5000 species. Regarding the difference of about 15000 species, the text concludes: "It will require many detailed field surveys before it is possible to provide a reliable estimate of the total number of species ..."
Regional and group estimates have been made, as well:
and so on, but lacking any scientific basis or reliable sources, these numbers have no more credibility than the British ones mentioned above. Most estimates also omit microscopic algae, such as phytoplankton.
The most recent estimate suggests 72,500 algal species worldwide.
<h2>Distribution.</h2>
The distribution of algal species has been fairly well studied since the founding of phytogeography in the mid-19th century. Algae spread mainly by the dispersal of spores analogously to the dispersal of Plantae by seeds and spores. This dispersal can be accomplished by air, water, or other organisms. Due to this, spores can be found in a variety of environments: fresh and marine waters, air, soil, and in or on other organisms. Whether a spore is to grow into an organism depends on the combination of the species and the environmental conditions where the spore lands.
The spores of freshwater algae are dispersed mainly by running water and wind, as well as by living carriers. However, not all bodies of water can carry all species of algae, as the chemical composition of certain water bodies limits the algae that can survive within them. Marine spores are often spread by ocean currents. Ocean water presents many vastly different habitats based on temperature and nutrient availability, resulting in phytogeographic zones, regions, and provinces.
To some degree, the distribution of algae is subject to floristic discontinuities caused by geographical features, such as Antarctica, long distances of ocean or general land masses. It is, therefore, possible to identify species occurring by locality, such as "Pacific algae" or "North Sea algae". When they occur out of their localities, hypothesizing a transport mechanism is usually possible, such as the hulls of ships. For example, "Ulva reticulata" and "U. fasciata" travelled from the mainland to Hawaii in this manner.
Mapping is possible for select species only: "there are many valid examples of confined distribution patterns." For example, "Clathromorphum" is an arctic genus and is not mapped far south of there. However, scientists regard the overall data as insufficient due to the "difficulties of undertaking such studies."
<h2>Ecology.</h2>
Algae are prominent in bodies of water, common in terrestrial environments, and are found in unusual environments, such as on snow and ice. Seaweeds grow mostly in shallow marine waters, under deep; however, some have been recorded to a depth of .
The various sorts of algae play significant roles in aquatic ecology. Microscopic forms that live suspended in the water column (phytoplankton) provide the food base for most marine food chains. In very high densities (algal blooms), these algae may discolor the water and outcompete, poison, or asphyxiate other life forms.
Algae can be used as indicator organisms to monitor pollution in various aquatic systems. In many cases, algal metabolism is sensitive to various pollutants. Due to this, the species composition of algal populations may shift in the presence of chemical pollutants. To detect these changes, algae can be sampled from the environment and maintained in laboratories with relative ease.
On the basis of their habitat, algae can be categorized as: aquatic (planktonic, benthic, marine, freshwater), terrestrial, aerial (subareial), lithophytic, halophytic (or euryhaline), psammon, thermophilic, cryophilic, epibiont (epiphytic, epizoic), endosymbiont (endophytic, endozoic), parasitic, calcifilic or lichenic (phycobiont).
<h2>Cultural associations.</h2>
In classical Chinese, the word is used both for "algae" and (in the modest tradition of the imperial scholars) for "literary talent". The third island in Kunming Lake beside the Summer Palace in Beijing is known as the Zaojian Tang Dao, which thus simultaneously means "Island of the Algae-Viewing Hall" and "Island of the Hall for Reflecting on Literary Talent".
<h2>Uses.</h2>
<h3>Agar.</h3>
Agar, a gelatinous substance derived from red algae, has a number of commercial uses. It is a good medium on which to grow bacteria and fungi, as most microorganisms cannot digest agar.
<h3>Alginates.</h3>
Alginic acid, or alginate, is extracted from brown algae. Its uses range from gelling agents in food, to medical dressings. Alginic acid also has been used in the field of biotechnology as a biocompatible medium for cell encapsulation and cell immobilization. Molecular cuisine is also a user of the substance for its gelling properties, by which it becomes a delivery vehicle for flavours.
Between 100,000 and 170,000 wet tons of "Macrocystis" are harvested annually in New Mexico for alginate extraction and abalone feed.
<h3>Energy source.</h3>
To be competitive and independent from fluctuating support from (local) policy on the long run, biofuels should equal or beat the cost level of fossil fuels. Here, algae-based fuels hold great promise, directly related to the potential to produce more biomass per unit area in a year than any other form of biomass. The break-even point for algae-based biofuels is estimated to occur by 2025.
<h3>Fertilizer.</h3>
For centuries, seaweed has been used as a fertilizer; George Owen of Henllys writing in the 16th century referring to drift weed in South Wales:This kind of ore they often gather and lay on great heapes, where it heteth and rotteth, and will have a strong and loathsome smell; when being so rotten they cast on the land, as they do their muck, and thereof springeth good corn, especially barley ... After spring-tydes or great rigs of the sea, they fetch it in sacks on horse backes, and carie the same three, four, or five miles, and cast it on the lande, which doth very much better the ground for corn and grass.
Today, algae are used by humans in many ways; for example, as fertilizers, soil conditioners, and livestock feed. Aquatic and microscopic species are cultured in clear tanks or ponds and are either harvested or used to treat effluents pumped through the ponds. Algaculture on a large scale is an important type of aquaculture in some places. Maerl is commonly used as a soil conditioner.
<h3>Nutrition.</h3>
Naturally growing seaweeds are an important source of food, especially in Asia. They provide many vitamins including: A, B, B, B, niacin, and C, and are rich in iodine, potassium, iron, magnesium, and calcium. In addition, commercially cultivated microalgae, including both algae and cyanobacteria, are marketed as nutritional supplements, such as spirulina, "Chlorella" and the vitamin-C supplement from "Dunaliella", high in beta-carotene.
Algae are national foods of many nations: China consumes more than 70 species, including "fat choy", a cyanobacterium considered a vegetable; Japan, over 20 species; Ireland, dulse; Chile, cochayuyo. Laver is used to make "laver bread" in Wales, where it is known as "bara lawr"; in Korea, "gim"; in Japan, "nori" and "aonori". It is also used along the west coast of North America from California to British Columbia, in Hawaii and by the Māori of New Zealand. Sea lettuce and badderlocks are salad ingredients in Scotland, Ireland, Greenland, and Iceland.
The oils from some algae have high levels of unsaturated fatty acids. For example, "Parietochloris incisa" is very high in arachidonic acid, where it reaches up to 47% of the triglyceride pool. Some varieties of algae favored by vegetarianism and veganism contain the long-chain, essential omega-3 fatty acids, docosahexaenoic acid (DHA) and eicosapentaenoic acid (EPA). Fish oil contains the omega-3 fatty acids, but the original source is algae (microalgae in particular), which are eaten by marine life such as copepods and are passed up the food chain. Algae have emerged in recent years as a popular source of omega-3 fatty acids for vegetarians who cannot get long-chain EPA and DHA from other vegetarian sources such as flaxseed oil, which only contains the short-chain alpha-linolenic acid (ALA).
Agricultural Research Service scientists found that 60–90% of nitrogen runoff and 70–100% of phosphorus runoff can be captured from manure effluents using a horizontal algae scrubber, also called an algal turf scrubber (ATS). Scientists developed the ATS, which consists of shallow, 100-foot raceways of nylon netting where algae colonies can form, and studied its efficacy for three years. They found that algae can readily be used to reduce the nutrient runoff from agricultural fields and increase the quality of water flowing into rivers, streams, and oceans. Researchers collected and dried the nutrient-rich algae from the ATS and studied its potential as an organic fertilizer. They found that cucumber and corn seedlings grew just as well using ATS organic fertilizer as they did with commercial fertilizers. Algae scrubbers, using bubbling upflow or vertical waterfall versions, are now also being used to filter aquaria and ponds.
<h3>Bioremediation.</h3>
The alga "Stichococcus bacillaris" has been seen to colonize silicone resins used at archaeological sites; biodegrading the synthetic substance.
<h3>Pigments.</h3>
The natural pigments (carotenoids and chlorophylls) produced by algae can be used as alternatives to chemical dyes and coloring agents.
The presence of some individual algal pigments, together with specific pigment concentration ratios, are taxon-specific: analysis of their concentrations with various analytical methods, particularly high-performance liquid chromatography, can therefore offer deep insight into the taxonomic composition and relative abundance of natural alga populations in sea water samples.
<h3>Stabilizing substances.</h3>
Carrageenan, from the red alga "Chondrus crispus", is used as a stabilizer in milk products.

</doc>
<doc id="634" url="https://en.wikipedia.org/wiki?curid=634" title="Analysis of variance">
Analysis of variance

Analysis of variance (ANOVA) is a collection of statistical models used to analyze the differences among group means and their associated procedures (such as "variation" among and between groups), developed by statistician and evolutionary biologist Ronald Fisher. In the ANOVA setting, the observed variance in a particular variable is partitioned into components attributable to different sources of variation. In its simplest form, ANOVA provides a statistical test of whether or not the means of several groups are equal, and therefore generalizes the "t"-test to more than two groups. ANOVAs are useful for comparing (testing) three or more means (groups or variables) for statistical significance. It is conceptually similar to multiple two-sample t-tests, but is more conservative (results in less type I error) and is therefore suited to a wide range of practical problems.
<h2>History.</h2>
While the analysis of variance reached fruition in the 20th century, antecedents extend centuries into the past according to Stigler. These include hypothesis testing, the partitioning of sums of squares, experimental techniques and the additive model. Laplace was performing hypothesis testing in the 1770s. The development of least-squares methods by Laplace and Gauss circa 1800 provided an improved method of combining observations (over the existing practices of astronomy and geodesy). It also initiated much study of the contributions to sums of squares. Laplace soon knew how to estimate a variance from a residual (rather than a total) sum of squares. By 1827 Laplace was using least squares methods to address ANOVA problems regarding measurements of atmospheric tides. Before 1800 astronomers had isolated observational errors resulting 
from reaction times (the "personal equation") and had developed methods of reducing the errors. The experimental methods used in the study of the personal equation were later accepted by the emerging field of psychology which developed strong (full factorial) experimental methods to which randomization and blinding were soon added. An eloquent non-mathematical explanation of the additive effects model was
available in 1885.
Ronald Fisher introduced the term variance and proposed its formal analysis in a 1918 article "The Correlation Between Relatives on the Supposition of Mendelian Inheritance". His first application of the analysis of variance was published in 1921. Analysis of variance became widely known after being included in Fisher's 1925 book "Statistical Methods for Research Workers".
Randomization models were developed by several researchers. The first was published in Polish by Neyman in 1923.
One of the attributes of ANOVA which ensured its early popularity was computational elegance. The structure of the additive model allows solution for the additive coefficients by simple algebra rather than by matrix calculations. In the era of mechanical calculators this simplicity was critical. The determination of statistical significance also required access to tables of the F function which were supplied by early statistics texts.
<h2>Motivating example.</h2>
The analysis of variance can be used as an exploratory tool to explain observations. A dog show provides an example. A dog show is not a random sampling of the breed: it is typically limited to dogs that are adult, pure-bred, and exemplary. A histogram of dog weights from a show might plausibly be rather complex, like the yellow-orange distribution shown in the illustrations. Suppose we wanted to predict the weight of a dog based on a certain set of characteristics of each dog. Before we could do that, we would need to "explain" the distribution of weights by dividing the dog population into groups based on those characteristics. A successful grouping will split dogs such that (a) each group has a low variance of dog weights (meaning the group is relatively homogeneous) and (b) the mean of each group is distinct (if two groups have the same mean, then it isn't reasonable to conclude that the groups are, in fact, separate in any meaningful way).
In the illustrations to the right, each group is identified as "X", "X", etc. In the first illustration, we divide the dogs according to the product (interaction) of two binary groupings: young vs old, and short-haired vs long-haired (thus, group 1 is young, short-haired dogs, group 2 is young, long-haired dogs, etc.). Since the distributions of dog weight within each of the groups (shown in blue) has a large variance, and since the means are very close across groups, grouping dogs by these characteristics does not produce an effective way to explain the variation in dog weights: knowing which group a dog is in does not allow us to make any reasonable statements as to what that dog's weight is likely to be. Thus, this grouping fails to "fit" the distribution we are trying to explain (yellow-orange).
An attempt to explain the weight distribution by grouping dogs as (pet vs working breed) and (less athletic vs more athletic) would probably be somewhat more successful (fair fit). The heaviest show dogs are likely to be big strong working breeds, while breeds kept as pets tend to be smaller and thus lighter. As shown by the second illustration, the distributions have variances that are considerably smaller than in the first case, and the means are more reasonably distinguishable. However, the significant overlap of distributions, for example, means that we cannot reliably say that "X" and "X" are truly distinct (i.e., it is perhaps reasonably likely that splitting dogs according to the flip of a coin—by pure chance—might produce distributions that look similar).
An attempt to explain weight by breed is likely to produce a very good fit. All Chihuahuas are light and all St Bernards are heavy. The difference in weights between Setters and Pointers does not justify separate breeds. The analysis of variance provides the formal tools to justify these intuitive judgments. A common use of the method is the analysis of experimental data or the development of models. The method has some advantages over correlation: not all of the data must be numeric and one result of the method is a judgment in the confidence in an explanatory relationship.
<h2>Background and terminology.</h2>
ANOVA is a particular form of statistical hypothesis testing heavily used in the analysis of experimental data. A test result (calculated from the null hypothesis and the sample) is called statistically significant if it is deemed unlikely to have occurred by chance, "assuming the truth of the null hypothesis". A statistically significant result, when a probability (p-value) is less than a threshold (significance level), justifies the rejection of the null hypothesis, but only if the a priori probability of the null hypothesis is not high.
In the typical application of ANOVA, the null hypothesis is that all groups are simply random samples of the same population. For example, when studying the effect of different treatments on similar samples of patients, the null hypothesis would be that all treatments have the same effect (perhaps none). Rejecting the null hypothesis would imply that different treatments result in altered effects.
By construction, hypothesis testing limits the rate of Type I errors (false positives) to a significance level. Experimenters also wish to limit Type II errors (false negatives). 
The rate of Type II errors depends largely on sample size (the rate will increase for small numbers of samples), significance 
level (when the standard of proof is high, the chances of overlooking 
a discovery are also high) and effect size (a smaller effect size is more prone to Type II error).
The terminology of ANOVA is largely from the statistical 
design of experiments. The experimenter adjusts factors and 
measures responses in an attempt to determine an effect. Factors are 
assigned to experimental units by a combination of randomization and 
blocking to ensure the validity of the results. Blinding keeps the
weighing impartial. Responses show a variability that is partially 
the result of the effect and is partially random error.
ANOVA is the synthesis of several ideas and it is used for multiple 
purposes. As a consequence, it is difficult to define concisely or precisely.
"Classical ANOVA for balanced data does three things at once:
In short, ANOVA is a statistical tool used in several ways to develop and confirm an explanation for the observed data.
Additionally:
As a result:
ANOVA "has long enjoyed the status of being the most used (some would 
say abused) statistical technique in psychological research."
ANOVA "is probably the most useful technique in the field of 
statistical inference."
ANOVA is difficult to teach, particularly for complex experiments, with split-plot designs being notorious. In some cases the proper 
application of the method is best determined by problem pattern recognition 
followed by the consultation of a classic authoritative test.
<h3>Design-of-experiments terms.</h3>
(Condensed from the NIST Engineering Statistics handbook: Section 5.7. A 
Glossary of DOE Terminology.)
<h2>Classes of models.</h2>
There are three classes of models used in the analysis of variance, and these are outlined here.
<h3>Fixed-effects models.</h3>
The fixed-effects model (class I) of analysis of variance applies to situations in which the experimenter applies one or more treatments to the subjects of the experiment to see whether the response variable values change. This allows the experimenter to estimate the ranges of response variable values that the treatment would generate in the population as a whole.
<h3>Random-effects models.</h3>
Random effects model (class II) is used when the treatments are not fixed. This occurs when the various factor levels are sampled from a larger population. Because the levels themselves are random variables, some assumptions and the method of contrasting the treatments (a multi-variable generalization of simple differences) differ from the fixed-effects model.
<h3>Mixed-effects models.</h3>
A mixed-effects model (class III) contains experimental factors of both fixed and random-effects types, with appropriately different interpretations and analysis for the two types.
Example:
Teaching experiments could be performed by a college or university department 
to find a good introductory textbook, with each text considered a 
treatment. The fixed-effects model would compare a list of candidate 
texts. The random-effects model would determine whether important 
differences exist among a list of randomly selected texts. The 
mixed-effects model would compare the (fixed) incumbent texts to 
randomly selected alternatives.
Defining fixed and random effects has proven elusive, with competing 
definitions arguably leading toward a linguistic quagmire.
<h2>Assumptions of ANOVA.</h2>
The analysis of variance has been studied from several approaches, the most common of which uses a linear model that relates the response to the treatments and blocks. Note that the model is linear in parameters but may be nonlinear across factor levels. Interpretation is easy when data is balanced across factors but much deeper understanding is needed for unbalanced data.
<h3>Textbook analysis using a normal distribution.</h3>
The analysis of variance can be presented in terms of a linear model, which makes the following assumptions about the probability distribution of the responses:
The separate assumptions of the textbook model imply that the errors are independently, identically, and normally distributed for fixed effects models, that is, that the errors (formula_1) are independent and
<h3>Randomization-based analysis.</h3>
In a randomized controlled experiment, the treatments are randomly assigned to experimental units, following the experimental protocol. This randomization is objective and declared before the experiment is carried out. The objective random-assignment is used to test the significance of the null hypothesis, following the ideas of C. S. Peirce and Ronald Fisher. This design-based analysis was discussed and developed by Francis J. Anscombe at Rothamsted Experimental Station and by Oscar Kempthorne at Iowa State University. Kempthorne and his students make an assumption of "unit treatment additivity", which is discussed in the books of Kempthorne and David R. Cox.
<h4>Unit-treatment additivity.</h4>
In its simplest form, the assumption of unit-treatment additivity states that the observed response formula_3 from experimental unit formula_4 when receiving treatment formula_5 can be written as the sum of the unit's response formula_6 and the treatment-effect formula_7, that is 
The assumption of unit-treatment additivity implies that, for every treatment formula_5, the formula_5th treatment has exactly the same effect formula_11 on every experiment unit.
The assumption of unit treatment additivity usually cannot be directly falsified, according to Cox and Kempthorne. However, many "consequences" of treatment-unit additivity can be falsified. For a randomized experiment, the assumption of unit-treatment additivity "implies" that the variance is constant for all treatments. Therefore, by contraposition, a necessary condition for unit-treatment additivity is that the variance is constant.
The use of unit treatment additivity and randomization is similar to the design-based inference that is standard in finite-population survey sampling.
<h4>Derived linear model.</h4>
Kempthorne uses the randomization-distribution and the assumption of "unit treatment additivity" to produce a "derived linear model", very similar to the textbook model discussed previously. The test statistics of this derived linear model are closely approximated by the test statistics of an appropriate normal linear model, according to approximation theorems and simulation studies. However, there are differences. For example, the randomization-based analysis results in a small but (strictly) negative correlation between the observations. In the randomization-based analysis, there is "no assumption" of a "normal" distribution and certainly "no assumption" of "independence". On the contrary, "the observations are dependent"!
The randomization-based analysis has the disadvantage that its exposition involves tedious algebra and extensive time. Since the randomization-based analysis is complicated and is closely approximated by the approach using a normal linear model, most teachers emphasize the normal linear model approach. Few statisticians object to model-based analysis of balanced randomized experiments.
<h4>Statistical models for observational data.</h4>
However, when applied to data from non-randomized experiments or observational studies, model-based analysis lacks the warrant of randomization. For observational data, the derivation of confidence intervals must use "subjective" models, as emphasized by Ronald Fisher and his followers. In practice, the estimates of treatment-effects from observational studies generally are often inconsistent. In practice, "statistical models" and observational data are useful for suggesting hypotheses that should be treated very cautiously by the public.
<h3>Summary of assumptions.</h3>
The normal-model based ANOVA analysis assumes the independence, normality and 
homogeneity of the variances of the residuals. The 
randomization-based analysis assumes only the homogeneity of the 
variances of the residuals (as a consequence of unit-treatment 
additivity) and uses the randomization procedure of the experiment. 
Both these analyses require homoscedasticity, as an assumption for the normal-model analysis and as a consequence of randomization and additivity for the randomization-based analysis.
However, studies of processes that 
change variances rather than means (called dispersion effects) have 
been successfully conducted using ANOVA. There are
"no" necessary assumptions for ANOVA in its full generality, but the
F-test used for ANOVA hypothesis testing has assumptions and practical 
limitations which are of continuing interest.
Problems which do not satisfy the assumptions of ANOVA can often be transformed to satisfy the assumptions. 
The property of unit-treatment additivity is not invariant under a "change of scale", so statisticians often use transformations to achieve unit-treatment additivity. If the response variable is expected to follow a parametric family of probability distributions, then the statistician may specify (in the protocol for the experiment or observational study) that the responses be transformed to stabilize the variance. Also, a statistician may specify that logarithmic transforms be applied to the responses, which are believed to follow a multiplicative model.
According to Cauchy's functional equation theorem, the logarithm is the only continuous transformation that transforms real multiplication to addition.
<h2>Characteristics of ANOVA.</h2>
ANOVA is used in the analysis of comparative experiments, those in 
which only the difference in outcomes is of interest. The statistical
significance of the experiment is determined by a ratio of two 
variances. This ratio is independent of several possible alterations
to the experimental observations: Adding a constant to all 
observations does not alter significance. Multiplying all 
observations by a constant does not alter significance. So ANOVA 
statistical significance result is independent of constant bias and 
scaling errors as well as the units used in expressing observations. 
In the era of mechanical calculation it was common to 
subtract a constant from all observations (when equivalent to 
dropping leading digits) to simplify data entry. This is an example of data
coding.
<h2>Logic of ANOVA.</h2>
The calculations of ANOVA can be characterized as computing a number
of means and variances, dividing two variances and comparing the ratio 
to a handbook value to determine statistical significance. Calculating 
a treatment effect is then trivial, "the effect of any treatment is 
estimated by taking the difference between the mean of the 
observations which receive the treatment and the general mean."
<h3>Partitioning of the sum of squares.</h3>
ANOVA uses traditional standardized terminology. The definitional 
equation of sample variance is
formula_12, where the 
divisor is called the degrees of freedom (DF), the summation is called 
the sum of squares (SS), the result is called the mean square (MS) and 
the squared terms are deviations from the sample mean. ANOVA 
estimates 3 sample variances: a total variance based on all the 
observation deviations from the grand mean, an error variance based on 
all the observation deviations from their appropriate 
treatment means and a treatment variance. The treatment variance is
based on the deviations of treatment means from the grand mean, the 
result being multiplied by the number of observations in each 
treatment to account for the difference between the variance of 
observations and the variance of means.
The fundamental technique is a partitioning of the total sum of squares "SS" into components related to the effects used in the model. For example, the model for a simplified ANOVA with one type of treatment at different levels.
The number of degrees of freedom "DF" can be partitioned in a similar way: one of these components (that for error) specifies a chi-squared distribution which describes the associated sum of squares, while the same is true for "treatments" if there is no treatment effect.
See also Lack-of-fit sum of squares.
<h3>The F-test.</h3>
The F-test is used for comparing the factors of the total deviation. For example, in one-way, or single-factor ANOVA, statistical significance is tested for by comparing the F test statistic
where "MS" is mean square, formula_17 = number of treatments and 
formula_18 = total number of cases
to the F-distribution with formula_19, formula_20 degrees of freedom. Using the F-distribution is a natural candidate because the test statistic is the ratio of two scaled sums of squares each of which follows a scaled chi-squared distribution.
The expected value of F is formula_21 (where n is the treatment sample size)
which is 1 for no treatment effect. As values of F increase above 1, the evidence is increasingly inconsistent with the null hypothesis. Two apparent experimental methods of increasing F are increasing the sample size and reducing the error variance by tight experimental controls.
There are two methods of concluding the ANOVA hypothesis test, both of which produce the same result:
The ANOVA F-test is known to be nearly optimal in the sense of minimizing false negative errors for a fixed rate of false positive errors (i.e. maximizing power for a fixed significance level). For example, to test the hypothesis that various medical treatments have exactly the same effect, the F-test's p-values closely approximate the permutation test's p-values: The approximation is particularly close when the design is balanced. Such permutation tests characterize tests with maximum power against all alternative hypotheses, as observed by Rosenbaum. The ANOVA F–test (of the null-hypothesis that all treatments have exactly the same effect) is recommended as a practical test, because of its robustness against many alternative distributions.
<h3>Extended logic.</h3>
ANOVA consists of separable parts; partitioning sources of variance 
and hypothesis testing can be used individually. ANOVA is used to 
support other statistical tools. Regression is first used to fit more 
complex models to data, then ANOVA is used to compare models with the 
objective of selecting simple(r) models that adequately describe the 
data. "Such models could be fit without any reference to ANOVA, but 
ANOVA tools could then be used to make some sense of the fitted models, 
and to test hypotheses about batches of coefficients." 
"[W]e think of the analysis of variance as a way of understanding and structuring 
multilevel models—not as an alternative to regression but as a tool 
for summarizing complex high-dimensional inferences ..."
<h2>ANOVA for a single factor.</h2>
The simplest experiment suitable for ANOVA analysis is the completely 
randomized experiment with a single factor. More complex experiments 
with a single factor involve constraints on randomization and include 
completely randomized blocks and Latin squares (and variants: 
Graeco-Latin squares, etc.). The more complex experiments share many 
of the complexities of multiple factors. A relatively complete 
discussion of the analysis (models, data summaries, ANOVA table) of 
the completely randomized experiment is 
available.
<h2>ANOVA for multiple factors.</h2>
ANOVA generalizes to the study of the effects of multiple factors. 
When the experiment includes observations at all combinations of 
levels of each factor, it is termed factorial. 
Factorial experiments 
are more efficient than a series of single factor experiments and the 
efficiency grows as the number of factors increases. Consequently, factorial designs are heavily used.
The use of ANOVA to study the effects of multiple factors has a complication. In a 3-way ANOVA with factors x, y and z, the ANOVA model includes terms for the main effects (x, y, z) and terms for interactions (xy, xz, yz, xyz). 
All terms require hypothesis tests. The proliferation of interaction terms increases the risk that some hypothesis test will produce a false positive by chance. Fortunately, experience says that high order interactions are rare. 
The ability to detect interactions is a major advantage of multiple 
factor ANOVA. Testing one factor at a time hides interactions, but 
produces apparently inconsistent experimental results.
Caution is advised when encountering interactions; Test 
interaction terms first and expand the analysis beyond ANOVA if 
interactions are found. Texts vary in their recommendations regarding 
the continuation of the ANOVA procedure after encountering an 
interaction. Interactions complicate the interpretation of 
experimental data. Neither the calculations of significance nor the 
estimated treatment effects can be taken at face value. "A 
significant interaction will often mask the significance of main effects." Graphical methods are recommended
to enhance understanding. Regression is often useful. A lengthy discussion of interactions is available in Cox (1958). Some interactions can be removed (by transformations) while others cannot.
A variety of techniques are used with multiple factor ANOVA to reduce expense. One technique used in factorial designs is to minimize replication (possibly no replication with support of analytical trickery) and to combine groups when effects are found to be statistically (or practically) insignificant. An experiment with many insignificant factors may collapse into one with a few factors supported by many replications.
<h2>Worked numeric examples.</h2>
Several fully worked numerical examples are available. A 
simple case uses one-way (a single factor) analysis. A more complex case uses two-way (two-factor) analysis.
<h2>Associated analysis.</h2>
Some analysis is required in support of the "design" of the experiment while other analysis is performed after changes in the factors are formally found to produce statistically significant changes in the responses. Because experimentation is iterative, the results of one experiment alter plans for following experiments.
<h3>Preparatory analysis.</h3>
<h4>The number of experimental units.</h4>
In the design of an experiment, the number of experimental units is planned to satisfy the goals of the experiment. Experimentation is often sequential.
Early experiments are often designed to provide mean-unbiased estimates of treatment effects and of experimental error. Later experiments are often designed to test a hypothesis that a treatment effect has an important magnitude; in this case, the number of experimental units is chosen so that the experiment is within budget and has adequate power, among other goals.
Reporting sample size analysis is generally required in psychology. "Provide information on sample size and the process that led to sample size decisions." The analysis, which is written in the experimental protocol before the experiment is conducted, is examined in grant applications and administrative review boards.
Besides the power analysis, there are less formal methods for selecting the number of experimental units. These include graphical methods based on limiting
the probability of false negative errors, graphical methods based on an expected variation increase (above the residuals) and methods based on achieving a desired confident interval.
<h4>Power analysis.</h4>
Power analysis is often applied in the context of ANOVA in order to assess the probability of successfully rejecting the null hypothesis if we assume a certain ANOVA design, effect size in the population, sample size and significance level. Power analysis can assist in study design by determining what sample size would be required in order to have a reasonable chance of rejecting the null hypothesis when the alternative hypothesis is true.
<h4>Effect size.</h4>
Several standardized measures of effect have been proposed for ANOVA to summarize the strength of the association between a predictor(s) and the dependent variable (e.g., η, ω, or ƒ) or the overall standardized difference (Ψ) of the complete model. Standardized effect-size estimates facilitate comparison of findings across studies and disciplines. However, while standardized effect sizes are commonly used in much of the professional literature, a non-standardized measure of effect size that has immediately "meaningful" units may be preferable for reporting purposes.
<h3>Follow-up analysis.</h3>
It is always appropriate to carefully consider outliers. They have a disproportionate impact on statistical conclusions and are often the result of errors.
<h4>Model confirmation.</h4>
It is prudent to verify that the assumptions of ANOVA have been met. Residuals are examined or analyzed to confirm homoscedasticity and gross normality. Residuals should have the appearance of (zero mean normal distribution) noise when plotted as a function of anything including time and 
modeled data values. Trends hint at interactions among factors or among observations. One rule of thumb: "If the largest standard deviation is less than twice the smallest standard deviation, we can use methods based on the assumption of equal standard deviations and our results 
will still be approximately correct."
<h4>Follow-up tests.</h4>
A statistically significant effect in ANOVA is often followed up with one or more different follow-up tests. This can be done in order to assess which groups are different from which other groups or to test various other focused hypotheses. Follow-up tests are often distinguished in terms of whether they are planned (a priori) or post hoc. Planned tests are determined before looking at the data and post hoc tests are performed after looking at the data.
Often one of the "treatments" is none, so the treatment group can act as a control. Dunnett's test (a modification of the t-test) tests whether each of the other treatment groups has the same 
mean as the control.
Post hoc tests such as Tukey's range test most commonly compare every group mean with every other group mean and typically incorporate some method of controlling for Type I errors. Comparisons, which are most commonly planned, can be either simple or compound. Simple comparisons compare one group mean with one other group mean. Compound comparisons typically compare two sets of groups means where one set has two or more groups (e.g., compare average group means of group A, B and C with group D). Comparisons can also look at tests of trend, such as linear and quadratic relationships, when the independent variable involves ordered levels.
Following ANOVA with pair-wise multiple-comparison tests has been criticized on several grounds. There are many such tests (10 in one table) and recommendations regarding their use are vague or conflicting.
<h2>Study designs and ANOVAs.</h2>
There are several types of ANOVA. Many statisticians base ANOVA on the design of the experiment, especially on the protocol that specifies the random assignment of treatments to subjects; the protocol's description of the assignment mechanism should include a specification of the structure of the treatments and of any blocking. It is also common to apply ANOVA to observational data using an appropriate statistical model.
Some popular designs use the following types of ANOVA:
<h2>ANOVA cautions.</h2>
Balanced experiments (those with an equal sample size for each treatment) are relatively easy to interpret; Unbalanced 
experiments offer more complexity. For single factor (one way) ANOVA, the adjustment for unbalanced data is easy, but the unbalanced analysis lacks both robustness and power. For more complex designs the lack of balance leads to further complications. "The orthogonality property of main effects and interactions present in balanced data does not carry over to the unbalanced case. This means that the usual analysis of variance techniques do not apply. 
Consequently, the analysis of unbalanced factorials is much more difficult than that for balanced designs." In the general case, "The analysis of variance can also be applied to unbalanced data, but then the sums of squares, mean squares, and F-ratios will depend on the order in which the sources of variation 
are considered." The simplest techniques for handling unbalanced data restore balance by either throwing out data or by synthesizing missing data. More complex techniques use regression.
ANOVA is (in part) a significance test. The American Psychological Association holds the view that simply reporting significance is insufficient and that reporting confidence bounds is preferred.
While ANOVA is conservative (in maintaining a significance level) against multiple comparisons in one dimension, it is not conservative against comparisons in multiple dimensions.
<h2>Generalizations.</h2>
ANOVA is considered to be a special case of linear regression which in turn is a special case of the general linear model. All consider the observations to be the sum of a model (fit) and a residual (error) to be minimized.
The Kruskal–Wallis test and the Friedman test are nonparametric tests, which do not rely on an assumption of normality.
<h3>Connection to Linear Regression.</h3>
Below we make clear the connection between multi-way ANOVA and linear regression. Linearly re-order the data so that formula_22 observation is associated with a response formula_23 and factors formula_24 where formula_25 denotes the different factors and formula_26 is the total number of factors. In one-way ANOVA formula_27 and in two-way ANOVA formula_28. Furthermore, we assume the formula_29 factor has formula_30 levels. Now, we can one-hot encode the factors into the formula_31 dimensional vector formula_32.
The one-hot encoding function formula_33 is defined such that the formula_34 entry of formula_35 is
formula_36
The vector formula_32 is the concatenation of all of the above vectors for all formula_38. Thus, formula_39. In order to obtain a fully general formula_26-way interaction ANOVA we must also concatenate every additional interaction term in the vector formula_32 and then add an intercept term. Let that vector be formula_42.
With this notation in place, we now have the exact connection with linear regression. We simply regress response formula_23 against the vector formula_44. However, there is a concern about identifiability. In order to overcome such issues we assume that the sum of the parameters within each set of interactions is equal to zero. From here, one can use F-statistics or other methods to determine the relevance of the individual factors.
<h4>Example.</h4>
We can consider the 2-way interaction example where we assume that the first factor has 2 levels and the second factor has 3 levels.
Define formula_45 if formula_46 and formula_47 if formula_48, i.e. formula_49 is the one-hot encoding of the first factor and formula_38 is the one-hot encoding of the second factor.
With that,
formula_51
where the last term is an intercept term. For a more concrete example suppose that
formula_52
Then,
formula_53

</doc>
<doc id="639" url="https://en.wikipedia.org/wiki?curid=639" title="Alkane">
Alkane

In organic chemistry, an alkane, or paraffin (a historical name that also has other meanings), is an acyclic saturated hydrocarbon. In other words, an alkane consists of hydrogen and carbon atoms arranged in a tree structure in which all the carbon-carbon bonds are single. Alkanes have the general chemical formula . For example, the case of "n" = 1 is CH, which is methane.
Besides this standard definition by the International Union of Pure and Applied Chemistry, in some authors' usage the term "alkane" is applied to any saturated hydrocarbon, including those that are either monocyclic (i.e., the cycloalkanes) or polycyclic.
In an alkane, each carbon atom has 4 bonds (either C-C or C-H), and each hydrogen atom is joined to one of the carbon atoms (so in a C-H bond). A longest series of linked carbon atoms in the molecule is known as its carbon skeleton or carbon backbone. The number of carbon atoms may be thought of as the size of the alkane, so one might speak for instance of a "C alkane."
The alkanes range in complexity from the simplest case of methane, CH (sometimes called the parent molecule), to arbitrarily large molecules. One group of the higher alkanes are waxes for which the number of carbons in the carbon backbone is greater than about 17. Beyond that the compounds are solids at standard ambient temperature and pressure (SATP).
With their repeated -CH- units, the alkanes constitute a homologous series of organic compounds in which the members differ in molecular mass by multiples of 14.03 u (the total mass of each such methylene-bridge unit, which comprises a single carbon atom of mass 12.01 u and two hydrogen atoms of mass ~1.01 u each).
Alkanes are not very reactive and have little biological activity. They can be viewed as molecular trees upon which can be hung the more active/reactive functional groups of biological molecules.
The alkanes have two main commercial sources: petroleum (crude oil) and natural gas.
An alkyl group, generally abbreviated with the symbol R, is a functional group that, like an alkane, consists solely of single-bonded carbon and hydrogen atoms connected acyclically—for example a methyl or ethyl group.
<h2>Structure classification.</h2>
Saturated hydrocarbons are hydrocarbons having only single covalent bonds between their carbons. They can be:
According to the definition by IUPAC, the former two are alkanes, whereas the third group is called cycloalkanes. Saturated hydrocarbons can also combine any of the linear, cyclic (e.g., polycyclic) and branching structures; the general formula is , where "k" is the number of independent loops. Alkanes are the acyclic (loopless) ones, corresponding to "k" = 0.
<h2>Isomerism.</h2>
Alkanes with more than three carbon atoms can be arranged in various different ways, forming structural isomers. The simplest isomer of an alkane is the one in which the carbon atoms are arranged in a single chain with no branches. This isomer is sometimes called the "n"-isomer ("n" for "normal", although it is not necessarily the most common). However the chain of carbon atoms may also be branched at one or more points. The number of possible isomers increases rapidly with the number of carbon atoms. For example:
Branched alkanes can be chiral. For example, 3-methylhexane and its higher homologues are chiral due to their stereogenic center at carbon atom number 3. In addition to the alkane isomers, the chain of carbon atoms may form one or more loops. Such compounds are called cycloalkanes.
<h2>Nomenclature.</h2>
The IUPAC nomenclature (systematic way of naming compounds) for alkanes is based on identifying hydrocarbon chains. Unbranched, saturated hydrocarbon chains are named systematically with a Greek numerical prefix denoting the number of carbons and the suffix "-ane".
In 1866, August Wilhelm von Hofmann suggested systematizing nomenclature by using the whole sequence of vowels a, e, i, o and u to create suffixes -ane, -ene, -ine (or -yne), -one, -une, for the hydrocarbons CH, CH, CH, CH, CH. Now, the first three name hydrocarbons with single, double and triple bonds; "-one" represents a ketone; "-ol" represents an alcohol or OH group; "-oxy-" means an ether and refers to oxygen between two carbons, so that methoxymethane is the IUPAC name for dimethyl ether.
It is difficult or impossible to find compounds with more than one IUPAC name. This is because shorter chains attached to longer chains are prefixes and the convention includes brackets. Numbers in the name, referring to which carbon a group is attached to, should be as low as possible, so that 1- is implied and usually omitted from names of organic compounds with only one side-group. Symmetric compounds will have two ways of arriving at the same name.
<h3>Linear alkanes.</h3>
Straight-chain alkanes are sometimes indicated by the prefix ""n"-" (for "normal") where a non-linear isomer exists. Although this is not strictly necessary, the usage is still common in cases where there is an important difference in properties between the straight-chain and branched-chain isomers, e.g., "n"-hexane or 2- or 3-methylpentane. Alternative names for this group are: linear paraffins or "n"-paraffins.
The members of the series (in terms of number of carbon atoms) are named as follows:
The first four names were derived from methanol, ether, propionic acid and butyric acid, respectively. Alkanes with five or more carbon atoms are named by adding the suffix -ane to the appropriate numerical multiplier prefix with elision of any terminal vowel ("-a" or "-o") from the basic numerical term. Hence, pentane, CH; hexane, CH; heptane, CH; octane, CH; etc. The prefix is generally Greek, however alkanes with a carbon atom count ending in nine, for example nonane, use the Latin prefix non-. For a more complete list, see List of alkanes.
<h3>Branched alkanes.</h3>
Simple branched alkanes often have a common name using a prefix to distinguish them from linear alkanes, for example "n"-pentane, isopentane, and neopentane.
IUPAC naming conventions can be used to produce a systematic name.
The key steps in the naming of more complicated branched alkanes are as follows:
<h3>Saturated cyclic hydrocarbons.</h3>
Though technically distinct from the alkanes, this class of hydrocarbons is referred to by some as the "cyclic alkanes." As their description implies, they contain one or more rings.
Simple cycloalkanes have a prefix "cyclo-" to distinguish them from alkanes. Cycloalkanes are named as per their acyclic counterparts with respect to the number of carbon atoms in their backbones, e.g., cyclopentane (CH) is a cycloalkane with 5 carbon atoms just like pentane (CH), but they are joined up in a five-membered ring. In a similar manner, propane and cyclopropane, butane and cyclobutane, etc.
Substituted cycloalkanes are named similarly to substituted alkanes — the cycloalkane ring is stated, and the substituents are according to their position on the ring, with the numbering decided by the Cahn–Ingold–Prelog priority rules.
<h3>Trivial/common names.</h3>
The trivial (non-systematic) name for alkanes is "paraffins". Together, alkanes are known as the "paraffin series". Trivial names for compounds are usually historical artifacts. They were coined before the development of systematic names, and have been retained due to familiar usage in industry. Cycloalkanes are also called naphthenes.
It is almost certain that the term "paraffin" stems from the petrochemical industry. Branched-chain alkanes are called "isoparaffins". The use of the term "paraffin" is a general term and often does not distinguish between pure compounds and mixtures of isomers, i.e., compounds with the same chemical formula, e.g., pentane and isopentane.
The following trivial names are retained in the IUPAC system:
<h2>Physical properties.</h2>
All alkanes are colourless and odourless.
<h3>Boiling point.</h3>
Alkanes experience intermolecular van der Waals forces. Stronger intermolecular van der Waals forces give rise to greater boiling points of alkanes.
There are two determinants for the strength of the van der Waals forces:
Under standard conditions, from CH to CH alkanes are gaseous; from CH to CH they are liquids; and after CH they are solids. As the boiling point of alkanes is primarily determined by weight, it should not be a surprise that the boiling point has almost a linear relationship with the size (molecular weight) of the molecule. As a rule of thumb, the boiling point rises 20–30 °C for each carbon added to the chain; this rule applies to other homologous series.
A straight-chain alkane will have a boiling point higher than a branched-chain alkane due to the greater surface area in contact, thus the greater van der Waals forces, between adjacent molecules. For example, compare isobutane (2-methylpropane) and n-butane (butane), which boil at −12 and 0 °C, and 2,2-dimethylbutane and 2,3-dimethylbutane which boil at 50 and 58 °C, respectively. For the latter case, two molecules 2,3-dimethylbutane can "lock" into each other better than the cross-shaped 2,2-dimethylbutane, hence the greater van der Waals forces.
On the other hand, cycloalkanes tend to have higher boiling points than their linear counterparts due to the locked conformations of the molecules, which give a plane of intermolecular contact.
<h3>Melting points.</h3>
The melting points of the alkanes follow a similar trend to boiling points for the same reason as outlined above. That is, (all other things being equal) the larger the molecule the higher the melting point. There is one significant difference between boiling points and melting points. Solids have more rigid and fixed structure than liquids. This rigid structure requires energy to break down. Thus the better put together solid structures will require more energy to break apart. For alkanes, this can be seen from the graph above (i.e., the blue line). The odd-numbered alkanes have a lower trend in melting points than even numbered alkanes. This is because even numbered alkanes pack well in the solid phase, forming a well-organized structure, which requires more energy to break apart. The odd-numbered alkanes pack less well and so the "looser" organized solid packing structure requires less energy to break apart.
The melting points of branched-chain alkanes can be either higher or lower than those of the corresponding straight-chain alkanes, again depending on the ability of the alkane in question to pack well in the solid phase: This is particularly true for isoalkanes (2-methyl isomers), which often have melting points higher than those of the linear analogues.
<h3>Conductivity and solubility.</h3>
Alkanes do not conduct electricity, nor are they substantially polarized by an electric field. For this reason they do not form hydrogen bonds and are insoluble in polar solvents such as water. Since the hydrogen bonds between individual water molecules are aligned away from an alkane molecule, the coexistence of an alkane and water leads to an increase in molecular order (a reduction in entropy). As there is no significant bonding between water molecules and alkane molecules, the second law of thermodynamics suggests that this reduction in entropy should be minimized by minimizing the contact between alkane and water: Alkanes are said to be hydrophobic in that they repel water.
Their solubility in nonpolar solvents is relatively good, a property that is called lipophilicity. Different alkanes are, for example, miscible in all proportions among themselves.
The density of the alkanes usually increases with the number of carbon atoms, but remains less than that of water. Hence, alkanes form the upper layer in an alkane–water mixture.
<h3>Molecular geometry.</h3>
The molecular structure of the alkanes directly affects their physical and chemical characteristics. It is derived from the electron configuration of carbon, which has four valence electrons. The carbon atoms in alkanes are always sp hybridized, that is to say that the valence electrons are said to be in four equivalent orbitals derived from the combination of the 2s orbital and the three 2p orbitals. These orbitals, which have identical energies, are arranged spatially in the form of a tetrahedron, the angle of cos(−) ≈ 109.47° between them.
<h3>Bond lengths and bond angles.</h3>
An alkane molecule has only C–H and C–C single bonds. The former result from the overlap of an sp orbital of carbon with the 1s orbital of a hydrogen; the latter by the overlap of two sp orbitals on different carbon atoms. The bond lengths amount to 1.09 × 10 m for a C–H bond and 1.54 × 10 m for a C–C bond.
The spatial arrangement of the bonds is similar to that of the four sp orbitals—they are tetrahedrally arranged, with an angle of 109.47° between them. Structural formulae that represent the bonds as being at right angles to one another, while both common and useful, do not correspond with the reality.
<h3>Conformation.</h3>
The structural formula and the bond angles are not usually sufficient to completely describe the geometry of a molecule. There is a further degree of freedom for each carbon–carbon bond: the torsion angle between the atoms or groups bound to the atoms at each end of the bond. The spatial arrangement described by the torsion angles of the molecule is known as its conformation.
Ethane forms the simplest case for studying the conformation of alkanes, as there is only one C–C bond. If one looks down the axis of the C–C bond, one will see the so-called Newman projection. The hydrogen atoms on both the front and rear carbon atoms have an angle of 120° between them, resulting from the projection of the base of the tetrahedron onto a flat plane. However, the torsion angle between a given hydrogen atom attached to the front carbon and a given hydrogen atom attached to the rear carbon can vary freely between 0° and 360°. This is a consequence of the free rotation about a carbon–carbon single bond. Despite this apparent freedom, only two limiting conformations are important: eclipsed conformation and staggered conformation.
The two conformations, also known as rotamers, differ in energy: The staggered conformation is 12.6 kJ/mol lower in energy (more stable) than the eclipsed conformation (the least stable).
This difference in energy between the two conformations, known as the torsion energy, is low compared to the thermal energy of an ethane molecule at ambient temperature. There is constant rotation about the C–C bond. The time taken for an ethane molecule to pass from one staggered conformation to the next, equivalent to the rotation of one CH group by 120° relative to the other, is of the order of 10 seconds.
The case of higher alkanes is more complex but based on similar principles, with the antiperiplanar conformation always being the most favored around each carbon–carbon bond. For this reason, alkanes are usually shown in a zigzag arrangement in diagrams or in models. The actual structure will always differ somewhat from these idealized forms, as the differences in energy between the conformations are small compared to the thermal energy of the molecules: Alkane molecules have no fixed structural form, whatever the models may suggest.
<h3>Spectroscopic properties.</h3>
Virtually all organic compounds contain carbon–carbon and carbon–hydrogen bonds, and so show some of the features of alkanes in their spectra. Alkanes are notable for having no other groups, and therefore for the "absence" of other characteristic spectroscopic features of different functional group like –OH, –CHO, –COOH etc.
<h4>Infrared spectroscopy.</h4>
The carbon–hydrogen stretching mode gives a strong absorption between 2850 and 2960 cm, while the carbon–carbon stretching mode absorbs between 800 and 1300 cm. The carbon–hydrogen bending modes depend on the nature of the group: methyl groups show bands at 1450 cm and 1375 cm, while methylene groups show bands at 1465 cm and 1450 cm. Carbon chains with more than four carbon atoms show a weak absorption at around 725 cm.
<h4>NMR spectroscopy.</h4>
The proton resonances of alkanes are usually found at "δ" = 0.5–1.5. The carbon-13 resonances depend on the number of hydrogen atoms attached to the carbon: "δ" = 8–30 (primary, methyl, –CH), 15–55 (secondary, methylene, –CH–), 20–60 (tertiary, methyne, C–H) and quaternary. The carbon-13 resonance of quaternary carbon atoms is characteristically weak, due to the lack of nuclear Overhauser effect and the long relaxation time, and can be missed in weak samples, or samples that have not been run for a sufficiently long time.
<h4>Mass spectrometry.</h4>
Alkanes have a high ionization energy, and the molecular ion is usually weak. The fragmentation pattern can be difficult to interpret, but, in the case of branched chain alkanes, the carbon chain is preferentially cleaved at tertiary or quaternary carbons due to the relative stability of the resulting free radicals. The fragment resulting from the loss of a single methyl group ("M" − 15) is often absent, and other fragment are often spaced by intervals of fourteen mass units, corresponding to sequential loss of CH groups.
<h2>Chemical properties.</h2>
Alkanes are only weakly reactive with ionic and other polar substances. The acid dissociation constant (pK) values of all alkanes are above 60, hence they are practically inert to acids and bases (see: carbon acids). This inertness is the source of the term "paraffins" (with the meaning here of "lacking affinity"). In crude oil the alkane molecules have remained chemically unchanged for millions of years.
However redox reactions of alkanes, in particular with oxygen and the halogens, are possible as the carbon atoms are in a strongly reduced condition; in the case of methane, the lowest possible oxidation state for carbon (−4) is reached. Reaction with oxygen ("if" present in sufficient quantity to satisfy the reaction stoichiometry) leads to combustion without any smoke, producing carbon dioxide and water. Free radical halogenation reactions occur with halogens, leading to the production of haloalkanes. In addition, alkanes have been shown to interact with, and bind to, certain transition metal complexes in C–H bond activation.
Free radicals, molecules with unpaired electrons, play a large role in most reactions of alkanes, such as cracking and reformation where long-chain alkanes are converted into shorter-chain alkanes and straight-chain alkanes into branched-chain isomers.
In highly branched alkanes, the bond angle may differ significantly from the optimal value (109.5°) in order to allow the different groups sufficient space. This causes a tension in the molecule, known as steric hindrance, and can substantially increase the reactivity.
<h3>Reactions with oxygen (combustion reaction).</h3>
All alkanes react with oxygen in a combustion reaction, although they become increasingly difficult to ignite as the number of carbon atoms increases. The general equation for complete combustion is:
In the absence of sufficient oxygen, carbon monoxide or even soot can be formed, as shown below:
For example, methane:
See the alkane heat of formation table for detailed data.
The standard enthalpy change of combustion, Δ"H", for alkanes increases by about 650 kJ/mol per CH group. Branched-chain alkanes have lower values of Δ"H" than straight-chain alkanes of the same number of carbon atoms, and so can be seen to be somewhat more stable.
<h3>Reactions with halogens.</h3>
Alkanes react with halogens in a so-called "free radical halogenation" reaction. The hydrogen atoms of the alkane are progressively replaced by halogen atoms. Free radicals are the reactive species that participate in the reaction, which usually leads to a mixture of products. The reaction is highly exothermic, and can lead to an explosion.
These reactions are an important industrial route to halogenated hydrocarbons. There are three steps:
Experiments have shown that all halogenation produces a mixture of all possible isomers, indicating that all hydrogen atoms are susceptible to reaction. The mixture produced, however, is not a statistical mixture: Secondary and tertiary hydrogen atoms are preferentially replaced due to the greater stability of secondary and tertiary free-radicals. An example can be seen in the monobromination of propane:
<h3>Cracking.</h3>
Cracking breaks larger molecules into smaller ones. This can be done with a thermal or catalytic method. The thermal cracking process follows a homolytic mechanism with formation of free-radicals. The catalytic cracking process involves the presence of acid catalysts (usually solid acids such as silica-alumina and zeolites), which promote a heterolytic (asymmetric) breakage of bonds yielding pairs of ions of opposite charges, usually a carbocation and the very unstable hydride anion. Carbon-localized free radicals and cations are both highly unstable and undergo processes of chain rearrangement, C–C scission in position beta (i.e., cracking) and intra- and intermolecular hydrogen transfer or hydride transfer. In both types of processes, the corresponding reactive intermediates (radicals, ions) are permanently regenerated, and thus they proceed by a self-propagating chain mechanism. The chain of reactions is eventually terminated by radical or ion recombination.
<h3>Isomerization and reformation.</h3>
Dragan and his colleague were the first to report about isomerization in alkanes. Isomerization and reformation are processes in which straight-chain alkanes are heated in the presence of a platinum catalyst. In isomerization, the alkanes become branched-chain isomers. In other words, it does not lose any carbons or hydrogens, keeping the same molecular weight. In reformation, the alkanes become cycloalkanes or aromatic hydrocarbons, giving off hydrogen as a by-product. Both of these processes raise the octane number of the substance. Butane is the most common alkane that is put under the process of isomerization, as it makes many branched alkanes with high octane numbers.
<h3>Other reactions.</h3>
Alkanes will react with steam in the presence of a nickel catalyst to give hydrogen. Alkanes can be chlorosulfonated and nitrated, although both reactions require special conditions. The fermentation of alkanes to carboxylic acids is of some technical importance. In the Reed reaction, sulfur dioxide, chlorine and light convert hydrocarbons to sulfonyl chlorides. Nucleophilic Abstraction can be used to separate an alkane from a metal. Alkyl groups can be transferred from one compound to another by transmetalation reactions.
<h2>Occurrence.</h2>
<h3>Occurrence of alkanes in the Universe.</h3>
Alkanes form a small portion of the atmospheres of the outer gas planets such as Jupiter (0.1% methane, 2 ppm ethane), Saturn (0.2% methane, 5 ppm ethane), Uranus (1.99% methane, 2.5 ppm ethane) and Neptune (1.5% methane, 1.5 ppm ethane). Titan (1.6% methane), a satellite of Saturn, was examined by the "Huygens" probe, which indicated that Titan's atmosphere periodically rains liquid methane onto the moon's surface. Also on Titan the Cassini mission has imaged seasonal methane/ethane lakes near the polar regions of Titan. Methane and ethane have also been detected in the tail of the comet Hyakutake. Chemical analysis showed that the abundances of ethane and methane were roughly equal, which is thought to imply that its ices formed in interstellar space, away from the Sun, which would have evaporated these volatile molecules. Alkanes have also been detected in meteorites such as carbonaceous chondrites.
<h3>Occurrence of alkanes on Earth.</h3>
Traces of methane gas (about 0.0002% or 1745 ppb) occur in the Earth's atmosphere, produced primarily by methanogenic microorganisms, such as Archaea in the gut of ruminants.
The most important commercial sources for alkanes are natural gas and oil. Natural gas contains primarily methane and ethane, with some propane and butane: oil is a mixture of liquid alkanes and other hydrocarbons. These hydrocarbons were formed when marine animals and plants (zooplankton and phytoplankton) died and sank to the bottom of ancient seas and were covered with sediments in an anoxic environment and converted over many millions of years at high temperatures and high pressure to their current form. Natural gas resulted thereby for example from the following reaction:
These hydrocarbon deposits, collected in porous rocks trapped beneath impermeable cap rocks, comprise commercial oil fields. They have formed over millions of years and once exhausted cannot be readily replaced. The depletion of these hydrocarbons reserves is the basis for what is known as the energy crisis.
Methane is also present in what is called biogas, produced by animals and decaying matter, which is a possible renewable energy source.
Alkanes have a low solubility in water, so the content in the oceans is negligible; however, at high pressures and low temperatures (such as at the bottom of the oceans), methane can co-crystallize with water to form a solid methane clathrate (methane hydrate). Although this cannot be commercially exploited at the present time, the amount of combustible energy of the known methane clathrate fields exceeds the energy content of all the natural gas and oil deposits put together. Methane extracted from methane clathrate is therefore a candidate for future fuels.
<h3>Biological occurrence.</h3>
Acyclic alkanes occur in nature in various ways.
Certain types of bacteria can metabolize alkanes: they prefer even-numbered carbon chains as they are easier to degrade than odd-numbered chains.
On the other hand, certain archaea, the methanogens, produce large quantities of methane by the metabolism of carbon dioxide or other oxidized organic compounds. The energy is released by the oxidation of hydrogen:
Methanogens are also the producers of marsh gas in wetlands, and release about two billion tonnes of methane per year—the atmospheric content of this gas is produced nearly exclusively by them. The methane output of cattle and other herbivores, which can release up to 150 liters per day, and of termites, is also due to methanogens. They also produce this simplest of all alkanes in the intestines of humans. Methanogenic archaea are, hence, at the end of the carbon cycle, with carbon being released back into the atmosphere after having been fixed by photosynthesis. It is probable that our current deposits of natural gas were formed in a similar way.
Alkanes also play a role, if a minor role, in the biology of the three eukaryotic groups of organisms: fungi, plants and animals. Some specialized yeasts, e.g., "Candida tropicale", "Pichia" sp., "Rhodotorula" sp., can use alkanes as a source of carbon or energy. The fungus "Amorphotheca resinae" prefers the longer-chain alkanes in aviation fuel, and can cause serious problems for aircraft in tropical regions.
In plants, the solid long-chain alkanes are found in the plant cuticle and epicuticular wax of many species, but are only rarely major constituents. They protect the plant against water loss, prevent the leaching of important minerals by the rain, and protect against bacteria, fungi, and harmful insects. The carbon chains in plant alkanes are usually odd-numbered, between 27 and 33 carbon atoms in length and are made by the plants by decarboxylation of even-numbered fatty acids. The exact composition of the layer of wax is not only species-dependent, but changes also with the season and such environmental factors as lighting conditions, temperature or humidity.
More volatile short-chain alkanes are also produced by and found in plant tissues. The Jeffrey pine is noted for producing exceptionally high levels of "n"-heptane in its resin, for which reason its distillate was designated as the zero point for one octane rating. Floral scents have also long been known to contain volatile alkane components, and "n"-nonane is a significant component in the scent of some roses. Emission of gaseous and volatile alkanes such as ethane, pentane, and hexane by plants has also been documented at low levels, though they are not generally considered to be a major component of biogenic air pollution.
Edible vegetable oils also typically contain small fractions of biogenic alkanes with a wide spectrum of carbon numbers, mainly 8 to 35, usually peaking in the low to upper 20s, with concentrations up to dozens of milligrams per kilogram (parts per million by weight) and sometimes over a hundred for the total alkane fraction.
Alkanes are found in animal products, although they are less important than unsaturated hydrocarbons. One example is the shark liver oil, which is approximately 14% pristane (2,6,10,14-tetramethylpentadecane, CH). They are important as pheromones, chemical messenger materials, on which insects depend for communication. In some species, e.g. the support beetle "Xylotrechus colonus", pentacosane (CH), 3-methylpentaicosane (CH) and 9-methylpentaicosane (CH) are transferred by body contact. With others like the tsetse fly "Glossina morsitans morsitans", the pheromone contains the four alkanes 2-methylheptadecane (CH), 17,21-dimethylheptatriacontane (CH), 15,19-dimethylheptatriacontane (CH) and 15,19,23-trimethylheptatriacontane (CH), and acts by smell over longer distances. Waggle-dancing honey bees produce and release two alkanes, tricosane and pentacosane.
<h3>Ecological relations.</h3>
One example, in which both plant and animal alkanes play a role, is the ecological relationship between the sand bee ("Andrena nigroaenea") and the early spider orchid ("Ophrys sphegodes"); the latter is dependent for pollination on the former. Sand bees use pheromones in order to identify a mate; in the case of "A. nigroaenea", the females emit a mixture of tricosane (CH), pentacosane (CH) and heptacosane (CH) in the ratio 3:3:1, and males are attracted by specifically this odor. The orchid takes advantage of this mating arrangement to get the male bee to collect and disseminate its pollen; parts of its flower not only resemble the appearance of sand bees, but also produce large quantities of the three alkanes in the same ratio as female sand bees. As a result, numerous males are lured to the blooms and attempt to copulate with their imaginary partner: although this endeavor is not crowned with success for the bee, it allows the orchid to transfer its pollen,
which will be dispersed after the departure of the frustrated male to different blooms.
<h2>Production.</h2>
<h3>Petroleum refining.</h3>
As stated earlier, the most important source of alkanes is natural gas and crude oil. Alkanes are separated in an oil refinery by fractional distillation and processed into many different products.
<h3>Fischer–Tropsch.</h3>
The Fischer–Tropsch process is a method to synthesize liquid hydrocarbons, including alkanes, from carbon monoxide and hydrogen. This method is used to produce substitutes for petroleum distillates.
<h3>Laboratory preparation.</h3>
There is usually little need for alkanes to be synthesized in the laboratory, since they are usually commercially available. Also, alkanes are generally unreactive chemically or biologically, and do not undergo functional group interconversions cleanly. When alkanes are produced in the laboratory, it is often a side-product of a reaction. For example, the use of "n"-butyllithium as a strong base gives the conjugate acid, "n"-butane as a side-product:
However, at times it may be desirable to make a section of a molecule into an alkane like functionality (alkyl group) using the above or similar methods. For example, an ethyl group is an alkyl group; when this is attached to a hydroxy group, it gives ethanol, which is not an alkane. To do so, the best-known methods are hydrogenation of alkenes:
Alkanes or alkyl groups can also be prepared directly from alkyl halides in the Corey–House–Posner–Whitesides reaction. The Barton–McCombie deoxygenation removes hydroxyl groups from alcohols e.g.
and the Clemmensen reduction removes carbonyl groups from aldehydes and ketones to form alkanes or alkyl-substituted compounds e.g.:
<h2>Applications.</h2>
The applications of a certain alkane can be determined quite well according to the number of carbon atoms. The first four alkanes are used mainly for heating and cooking purposes, and in some countries for electricity generation. Methane and ethane are the main components of natural gas; they are normally stored as gases under pressure. It is, however, easier to transport them as liquids: This requires both compression and cooling of the gas.
Propane and butane can be liquefied at fairly low pressures, and are well known as liquified petroleum gas (LPG). Propane, for example, is used in the propane gas burner and as a fuel for cars, butane in disposable cigarette lighters. The two alkanes are used as propellants in aerosol sprays.
From pentane to octane the alkanes are reasonably volatile liquids. They are used as fuels in internal combustion engines, as they vaporise easily on entry into the combustion chamber without forming droplets, which would impair the uniformity of the combustion. Branched-chain alkanes are preferred as they are much less prone to premature ignition, which causes knocking, than their straight-chain homologues. This propensity to premature ignition is measured by the octane rating of the fuel, where 2,2,4-trimethylpentane ("isooctane") has an arbitrary value of 100, and heptane has a value of zero. Apart from their use as fuels, the middle alkanes are also good solvents for nonpolar substances.
Alkanes from nonane to, for instance, hexadecane (an alkane with sixteen carbon atoms) are liquids of higher viscosity, less and less suitable for use in gasoline. They form instead the major part of diesel and aviation fuel. Diesel fuels are characterized by their cetane number, cetane being an old name for hexadecane. However, the higher melting points of these alkanes can cause problems at low temperatures and in polar regions, where the fuel becomes too thick to flow correctly.
Alkanes from hexadecane upwards form the most important components of fuel oil and lubricating oil. In the latter function, they work at the same time as anti-corrosive agents, as their hydrophobic nature means that water cannot reach the metal surface. Many solid alkanes find use as paraffin wax, for example, in candles. This should not be confused however with true wax, which consists primarily of esters.
Alkanes with a chain length of approximately 35 or more carbon atoms are found in bitumen, used, for example, in road surfacing. However, the higher alkanes have little value and are usually split into lower alkanes by cracking.
Some synthetic polymers such as polyethylene and polypropylene are alkanes with chains containing hundreds of thousands of carbon atoms. These materials are used in innumerable applications, and billions of kilograms of these materials are made and used each year.
<h2>Environmental transformations.</h2>
When released in the environment, alkanes don't undergo rapid biodegradation, because they have no functional groups (like hydroxyl or carbonyl) that are needed by most organisms in order to metabolize the compound.
However, some bacteria can metabolize some alkanes (especially those linear and short), by oxidizing the terminal carbon atom. The product is an alcohol, that could be next oxidized to an aldehyde, and finally to a carboxylic acid. The resulting fatty acid could be metabolized through the fatty acid degradation pathway.
<h2>Hazards.</h2>
Methane is explosive when mixed with air (1–8% CH). Other lower alkanes can also form explosive mixtures with air. The lighter liquid alkanes are highly flammable, although this risk decreases with the length of the carbon chain. Pentane, hexane, heptane, and octane are classed as "dangerous for the environment" and "harmful".
Considerations for detection / risk control:

</doc>
<doc id="640" url="https://en.wikipedia.org/wiki?curid=640" title="Appellate procedure in the United States">
Appellate procedure in the United States

United States appellate procedure involves the rules and regulations for filing appeals in state courts and federal courts. The nature of an appeal can vary greatly depending on the type of case and the rules of the court in the jurisdiction where the case was prosecuted. There are many types of standard of review for appeals, such as "de novo" and abuse of discretion. However, most appeals begin when a party files a petition for review to a higher court for the purpose of overturning the lower court's decision.
An appellate court is a court that hears cases on appeal from another court. Depending on the particular legal rules that apply to each circumstance, a party to a court case who is unhappy with the result might be able to challenge that result in an appellate court on specific grounds. These grounds typically could include errors of law, fact, procedure or due process. In different jurisdictions, appellate courts are also called appeals courts, courts of appeals, superior courts, or supreme courts.
The specific procedures for appealing, including even whether there is a right of appeal from a particular type of decision, can vary greatly from state to state. The right to file an appeal can also vary from state to state; for example, the New Jersey Constitution vests judicial power in a Supreme Court, a Superior Court, and other courts of limited jurisdiction, with an appellate court being part of the Superior Court.
<h2>Access to appellant status.</h2>
A party who files an appeal is called an "appellant", "plaintiff in error", "petitioner" or "pursuer", and a party on the other side is called a "appellee". A "cross-appeal" is an appeal brought by the respondent. For example, suppose at trial the judge found for the plaintiff and ordered the defendant to pay $50,000. If the defendant files an appeal arguing that he should not have to pay any money, then the plaintiff might file a cross-appeal arguing that the defendant should have to pay $200,000 instead of $50,000.
The appellant is the party who, having lost part or all their claim in a lower court decision, is appealing to a higher court to have their case reconsidered. This is usually done on the basis that the lower court judge erred in the application of law, but it may also be possible to appeal on the basis of court misconduct, or that a finding of fact was entirely unreasonable to make on the evidence.
The appellant in the new case can be either the plaintiff (or claimant), defendant, third-party intervenor, or respondent (appellee) from the lower case, depending on who was the losing party. The winning party from the lower court, however, is now the respondent. In unusual cases the appellant can be the victor in the court below, but still appeal.
An appellee is the party to an appeal in which the lower court judgment was in its favor. The appellee is required to respond to the petition, oral arguments, and legal briefs of the appellant. In general, the appellee takes the procedural posture that the lower court's decision should be affirmed.
<h2>Ability to appeal.</h2>
An appeal "as of right" is one that is guaranteed by statute or some underlying constitutional or legal principle. The appellate court cannot refuse to listen to the appeal. An appeal "by leave" or "permission" requires the appellant to obtain leave to appeal; in such a situation either or both of the lower court and the court may have the discretion to grant or refuse the appellant's demand to appeal the lower court's decision. In the Supreme Court, review in most cases is available only if the Court exercises its discretion and grants a writ of certiorari.
In tort, equity, or other civil matters either party to a previous case may file an appeal. In criminal matters, however, the state or prosecution generally has no appeal "as of right". And due to the double jeopardy principle, the state or prosecution may never appeal a jury or bench verdict of acquittal. But in some jurisdictions, the state or prosecution may appeal "as of right" from a trial court's dismissal of an indictment in whole or in part or from a trial court's granting of a defendant's suppression motion. Likewise, in some jurisdictions, the state or prosecution may appeal an issue of law "by leave" from the trial court or the appellate court. The ability of the prosecution to appeal a decision in favor of a defendant varies significantly internationally. All parties must present grounds to appeal, or it will not be heard.
By convention in some law reports, the appellant is named first. This can mean that where it is the defendant who appeals, the name of the case in the law reports reverses (in some cases twice) as the appeals work their way up the court hierarchy. This is not always true, however. In the federal courts, the parties' names always stay in the same order as the lower court when an appeal is taken to the circuit courts of appeals, and are re-ordered only if the appeal reaches the Supreme Court.
<h2>Direct or collateral: Appealing criminal convictions.</h2>
Many jurisdictions recognize two types of appeals, particularly in the criminal context. The first is the traditional "direct" appeal in which the appellant files an appeal with the next higher court of review. The second is the collateral appeal or post-conviction petition, in which the petitioner-appellant files the appeal in a court of first instance—usually the court that tried the case.
The key distinguishing factor between direct and collateral appeals is that the former occurs in state courts, and the latter in federal courts.
Relief in post-conviction is rare and is most often found in capital or violent felony cases. The typical scenario involves an incarcerated defendant locating DNA evidence demonstrating the defendant's actual innocence.
<h3>Appellate review.</h3>
"Appellate review" is the general term for the process by which courts with appellate jurisdiction take jurisdiction of matters decided by lower courts. It is distinguished from judicial review, which refers to the court's overriding constitutional or statutory right to determine if a legislative act or administrative decision is defective for jurisdictional or other reasons (which may vary by jurisdiction).
In most jurisdictions the normal and preferred way of seeking appellate review is by filing an appeal of the final judgment. Generally, an appeal of the judgment will also allow appeal of all other orders or rulings made by the trial court in the course of the case. This is because such orders cannot be appealed "as of right". However, certain critical interlocutory court orders, such as the denial of a request for an interim injunction, or an order holding a person in contempt of court, can be appealed immediately although the case may otherwise not have been fully disposed of.
There are two distinct forms of appellate review, "direct" and "collateral". For example, a criminal defendant may be convicted in state court, and lose on "direct appeal" to higher state appellate courts, and if unsuccessful, mount a "collateral" action such as filing for a writ of habeas corpus in the federal courts. Generally speaking, "[d]irect appeal statutes afford defendants the opportunity to challenge the merits of a judgment and allege errors of law or fact. ... [Collateral review], on the other hand, provide[s] an independent and civil inquiry into the validity of a conviction and sentence, and as such are generally limited to challenges to constitutional, jurisdictional, or other fundamental violations that occurred at trial." "Graham v. Borgen", 483 F 3d. 475 (7th Cir. 2007) (no. 04-4103) (slip op. at 7) (citation omitted).
In Anglo-American common law courts, appellate review of lower court decisions may also be obtained by filing a petition for review by prerogative writ in certain cases. There is no corresponding right to a writ in any pure or continental civil law legal systems, though some mixed systems such as Quebec recognize these prerogative writs.
<h4>Direct Appeal.</h4>
After exhausting the first appeal as of right, defendants usually petition the highest state court to review the decision. This appeal is known as a direct appeal. The highest state court, generally known as the Supreme Court, exercises discretion over whether it will review the case. On direct appeal, a prisoner challenges the grounds of the conviction based on an error that occurred at trial or some other stage in the adjudicative process.
<h5>Preservation Issues.</h5>
An appellant's claim(s) must usually be preserved at trial. This means that the defendant had to object to the error when it occurred in the trial. Because constitutional claims are of great magnitude, appellate courts might be more lenient to review the claim even if it was not preserved. For example, Connecticut applies the following standard to review unpreserved claims: 1.the record is adequate to review the alleged claim of error; 2. the claim is of constitutional magnitude alleging the violation of a fundamental right; 3. the alleged constitutional violation clearly exists and clearly deprived the defendant of a fair trial; 4. if subject to harmless error analysis, the state has failed to demonstrate harmlessness of the alleged constitutional violation beyond a reasonable doubt.
<h4>State Post Conviction Relief: Collateral Appeal.</h4>
All States have a post-conviction relief process. Similar to federal post-conviction relief, an appellant can petition the court to correct alleged fundamental errors that were not corrected on direct review. Typical claims might include ineffective assistance of counsel and actual innocence based on new evidence. These proceedings are normally separate from the direct appeal, however some states allow for collateral relief to be sought on direct appeal. After direct appeal, the conviction is considered final. An appeal from the post conviction court proceeds just as a direct appeal. That is, it goes to the intermediate appellate court, followed by the highest court. If the petition is granted the appellant could be released from incarceration, the sentence could be modified, or a new trial could be ordered.
<h2>Notice of appeal.</h2>
A "notice of appeal" is a form or document that in many cases is required to begin an appeal. The form is completed by the appellant or by the appellant's legal representative. The nature of this form can vary greatly from country to country and from court to court within a country.
The specific rules of the legal system will dictate exactly how the appeal is officially begun. For example, the appellant might have to file the notice of appeal with the appellate court, or with the court from which the appeal is taken, or both.
Some courts have samples of a notice of appeal on the court's own web site. In New Jersey, for example, the Administrative Office of the Court has promulgated a form of notice of appeal for use by appellants, though using this exact form is not mandatory and the failure to use it is not a jurisdictional defect provided that all pertinent information is set forth in whatever form of notice of appeal is used.
The deadline for beginning an appeal can often be very short: traditionally, it is measured in days, not months. This can vary from country to country, as well as within a country, depending on the specific rules in force. In the U.S. federal court system, criminal defendants must file a notice of appeal within 10 days of the entry of either the judgment or the order being appealed, or the right to appeal is forfeited.
<h2>Appellate procedure.</h2>
Generally speaking the appellate court examines the record of evidence presented in the trial court and the law that the lower court applied and decides whether that decision was legally sound or not. The appellate court will typically be deferential to the lower court's findings of fact (such as whether a defendant committed a particular act), unless clearly erroneous, and so will focus on the court's application of the law to those facts (such as whether the act found by the court to have occurred fits a legal definition at issue).
If the appellate court finds no defect, it "affirms" the judgment. If the appellate court does find a legal defect in the decision "below" (i.e., in the lower court), it may "modify" the ruling to correct the defect, or it may nullify ("reverse" or "vacate") the whole decision or any part of it. It may, in addition, send the case back ("remand" or "remit") to the lower court for further proceedings to remedy the defect.
In some cases, an appellate court may review a lower court decision "de novo" (or completely), challenging even the lower court's findings of fact. This might be the proper standard of review, for example, if the lower court resolved the case by granting a pre-trial motion to dismiss or motion for summary judgment which is usually based only upon written submissions to the trial court and not on any trial testimony.
Another situation is where appeal is by way of "re-hearing". Certain jurisdictions permit certain appeals to cause the trial to be heard afresh in the appellate court.
Sometimes, the appellate court finds a defect in the procedure the parties used in filing the appeal and dismisses the appeal without considering its merits, which has the same effect as affirming the judgment below. (This would happen, for example, if the appellant waited too long, under the appellate court's rules, to file the appeal.)
Generally, there is no trial in an appellate court, only consideration of the record of the evidence presented to the trial court and all the pre-trial and trial court proceedings are reviewed—unless the appeal is by way of re-hearing, new evidence will usually only be considered on appeal in "very" rare instances, for example if that material evidence was unavailable to a party for some very significant reason such as prosecutorial misconduct.
In some systems, an appellate court will only consider the written decision of the lower court, together with any written evidence that was before that court and is relevant to the appeal. In other systems, the appellate court will normally consider the record of the lower court. In those cases the record will first be certified by the lower court.
The appellant has the opportunity to present arguments for the granting of the appeal and the appellee (or respondent) can present arguments against it. Arguments of the parties to the appeal are presented through their appellate lawyers, if represented, or "pro se" if the party has not engaged legal representation. Those arguments are presented in written briefs and sometimes in oral argument to the court at a hearing. At such hearings each party is allowed a brief presentation at which the appellate judges ask questions based on their review of the record below and the submitted briefs.
In an adversarial system, appellate courts do not have the power to review lower court decisions unless a party appeals it. Therefore, if a lower court has ruled in an improper manner, or against legal precedent, that judgment will stand if not appealed – even if it might have been overturned on appeal.
The United States legal system generally recognizes two types of appeals: a trial "de novo" or an appeal on the record.
A trial de novo is usually available for review of informal proceedings conducted by some minor judicial tribunals in proceedings that do not provide all the procedural attributes of a formal judicial trial. If unchallenged, these decisions have the power to settle more minor legal disputes once and for all. If a party is dissatisfied with the finding of such a tribunal, one generally has the power to request a trial "de novo" by a court of record. In such a proceeding, all issues and evidence may be developed newly, as though never heard before, and one is not restricted to the evidence heard in the lower proceeding. Sometimes, however, the decision of the lower proceeding is itself admissible as evidence, thus helping to curb frivolous appeals.
In some cases, an application for "trial de novo" effectively erases the prior trial as if it had never taken place. The Supreme Court of Virginia has stated that '"This Court has repeatedly held that the effect of an appeal to circuit court is to "annul the judgment of the inferior tribunal as completely as if there had been no previous trial."' The only exception to this is that if a defendant appeals a conviction for a crime having multiple levels of offenses, where they are convicted on a lesser offense, the appeal is of the lesser offense; the conviction represents an acquittal of the more serious offenses. "[A] trial on the same charges in the circuit court does not violate double jeopardy principles, . . . subject only to the limitation that conviction in [the] district court for an offense lesser included in the one charged constitutes an acquittal of the greater offense,
permitting trial de novo in the circuit court only for the lesser-included offense."
In an appeal on the record from a decision in a judicial proceeding, both appellant and respondent are bound to base their arguments wholly on the proceedings and body of evidence as they were presented in the lower tribunal. Each seeks to prove to the higher court that the result they desired was the just result. Precedent and case law figure prominently in the arguments. In order for the appeal to succeed, the appellant must prove that the lower court committed reversible error, that is, an impermissible action by the court acted to cause a result that was unjust, and which would not have resulted had the court acted properly. Some examples of reversible error would be erroneously instructing the jury on the law applicable to the case, permitting seriously improper argument by an attorney, admitting or excluding evidence improperly, acting outside the court's jurisdiction, injecting bias into the proceeding or appearing to do so, juror misconduct, etc. The failure to formally object at the time, to what one views as improper action in the lower court, may result in the affirmance of the lower court's judgment on the grounds that one did not "preserve the issue for appeal" by objecting.
In cases where a judge rather than a jury decided issues of fact, an appellate court will apply an "abuse of discretion" standard of review. Under this standard, the appellate court gives deference to the lower court's view of the evidence, and reverses its decision only if it were a clear abuse of discretion. This is usually defined as a decision outside the bounds of reasonableness. On the other hand, the appellate court normally gives less deference to a lower court's decision on issues of law, and may reverse if it finds that the lower court applied the wrong legal standard.
In some cases, an appellant may successfully argue that the law under which the lower decision was rendered was unconstitutional or otherwise invalid, or may convince the higher court to order a new trial on the basis that evidence earlier sought was concealed or only recently discovered. In the case of new evidence, there must be a high probability that its presence or absence would have made a material difference in the trial. Another issue suitable for appeal in criminal cases is effective assistance of counsel. If a defendant has been convicted and can prove that his lawyer did not adequately handle his case and that there is a reasonable probability that the result of the trial would have been different had the lawyer given competent representation, he is entitled to a new trial.
A lawyer traditionally starts an oral argument to any appellate court with the words "May it please the court."
After an appeal is heard, the "mandate" is a formal notice of a decision by a court of appeal; this notice is transmitted to the trial court and, when filed by the clerk of the trial court, constitutes the final judgment on the case, unless the appeal court has directed further proceedings in the trial court. The mandate is distinguished from the appeal court's opinion, which sets out the legal reasoning for its decision. In some jurisdictions the mandate is known as the "remittitur".
<h2>Results.</h2>
The result of an appeal can be:
There can be multiple outcomes, so that the reviewing court can affirm some rulings, reverse others and remand the case all at the same time. Remand is not required where there is nothing left to do in the case. "Generally speaking, an appellate court's judgment provides 'the final directive of the appeals courts as to the matter appealed, setting out with specificity the court's determination that the action appealed from should be affirmed, reversed, remanded or modified'".
Some reviewing courts who have discretionary review may send a case back without comment other than "review improvidently granted". In other words, after looking at the case, they chose not to say anything. The result for the case of "review improvidently granted" is effectively the same as affirmed, but without that extra higher court stamp of approval.

</doc>
<doc id="642" url="https://en.wikipedia.org/wiki?curid=642" title="Answer">
Answer

Generally, an answer is a reply to a question. It can be solution, a retaliation or a response to it.
In law, an answer was originally a solemn assertion in opposition to someone or something, and thus generally any counter-statement or defense, a reply to a question or response, or objection, or a correct solution of a problem.
In the common law, an answer is the first pleading by a defendant, usually filed and served upon the plaintiff within a certain strict time limit after a civil complaint or criminal information or indictment has been served upon the defendant. It may have been preceded by an "optional" "pre-answer" motion to dismiss or demurrer; if such a motion is unsuccessful, the defendant "must" file an answer to the complaint or risk an adverse default judgment.
In a criminal case, there is usually an arraignment or some other kind of appearance before the defendant comes to court. The pleading in the criminal case, which is entered on the record in open court, is usually either guilty or not guilty. Generally speaking in private, civil cases there is no plea entered of guilt or innocence. There is only a judgment that grants money damages or some other kind of equitable remedy such as restitution or a permanent injunction. Criminal cases may lead to fines or other punishment, such as imprisonment.
The famous Latin "Responsa Prudentium" ("answers of the learned ones") were the accumulated views of many successive generations of Roman lawyers, a body of legal opinion which gradually became authoritative.
In music an "answer" (also known as countersubject) is the technical name in counterpoint for the repetition or modification by one part or instrument of a theme proposed by another. During debates of a contentious nature, deflection, colloquially known as 'changing the topic', has been widely observed, and is often seen as a failure to answer a question.

</doc>
<doc id="643" url="https://en.wikipedia.org/wiki?curid=643" title="Appellate court">
Appellate court

An appellate court, commonly called an appeals court, court of appeals (American English), appeal court (British English), court of second instance or second instance court, is any court of law that is empowered to hear an appeal of a trial court or other lower tribunal. In most jurisdictions, the court system is divided into at least three levels: the trial court, which initially hears cases and reviews evidence and testimony to determine the facts of the case; at least one intermediate appellate court; and a supreme court (or court of last resort) which primarily reviews the decisions of the intermediate courts. A jurisdiction's supreme court is that jurisdiction's highest appellate court. Appellate courts nationwide can operate by varying rules.
The authority of appellate courts to review decisions of lower courts varies widely from one jurisdiction to another. In some places, the appellate court has limited powers of review. Generally speaking, an appellate court's judgment provides the final directive of the appeals courts as to the matter appealed, setting out with specificity the court's determination that the action appealed from should be affirmed, reversed, remanded or modified.
<h2>United States.</h2>
In the United States, both state and federal appellate courts are usually restricted to examining whether the lower court made the correct legal determinations, rather than hearing direct evidence and determining what the facts of the case were. Furthermore, U.S. appellate courts are usually restricted to hearing appeals based on matters that were originally brought up before the trial court. Hence, such an appellate court will not consider an appellant's argument if it is based on a theory that is raised for the first time in the appeal.
In most U.S. states, and in U.S. federal courts, parties before the court are allowed one appeal as of right. This means that a party who is unsatisfied with the outcome of a trial may bring an appeal to contest that outcome. However, appeals may be costly, and the appellate court must find an error on the part of the court below that justifies upsetting the verdict. Therefore, only a small proportion of trial court decisions result in appeals. Some appellate courts, particularly supreme courts, have the power of discretionary review, meaning that they can decide whether they will hear an appeal brought in a particular case.
<h3>Institutional titles.</h3>
Many U.S. jurisdictions title their appellate court a court of appeal or court of appeals. Historically, others have titled their appellate court a court of errors (or court of errors and appeals), on the premise that it was intended to correct errors made by lower courts. Examples of such courts include the New Jersey Court of Errors and Appeals (which existed from 1844 to 1947), the Connecticut Supreme Court of Errors (which has been renamed the Connecticut Supreme Court), the Kentucky Court of Errors (renamed the Kentucky Supreme Court), and the Mississippi High Court of Errors and Appeals (since renamed the Supreme Court of Mississippi). In some jurisdictions, courts able to hear appeals are known as an appellate division.
The phrase "court of appeals" most often refers to intermediate appellate courts. However, the New York system is different: the "New York Court of Appeals" is the highest appellate court; and the phrase "New York Supreme Court" applies to the trial court of general jurisdiction.
Depending on the system, certain courts may serve as both trial courts and appellate courts, hearing appeals of decisions made by courts with more limited jurisdiction. Some jurisdictions have specialized appellate courts, such as the Texas Court of Criminal Appeals, which only hears appeals raised in criminal cases, and the United States Court of Appeals for the Federal Circuit, which has general jurisdiction but derives most of its caseload from patent cases, on one hand, and appeals from the Court of Federal Claims on the other.
<h2>New Zealand.</h2>
The Court of Appeal of New Zealand, located in Wellington, is New Zealand's principal intermediate appellate court. In practice, most appeals are resolved at this intermediate appellate level, rather than in the Supreme Court.

</doc>
<doc id="649" url="https://en.wikipedia.org/wiki?curid=649" title="Arraignment">
Arraignment

Arraignment is a formal reading of a criminal charging document in the presence of the defendant to inform the defendant of the charges against the defendant. In response to arraignment, the accused is expected to enter a plea. Acceptable pleas vary among jurisdictions, but they generally include "guilty", "not guilty", and the peremptory pleas (or pleas in bar) setting out reasons why a trial cannot proceed. Pleas of "nolo contendere" (no contest) and the ""Alford" plea" are allowed in some circumstances.
<h2>Australia.</h2>
In Australia, arraignment is the first of eleven stages in a criminal trial, and involves the clerk of the court reading out the indictment. The judge will testify during the indictment process.
<h2>Canada.</h2>
In every province in Canada except British Columbia, defendants are arraigned on the day of their trial. In British Columbia, arraignment takes places in one of the first few court appearances by the defendant or their lawyer. The defendant is asked whether he or she pleads guilty or not guilty to each charge.
<h2>France.</h2>
In France, the general rule is that one cannot remain in police custody for more than 24 hours from the time of the arrest. However, police custody can last another 24 hours in specific circumstances, especially if the offence is punishable by at least one year's imprisonment, or if the investigation is deemed to require the extra time, and can last up to 96 hours in certain cases involving terrorism, drug trafficking or organised crime. The police needs to have the consent of the prosecutor (in the vast majority of cases, the prosecutor will consent).
<h2>Germany.</h2>
In Germany, if one has been arrested and taken into custody by the police one must be brought before a judge as soon as possible and at the latest on the day after the arrest.
<h2>New Zealand.</h2>
At the first appearance, the accused is read the charges and asked for a plea. The available pleas are, guilty, not guilty, and no plea. No plea allows the defendant to get legal advice on the plea, which must be made on the second appearance.
<h2>South Africa.</h2>
In South Africa, arraignment is defined as the calling upon the accused to appear, the informing of the accused of the crime charged against him, the demanding of the accused whether he be guilty or not guilty, and the entering of his plea. His plea having been entered he is said to stand arraigned.
<h2>United Kingdom.</h2>
In England, Wales, and Northern Ireland, arraignment is the first of eleven stages in a criminal trial, and involves the clerk of the court reading out the indictment.
In England and Wales, the police cannot legally detain anyone for more than 24 hours without charging them unless an officer with the rank of superintendent (or above) authorises detention for a further 12 hours (36 hours total), or a judge (who will be a magistrate) authorises detention by the police before charge for up to a maximum of 96 hours, but for terrorism-related offences people can be held by the police for up to 28 days before charge. If they are not released after being charged, they should be brought before a court as soon as practicable.
<h2>United States.</h2>
Under the United States Federal Rules of Criminal Procedure, "arraignment shall [...] [consist of an] open [...] reading [of] the indictment [...] to the defendant [...] and call[] on him to plead thereto. He/she shall be given a copy of the indictment [...] before he/she is called upon to plead."
In federal courts, arraignment takes place in two stages. The first is called the initial arraignment and must take place within 48 hours of an individual's arrest, 72 hours if the individual was arrested on the weekend and not able to go before a judge until Monday. During this arraignment the defendant is informed of the pending legal charges and is informed of his or her right to retain counsel. The presiding judge also decides at what amount, if any, to set bail. During the second arraignment, a post-indictment arraignment or PIA, the defendant is allowed to enter a plea.
In New York, most people arrested must be released if they are not arraigned within 24 hours.
In California, arraignments must be conducted without unnecessary delay and, in any event, within 48 hours of arrest, excluding weekends and holidays. Thus, an individual arrested without a warrant, in some cases, may be held for as long as 168 hours (7 days) without arraignment or charge.
<h2>Form of the arraignment.</h2>
The wording of the arraignment varies from jurisdiction to jurisdiction. However, it generally conforms with the following principles:
<h2>Video arraignment.</h2>
Video arraignment is the act of conducting the arraignment process using some form of videoconferencing technology. Use of video arraignment system allows the courts to conduct the requisite arraignment process without the need to transport the defendant to the courtroom by using an audio-visual link between the location where the defendant is being held and the courtroom.
Use of the video arraignment process addresses the problems associated with having to transport defendants. The transportation of defendants requires time, puts additional demands on the public safety organizations to provide for the safety of the public, court personnel and for the security of the population held in detention. It also addresses the rising costs of transportation.
<h2>Guilty and not-guilty pleas.</h2>
If the defendant pleads guilty, an evidentiary hearing usually follows. The court is not required to accept a guilty plea. During the hearing, the judge assesses the offense, the mitigating factors, and the defendant's character, and passes sentence.
If the defendant pleads not guilty, a date is set for a preliminary hearing or a trial.
In the past, a defendant who refused to plead (or "stood mute") was subject to peine forte et dure (Law French for "strong and hard punishment"). Today in common-law jurisdictions, the court enters a plea of not guilty for a defendant who refuses to enter a plea. The rationale for this is the defendant's right to silence.
<h2>Pre-trial release.</h2>
This is also often the stage at which arguments for or against pre-trial release and bail may be made, depending on the alleged crime and jurisdiction.

</doc>
<doc id="651" url="https://en.wikipedia.org/wiki?curid=651" title="America the Beautiful">
America the Beautiful

"America the Beautiful" is an American patriotic song. The lyrics were written by Katharine Lee Bates, and the music was composed by church organist and choirmaster Samuel A. Ward at Grace Episcopal Church in Newark.
Bates originally wrote the words as a poem, "Pikes Peak", first published in the Fourth of July edition of the church periodical "The Congregationalist" in 1895. At that time, the poem was titled "America" for publication.
Ward had originally written the music, "Materna", for the hymn "O Mother dear, Jerusalem" in 1882, though it was not first published until 1892. Ward's music combined with the Bates poem was first published in 1910 and titled "America the Beautiful".
The song is one of the most popular of the many American patriotic songs.
<h2>History.</h2>
In 1893, at the age of 33, Bates, an English professor at Wellesley College, had taken a train trip to Colorado Springs, Colorado, to teach a short summer school session at Colorado College. Several of the sights on her trip inspired her, and they found their way into her poem, including the World's Columbian Exposition in Chicago, the "White City" with its promise of the future contained within its alabaster buildings; the wheat fields of America's heartland Kansas, through which her train was riding on July 16; and the majestic view of the Great Plains from high atop Zebulon Pikes Peak.
On the pinnacle of that mountain, the words of the poem started to come to her, and she wrote them down upon returning to her hotel room at the original Antlers Hotel. The poem was initially published two years later in "The Congregationalist" to commemorate the Fourth of July. It quickly caught the public's fancy. Amended versions were published in 1904 and 1911.
Several existing pieces of music were adapted to the poem. A hymn tune composed by Samuel A. Ward was generally considered the best music as early as 1910 and is still the popular tune today. Just as Bates had been inspired to write her poem, Ward, too, was inspired to compose his tune. The tune came to him while he was on a ferryboat trip from Coney Island back to his home in New York City, after a leisurely summer day in 1882, and he immediately wrote it down. He was so anxious to capture the tune in his head, he asked fellow passenger friend Harry Martin for his shirt cuff to write the tune on. He composed the tune for the old hymn "O Mother Dear, Jerusalem", retitling the work "Materna". Ward's music combined with Bates's poem were first published together in 1910 and titled "America the Beautiful".
Ward died in 1903, not knowing the national stature his music would attain since the music was only first applied to the song in 1904. Bates was more fortunate since the song's popularity was well established by the time of her death in 1929.
At various times in the more than 100 years that have elapsed since the song was written, particularly during the John F. Kennedy administration, there have been efforts to give "America the Beautiful" legal status either as a national hymn or as a national anthem equal to, or in place of, "The Star-Spangled Banner", but so far this has not succeeded. Proponents prefer "America the Beautiful" for various reasons, saying it is easier to sing, more melodic, and more adaptable to new orchestrations while still remaining as easily recognizable as "The Star-Spangled Banner". Some prefer "America the Beautiful" over "The Star-Spangled Banner" due to the latter's war-oriented imagery. Others prefer "The Star-Spangled Banner" for the same reason. While that national dichotomy has stymied any effort at changing the tradition of the national anthem, "America the Beautiful" continues to be held in high esteem by a large number of Americans.
This song was used as the background music of the television broadcast of the Tiangong-1 launch.
The song is often included in songbooks in a wide variety of religious congregations in the United States.
<h2>Popular versions.</h2>
In 1976, while the United States celebrated its bicentennial, a soulful version popularized by Ray Charles peaked at number 98 on the US R&B Charts, and is included on the soundtrack for the movie "The Sandlot".
Three different renditions of the song have entered the Hot Country Songs charts. The first was by Charlie Rich, which went to number 22 in 1976. A second, by Mickey Newbury, peaked at number 82 in 1980. An all-star version of "America the Beautiful" performed by country singers Trace Adkins, Sherrié Austin, Billy Dean, Vince Gill, Carolyn Dawn Johnson, Toby Keith, Brenda Lee, Lonestar, Lyle Lovett, Lila McCann, Lorrie Morgan, Jamie O'Neal, The Oak Ridge Boys, Collin Raye, Kenny Rogers, Keith Urban and Phil Vassar reached number 58 in July 2001. The song re-entered the chart following the September 11 attacks.
Popularity of the song increased greatly following the September 11 attacks; at some sporting events it was sung in addition to the traditional singing of the national anthem. During the first taping of the "Late Show with David Letterman" following the attacks, CBS newsman Dan Rather cried briefly as he quoted the fourth verse.
For Super Bowl XLVIII, The Coca-Cola Company aired a multilingual version of the song, sung in several different languages. This commercial incited an outcry from quite a few Americans on popular social media sites, Twitter and Facebook, as well as popular and influential conservatives, such as Glenn Beck..
<h2>Idioms.</h2>
"From sea to shining sea", originally used in the charters of some of the English Colonies in North America, is an American idiom meaning from the Atlantic Ocean to the Pacific Ocean (or vice versa). Many songs have used this term, including the American patriotic songs "America, the Beautiful" and "God Bless the USA". In addition to these, it is also featured in Schoolhouse Rock's "Elbow Room". A term similar to this is the official Canadian (Latin) motto "" (From sea to sea).
"Purple mountain majesties" refers to the shade of the Pikes Peak in Colorado Springs, Colorado, which Bates looked at while writing the poem.
<h2>Books.</h2>
Lynn Sherr's 2001 book "America the Beautiful" discusses the origins of the song and the backgrounds of its authors in depth. The book points out that the poem has the same meter as that of "Auld Lang Syne"; the songs can be sung interchangeably. Additionally, Sherr discusses the evolution of the lyrics, for instance, changes to the original third verse written by Bates. The song appears in Ellen Raskin's "The Westing Game".

</doc>
<doc id="653" url="https://en.wikipedia.org/wiki?curid=653" title="Assistive technology">
Assistive technology

Assistive technology is an umbrella term that includes assistive, adaptive, and rehabilitative devices for people with disabilities and also includes the process used in selecting, locating, and using them. Assistive technology promotes greater independence by enabling people to perform tasks that they were formerly unable to accomplish, or had great difficulty accomplishing, by providing enhancements to, or changing methods of interacting with, the technology needed to accomplish such tasks.
<h2>Adaptive technology.</h2>
The term adaptive technology is often used as the synonym for assistive technology; however, they are different terms. Assistive technology refers to "any item, piece of equipment, or product system, whether acquired commercially, modified, or customized, that is used to increase, maintain, or improve functional capabilities of individuals with disabilities", while adaptive technology covers items that are specifically designed for persons with disabilities and would seldom be used by non-disabled persons. In other words, "assistive technology is any object or system that increases or maintains the capabilities of people with disabilities," while adaptive technology is "any object or system that is specifically designed for the purpose of increasing or maintaining the capabilities of people with disabilities." Consequently, adaptive technology is a subset of assistive technology. Adaptive technology often refers specifically to electronic and information technology access.
<h2>Mobility impairments.</h2>
<h3>Wheelchairs.</h3>
Wheelchairs are devices that can be manually propelled or electrically propelled and that include a seating system and are designed to be a substitute for the normal mobility that most people enjoy. Wheelchairs and other mobility devices allow people to perform mobility related activities of daily living which include feeding, toileting, dressing grooming and bathing. The devices comes in a number of variations where they can be propelled either by hand or by motors where the occupant uses electrical controls to manage motors and seating control actuators through a joystick, sip-and-puff control, or other input devices. Often there are handles behind the seat for someone else to do the pushing or input devices for caregivers. Wheelchairs are used by people for whom walking is difficult or impossible due to illness, injury, or disability. People with both sitting and walking disability often need to use a wheelchair or walker.
<h3>Transfer devices.</h3>
Patient transfer devices generally allow patients with impaired mobility to be moved by caregivers between beds, wheelchairs, commodes, toilets, chairs, stretchers, shower benches, automobiles, swimming pools, and other patient support systems (i.e., radiology, surgical, or examining tables). The most common devices are Patient lifts (for vertical transfer), Transfer benches, stretcher or convertible chairs (for lateral, supine transfer), sit-to-stand lifts (for moving patients from one seated position to another i.e., from wheelchairs to commodes), air bearing inflatable mattresses (for supine transfer i.e., transfer from a gurney to an operating room table), and sliding boards (usually used for transfer from a bed to a wheelchair). Highly dependent patients who cannot assist their caregiver in moving them often require a Patient lift (a floor or ceiling-suspended sling lift) which though invented in 1955 and in common use since the early 1960s is still considered the state-of-the-art transfer device by OSHA and the American Nursing Association.
<h3>Walkers.</h3>
A walker or walking frame or Rollator is a tool for disabled people who need additional support to maintain balance or stability while walking. It consists of a frame that is about waist high, approximately twelve inches deep and slightly wider than the user. Walkers are also available in other sizes, such as for children, or for heavy people. Modern walkers are height-adjustable. The front two legs of the walker may or may not have wheels attached depending on the strength and abilities of the person using it. It is also common to see caster wheels or glides on the back legs of a walker with wheels on the front.
<h3>Prosthesis.</h3>
A prosthesis, prosthetic, or prosthetic limb is a device that replaces a missing body part. It is part of the field of biomechatronics, the science of using mechanical devices with human muscle, skeleton, and nervous systems to assist or enhance motor control lost by trauma, disease, or defect. Prostheses are typically used to replace parts lost by injury (traumatic) or missing from birth (congenital) or to supplement defective body parts. Inside the body, artificial heart valves are in common use with artificial hearts and lungs seeing less common use but under active technology development. Other medical devices and aids that can be considered prosthetics include hearing aids, artificial eyes, palatal obturator, gastric bands, and dentures.
Prostheses are specifically "not" orthoses, although given certain circumstances a prosthesis might end up performing some or all of the same functionary benefits as an orthosis. Prostheses are technically the complete finished item. For instance, a C-Leg knee alone is "not" a prosthesis, but only a prosthetic "component". The complete prosthesis would consist of the attachment system  to the residual limb — usually a "socket", and all the attachment hardware components all the way down to and including the terminal device. Keep this in mind as nomenclature is often interchanged.
The terms "prosthetic" and "orthotic" are adjectives used to describe devices such as a prosthetic knee. The terms "prosthetics" and "orthotics" are used to describe the respective allied health fields. The devices themselves are properly referred to as "prostheses" and "orthoses" in the plural and "prosthesis" and "orthosis" in the singular.
<h2>Visual impairments.</h2>
Many people with serious visual impairments live independently, using a wide range of tools and techniques. Examples of assistive technology for visually impairment include screen readers, screen magnifiers, Braille embossers, desktop video magnifiers, and voice recorders.
<h3>Screen readers.</h3>
Screen readers allow the visually impaired to easily access electronic information. These software programs connect to a computer to read the text displayed out loud. There is a variety of platforms and applications available for a variety of costs.
<h3>Braille and braille embossers.</h3>
Braille is a system of raised dots formed into units called braille cells. A full braille cell is made up of six dots, with two parallel rows of three dots, but other combinations and quantities of dots represent other letters, numbers, punctuation marks, or words. People can then use their fingers to read the code of raised dots.
A braille embosser is, simply put, a printer for braille. Instead of a standard printer adding ink onto a page, the braille embosser imprints the raised dots of braille onto a page. Some braille embossers combine both braille and ink so the documents can be read with either sight or touch.
<h3>Desktop video magnifier.</h3>
Desktop video magnifiers are electronic devices that use a camera and a display screen to perform digital magnification of printed materials. They enlarge printed pages for those with low vision. A camera connects to a monitor that displays real time images, and the user can control settings such as magnification, focus, contrast, underlining, highlighting, and other screen preferences. They come in a variety of sizes and styles; some are small and portable with handheld cameras, while others are much larger and mounted on a fixed stand.
<h3>Screen magnification software.</h3>
A screen magnifier is software that interfaces with a computer's graphical output to present enlarged screen content. It allows users to enlarge the texts and graphics on their computer screens for easier viewing. Similar to desktop video magnifiers, this technology assists people with low vision. After the user loads the software into their computer's memory, it serves as a kind of "computer magnifying glass." Wherever the computer cursor moves, it enlarges the area around it. This allows greater computer accessibility for a wide range of visual abilities.
<h3>Large-print and tactile keyboards.</h3>
A large-print keyboard has large letters printed on the keys. On the keyboard shown, the round buttons at the top control software which can magnify the screen (zoom in), change the background color of the screen, or make the mouse cursor on the screen larger. The "bump dots" on the keys, installed in this case by the organization using the keyboards, help the user find the right keys in a tactile way.
<h2>Personal emergency response systems.</h2>
Personal emergency response systems (PERS), or Telecare (UK term), are a particular sort of assistive technology that use electronic sensors connected to an alarm system to help caregivers manage risk and help vulnerable people stay independent at home longer. An example would be the systems being put in place for senior people such as fall detectors, thermometers (for hypothermia risk), flooding and unlit gas sensors (for people with mild dementia). Notably, these alerts can be customized to the particular person's risks. When the alert is triggered, a message is sent to a caregiver or contact center who can respond appropriately.
<h2>Accessibility software.</h2>
In human–computer interaction, computer accessibility (also known as accessible computing) refers to the accessibility of a computer system to all people, regardless of disability or severity of impairment, examples include web accessibility guidelines. Another approach is for the user to present a token to the computer terminal, such as a smart card, that has configuration information to adjust the computer speed, text size, etc. to their particular needs. This is useful where users want to access public computer based terminals in Libraries, ATM, Information kiosks etc. The concept is encompassed by the CEN EN 1332-4 Identification Card Systems - Man-Machine Interface. This development of this standard has been supported in Europe by SNAPI and has been successfully incorporated into the Lasseo specifications, but with limited success due to the lack of interest from public computer terminal suppliers.
<h2>Hearing impairments.</h2>
The deaf or hard of hearing community has a difficult time to communicate and perceive information as compared to hearing individuals. Thus, these individuals often rely on visual and tactile mediums for receiving and communicating information. The use of assistive technology and devices provides this community with various solutions to their problems by providing higher sound (for those who are hard of hearing), tactile feedback, visual cues and improved technology access. Individuals who are deaf or hard of hearing utilize a variety of assistive technologies that provide them with improved accessibility to information in numerous environments. Most devices either provide amplified sound or alternate ways to access information through vision and/or vibration. These technologies can be grouped into three general categories: Hearing Technology, alerting devices, and communication support.
<h3>Hearing aids.</h3>
A hearing aid or deaf aid is an electroacoustic device which is designed to amplify sound for the wearer, usually with the aim of making speech more intelligible, and to correct impaired hearing as measured by audiometry. This type of assistive technology helps people with hearing loss participate more fully in their communities by allowing them to hear more clearly. They amplify any and all sound waves through use of a microphone, amplifier, and speaker. There is a wide variety of hearing aids available, including digital, in-the-ear, in-the-canal, behind-the-ear, and on-the-body aids.
<h3>Assistive listening devices.</h3>
Assistive listening devices include FM, infrared, and loop assistive listening devices. This type of technology allows people with hearing difficulties to focus on a speaker or subject by getting rid of extra background noises and distractions, making places like auditoriums, classrooms, and meetings much easier to participate in. The assistive listening device usually uses a microphone to capture an audio source near to its origin and broadcast it wirelessly over an FM (Frequency Modulation) transmission, IR (Infra Red) transmission, IL (Induction Loop) transmission, or other transmission method. The person who is listening may use an FM/IR/IL Receiver to tune into the signal and listen at his/her preferred volume.
<h3>Amplified telephone equipment.</h3>
This type of assistive technology allows users to amplify the volume and clarity of their phone calls so that they can easily partake in this medium of communication. There are also options to adjust the frequency and tone of a call to suit their individual hearing needs. Additionally, there is a wide variety of amplified telephones to choose from, with different degrees of amplification. For example, a phone with 26 to 40 decibel is generally sufficient for mild hearing loss, while a phone with 71 to 90 decibel is better for more severe hearing loss.
<h2>Augmentative and alternative communication.</h2>
Augmentative and alternative communication (AAC) is an umbrella term that encompasses methods of communication for those with impairments or restrictions on the production or comprehension of spoken or written language. AAC systems are extremely diverse and depend on the capabilities of the user. They may be as basic as pictures on a board that are used to request food, drink, or other care; or they can be advanced speech generating devices, based on speech synthesis, that are capable of storing hundreds of phrases and words.
<h2>Cognitive impairments.</h2>
Assistive technology for cognition (ATC) is the use of technology (usually high tech) to augment and assistive cognitive processes such as attention, memory, self-regulation, navigation, emotion recognition and management, planning, and sequencing activity. Systematic reviews of the field have found that the number of ATC are growing rapidly, but have focused on memory and planning, that there is emerging evidence for efficacy, that a lot of scope exists to develop new ATC. Examples of ATC include: NeuroPage which prompts users about meetings, Wakamaru, which provides companionship and reminds users to take medicine and calls for help if something is wrong, and telephone Reassurance systems.
<h3>Memory aids.</h3>
Memory aids are any type of assistive technology that helps a user learn and remember certain information. Many memory aids are used for cognitive impairments such as reading, writing, or organizational difficulties. For example, a Smartpen records handwritten notes by creating both a digital copy and an audio recording of the text. Users simply tap certain parts of their notes and the pen saves it and reads it back to them. From there, the user can also download their notes onto a computer for increased accessibility. Digital voice recorders are also used to record "in the moment" information for fast and easy recall at a later time.
<h3>Educational software.</h3>
Educational software is software that assists people with reading, learning, comprehension, and organizational difficulties. Any accommodation software such as text readers, notetakers, text enlargers, organization tools, word predictions, and talking word processors falls under the category of educational software.
<h2>Assistive technology in sport.</h2>
Assistive technology in sport is an area of technology design that is growing. Assistive technology is the array of new devices created to enable sports enthusiasts who have disabilities to play. Assistive technology may be used in adaptive sports, where an existing sport is modified to enable players with a disability to participate; or, assistive technology may be used to invent completely new sports with athletes with disabilities exclusively in mind.
An increasing number of people with disabilities are participating in sports, leading to the development of new assistive technology. Assistive technology devices can be simple, or "low-tech", or they may use highly advanced technology, with some even using computers. Assistive technology for sports may also be simple, or advanced. Accordingly, assistive technology can be found in sports ranging from local community recreation to the elite Paralympic Games. More complex assistive technology devices have been developed over time, and as a result, sports for people with disabilities "have changed from being a clinical therapeutic tool to an increasingly competition-oriented activity".
<h2>Assistive technology in education.</h2>
In the United States there are two major pieces of legislation that govern the use of assistive technology within the school system. The first is Section 504 of the Rehabilitation Act of 1973 and the second being the Individuals with Disabilities Education Act (IDEA) which was first enacted in 1975 under the name The Education for All Handicapped Children Act. In 2004, during the reauthorization period for IDEA, the National Instructional Material Access Center (NIMAC) was created which provided a repository of accessible text including publisher's textbooks to students with a qualifying disability. Files provided are in XML format and used as a starting platform for braille readers, screen readers, and other digital text software. IDEA defines assistive technology as follows: "any item, piece of equipment, or product system, whether acquired commercially off the shelf, modified, or customized, that is used to increase, maintain, or improve functional capabilities of a child with a disability. (B) Exception.--The term does not include a medical device that is surgically implanted, or the replacement of such device." 
Assistive technology in this area is broken down into low, mid, and high tech categories. Low tech encompasses equipment that is often low cost and does not include batteries or requires charging. Examples include adapted paper and pencil grips for writing or masks and color overlays for reading. Mid tech supports used in the school setting include the use of handheld spelling dictionaries and portable word processors used to keyboard writing. High tech supports involve the use of tablet devices and computers with accompanying software. Software supports for writing include the use of auditory feedback while keyboarding, word prediction for spelling, and speech to text. Supports for reading include the use of text to speech (TTS) software and font modification via access to digital text. Limited supports are available for math instruction and mostly consist of grid based software to allow younger students to keyboard equations and auditory feedback of more complex equations using MathML and Daisy.
<h2>Computer accessibility.</h2>
One of the largest problems that affect people with disabilities is discomfort with prostheses. An experiment performed in Massachusetts utilized 20 people with various sensors attached to their arms. The subjects tried different arm exercises, and the sensors recorded their movements. All of the data helped engineers develop new engineering concepts for prosthetics.
Assistive technology may attempt to improve the ergonomics of the devices themselves such as Dvorak and other alternative keyboard layouts, which offer more ergonomic layouts of the keys.
Assistive technology devices have been created to enable people with disabilities to use modern touch screen mobile computers such as the iPad, iPhone and iPod touch. The Pererro is a plug and play adapter for iOS devices which uses the built in Apple VoiceOver feature in combination with a basic switch. This brings touch screen technology to those who were previously unable to use it. Apple, with the release of iOS 7 had introduced the ability to navigate apps using switch control. Switch access could be activated either through an external bluetooth connected switch, single touch of the screen, or use of right and left head turns using the device's camera. Additional accessibility features include the use of Assistive Touch which allows a user to access multi-touch gestures through pre-programmed onscreen buttons.
For users with physical disabilities a large variety of switches are available and customizable to the user's needs varying in size, shape, or amount of pressure required for activation. Switch access may be placed near any area of the body which has consistent and reliable mobility and less subject to fatigue. Common sites include the hands, head, and feet. Eye gaze and head mouse systems can also be used as an alternative mouse navigation. A user may utilize single or multiple switch sites and the process often involves a scanning through items on a screen and activating the switch once the desired object is highlighted.
<h2>Home automation.</h2>
The form of home automation called assistive domotics focuses on making it possible for elderly and disabled people to live independently. Home automation is becoming a viable option for the elderly and disabled who would prefer to stay in their own homes rather than move to a healthcare facility. This field uses much of the same technology and equipment as home automation for security, entertainment, and energy conservation but tailors it towards elderly and disabled users. For example, automated prompts and reminders utilize motion sensors and pre-recorded audio messages; an automated prompt in the kitchen may remind the resident to turn off the oven, and one by the front door may remind the resident to lock the door.
<h2>Impacts of assistive technology.</h2>
Overall, assistive technology aims to allow people with disabilities to "participate more fully in all aspects of life (home, school, and community)" and increases their opportunities for "education, social interactions, and potential for meaningful employment." It creates greater independence and control for disabled individuals. For example, in one study of 1,342 infants, toddlers and preschoolers, all with some kind of developmental, physical, sensory, or cognitive disability, the use of assistive technology created improvements in child development. These included improvements in "cognitive, social, communication, literacy, motor, adaptive, and increases in engagement in learning activities."

</doc>
<doc id="655" url="https://en.wikipedia.org/wiki?curid=655" title="Abacus">
Abacus

The abacus ("plural" abaci or abacuses), also called a counting frame, is a calculating tool that was in use in Europe, China and Russia, centuries before the adoption of the written Hindu–Arabic numeral system and is still used by merchants, traders and clerks in some parts of Eastern Europe, Russia, China and Africa. Today, abaci are often constructed as a bamboo frame with beads sliding on wires, but originally they were beans or stones moved in grooves in sand or on tablets of wood, stone, or metal.
<h2>Etymology.</h2>
The use of the word "abacus" dates before 1387 AD, when a Middle English work borrowed the word from Latin to describe a sandboard abacus. The Latin word came from Greek ἄβαξ "abax" which means something without base, and improperly, any piece of rectangular board or plank. 
Alternatively, without reference to ancient texts on etymology, it has been suggested that it means "a square tablet strewn with dust", or "drawing-board covered with dust (for the use of mathematics)" (the exact shape of the Latin perhaps reflects the genitive form of the Greek word, ἄβακoς "abakos"). Whereas the table strewn with dust definition is popular, there are those that do not place credence in this at all and in fact state that it is not proven. Greek ἄβαξ itself is probably a borrowing of a Northwest Semitic, perhaps Phoenician, word akin to Hebrew "ʾābāq" (אבק), "dust" (or in post-Biblical sense meaning "sand used as a writing surface").
The preferred plural of "abacus" is a subject of disagreement, with both "abacuses" and "abaci" in use. The user of an abacus is called an "abacist".
<h2>History.</h2>
<h3>Mesopotamian.</h3>
The period 2700–2300 BC saw the first appearance of the Sumerian abacus, a table of successive columns which delimited the successive orders of magnitude of their sexagesimal number system.
Some scholars point to a character from the Babylonian cuneiform which may have been derived from a representation of the abacus. It is the belief of Old Babylonian scholars such as Carruccio that Old Babylonians "may have used the abacus for the operations of addition and subtraction; however, this primitive device proved difficult to use for more complex calculations".
<h3>Egyptian.</h3>
The use of the abacus in Ancient Egypt is mentioned by the Greek historian Herodotus, who writes that the Egyptians manipulated the pebbles from right to left, opposite in direction to the Greek left-to-right method. Archaeologists have found ancient disks of various sizes that are thought to have been used as counters. However, wall depictions of this instrument have not been discovered.
<h3>Persian.</h3>
During the Achaemenid Empire, around 600 BC the Persians first began to use the abacus. Under the Parthian, Sassanian and Iranian empires, scholars concentrated on exchanging knowledge and inventions with the countries around them – India, China, and the Roman Empire, when it is thought to have been exported to other countries.
<h3>Greek.</h3>
The earliest archaeological evidence for the use of the Greek abacus dates to the 5th century BC. Also Demosthenes (384 BC–322 BC) talked of the need to use pebbles for calculations too difficult for your head. A play by Alexis from the 4th century BC mentions an abacus and pebbles for accounting, and both Diogenes and Polybius mention men that sometimes stood for more and sometimes for less, like the pebbles on an abacus. The Greek abacus was a table of wood or marble, pre-set with small counters in wood or metal for mathematical calculations. This Greek abacus saw use in Achaemenid Persia, the Etruscan civilization, Ancient Rome and, until the French Revolution, the Western Christian world.
A tablet found on the Greek island Salamis in 1846 AD (the Salamis Tablet), dates back to 300 BC, making it the oldest counting board discovered so far. It is a slab of white marble long, wide, and thick, on which are 5 groups of markings. In the center of the tablet is a set of 5 parallel lines equally divided by a vertical line, capped with a semicircle at the intersection of the bottom-most horizontal line and the single vertical line. Below these lines is a wide space with a horizontal crack dividing it. Below this crack is another group of eleven parallel lines, again divided into two sections by a line perpendicular to them, but with the semicircle at the top of the intersection; the third, sixth and ninth of these lines are marked with a cross where they intersect with the vertical line. Also from this time frame the "Darius Vase" was unearthed in 1851. It was covered with pictures including a "treasurer" holding a wax tablet in one hand while manipulating counters on a table with the other.
<h3>Chinese.</h3>
The earliest known written documentation of the Chinese abacus dates to the 2nd century BC.
The Chinese abacus, known as the suanpan (, lit. "Counting tray", Mandarin "suàn pán", Cantonese "syun pun"), is typically tall and comes in various widths depending on the operator. It usually has more than seven rods. There are two beads on each rod in the upper deck and five beads each in the bottom for both decimal and hexadecimal computation. The beads are usually rounded and made of a hardwood. The beads are counted by moving them up or down towards the beam. If you move them toward the beam, you count their value. If you move away, you don't count their value. The suanpan can be reset to the starting position instantly by a quick movement along the horizontal axis to spin all the beads away from the horizontal beam at the center.
Suanpans can be used for functions other than counting. Unlike the simple counting board used in elementary schools, very efficient suanpan techniques have been developed to do multiplication, division, addition, subtraction, square root and cube root operations at high speed. There are currently schools teaching students how to use it.
In the long scroll "Along the River During the Qingming Festival" painted by Zhang Zeduan (1085–1145 AD) during the Song dynasty (960–1297 AD), a suanpan is clearly seen lying beside an account book and doctor's prescriptions on the counter of an apothecary's (Feibao).
The similarity of the Roman abacus to the Chinese one suggests that one could have inspired the other, as there is some evidence of a trade relationship between the Roman Empire and China. However, no direct connection can be demonstrated, and the similarity of the abaci may be coincidental, both ultimately arising from counting with five fingers per hand. Where the Roman model (like most modern Korean and Japanese) has 4 plus 1 bead per decimal place, the standard suanpan has 5 plus 2. (Incidentally, this allows use with a hexadecimal numeral system.) Instead of running on wires as in the Chinese, Korean, and Japanese models, the beads of Roman model run in grooves, presumably making arithmetic calculations much slower.
Another possible source of the suanpan is Chinese counting rods, which operated with a decimal system but lacked the concept of zero as a place holder. The zero was probably introduced to the Chinese in the Tang dynasty (618-907 AD) when travel in the Indian Ocean and the Middle East would have provided direct contact with India, allowing them to acquire the concept of zero and the decimal point from Indian merchants and mathematicians.
<h3>Roman.</h3>
The normal method of calculation in ancient Rome, as in Greece, was by moving counters on a smooth table. Originally pebbles ("calculi") were used. Later, and in medieval Europe, jetons were manufactured. Marked lines indicated units, fives, tens etc. as in the Roman numeral system. This system of 'counter casting' continued into the late Roman empire and in medieval Europe, and persisted in limited use into the nineteenth century. Due to Pope Sylvester II's reintroduction of the abacus with very useful modifications, it became widely used in Europe once again during the 11th century This abacus used beads on wires, unlike the traditional Roman counting boards, which meant the abacus could be used much faster.
Writing in the 1st century BC, Horace refers to the wax abacus, a board covered with a thin layer of black wax on which columns and figures were inscribed using a stylus.
One example of archaeological evidence of the Roman abacus, shown here in reconstruction, dates to the 1st century AD. It has eight long grooves containing up to five beads in each and eight shorter grooves having either one or no beads in each. The groove marked I indicates units, X tens, and so on up to millions. The beads in the shorter grooves denote fives –five units, five tens etc., essentially in a bi-quinary coded decimal system, obviously related to the Roman numerals. The short grooves on the right may have been used for marking Roman "ounces" (i.e. fractions).
<h3>Indian.</h3>
There is no clear evidence for use of the abacus in India. The decimal number system invented in India replaced the abacus in Western Europe. 
The "Abhidharmakośabhāṣya" of Vasubandhu (316-396), a Sanskrit work on Buddhist philosophy, says that the second-century CE philosopher Vasumitra said that "placing a wick (Sanskrit "vartikā") on the number one ("ekāṅka") means it is a one, while placing the wick on the number hundred means it is called a hundred, and on the number one thousand means it is called a thousand". It is unclear exactly what this arrangement may have been. Around the 5th century, Indian clerks were already finding new ways of recording the contents of the Abacus. Hindu texts used the term "śūnya" (zero) to indicate the empty column on the abacus.
<h3>Japanese.</h3>
In Japanese, the abacus is called "soroban" (, lit. "Counting tray"), imported from China in the 14th century. It was probably in use by the working class a century or more before the ruling class started, as the class structure did not allow for devices used by the lower class to be adopted or used by the ruling class. The 1/4 abacus, which is suited to decimal calculation, appeared circa 1930, and became widespread as the Japanese abandoned hexadecimal weight calculation which was still common in China. The abacus is still manufactured in Japan today even with the proliferation, practicality, and affordability of pocket electronic calculators. The use of the soroban is still taught in Japanese primary schools as part of mathematics, primarily as an aid to faster mental calculation. Using visual imagery of a soroban, one can arrive at the answer in the same time as, or even faster than, is possible with a physical instrument.
<h3>Korean.</h3>
The Chinese abacus migrated from China to Korea around 1400 AD. Koreans call it "jupan" (주판), "supan" (수판) or "jusan" (주산).
<h3>Native American.</h3>
Some sources mention the use of an abacus called a "nepohualtzintzin" in ancient Aztec culture. This Mesoamerican abacus used a 5-digit base-20 system.
The word Nepōhualtzintzin comes from Nahuatl and it is formed by the roots; "Ne" - personal -; "pōhual" or "pōhualli" - the account -; and "tzintzin" - small similar elements. Its complete meaning was taken as: counting with small similar elements by somebody. Its use was taught in the Calmecac to the "temalpouhqueh" , who were students dedicated to take the accounts of skies, from childhood.
The Nepōhualtzintzin was divided in two main parts separated by a bar or intermediate cord. In the left part there were four beads, which in the first row have unitary values (1, 2, 3, and 4), and in the right side there are three beads with values of 5, 10, and 15 respectively. In order to know the value of the respective beads of the upper rows, it is enough to multiply by 20 (by each row), the value of the corresponding account in the first row.
Altogether, there were 13 rows with 7 beads in each one, which made up 91 beads in each Nepōhualtzintzin. This was a basic number to understand, 7 times 13, a close relation conceived between natural phenomena, the underworld and the cycles of the heavens. One Nepōhualtzintzin (91) represented the number of days that a season of the year lasts, two Nepōhualtzitzin (182) is the number of days of the corn's cycle, from its sowing to its harvest, three Nepōhualtzintzin (273) is the number of days of a baby's gestation, and four Nepōhualtzintzin (364) completed a cycle and approximate a year (1 days short). When translated into modern computer arithmetic, the Nepōhualtzintzin amounted to the rank from 10 to the 18 in floating point, which calculated stellar as well as infinitesimal amounts with absolute precision, meant that no round off was allowed.
The rediscovery of the Nepōhualtzintzin was due to the Mexican engineer David Esparza Hidalgo, who in his wanderings throughout Mexico found diverse engravings and paintings of this instrument and reconstructed several of them made in gold, jade, encrustations of shell, etc. There have also been found very old Nepōhualtzintzin attributed to the Olmec culture, and even some bracelets of Mayan origin, as well as a diversity of forms and materials in other cultures.
George I. Sanchez, "Arithmetic in Maya", Austin-Texas, 1961 found another base 5, base 4 abacus in the Yucatán peninsula that also computed calendar data. This was a finger abacus, on one hand 0, 1, 2, 3, and 4 were used; and on the other hand 0, 1, 2 and 3 were used. Note the use of zero at the beginning and end of the two cycles. Sanchez worked with Sylvanus Morley, a noted Mayanist.
The quipu of the Incas was a system of colored knotted cords used to record numerical data, like advanced tally sticks – but not used to perform calculations. Calculations were carried out using a yupana (Quechua for "counting tool"; see figure) which was still in use after the conquest of Peru. The working principle of a yupana is unknown, but in 2001 an explanation of the mathematical basis of these instruments was proposed by Italian mathematician Nicolino De Pasquale. By comparing the form of several yupanas, researchers found that calculations were based using the Fibonacci sequence 1, 1, 2, 3, 5 and powers of 10, 20 and 40 as place values for the different fields in the instrument. Using the Fibonacci sequence would keep the number of grains within any one field at a minimum.
<h3>Russian.</h3>
The Russian abacus, the "schoty" (счёты), usually has a single slanted deck, with ten beads on each wire (except one wire, usually positioned near the user, with four beads for quarter-ruble fractions). Older models have another 4-bead wire for quarter-kopeks, which were minted until 1916. The Russian abacus is often used vertically, with wires from left to right in the manner of a book. The wires are usually bowed to bulge upward in the center, to keep the beads pinned to either of the two sides. It is cleared when all the beads are moved to the right. During manipulation, beads are moved to the left. For easy viewing, the middle 2 beads on each wire (the 5th and 6th bead) usually are of a different color from the other eight beads. Likewise, the left bead of the thousands wire (and the million wire, if present) may have a different color.
As a simple, cheap and reliable device, the Russian abacus was in use in all shops and markets throughout the former Soviet Union, and the usage of it was taught in most schools until the 1990s. Even the 1874 invention of mechanical calculator, Odhner arithmometer, had not replaced them in Russia and likewise the mass production of Felix arithmometers since 1924 did not significantly reduce their use in the Soviet Union. The Russian abacus began to lose popularity only after the mass production of microcalculators had started in the Soviet Union in 1974. Today it is regarded as an archaism and replaced by the handheld calculator.
The Russian abacus was brought to France around 1820 by the mathematician Jean-Victor Poncelet, who served in Napoleon's army and had been a prisoner of war in Russia. The abacus had fallen out of use in western Europe in the 16th century with the rise of decimal notation and algorismic methods. To Poncelet's French contemporaries, it was something new. Poncelet used it, not for any applied purpose, but as a teaching and demonstration aid. The Turks and the Armenian people also used abaci similar to the Russian schoty. It was named a "coulba" by the Turks and a "choreb" by the Armenians.
<h2>School abacus.</h2>
Around the world, abaci have been used in pre-schools and elementary schools as an aid in teaching the numeral system and arithmetic.
In Western countries, a bead frame similar to the Russian abacus but with straight wires and a vertical frame has been common (see image). It is still often seen as a plastic or wooden toy.
The wire frame may be used either with positional notation like other abaci (thus the 10-wire version may represent numbers up to 9,999,999,999), or each bead may represent one unit (so that e.g. 74 can be represented by shifting all beads on 7 wires and 4 beads on the 8th wire, so numbers up to 100 may be represented). In the bead frame shown, the gap between the 5th and 6th wire, corresponding to the color change between the 5th and the 6th bead on each wire, suggests the latter use.
The red-and-white abacus is used in contemporary primary schools for a wide range of number-related lessons. The twenty bead version, referred to by its Dutch name "rekenrek", is often used, sometimes on a string of beads, sometimes on a rigid framework.
<h2>Uses by the blind.</h2>
An adapted abacus, invented by Tim Cranmer, called a Cranmer abacus is still commonly used by individuals who are blind. A piece of soft fabric or rubber is placed behind the beads so that they do not move inadvertently. This keeps the beads in place while the users feel or manipulate them. They use an abacus to perform the mathematical functions multiplication, division, addition, subtraction, square root and cube root.
Although blind students have benefited from talking calculators, the abacus is still very often taught to these students in early grades, both in public schools and state schools for the blind. The abacus teaches mathematical skills that can never be replaced with talking calculators and is an important learning tool for blind students. Blind students also complete mathematical assignments using a braille-writer and Nemeth code (a type of braille code for mathematics) but large multiplication and long division problems can be long and difficult. The abacus gives blind and visually impaired students a tool to compute mathematical problems that equals the speed and mathematical knowledge required by their sighted peers using pencil and paper. Many blind people find this number machine a very useful tool throughout life.
<h2>Binary abacus.</h2>
The binary abacus is used to explain how computers manipulate numbers. The abacus shows how numbers, letters, and signs can be stored in a binary system on a computer, or via ASCII. The device consists of a series of beads on parallel wires arranged in three separate rows. The beads represent a switch on the computer in either an 'on' or 'off' position.

</doc>
<doc id="656" url="https://en.wikipedia.org/wiki?curid=656" title="Acid">
Acid

An acid is a molecule or ion capable of donating a hydron (proton or hydrogen ion H), or, alternatively, capable of forming a covalent bond with an electron pair (a Lewis acid).
The first category of acids is the proton donors or Brønsted acids. In the special case of aqueous solutions, proton donors form the hydronium ion HO and are known as Arrhenius acids. Brønsted and Lowry generalized the Arrhenius theory to include non-aqueous solvents. A Brønsted or Arrhenius acid usually contains a hydrogen atom bonded to a chemical structure that is still energetically favorable after loss of H. 
Aqueous Arrhenius acids have characteristic properties which provide a practical description of an acid. Acids form aqueous solutions with a sour taste, can turn blue litmus red, and react with bases and certain metals (like calcium) to form salts. The word "acid" is derived from the Latin "acidus/acēre" meaning "sour". An aqueous solution of an acid has a pH less than 7 and is colloquially also referred to as 'acid' (as in 'dissolved in acid'), while the strict definition refers only to the solute. A lower pH means a higher acidity, and thus a higher concentration of positive hydrogen ions in the solution. Chemicals or substances having the property of an acid are said to be acidic.
Common aqueous acids include hydrochloric acid (a solution of hydrogen chloride which is found in gastric acid in the stomach and activates digestive enzymes), acetic acid (vinegar is a dilute aqueous solution of this liquid), sulfuric acid (used in car batteries), and citric acid (found in citrus fruits). As these examples show, acids (in the colloquial sense) can be solutions or pure substances, and can be derived from acids (in the strict sense) that are solids, liquids, or gases. Strong acids and some concentrated weak acids are corrosive, but there are exceptions such as carboranes and boric acid.
The second category of acids are Lewis acids, which form a covalent bond with an electron pair. An example is boron trifluoride (BF), whose boron atom has a vacant orbital which can form a covalent bond by sharing a lone pair of electrons on an atom in a base, for example the nitrogen atom in ammonia (NH). Lewis considered this as a generalization of the Brønsted definition, so that an acid is a chemical species that accepts electron pairs either directly "or" by releasing protons (H) into the solution, which then accept electron pairs. However, hydrogen chloride, acetic acid, and most other Brønsted-Lowry acids cannot form a covalent bond with an electron pair and are therefore not Lewis acids. Conversely, many Lewis acids are not Arrhenius or Brønsted-Lowry acids. In modern terminology, an "acid" is implicitly a Brønsted acid and not a Lewis acid, since chemists almost always refer to a Lewis acid explicitly as "a Lewis acid". 
<h2>Definitions and concepts.</h2>
Modern definitions are concerned with the fundamental chemical reactions common to all acids.
Most acids encountered in everyday life are aqueous solutions, or can be dissolved in water, so the Arrhenius and Brønsted-Lowry definitions are the most relevant.
The Brønsted-Lowry definition is the most widely used definition; unless otherwise specified, acid-base reactions are assumed to involve the transfer of a proton (H) from an acid to a base.
Hydronium ions are acids according to all three definitions. Interestingly, although alcohols and amines can be Brønsted-Lowry acids, they can also function as Lewis bases due to the lone pairs of electrons on their oxygen and nitrogen atoms.
<h3>Arrhenius acids.</h3>
The Swedish chemist Svante Arrhenius attributed the properties of acidity to hydrogen ions (H) or protons in 1884. An Arrhenius acid is a substance that, when added to water, increases the concentration of H ions in the water. Note that chemists often write H("aq") and refer to the hydrogen ion when describing acid-base reactions but the free hydrogen nucleus, a proton, does not exist alone in water, it exists as the hydronium ion, HO. Thus, an Arrhenius acid can also be described as a substance that increases the concentration of hydronium ions when added to water. Examples include molecular substances such as HCl and acetic acid.
An Arrhenius base, on the other hand, is a substance which increases the concentration of hydroxide (OH) ions when dissolved in water. This decreases the concentration of hydronium because the ions react to form HO molecules:
HO + OH ⇌ HO + HO
Due to this equilibrium, any increase in the concentration of hydronium is accompanied by a decrease in the concentration of hydroxide. Thus, an Arrhenius acid could also be said to be one that decreases hydroxide concentration, while an Arrhenius base increases it.
In an acidic solution, the concentration of hydronium ions is greater than 10 moles per liter. Since pH is defined as the negative logarithm of the concentration of hydronium ions, acidic solutions thus have a pH of less than 7.
<h3>Brønsted–Lowry acids.</h3>
While the Arrhenius concept is useful for describing many reactions, it is also quite limited in its scope. In 1923 chemists Johannes Nicolaus Brønsted and Thomas Martin Lowry independently recognized that acid-base reactions involve the transfer of a proton. A Brønsted-Lowry acid (or simply Brønsted acid) is a species that donates a proton to a Brønsted-Lowry base. Brønsted-Lowry acid-base theory has several advantages over Arrhenius theory. Consider the following reactions of acetic acid (CHCOOH), the organic acid that gives vinegar its characteristic taste:
Both theories easily describe the first reaction: CHCOOH acts as an Arrhenius acid because it acts as a source of HO when dissolved in water, and it acts as a Brønsted acid by donating a proton to water. In the second example CHCOOH undergoes the same transformation, in this case donating a proton to ammonia (NH), but does not relate to the Arrhenius definition of an acid because the reaction does not produce hydronium. Nevertheless, CHCOOH is both an Arrhenius and a Brønsted-Lowry acid.
Brønsted-Lowry theory can be used to describe reactions of molecular compounds in nonaqueous solution or the gas phase. Hydrogen chloride (HCl) and ammonia combine under several different conditions to form ammonium chloride, NHCl. In aqueous solution HCl behaves as hydrochloric acid and exists as hydronium and chloride ions. The following reactions illustrate the limitations of Arrhenius's definition:
As with the acetic acid reactions, both definitions work for the first example, where water is the solvent and hydronium ion is formed by the HCl solute. The next two reactions do not involve the formation of ions but are still proton-transfer reactions. In the second reaction hydrogen chloride and ammonia (dissolved in benzene) react to form solid ammonium chloride in a benzene solvent and in the third gaseous HCl and NH combine to form the solid.
<h3>Lewis acids.</h3>
A third, only marginally related concept was proposed in 1923 by Gilbert N. Lewis, which includes reactions with acid-base characteristics that do not involve a proton transfer. A Lewis acid is a species that accepts a pair of electrons from another species; in other words, it is an electron pair acceptor. Brønsted acid-base reactions are proton transfer reactions while Lewis acid-base reactions are electron pair transfers. Many Lewis acids are not Brønsted-Lowry acids. Contrast how the following reactions are described in terms of acid-base chemistry:
In the first reaction a fluoride ion, F, gives up an electron pair to boron trifluoride to form the product tetrafluoroborate. Fluoride "loses" a pair of valence electrons because the electrons shared in the B—F bond are located in the region of space between the two atomic nuclei and are therefore more distant from the fluoride nucleus than they are in the lone fluoride ion. BF is a Lewis acid because it accepts the electron pair from fluoride. This reaction cannot be described in terms of Brønsted theory because there is no proton transfer. The second reaction can be described using either theory. A proton is transferred from an unspecified Brønsted acid to ammonia, a Brønsted base; alternatively, ammonia acts as a Lewis base and transfers a lone pair of electrons to form a bond with a hydrogen ion. The species that gains the electron pair is the Lewis acid; for example, the oxygen atom in HO gains a pair of electrons when one of the H—O bonds is broken and the electrons shared in the bond become localized on oxygen. Depending on the context, a Lewis acid may also be described as an oxidizer or an electrophile. Organic Brønsted acids, such as acetic, citric, or oxalic acid, are not Lewis acids. They dissociate in water to produce a Lewis acid, H, but at the same time also yield an equal amount of a Lewis base (acetate, citrate, or oxalate, respectively, for the acids mentioned). Few, if any, of the acids discussed in the following are Lewis acids.
<h2>Dissociation and equilibrium.</h2>
Reactions of acids are often generalized in the form HA H + A, where HA represents the acid and A is the conjugate base. This reaction is referred to as protolysis. The protonated form (HA) of an acid is also sometimes referred to as the free acid.
Acid-base conjugate pairs differ by one proton, and can be interconverted by the addition or removal of a proton (protonation and deprotonation, respectively). Note that the acid can be the charged species and the conjugate base can be neutral in which case the generalized reaction scheme could be written as HA H + A. In solution there exists an equilibrium between the acid and its conjugate base. The equilibrium constant "K" is an expression of the equilibrium concentrations of the molecules or the ions in solution. Brackets indicate concentration, such that [HO] means "the concentration of HO". The acid dissociation constant "K" is generally used in the context of acid-base reactions. The numerical value of "K" is equal to the product of the concentrations of the products divided by the concentration of the reactants, where the reactant is the acid (HA) and the products are the conjugate base and H.
The stronger of two acids will have a higher "K" than the weaker acid; the ratio of hydrogen ions to acid will be higher for the stronger acid as the stronger acid has a greater tendency to lose its proton. Because the range of possible values for "K" spans many orders of magnitude, a more manageable constant, p"K" is more frequently used, where p"K" = -log "K". Stronger acids have a smaller p"K" than weaker acids. Experimentally determined p"K" at 25 °C in aqueous solution are often quoted in textbooks and reference material.
<h2>Nomenclature.</h2>
In the classical naming system, acids are named according to their anions. That ionic suffix is dropped and replaced with a new suffix (and sometimes prefix), according to the table below.
For example, HCl has chloride as its anion, so the -ide suffix makes it take the form hydrochloric acid. In the IUPAC naming system, "aqueous" is simply added to the name of the ionic compound. Thus, for hydrogen chloride, the IUPAC name would be aqueous hydrogen chloride. The prefix "hydro-" is added only if the acid is made up of just hydrogen and one other element.
Classical naming system:
<h2>Acid strength.</h2>
The strength of an acid refers to its ability or tendency to lose a proton. A strong acid is one that completely dissociates in water; in other words, one mole of a strong acid HA dissolves in water yielding one mole of H and one mole of the conjugate base, A, and none of the protonated acid HA. In contrast, a weak acid only partially dissociates and at equilibrium both the acid and the conjugate base are in solution. Examples of strong acids are hydrochloric acid (HCl), hydroiodic acid (HI), hydrobromic acid (HBr), perchloric acid (HClO), nitric acid (HNO) and sulfuric acid (HSO). In water each of these essentially ionizes 100%. The stronger an acid is, the more easily it loses a proton, H. Two key factors that contribute to the ease of deprotonation are the polarity of the H—A bond and the size of atom A, which determines the strength of the H—A bond. Acid strengths are also often discussed in terms of the stability of the conjugate base.
Stronger acids have a larger "K" and a more negative p"K" than weaker acids.
Sulfonic acids, which are organic oxyacids, are a class of strong acids. A common example is toluenesulfonic acid (tosylic acid). Unlike sulfuric acid itself, sulfonic acids can be solids. In fact, polystyrene functionalized into polystyrene sulfonate is a solid strongly acidic plastic that is filterable.
Superacids are acids stronger than 100% sulfuric acid. Examples of superacids are fluoroantimonic acid, magic acid and perchloric acid. Superacids can permanently protonate water to give ionic, crystalline hydronium "salts". They can also quantitatively stabilize carbocations.
While "K" measures the strength of an acid compound, the strength of an aqueous acid solution is measured by pH, which is an indication of the concentration of hydronium in the solution. The pH of a simple solution of an acid compound in water is determined by the dilution of the compound and the compound's "K".
<h2>Chemical characteristics.</h2>
<h3>Monoprotic acids.</h3>
Monoprotic acids are those acids that are able to donate one proton per molecule during the process of dissociation (sometimes called ionization) as shown below (symbolized by HA):
Common examples of monoprotic acids in mineral acids include hydrochloric acid (HCl) and nitric acid (HNO). On the other hand, for organic acids the term mainly indicates the presence of one carboxylic acid group and sometimes these acids are known as monocarboxylic acid. Examples in organic acids include formic acid (HCOOH), acetic acid (CHCOOH) and benzoic acid (CHCOOH).
<h3>Polyprotic acids.</h3>
Polyprotic acids, also known as polybasic acids, are able to donate more than one proton per acid molecule, in contrast to monoprotic acids that only donate one proton per molecule. Specific types of polyprotic acids have more specific names, such as diprotic acid (two potential protons to donate) and triprotic acid (three potential protons to donate).
A diprotic acid (here symbolized by HA) can undergo one or two dissociations depending on the pH. Each dissociation has its own dissociation constant, K and K.
The first dissociation constant is typically greater than the second; i.e., "K" > "K". For example, sulfuric acid (HSO) can donate one proton to form the bisulfate anion (HSO), for which "K" is very large; then it can donate a second proton to form the sulfate anion (SO), wherein the "K" is intermediate strength. The large "K" for the first dissociation makes sulfuric a strong acid. In a similar manner, the weak unstable carbonic acid (HCO) can lose one proton to form bicarbonate anion (HCO) and lose a second to form carbonate anion (CO). Both "K" values are small, but "K" > "K" .
A triprotic acid (HA) can undergo one, two, or three dissociations and has three dissociation constants, where "K" > "K" > "K".
An inorganic example of a triprotic acid is orthophosphoric acid (HPO), usually just called phosphoric acid. All three protons can be successively lost to yield HPO, then HPO, and finally PO, the orthophosphate ion, usually just called phosphate. Even though the positions of the three protons on the original phosphoric acid molecule are equivalent, the successive "K" values differ since it is energetically less favorable to lose a proton if the conjugate base is more negatively charged. An organic example of a triprotic acid is citric acid, which can successively lose three protons to finally form the citrate ion.
Although the subsequent loss of each hydrogen ion is less favorable, all of the conjugate bases are present in solution. The fractional concentration, "α" (alpha), for each species can be calculated. For example, a generic diprotic acid will generate 3 species in solution: HA, HA, and A. The fractional concentrations can be calculated as below when given either the pH (which can be converted to the [H]) or the concentrations of the acid with all its conjugate bases:
A plot of these fractional concentrations against pH, for given "K" and "K", is known as a Bjerrum plot. A pattern is observed in the above equations and can be expanded to the general "n" -protic acid that has been deprotonated "i" -times:
\alpha_{\ce H_{n-i} A^{i-} }= 

</doc>
<doc id="657" url="https://en.wikipedia.org/wiki?curid=657" title="Asphalt">
Asphalt

Asphalt (, , occasionally ), also known as bitumen (, ) is a sticky, black and highly viscous liquid or semi-solid form of petroleum. It may be found in natural deposits or may be a refined product; it is a substance classed as a pitch. Until the 20th century, the term asphaltum was also used. The word is derived from the Ancient Greek ἄσφαλτος "ásphaltos".
The primary use (70%) of asphalt/bitumen is in road construction, where it is used as the glue or binder mixed with aggregate particles to create asphalt concrete. Its other main uses are for bituminous waterproofing products, including production of roofing felt and for sealing flat roofs.
The terms "asphalt" and "bitumen" are often used interchangeably to mean both natural and manufactured forms of the substance. In American English, asphalt (or asphalt cement) is the carefully refined residue from the distillation process of selected crude oils. Outside the United States, the product is often called bitumen. Geologists often prefer the term "bitumen". Common usage often refers to various forms of asphalt/bitumen as "tar", such as at the La Brea Tar Pits. Another archaic term for asphalt/bitumen is "pitch".
Naturally occurring asphalt/bitumen is sometimes specified by the term "crude bitumen". Its viscosity is similar to that of cold molasses while the material obtained from the fractional distillation of crude oil boiling at is sometimes referred to as "refined bitumen". The Canadian province of Alberta has most of the world's reserves of natural bitumen, covering , an area larger than England.
<h2>Composition.</h2>
The components of asphalt are classified into four classes of compounds: 
The naphthene aromatics and polar aromatics are typically the majority components. Additionally, most natural bitumens contain organosulfur compounds, resulting in an overall sulfur content of up to 4%. Nickel and vanadium are found in the <10 ppm level, as is typical of some petroleum.
The substance is soluble in carbon disulfide. It is commonly modelled as a colloid, with asphaltenes as the dispersed phase and maltenes as the continuous phase. and "it is almost impossible to separate and identify all the different molecules of asphalt, because the number of molecules with different chemical structure is extremely large".
Asphalt/bitumen can sometimes be confused with "coal tar", which is a visually similar black, thermoplastic material produced by the destructive distillation of coal. During the early and mid-20th century when town gas was produced, coal tar was a readily available byproduct and extensively used as the binder for road aggregates. The addition of tar to macadam roads led to the word tarmac, which is now used in common parlance to refer to road-making materials. However, since the 1970s, when natural gas succeeded town gas, asphalt/bitumen has completely overtaken the use of coal tar in these applications. Other examples of this confusion include the La Brea Tar Pits and the Canadian oil sands, both of which actually contain natural bitumen rather than tar. Pitch is another term sometimes used at times to refer to asphalt/bitumen, as in Pitch Lake.
<h2>Occurrence.</h2>
The great majority of asphalt used commercially is obtained from petroleum. Nonetheless, large amounts of asphalt occur in concentrated form in nature. Naturally occurring deposits of asphalt/bitumen are formed from the remains of ancient, microscopic algae (diatoms) and other once-living things. These remains were deposited in the mud on the bottom of the ocean or lake where the organisms lived. Under the heat (above 50 °C) and pressure of burial deep in the earth, the remains were transformed into materials such as asphalt/bitumen, kerogen, or petroleum.
Natural deposits of asphalt/bitumen include lakes such as the Pitch Lake in Trinidad and Tobago and Lake Bermudez in Venezuela. Natural seeps of asphalt/bitumen occur in the La Brea Tar Pits and in the Dead Sea.
Asphalt/bitumen also occurs in unconsolidated sandstones known as "oil sands" in Alberta, Canada, and the similar "tar sands" in Utah, US.
The Canadian province of Alberta has most of the world's reserves of natural bitumen, in three huge deposits covering , an area larger than England or New York state. These bituminous sands contain of commercially established oil reserves, giving Canada the third largest oil reserves in the world. and produce over of heavy crude oil and synthetic crude oil. Although historically it was used without refining to pave roads, nearly all of the bitumen is now used as raw material for oil refineries in Canada and the United States.
The world's largest deposit of natural bitumen, known as the Athabasca oil sands is located in the McMurray Formation of Northern Alberta. This formation is from the early Cretaceous, and is composed of numerous lenses of oil-bearing sand with up to 20% oil. Isotopic studies attribute the oil deposits to be about 110 million years old. Two smaller but still very large formations occur in the Peace River oil sands and the Cold Lake oil sands, to the west and southeast of the Athabasca oil sands, respectively. Of the Alberta bitumen deposits, only parts of the Athabasca oil sands are shallow enough to be suitable for surface mining. The other 80% has to be produced by oil wells using enhanced oil recovery techniques like steam-assisted gravity drainage.
Much smaller heavy oil or bitumen deposits also occur in the Uinta Basin in Utah, US. The Tar Sand Triangle deposit, for example, is roughly 6% bitumen.
Asphalt/bitumen occurs in hydrothermal veins. An example of this is within the Uinta Basin of Utah, in the US, where there is a swarm of laterally and vertically extensive veins composed of a solid hydrocarbon termed Gilsonite. These veins formed by the polymerization and solidification of hydrocarbons that were mobilized from the deeper oil shales of the Green River Formation during burial and diagenesis.
Asphalt/bitumen is similar to the organic matter in carbonaceous meteorites. However, detailed studies have shown these materials to be distinct. The vast Alberta bitumen resources are believed to have started out as living material from marine plants and animals, mainly algae, that died millions of years ago when an ancient ocean covered Alberta. They were covered by mud, buried deeply over the eons, and gently cooked into oil by geothermal heat at a temperature of . Due to pressure from the rising of the Rocky Mountains in southwestern Alberta, 80 to 55 million years ago, the oil was driven northeast hundreds of kilometres into underground sand deposits left behind by ancient river beds and ocean beaches, thus forming the oil sands.
<h2>History.</h2>
<h3>Ancient times.</h3>
The use of asphalt/bitumen for waterproofing and as an adhesive dates at least to the fifth millennium BC in the early Indus valley sites like Mehrgarh, where it was used to line the baskets in which crops were gathered.
In the ancient Middle East, the Sumerians used natural asphalt/bitumen deposits for mortar between bricks and stones, to cement parts of carvings, such as eyes, into place, for ship caulking, and for waterproofing. The Greek historian Herodotus said hot asphalt/bitumen was used as mortar in the walls of Babylon, as did Moses in reference to the Tower of Babel.
A tunnel beneath the river Euphrates at Babylon in the time of Queen Semiramis (ca. 800 BC) was reportedly constructed of burnt bricks covered with asphalt/bitumen as a waterproofing agent.
Asphalt/bitumen was used by ancient Egyptians to embalm mummies. The Persian word for asphalt is "moom", which is related to the English word mummy. The Egyptians' primary source of asphalt/bitumen was the Dead Sea, which the Romans knew as "Palus Asphaltites" (Asphalt Lake).
Approximately 40 AD, Dioscorides described the Dead Sea material as "Judaicum bitumen", and noted other places in the region where it could be found.
The Sidon bitumen is thought to refer to asphalt/bitumen found at Hasbeya. Pliny refers also to asphalt/bitumen being found in Epirus. It was a valuable strategic resource; the object of the first known battle for a hydrocarbon deposit, between the Seleucids and the Nabateans in 312 BC.
In the ancient Far East, natural asphalt/bitumen was slowly boiled to get rid of the higher fractions, leaving a thermoplastic material of higher molecular weight which when layered on objects became quite hard upon cooling. This was used to cover objects that needed waterproofing, such as scabbards and other items. Statuettes of household deities were also cast with this type of material in Japan, and probably also in China.
In North America, archaeological recovery has indicated asphalt/bitumen was sometimes used to adhere stone projectile points to wooden shafts. In Canada, aboriginal people used bitumen seeping out of the banks of the Athabasca and other rivers to waterproof birch bark canoes, and also heated it in smudge pots to ward off mosquitoes in the summer time.
<h3>Early use in Europe.</h3>
In 1453, Pierre Belon described in his work "Observations" in 1553 that "pissasphalto", a mixture of pitch and bitumen, was used in the Republic of Ragusa (now Dubrovnik, Croatia) for tarring of ships from where it was exported to a market place in Venice where it could be bought by anyone.
An 1838 edition of "Mechanics Magazine" cites an early use of asphalt in France. A pamphlet dated 1621, by "a certain Monsieur d'Eyrinys, states that he had discovered the existence (of asphaltum) in large quantities in the vicinity of Neufchatel", and that he proposed to use it in a variety of ways – "principally in the construction of air-proof granaries, and in protecting, by means of the arches, the water-courses in the city of Paris from the intrusion of dirt and filth", which at that time made the water unusable. "He expatiates also on the excellence of this material for forming level and durable terraces" in palaces, "the notion of forming such terraces in the streets not one likely to cross the brain of a Parisian of that generation". But it was generally neglected in France until the revolution of 1830. Then, in the 1830s, there was a surge of interest, and asphalt became widely used "for pavements, flat roofs, and the lining of cisterns, and in England, some use of it had been made of it for similar purposes". Its rise in Europe was "a sudden phenomenon", after natural deposits were found "in France at Osbann (Bas-Rhin), the Parc (Ain) and the Puy-de-la-Poix (Puy-de-Dôme)", although it could also be made artificially. One of the earliest uses in France was the laying of about 24,000 square yards of Seyssel asphalt at the Place de la Concorde in 1835.
<h3>Photography and art.</h3>
Bitumen was used in early photographic technology. In 1826 or 1827, it was used by French scientist Joseph Nicéphore Niépce to make the oldest surviving photograph from nature. The bitumen was thinly coated onto a pewter plate which was then exposed in a camera. Exposure to light hardened the bitumen and made it insoluble, so that when it was subsequently rinsed with a solvent only the sufficiently light-struck areas remained. Many hours of exposure in the camera were required, making bitumen impractical for ordinary photography, but from the 1850s to the 1920s it was in common use as a photoresist in the production of printing plates for various photomechanical printing processes.
Bitumen was the nemesis of many artists during the 19th century. Although widely used for a time, it ultimately proved unstable for use in oil painting, especially when mixed with the most common diluents, such as linseed oil, varnish and turpentine. Unless thoroughly diluted, bitumen never fully solidifies and will in time corrupt the other pigments with which it comes into contact. The use of bitumen as a glaze to set in shadow or mixed with other colors to render a darker tone resulted in the eventual deterioration of many paintings, for instance those of Delacroix. Perhaps the most famous example of the destructiveness of bitumen is Théodore Géricault's Raft of the Medusa (1818–1819), where his use of bitumen caused the brilliant colors to degenerate into dark greens and blacks and the paint and canvas to buckle.
<h3>Early use in the United Kingdom.</h3>
Among the earlier uses of asphalt/bitumen in the United Kingdom was for etching. William Salmon's "Polygraphice" (1673) provides a recipe for varnish used in etching, consisting of three ounces of virgin wax, two ounces of mastic, and one ounce of asphaltum. By the fifth edition in 1685, he had included more asphaltum recipes from other sources.
The first British patent for the use of asphalt/bitumen was 'Cassell's patent asphalte or bitumen' in 1834. Then on 25 November 1837, Richard Tappin Claridge patented the use of Seyssel asphalt (patent #7849), for use in asphalte pavement, having seen it employed in France and Belgium when visiting with Frederick Walter Simms, who worked with him on the introduction of asphalt to Britain. Dr T. Lamb Phipson writes that his father, Samuel Ryland Phipson, a friend of Claridge, was also "instrumental in introducing the asphalte pavement (in 1836)". Indeed, mastic pavements had been previously employed at Vauxhall by a competitor of Claridge, but without success.
In 1838, Claridge obtained patents in Scotland on 27 March, and Ireland on 23 April, and in 1851 extensions were sought for all three patents, by the trustees of a company previously formed by Claridge. This was "Claridge's Patent Asphalte Company", formed in 1838 for the purpose of introducing to Britain "Asphalte in its natural state from the mine at Pyrimont Seysell in France", and "laid one of the first asphalt pavements in Whitehall". Trials were made of the pavement in 1838 on the footway in Whitehall, the stable at Knightsbridge Barracks, "and subsequently on the space at the bottom of the steps leading from Waterloo Place to St. James Park". "The formation in 1838 of Claridge's Patent Asphalte Company (with a distinguished list of aristocratic patrons, and Marc and Isambard Brunel as, respectively, a trustee and consulting engineer), gave an enormous impetus to the development of a British asphalt industry". "By the end of 1838, at least two other companies, Robinson's and the Bastenne company, were in production", with asphalt being laid as paving at Brighton, Herne Bay, Canterbury, Kensington, the Strand, and a large floor area in Bunhill-row, while meantime Claridge's Whitehall paving "continue(d) in good order".
In 1838, there was a flurry of entrepreneurial activity involving asphalt/bitumen, which had uses beyond paving. For example, asphalt could also used for flooring, damp proofing in buildings, and for waterproofing of various types of pools and baths, with these latter themselves proliferating in the 19th century. On the London stockmarket, there were various claims as to the exclusivity of asphalt quality from France, Germany and England. And numerous patents were granted in France, with similar numbers of patent applications being denied in England due to their similarity to each other. In England, "Claridge's was the type most used in the 1840s and 50s"
In 1914, Claridge's Company entered into a joint venture to produce tar-bound macadam, with materials manufactured through a subsidiary company called Clarmac Roads Ltd. Two products resulted, namely "Clarmac", and "Clarphalte", with the former being manufactured by Clarmac Roads and the latter by Claridge's Patent Asphalte Co., although "Clarmac" was more widely used. However, the First World War impacted financially on the Clarmac Company, which entered into liquidation in 1915. The failure of Clarmac Roads Ltd had a flow-on effect to Claridge's Company, which was itself compulsorily wound up, ceasing operations in 1917, having invested a substantial amount of funds into the new venture, both at the outset, and in a subsequent attempt to save the Clarmac Company.
<h3>Early use in the US.</h3>
The first use of asphalt/bitumen in the New World was by indigenous peoples. On the west coast, as early as the 13th century, the Tongva, Luiseño and Chumash peoples collected the naturally occurring asphalt/bitumen that seeped to the surface above underlying petroleum deposits. All three used the substance as an adhesive. It is found on many different artifacts of tools and ceremonial items. For example, it was used on rattles to adhere gourds or turtle shells to rattle handles. It was also used in decorations. Small round shell beads were often set in asphaltum to provide decorations. It was used as a sealant on baskets to make them watertight for carrying water. Asphaltum was used also to seal the planks on ocean-going canoes.
Roads in the US have been paved with materials that include asphalt/bitumen since at least 1870, when a street in front of the Newark, NJ City Hall was paved. In many cases, these early pavings were made from naturally occurring "bituminous rock", such as at Ritchie Mines in Macfarlan in Ritchie County, West Virginia from 1852 to 1873. In 1876, asphalt-based paving was used to pave Pennsylvania Avenue in Washington, DC, in time for the celebration of the national centennial. Asphalt/bitumen was also used for flooring, paving and waterproofing of baths and swimming pools during the early 20th century, following similar trends in Europe.
<h3>Early use in Canada.</h3>
Canada has the world's largest deposit of natural bitumen in the Athabasca oil sands and Canadian First Nations along the Athabasca River had long used it to waterproof their canoes. In 1719, a Cree Indian named Wa-Pa-Su brought a sample for trade to Henry Kelsey of the Hudson’s Bay Company, who was the first recorded European to see it. However, it wasn't until 1787 that fur trader and explorer Alexander MacKenzie saw the Athabasca oil sands and said, "At about 24 miles from the fork (of the Athabasca and Clearwater Rivers) are some bituminous fountains into which a pole of 20 feet long may be inserted without the least resistance."
The value of the deposit was obvious from the start, but the means of extracting the bitumen were not. The nearest town, Fort McMurray, Alberta was a small fur trading post, other markets were far away, and transportation costs were too high to ship the raw bituminous sand for paving. In 1915, Sidney Ells of the Federal Mines Branch experimented with separation techniques and used the bitumen to pave 600 feet of road in Edmonton, Alberta. Other roads in Alberta were paved with oil sands, but it was generally not economic. During the 1920s Dr. Karl A. Clark of the Alberta Research Council patented a hot water oil separation process and entrepreneur Robert C. Fitzsimmons built the Bitumount oil separation plant, which between 1925 and 1958 produced up to per day of bitumen using Dr. Clark's method. Most of the bitumen was used for waterproofing roofs, but other uses included fuels, lubrication oils, printers ink, medicines, rust and acid-proof paints, fireproof roofing, street paving, patent leather, and fence post preservatives. Eventually Fitzsimmons ran out of money and the plant was taken over by the Alberta government. Today the Bitumount plant is a Provincial Historic Site.
<h2>Modern use.</h2>
<h3>Rolled asphalt concrete.</h3>
The largest use of asphalt/bitumen is for making asphalt concrete for road surfaces and accounts for approximately 85% of the asphalt consumed in the United States. Asphalt concrete pavement mixes are typically composed of 5% asphalt/bitumen cement and 95% aggregates (stone, sand, and gravel). Due to its highly viscous nature, asphalt/bitumen cement must be heated so it can be mixed with the aggregates at the asphalt mixing facility. The temperature required varies depending upon characteristics of the asphalt/bitumen and the aggregates, but warm-mix asphalt technologies allow producers to reduce the temperature required. There are about 4,000 asphalt concrete mixing plants in the U.S., and a similar number in Europe.
When maintenance is performed on asphalt pavements, such as milling to remove a worn or damaged surface, the removed material can be returned to a facility for processing into new pavement mixtures. The asphalt/bitumen in the removed material can be reactivated and put back to use in new pavement mixes. With some 95% of paved roads being constructed of or surfaced with asphalt, a substantial amount of asphalt pavement material is reclaimed each year. According to industry surveys conducted annually by the Federal Highway Administration and the National Asphalt Pavement Association, more than 99% of the asphalt removed each year from road surfaces during widening and resurfacing projects is reused as part of new pavements, roadbeds, shoulders and embankments.
Asphalt concrete paving is widely used in airports around the world. Due to the sturdiness and ability to be repaired quickly, it is widely used for runways dedicated to aircraft landing and taking off.
<h3>Mastic asphalt.</h3>
Mastic asphalt is a type of asphalt which differs from dense graded asphalt (asphalt concrete) in that it has a higher asphalt/bitumen (binder) content, usually around 7–10% of the whole aggregate mix, as opposed to rolled asphalt concrete, which has only around 5% added asphalt/bitumen. This thermoplastic substance is widely used in the building industry for waterproofing flat roofs and tanking underground. Mastic asphalt is heated to a temperature of and is spread in layers to form an impervious barrier about thick.
<h3>Asphalt emulsion.</h3>
A number of technologies allow asphalt/bitumen to be mixed at much lower temperatures. These involve mixing with petroleum solvents to form "cutbacks" with reduced melting point, or mixtures with water to turn the asphalt/bitumen into an emulsion. Asphalt emulsions contain up to 70% asphalt/bitumen and typically less than 1.5% chemical additives. There are two main types of emulsions with different affinity for aggregates, cationic and anionic. Asphalt emulsions are used in a wide variety of applications. Chipseal involves spraying the road surface with asphalt emulsion followed by a layer of crushed rock, gravel or crushed slag. Slurry seal involves the creation of a mixture of asphalt emulsion and fine crushed aggregate that is spread on the surface of a road. Cold-mixed asphalt can also be made from asphalt emulsion to create pavements similar to hot-mixed asphalt, several inches in depth and asphalt emulsions are also blended into recycled hot-mix asphalt to create low-cost pavements.
<h3>Synthetic crude oil.</h3>
Synthetic crude oil, also known as syncrude, is the output from a bitumen upgrader facility used in connection with oil sand production in Canada. Bituminous sands are mined using enormous (100 ton capacity) power shovels and loaded into even larger (400 ton capacity) dump trucks for movement to an upgrading facility. The process used to extract the bitumen from the sand is a hot water process originally developed by Dr. Karl Clark of the University of Alberta during the 1920s. After extraction from the sand, the bitumen is fed into a bitumen upgrader which converts it into a light crude oil equivalent. This synthetic substance is fluid enough to be transferred through conventional oil pipelines and can be fed into conventional oil refineries without any further treatment. By 2015 Canadian bitumen upgraders were producing over per day of synthetic crude oil, of which 75% was exported to oil refineries in the United States.
In Alberta, five bitumen upgraders produce synthetic crude oil and a variety of other products: The Suncor Energy upgrader near Fort McMurray, Alberta produces synthetic crude oil plus diesel fuel; the Syncrude Canada, Canadian Natural Resources, and Nexen upgraders near Fort McMurray produce synthetic crude oil; and the Shell Scotford Upgrader near Edmonton produces synthetic crude oil plus an intermediate feedstock for the nearby Shell Oil Refinery. A sixth upgrader, under construction in 2015 near Redwater, Alberta, will upgrade half of its crude bitumen directly to diesel fuel, with the remainder of the output being sold as feedstock to nearby oil refineries and petrochemical plants.
<h3>Non-upgraded crude bitumen.</h3>
Canadian bitumen does not differ substantially from oils such as Venezuelan extra-heavy and Mexican heavy oil in chemical composition, and the real difficulty is moving the extremely viscous bitumen through oil pipelines to the refinery. Many modern oil refineries are extremely sophisticated and can process non-upgraded bitumen directly into products such as gasoline, diesel fuel, and refined asphalt without any preprocessing. This is particularly common in areas such as the US Gulf coast, where refineries were designed to process Venezuelan and Mexican oil, and in areas such as the US Midwest where refineries were rebuilt to process heavy oil as domestic light oil production declined. Given the choice, such heavy oil refineries usually prefer to buy bitumen rather than synthetic oil because the cost is lower, and in some cases because they prefer to produce more diesel fuel and less gasoline. By 2015 Canadian production and exports of non-upgraded bitumen exceeded that of synthetic crude oil at over per day, of which about 65% was exported to the United States.
Because of the difficulty of moving crude bitumen through pipelines, non-upgraded bitumen is usually diluted with natural-gas condensate in a form called dilbit or with synthetic crude oil, called synbit. However, to meet international competition, much non-upgraded bitumen is now sold as a blend of multiple grades of bitumen, conventional crude oil, synthetic crude oil, and condensate in a standardized benchmark product such as Western Canadian Select. This sour, heavy crude oil blend is designed to have uniform refining characteristics to compete with internationally marketed heavy oils such as Mexican Mayan or Arabian Dubai Crude.
<h3>Other uses.</h3>
Roofing shingles account for most of the remaining asphalt/bitumen consumption. Other uses include cattle sprays, fence-post treatments, and waterproofing for fabrics. Asphalt/bitumen is used to make Japan black, a lacquer known especially for its use on iron and steel, and it is also used in paint and marker inks by some graffiti supply companies to increase the weather resistance and permanence of the paint or ink, and to make the color much darker. Asphalt/bitumen is also used to seal some alkaline batteries during the manufacturing process.
<h2>Production.</h2>
About 40,000,000 tons were produced in 1984. It is obtained as the "heavy" (i.e., difficult to distill) fraction. Material with a boiling point greater than around 500 °C is considered asphalt. Vacuum distillation separates it from the other components in crude oil (such as naphtha, gasoline and diesel). The resulting material is typically further treated to extract small but valuable amounts of lubricants and to adjust the properties of the material to suit applications. In a de-asphalting unit, the crude asphalt is treated with either propane or butane in a supercritical phase to extract the lighter molecules, which are then separated. Further processing is possible by "blowing" the product: namely reacting it with oxygen. This step makes the product harder and more viscous.
Asphalt/bitumen is typically stored and transported at temperatures around . Sometimes diesel oil or kerosene are mixed in before shipping to retain liquidity; upon delivery, these lighter materials are separated out of the mixture. This mixture is often called "bitumen feedstock", or BFS. Some dump trucks route the hot engine exhaust through pipes in the dump body to keep the material warm. The backs of tippers carrying asphalt/bitumen, as well as some handling equipment, are also commonly sprayed with a releasing agent before filling to aid release. Diesel oil is no longer used as a release agent due to environmental concerns.
<h3>From oil sands.</h3>
Naturally occurring crude asphalt/bitumen impregnated in sedimentary rock is the prime feed stock for petroleum production from "Oil sands", currently under development in Alberta, Canada. Canada has most of the world's supply of natural asphalt/bitumen, covering 140,000 square kilometres (an area larger than England), giving it the second-largest proven oil reserves in the world. The Athabasca oil sands is the largest asphalt/bitumen deposit in Canada and the only one accessible to surface mining, although recent technological breakthroughs have resulted in deeper deposits becoming producible by "in situ" methods. Because of oil price increases after 2003, producing bitumen became highly profitable, but as a result of the decline after 2014 it became uneconomic to build new plants again. By 2014, Canadian crude asphalt/bitumen production averaged about per day and was projected to rise to per day by 2020. The total amount of crude asphalt/bitumen in Alberta which could be extracted is estimated to be about , which at a rate of would last about 200 years.
<h3>Alternatives and bioasphalt.</h3>
Although uncompetitive economically, asphalt/bitumen can be made from nonpetroleum-based renewable resources such as sugar, molasses and rice, corn and potato starches. Asphalt/bitumen can also be made from waste material by fractional distillation of used motor oil, which is sometimes otherwise disposed of by burning or dumping into landfills. Use of motor oil may cause premature cracking in colder climates, resulting in roads that need to be repaved more frequently.
Nonpetroleum-based asphalt/bitumen binders can be made light-colored. Lighter-colored roads absorb less heat from solar radiation, and have less surface heat than darker surfaces, reducing their contribution to the urban heat island effect. Parking lots that use asphalt alternatives are called green parking lots.
<h3>Natural bitumen.</h3>
Selenizza is a naturally occurring solid hydrocarbon bitumen found in the native asphalt deposit of Selenice, in Albania, the only European asphalt mine still in use. The rock asphalt is found in the form of veins, filling cracks in a more or less horizontal direction. The bitumen content varies from 83% to 92% (soluble in carbon disulphide), with a penetration value near to zero and a softening point (ring & ball) around 120 °C. The insoluble matter, consisting mainly of silica ore, ranges from 8% to 17%.
The Albanian bitumen extraction has a long history and was practiced in an organized way by the Romans. After centuries of silence, the first mentions of Albanian bitumen appeared only in 1868, when the Frenchman Coquand published the first geological description of the deposits of Albanian bitumen. In 1875, the exploitation rights were granted to the Ottoman government and in 1912, they were transferred to the Italian company Simsa. Since 1945, the mine was exploited by the Albanian government and from 2001 to date, the management passed to a French company, which organized the mining process for the manufacture of the natural bitumen on an industrial scale.
Today the mine is predominantly exploited in an open pit quarry but several of the many underground mines (deep and extending over several km) still remain viable. The bitumen Selenizza is produced primarily in granular form, after melting the asphalt pieces selected in the mine.
Selenizza is mainly used as an additive in the road construction sector. It is mixed with traditional bitumen to improve both the viscoelastic properties and the resistance to ageing. It may be blended with the hot bitumen in tanks, but its granular form allows it to be fed in the mixer or in the recycling ring of normal asphalt plants. Other typical applications include the production of mastic asphalts for sidewalks, bridges, car-parks and urban roads as well as drilling fluid additives for the oil and gas industry. Selenizza is available in powder or in granular material of various particle sizes and is packaged in big bags or in thermal fusible polyethylene bags.
A Life Cycle Assessment (LCA) study of the natural bitumen Selenizza compared with petroleum bitumen, has shown that the environmental impact of the natural bitumen is about half the impact of the road bitumen produced in oil refineries in terms of carbon dioxide emission.
<h3>Occupational safety.</h3>
People can be exposed to asphalt in the workplace by breathing in fumes or skin absorption. The National Institute for Occupational Safety and Health (NIOSH) has set a Recommended exposure limit (REL) of 5 mg/m over a 15-minute period. Asphalt is basically an inert material that must be heated or diluted to a point where it becomes workable for the production of materials for paving, roofing, and other applications. In examining the potential health hazards associated with asphalt, the International Agency for Research on Cancer (IARC) determined that it is the application parameters, predominantly temperature, that affect occupational exposure and the potential bioavailable carcinogenic hazard/risk of the asphalt emissions. In particular, temperatures greater than 199 °C (390 °F), were shown to produce a greater exposure risk than when asphalt was heated to lower temperatures, such as those typically used in asphalt pavement mix production and placement.
<h2>Etymology.</h2>
The word "asphalt" is derived from the late Middle English, in turn from French "asphalte", based on Late Latin "asphalton", "asphaltum", which is the latinisation of the Greek ἄσφαλτος ("ásphaltos", "ásphalton"), a word meaning "asphalt/bitumen/pitch", which perhaps derives from ἀ-, "without" and σφάλλω ("sfallō"), "make fall". Note that in French, the term "asphalte" is used for naturally occurring bitumen-soaked limestone deposits, and for specialised manufactured products with fewer voids or greater bitumen content than the "asphaltic concrete" used to pave roads. It is a significant fact that the first use of asphalt by the ancients was in the nature of a cement for securing or joining together various objects, and it thus seems likely that the name itself was expressive of this application. Specifically Herodotus mentioned that bitumen was brought to Babylon to build its gigantic fortification wall. From the Greek, the word passed into late Latin, and thence into French ("asphalte") and English ("asphaltum" and "asphalt").
The expression "bitumen" originated in the Sanskrit, where we find the words "jatu", meaning "pitch," and "jatu-krit", meaning "pitch creating", "pitch producing" (referring to coniferous or resinous trees). The Latin equivalent is claimed by some to be originally "gwitu-men" (pertaining to pitch), and by others, "pixtumens" (exuding or bubbling pitch), which was subsequently shortened to "bitumen", thence passing via French into English. From the same root is derived the Anglo Saxon word "cwidu" (mastix), the German word "Kitt" (cement or mastic) and the old Norse word "kvada".
Neither of the terms asphalt or bitumen should be confused with tar or coal tars.
<h3>Modern usage.</h3>
In British English, the word 'asphalt' is used to refer to a mixture of mineral aggregate and asphalt/bitumen (also called tarmac in common parlance). When bitumen is mixed with clay it is usually called asphaltum. The earlier word 'asphaltum' is now archaic and not commonly used. In American English, 'asphalt' is equivalent to the British 'bitumen'. However, 'asphalt' is also commonly used as a shortened form of 'asphalt concrete' (therefore equivalent to the British 'asphalt' or 'tarmac'). In Australian English, bitumen is often used as the generic term for road surfaces. In Canadian English, the word bitumen is used to refer to the vast Canadian deposits of extremely heavy crude oil, while asphalt is used for the oil refinery product used to pave roads and manufacture roof shingles and various waterproofing products. Diluted bitumen (diluted with naphtha to make it flow in pipelines) is known as dilbit in the Canadian petroleum industry, while bitumen "upgraded" to synthetic crude oil is known as syncrude and syncrude blended with bitumen as synbit.
Bitumen is still the preferred geological term for naturally occurring deposits of the solid or semi-solid form of petroleum. Bituminous rock is a form of sandstone impregnated with bitumen. The tar sands of Alberta, Canada are a similar material.

</doc>
<doc id="659" url="https://en.wikipedia.org/wiki?curid=659" title="American National Standards Institute">
American National Standards Institute

The American National Standards Institute (ANSI, ) is a private non-profit organization that oversees the development of voluntary consensus standards for products, services, processes, systems, and personnel in the United States. The organization also coordinates U.S. standards with international standards so that American products can be used worldwide.
ANSI accredits standards that are developed by representatives of other standards organizations, government agencies, consumer groups, companies, and others. These standards ensure that the characteristics and performance of products are consistent, that people use the same definitions and terms, and that products are tested the same way. ANSI also accredits organizations that carry out product or personnel certification in accordance with requirements defined in international standards.
The organization's headquarters are in Washington, DC. ANSI's operations office is located in New York City. The ANSI annual operating budget is funded by the sale of publications, membership dues and fees, accreditation services, fee-based programs, and international standards programs.
<h2>History.</h2>
ANSI was originally formed in 1918, when six Stanton engineering societies and three government agencies founded the American Engineering Standards Committee (AESC). In 1928, the AESC became the American Standards Association (ASA). In 1966, the ASA was reorganized and became United States of America Standards Institute (USASI). The present name was adopted in 1969.
Prior to 1918, these five founding engineering societies:
had been members of the United Engineering Society (UES).
At the behest of the AIEE, they invited the U.S. government Departments of War, Navy (combined in 1947 to become the Department of Defense or DOD) and Commerce to join in founding a national standards organization.
According to Adam Stanton, the first permanent secretary and head of staff in 1919, AESC started as an ambitious program and little else. Staff for the first year consisted of one executive, Clifford B. LePage, who was on loan from a founding member, ASME. An annual budget of $7,500 was provided by the founding bodies.
In 1931, the organization (renamed ASA in 1928) became affiliated with the U.S. National Committee of the International Electrotechnical Commission (IEC), which had been formed in 1904 to develop electrical and electronics standards.
<h2>Members.</h2>
ANSI's members are government agencies, organizations, corporations, academic and international bodies, and individuals. In total, the Institute represents the interests of more than 125,000 companies and 3.5 million professionals.
<h2>Process.</h2>
Though ANSI itself does not develop standards, the Institute oversees the development and use of standards by accrediting the procedures of standards developing organizations. ANSI accreditation signifies that the procedures used by standards developing organizations meet the Institute's requirements for openness, balance, consensus, and due process.
ANSI also designates specific standards as American National Standards, or ANS, when the Institute determines that the standards were developed in an environment that is equitable, accessible and responsive to the requirements of various stakeholders.
Voluntary consensus standards quicken the market acceptance of products while making clear how to improve the safety of those products for the protection of consumers. There are approximately 9,500 American National Standards that carry the ANSI designation.
The American National Standards process involves:
<h2>International activities.</h2>
In addition to facilitating the formation of standards in the United States, ANSI promotes the use of U.S. standards internationally, advocates U.S. policy and technical positions in international and regional standards organizations, and encourages the adoption of international standards as national standards where appropriate.
The Institute is the official U.S. representative to the two major international standards organizations, the International Organization for Standardization (ISO), as a founding member, and the International Electrotechnical Commission (IEC), via the U.S. National Committee (USNC). ANSI participates in almost the entire technical program of both the ISO and the IEC, and administers many key committees and subgroups. In many instances, U.S. standards are taken forward to ISO and IEC, through ANSI or the USNC, where they are adopted in whole or in part as international standards.
<h3>Standards panels.</h3>
The Institute administers nine standards panels:
Each of the panels works to identify, coordinate, and harmonize voluntary standards relevant to these areas.
In 2009, ANSI and the National Institute of Standards and Technology (NIST) formed the Nuclear Energy Standards Coordination Collaborative (NESCC). NESCC is a joint initiative to identify and respond to the current need for standards in the nuclear industry.

</doc>
<doc id="661" url="https://en.wikipedia.org/wiki?curid=661" title="Argument (disambiguation)">
Argument (disambiguation)

In philosophy and logic, an argument is an attempt to persuade someone of something, or give evidence or reasons for accepting a particular conclusion.
Argument may also refer to: 

</doc>
<doc id="662" url="https://en.wikipedia.org/wiki?curid=662" title="Apollo 11">
Apollo 11

Apollo 11 was the first spaceflight that landed humans on the Moon. Mission commander Neil Armstrong and pilot Buzz Aldrin landed the lunar module "Eagle" on July 20, 1969, at 20:18 UTC. Armstrong became the first to step onto the lunar surface six hours later on July 21 at 02:56:15 UTC; Aldrin joined him about 20 minutes later. They spent about two and a quarter hours together outside the spacecraft, and collected of lunar material for return to Earth. Michael Collins piloted the command module "Columbia" alone in lunar orbit while they were on the Moon's surface. Armstrong and Aldrin spent just under a day on the lunar surface before rendezvousing with "Columbia" in lunar orbit.
Launched by a Saturn V rocket from Kennedy Space Center in Merritt Island, Florida, on July 16, Apollo 11 was the fifth manned mission of NASA's Apollo program. The Apollo spacecraft had three parts: a command module (CM) with a cabin for the three astronauts, and the only part that landed back on Earth; a service module (SM), which supported the command module with propulsion, electrical power, oxygen, and water; and a lunar module (LM) that had two stages – a lower stage for landing on the Moon, and an upper stage to place the astronauts back into lunar orbit. After being sent toward the Moon by the Saturn V's upper stage, the astronauts separated the spacecraft from it and traveled for three days until they entered into lunar orbit. Armstrong and Aldrin then moved into the lunar module "Eagle" and landed in the Sea of Tranquility. They stayed a total of about 21.5 hours on the lunar surface. The astronauts used "Eagle"'s upper stage to lift off from the lunar surface and rejoin Collins in the command module. They jettisoned "Eagle" before they performed the maneuvers that blasted them out of lunar orbit on a trajectory back to Earth. They returned to Earth and landed in the Pacific Ocean on July 24.
Broadcast on live TV to a worldwide audience, Armstrong stepped onto the lunar surface and described the event as "one small step for [a] man, one giant leap for mankind." Apollo 11 effectively ended the Space Race and fulfilled a national goal proposed in 1961 by U.S. President John F. Kennedy: "before this decade is out, of landing a man on the Moon and returning him safely to the Earth."
<h2>Framework.</h2>
<h3>Crew.</h3>
Apollo 11 was the second all-veteran multi-person crew (the first being Apollo 10) in human spaceflight history. A previous solo veteran flight had been made on Soyuz 1 in 1967 by Soviet cosmonaut Vladimir Komarov.
Collins was originally slated to be the Command Module Pilot (CMP) on Apollo 8 but was removed when he required surgery on his back and was replaced by Jim Lovell, his backup for that flight. After Collins was medically cleared, he took what would have been Lovell's spot on Apollo 11; as a veteran of Apollo 8, Lovell was transferred to Apollo 11's backup crew and promoted to backup commander.
<h3>Backup crew.</h3>
In early 1969, Anders accepted a job with the National Space Council effective August 1969 and announced that he would retire as an astronaut on that date. At that point Ken Mattingly was moved from the support crew into parallel training with Anders as backup Command Module Pilot in case Apollo 11 was delayed past its intended July launch (at which point Anders would be unavailable if needed) and would later join Lovell's crew and ultimately be assigned as the original Apollo 13 CMP.
<h3>Call signs.</h3>
After the crew of Apollo 10 named their spacecraft "Charlie Brown" and "Snoopy", assistant manager for public affairs Julian Scheer wrote to Manned Spacecraft Center director George M. Low to suggest the Apollo 11 crew be less flippant in naming their craft. During early mission planning, the names "Snowcone" and "Haystack" were used and put in the news release, but the crew later decided to change them.
The Command Module was named "Columbia" after the "Columbiad", the giant cannon shell "spacecraft" fired by a giant cannon (also from Florida) in Jules Verne's 1865 novel "From the Earth to the Moon". The Lunar Module was named "Eagle" for the national bird of the United States, the bald eagle, which is featured prominently on the mission insignia.
<h3>Insignia.</h3>
The Apollo 11 mission insignia was designed by Collins, who wanted a symbol for "peaceful lunar landing by the United States". He chose an eagle as the symbol, put an olive branch in its beak, and drew a lunar background with the Earth in the distance. NASA officials said the talons of the eagle looked too "warlike" and after some discussion, the olive branch was moved to the claws. The crew decided the Roman numeral XI would not be understood in some nations and went with "Apollo 11"; they decided not to put their names on the patch, so it would "be representative of "everyone" who had worked toward a lunar landing". All colors are natural, with blue and gold borders around the patch.
When the Eisenhower dollar coin was released in 1971, the patch design provided the eagle for its reverse side. The design was also used for the smaller Susan B. Anthony dollar unveiled in 1979, ten years after the Apollo 11 mission.
<h3>Mementos.</h3>
Neil Armstrong's personal preference kit carried a piece of wood from the Wright brothers' 1903 airplane's left propeller and a piece of fabric from its wing, along with a diamond-studded astronaut pin originally given to Deke Slayton by the widows of the Apollo 1 crew. This pin had been intended to be flown on Apollo 1 and given to Slayton after the mission but following the disastrous launch pad fire and subsequent funerals, the widows gave the pin to Slayton and Armstrong took it on Apollo 11.
<h2>Mission highlights.</h2>
<h3>Launch and flight to lunar orbit.</h3>
In addition to many people crowding highways and beaches near the launch site, millions watched the event on television, with NASA Chief of Public Information Jack King providing commentary. President Richard M. Nixon viewed the proceedings from the Oval Office of the White House.
A Saturn V launched Apollo 11 from Launch Pad 39A, part of the Launch Complex 39 site at the Kennedy Space Center on July 16, 1969 at 13:32:00 UTC (9:32:00 a.m. EDT local time). It entered Earth orbit, at an altitude of by , twelve minutes later. After one and a half orbits, the S-IVB third-stage engine pushed the spacecraft onto its trajectory toward the Moon with the trans-lunar injection (TLI) burn at 16:22:13 UTC. About 30 minutes later the command/service module pair separated from this last remaining Saturn V stage and docked with the Lunar Module still nestled in the Lunar Module Adaptor. After the Lunar Module was extracted, the combined spacecraft headed for the Moon, while the third stage booster flew on a trajectory past the Moon and into orbit around the Sun.
On July 19 at 17:21:50 UTC, Apollo 11 passed behind the Moon and fired its service propulsion engine to enter lunar orbit. In the thirty orbits that followed, the crew saw passing views of their landing site in the southern Sea of Tranquility (Mare Tranquillitatis) about southwest of the crater Sabine D (0.67408N, 23.47297E). The landing site was selected in part because it had been characterized as relatively flat and smooth by the automated "Ranger 8" and "Surveyor 5" landers along with the "Lunar Orbiter" mapping spacecraft and unlikely to present major landing or extravehicular activity (EVA) challenges.
<h3>Lunar descent.</h3>
On July 20, 1969, the Lunar Module "Eagle" separated from the Command Module "Columbia". Collins, alone aboard "Columbia", inspected "Eagle" as it pirouetted before him to ensure the craft was not damaged.
As the descent began, Armstrong and Aldrin found that they were passing landmarks on the surface four seconds early and reported that they were "long"; they would land miles west of their target point.
Five minutes into the descent burn, and above the surface of the Moon, the LM navigation and guidance computer distracted the crew with the first of several unexpected "1202" and "1201" program alarms. Inside Mission Control Center in Houston, Texas, computer engineer Jack Garman told guidance officer Steve Bales it was safe to continue the descent, and this was relayed to the crew. The program alarms indicated "executive overflows", meaning the guidance computer could not complete all of its tasks in real time and had to postpone some of them.
<h3>Landing.</h3>
When Armstrong again looked outside, he saw that the computer's landing target was in a boulder-strewn area just north and east of a diameter crater (later determined to be West crater, named for its location in the western part of the originally planned landing ellipse). Armstrong took semi-automatic control and, with Aldrin calling out altitude and velocity data, landed at 20:17:40 UTC on Sunday July 20 with about 25 seconds of fuel left.
Apollo 11 landed with less fuel than other missions, and the astronauts encountered a premature low fuel warning. This was later found to be the result of greater propellant 'slosh' than expected, uncovering a fuel sensor. On subsequent missions, extra anti-slosh baffles were added to the tanks to prevent this.
Throughout the descent, Aldrin had called out navigation data to Armstrong, who was busy piloting the LM. A few moments before the landing, a light informed Aldrin that at least one of the probes hanging from "Eagle" footpads had touched the surface, and he said: "Contact light!" Three seconds later, "Eagle" landed and Armstrong said "Shutdown." Aldrin immediately said "Okay, engine stop. ACA – out of detent." Armstrong acknowledged "Out of detent. Auto" and Aldrin continued "Mode control – both auto. Descent engine command override off. Engine arm – off. 413 is in."
Charles Duke, CAPCOM during the landing phase, acknowledged their landing by saying "We copy you down, Eagle."
Armstrong acknowledged Aldrin's completion of the post landing checklist with "Engine arm is off", before responding to Duke with the words, "Houston, Tranquility Base here. The "Eagle" has landed." Armstrong's unrehearsed change of call sign from "Eagle" to "Tranquility Base" emphasized to listeners that landing was complete and successful. Duke mispronounced his reply as he expressed the relief at Mission Control: "Roger, Twan— Tranquility, we copy you on the ground. You got a bunch of guys about to turn blue. We're breathing again. Thanks a lot."
Two and a half hours after landing, before preparations began for the EVA, Aldrin radioed to Earth:
The schedule for the mission called for the astronauts to follow the landing with a five-hour sleep period as they had been awake since early morning. However, they elected to forgo the sleep period and begin the preparations for the EVA early, thinking that they would be unable to sleep.
<h3>Lunar surface operations.</h3>
The astronauts planned placement of the Early Apollo Scientific Experiment Package (EASEP) and the U.S. flag by studying their landing site through "Eagle" twin triangular windows, which gave them a 60° field of view. Preparation required longer than the two hours scheduled. Armstrong initially had some difficulties squeezing through the hatch with his Portable Life Support System (PLSS). According to veteran Moon-walker John Young, a redesign of the LM to incorporate a smaller hatch had not been followed by a redesign of the PLSS backpack, so some of the highest heart rates recorded from Apollo astronauts occurred during LM egress and ingress.
Several books indicate early mission timelines had Buzz Aldrin rather than Neil Armstrong as the first man on the Moon.
At 02:39 UTC on Monday July 21, 1969, Armstrong opened the hatch, and at 02:51 UTC began his descent to the lunar surface. The Remote Control Unit controls on his chest kept him from seeing his feet. Climbing down the nine-rung ladder, Armstrong pulled a D-ring to deploy the Modular Equipment Stowage Assembly (MESA) folded against "Eagle" side and activate the TV camera, and at 02:56:15 UTC he set his left foot on the surface. The first landing used slow-scan television incompatible with commercial TV, so it was displayed on a special monitor and a conventional TV camera viewed this monitor, significantly reducing the quality of the picture. The signal was received at Goldstone in the United States but with better fidelity by Honeysuckle Creek Tracking Station in Australia. Minutes later the feed was switched to the more sensitive Parkes radio telescope in Australia. Despite some technical and weather difficulties, ghostly black and white images of the first lunar EVA were received and broadcast to at least 600 million people on Earth. Although copies of this video in broadcast format were saved and are widely available, recordings of the original slow scan source transmission from the lunar surface were accidentally destroyed during routine magnetic tape re-use at NASA.
While still on the ladder, Armstrong uncovered a plaque mounted on the LM Descent Stage bearing two drawings of Earth (of the Western and Eastern Hemispheres), an inscription, and signatures of the astronauts and President Nixon. The inscription read:
After describing the surface dust as "very fine-grained" and "almost like a powder," six and a half hours after landing, Armstrong stepped off "Eagle" footpad and declared, "That's one small step for [a] man, one giant leap for mankind."
Armstrong intended to say "That's one small step for a man", but the word ""a"" is not audible in the transmission, and thus was not initially reported by most observers of the live broadcast. When later asked about his quote, Armstrong said he believed he said "for a man", and subsequent printed versions of the quote included the "a" in square brackets. One explanation for the absence may be that his accent caused him to slur the words "for a" together; another is the intermittent nature of the audio and video links to Earth, partly because of storms near Parkes Observatory. More recent digital analysis of the tape claims to reveal the "a" may have been spoken but obscured by static.
About seven minutes after stepping onto the Moon's surface, Armstrong collected a contingency soil sample using a sample bag on a stick. He then folded the bag and tucked it into a pocket on his right thigh. This was to guarantee there would be some lunar soil brought back in case an emergency required the astronauts to abandon the EVA and return to the LM.
Twelve minutes after the contingency sample was collected, Aldrin joined Armstrong on the surface, and described the view with the simple phrase, "Magnificent desolation."
In addition to fulfilling President Kennedy's mandate to land a man on the Moon before the end of the 1960s, Apollo 11 was an engineering test of the Apollo system; therefore, Armstrong snapped photos of the LM so engineers would be able to judge its post-landing condition. He removed the TV camera from the MESA and made a panoramic sweep, then mounted it on a tripod from the LM. The TV camera cable remained partly coiled and presented a tripping hazard throughout the EVA.
Armstrong said that moving in the lunar gravity, one-sixth of Earth's, was "even perhaps easier than the simulations ... It's absolutely no trouble to walk around." Aldrin joined him on the surface and tested methods for moving around, including two-footed kangaroo hops. The PLSS backpack created a tendency to tip backwards, but neither astronaut had serious problems maintaining balance. Loping became the preferred method of movement. The astronauts reported that they needed to plan their movements six or seven steps ahead. The fine soil was quite slippery. Aldrin remarked that moving from sunlight into "Eagle" shadow produced no temperature change inside the suit, though the helmet was warmer in sunlight, so he felt cooler in shadow.
The astronauts planted a specially designed U.S. flag on the lunar surface, in clear view of the TV camera. Some time later, President Richard Nixon spoke to them through a telephone-radio transmission which Nixon called "the most historic phone call ever made from the White House." Nixon originally had a long speech prepared to read during the phone call, but Frank Borman, who was at the White House as a NASA liaison during Apollo 11, convinced Nixon to keep his words brief, to respect the lunar landing as Kennedy's legacy. Armstrong thanked the President, and gave a brief reflection on the significance of the moment:
Nixon: Hello, Neil and Buzz. I'm talking to you by telephone from the Oval Room at the White House. And this certainly has to be the most historic telephone call ever made. I just can't tell you how proud we all are of what you've done. For every American, this has to be the proudest day of our lives. And for people all over the world, I am sure they too join with Americans in recognizing what an immense feat this is. Because of what you have done, the heavens have become a part of man's world. And as you talk to us from the Sea of Tranquility, it inspires us to redouble our efforts to bring peace and tranquility to Earth. For one priceless moment in the whole history of man, all the people on this Earth are truly one: one in their pride in what you have done, and one in our prayers that you will return safely to Earth.
Armstrong: Thank you, Mr. President. It's a great honor and privilege for us to be here, representing not only the United States, but men of peace of all nations, and with interest and curiosity, and men with a vision for the future. It's an honor for us to be able to participate here today.
The MESA failed to provide a stable work platform and was in shadow, slowing work somewhat. As they worked, the moonwalkers kicked up gray dust which soiled the outer part of their suits, the integrated thermal meteoroid garment.
They deployed the EASEP, which included a passive seismograph and a Lunar Ranging Retroreflector (LRRR). Then Armstrong walked from the LM to snap photos at the rim of Little West Crater while Aldrin collected two core tubes. He used the geological hammer to pound in the tubes – the only time the hammer was used on Apollo 11. The astronauts then collected rock samples using scoops and tongs on extension handles. Many of the surface activities took longer than expected, so they had to stop documenting sample collection halfway through the allotted 34 minutes.
Three new minerals were discovered in the rock samples collected by the astronauts: armalcolite, tranquillityite, and pyroxferroite. Armalcolite was named after Armstrong, Aldrin, and Collins.
During this period, Mission Control used a coded phrase to warn Armstrong that his metabolic rates were high and that he should slow down. He was moving rapidly from task to task as time ran out. However, as metabolic rates remained generally lower than expected for both astronauts throughout the walk, Mission Control granted the astronauts a 15-minute extension. In a 2010 interview, Armstrong, who had walked a maximum of from the LM, explained that NASA limited the first moonwalk's time and distance because there was no empirical proof of how much cooling water the astronauts' PLSS backpacks would consume to handle their body heat generation while working on the Moon.
<h3>Lunar ascent and return.</h3>
Aldrin entered "Eagle" first. With some difficulty the astronauts lifted film and two sample boxes containing of lunar surface material to the LM hatch using a flat cable pulley device called the Lunar Equipment Conveyor. Armstrong reminded Aldrin of a bag of memorial items in his suit pocket sleeve, and Aldrin tossed the bag down; Armstrong then jumped to the ladder's third rung and climbed into the LM. After transferring to LM life support, the explorers lightened the ascent stage for return to lunar orbit by tossing out their PLSS backpacks, lunar overshoes, one Hasselblad camera, and other equipment. They then pressurized the LM and settled down to sleep.
President Nixon's speech writer William Safire had prepared "In Event of Moon Disaster" for the President to read on television in the event the Apollo 11 astronauts were stranded on the Moon. The contingency plan originated in a memo from Safire to Nixon's White House Chief of Staff H. R. Haldeman, in which Safire suggested a protocol the administration might follow in reaction to such a disaster. According to the plan, Mission Control would "close down communications" with the LM, and a clergyman would "commend their souls to the deepest of the deep" in a public ritual likened to burial at sea. The last line of the prepared text contained an allusion to Rupert Brooke's First World War poem, "The Soldier". The plan included presidential telephone calls to the astronauts' wives.
While moving within the cabin, Aldrin accidentally damaged the circuit breaker that would arm the main engine for lift off from the Moon. There was concern this would prevent firing the engine, stranding them on the Moon. Fortunately, a felt-tip pen was sufficient to activate the switch. Had this not worked, the Lunar Module circuitry could have been reconfigured to allow firing the ascent engine.
After about seven hours of rest, the crew was awakened by Houston to prepare for the return flight. Two and a half hours later, at 17:54 UTC, they lifted off in "Eagle" ascent stage to rejoin Collins aboard "Columbia" in lunar orbit.
After more than 21½ total hours on the lunar surface, they had left behind scientific instruments that included a retroreflector array used for the Lunar Laser Ranging Experiment and a Passive Seismic Experiment Package used to measure moonquakes. They also left an Apollo 1 mission patch, and a memorial bag containing a gold replica of an olive branch as a traditional symbol of peace and a silicon message disk. The disk carries the goodwill statements by Presidents Eisenhower, Kennedy, Johnson, and Nixon and messages from leaders of 73 countries around the world. The disc also carries a listing of the leadership of the US Congress, a listing of members of the four committees of the House and Senate responsible for the NASA legislation, and the names of NASA's past and present top management. (In his 1989 book, "Men from Earth", Aldrin says that the items included Soviet medals commemorating Cosmonauts Vladimir Komarov and Yuri Gagarin.) Also, according to Deke Slayton's book "Moonshot", Armstrong carried with him a special diamond-studded astronaut pin from Slayton.
Film taken from the LM Ascent Stage upon liftoff from the Moon reveals the American flag, planted some from the descent stage, whipping violently in the exhaust of the ascent stage engine. Aldrin looked up in time to witness the flag topple: "The ascent stage of the LM separated ... I was concentrating on the computers, and Neil was studying the attitude indicator, but I looked up long enough to see the flag fall over." Subsequent Apollo missions usually planted the American flags at least from the LM to prevent them being blown over by the ascent engine exhaust.
After rendezvous with "Columbia", "Eagle"s ascent stage was jettisoned into lunar orbit on July 21, 1969, at 23:41 UTC. Just before the Apollo 12 flight, it was noted that "Eagle" was still likely to be orbiting the Moon. Later NASA reports mentioned that "Eagle" orbit had decayed, resulting in it impacting in an "uncertain location" on the lunar surface. The location is uncertain because the "Eagle" ascent stage was not tracked after it was jettisoned, and the lunar gravity field is sufficiently non-uniform to make the orbit of the spacecraft unpredictable after a short time. NASA estimated that the orbit had decayed within months and would have impacted on the Moon.
On July 23, the last night before splashdown, the three astronauts made a television broadcast in which Collins commented: ... The Saturn V rocket which put us in orbit is an incredibly complicated piece of machinery, every piece of which worked flawlessly ... We have always had confidence that this equipment will work properly. All this is possible only through the blood, sweat, and tears of a number of a people ... All you see is the three of us, but beneath the surface are thousands and thousands of others, and to all of those, I would like to say, "Thank you very much."
Aldrin added: This has been far more than three men on a mission to the Moon; more, still, than the efforts of a government and industry team; more, even, than the efforts of one nation. We feel that this stands as a symbol of the insatiable curiosity of all mankind to explore the unknown ... Personally, in reflecting on the events of the past several days, a verse from Psalms comes to mind. "When I consider the heavens, the work of Thy fingers, the Moon and the stars, which Thou hast ordained; What is man that Thou art mindful of him?"
Armstrong concluded: The responsibility for this flight lies first with history and with the giants of science who have preceded this effort; next with the American people, who have, through their will, indicated their desire; next with four administrations and their Congresses, for implementing that will; and then, with the agency and industry teams that built our spacecraft, the Saturn, the Columbia, the Eagle, and the little EMU, the spacesuit and backpack that was our small spacecraft out on the lunar surface. We would like to give special thanks to all those Americans who built the spacecraft; who did the construction, design, the tests, and put their hearts and all their abilities into those craft. To those people tonight, we give a special thank you, and to all the other people that are listening and watching tonight, God bless you. Good night from Apollo 11.
On the return to Earth, a bearing at the Guam tracking station failed, potentially preventing communication on the last segment of the Earth return. A regular repair was not possible in the available time but the station director, Charles Force, had his ten-year-old son Greg use his small hands to reach into the housing and pack it with grease. Greg later was thanked by Armstrong.
<h3>Splashdown and quarantine.</h3>
On July 24, the astronauts returned home aboard the Command Module "Columbia" just before dawn local time (16:51 UTC) at , in the Pacific Ocean east of Wake Island, south of Johnston Atoll, and from the recovery ship, .
At 16:44 UTC the drogue parachutes had been deployed and seven minutes later the Command Module struck the water forcefully. During splashdown, the Command Module landed upside down but was righted within 10 minutes by flotation bags triggered by the astronauts. "Everything's okay. Our checklist is complete. Awaiting swimmers", was Armstrong's last official transmission from the "Columbia". A diver from the Navy helicopter hovering above attached a sea anchor to the Command Module to prevent it from drifting. Additional divers attached flotation collars to stabilize the module and position rafts for astronaut extraction. Though the chance of bringing back pathogens from the lunar surface was considered remote, it was considered a possibility and NASA took great precautions at the recovery site. Divers provided the astronauts with Biological Isolation Garments (BIGs) which were worn until they reached isolation facilities on board the "Hornet". Additionally, astronauts were rubbed down with a sodium hypochlorite solution and the Command Module wiped with Betadine to remove any lunar dust that might be present. The raft containing decontamination materials was then intentionally sunk.
A second Sea King helicopter hoisted the astronauts aboard one by one, where a NASA flight surgeon gave each a brief physical check during the trip back to the "Hornet".
After touchdown on the "Hornet", the astronauts exited the helicopter, leaving the flight surgeon and three crewmen. The helicopter was then lowered into hangar bay #2 where the astronauts walked the to the Mobile Quarantine Facility (MQF) where they would begin their 21 days of quarantine. This practice would continue for two more Apollo missions, Apollo 12 and Apollo 14, before the Moon was proven to be barren of life and the quarantine process dropped.
President Richard Nixon was aboard "Hornet" to personally welcome the astronauts back to Earth. He told the astronauts, "As a result of what you've done, the world has never been closer together before." After Nixon departed, the "Hornet" was brought alongside the five-ton Command Module where it was placed aboard by the ship's crane, placed on a dolly and moved next to the MQF. The "Hornet" sailed for Pearl Harbor where the Command Module and MQF were airlifted to the Manned Spacecraft Center.
In accordance with the recently passed Extra-Terrestrial Exposure Law, the astronauts were placed in quarantine for fear that the Moon might contain undiscovered pathogens and that the astronauts might have been exposed to them during their Moon walks. However, after almost three weeks in confinement (first in their trailer and later in the Lunar Receiving Laboratory at the Manned Spacecraft Center), the astronauts were given a clean bill of health. On August 10, 1969, the astronauts exited quarantine.
<h3>Celebration.</h3>
On August 13, they rode in parades in their honor in New York, Chicago, and Los Angeles. On the same evening in Los Angeles there was an official State Dinner to celebrate the flight, attended by members of Congress, 44 governors, the Chief Justice of the United States, and ambassadors from 83 nations at the Century Plaza Hotel. President Richard Nixon and Vice President Spiro T. Agnew honored each astronaut with a presentation of the Presidential Medal of Freedom. This celebration was the beginning of a 45-day "Giant Leap" tour that brought the astronauts to 25 foreign countries and included visits with prominent leaders such as Queen Elizabeth II of the United Kingdom. Many nations honored the first manned Moon landing with special features in magazines or by issuing Apollo 11 commemorative postage stamps or coins.
On September 16, 1969, the three astronauts spoke before a joint session of Congress on Capitol Hill. They presented two US flags, one to the House of Representatives and the other to the Senate, that had been carried to the surface of the Moon with them.
<h2>Moon race.</h2>
The Soviet Union was secretly attempting to compete with the US in landing a man on the Moon but had been hampered by repeated failures in development of a launcher comparable to the Saturn V. Meanwhile, they tried to beat the US to return lunar material to the Earth by means of unmanned probes. On July 13, three days before Apollo 11's launch, they launched Luna 15, which reached lunar orbit before Apollo 11. During descent, a malfunction caused Luna 15 to crash in Mare Crisium about two hours before Armstrong and Aldrin took off from the surface. The Jodrell Bank Observatory radio telescope in England was later discovered to have recorded transmissions from Luna 15 during its descent, and this was published in July 2009 on the 40th anniversary of Apollo 11.
<h2>Spacecraft location.</h2>
The Command Module "Columbia" is displayed at the National Air and Space Museum, Washington, D.C. It is in the central "Milestones of Flight" exhibition hall in front of the Jefferson Drive entrance, sharing the main hall with other pioneering flight vehicles such as the Wright Flyer, the "Spirit of St. Louis", the Bell X-1, the North American X-15, Mercury spacecraft "Friendship 7", and Gemini 4. Armstrong's and Aldrin's space suits are displayed in the museum's "Apollo to the Moon" exhibit. The quarantine trailer, the flotation collar, and the righting spheres are displayed at the Smithsonian's Steven F. Udvar-Hazy Center annex near Washington Dulles International Airport in Virginia.
In 2009, the Lunar Reconnaissance Orbiter (LRO) imaged the various Apollo landing sites on the surface of the Moon, for the first time with sufficient resolution to see the descent stages of the lunar modules, scientific instruments, and foot trails made by the astronauts.
In March 2012 Amazon founder Jeff Bezos located the F-1 engines that launched Apollo 11 into space. The engines were found below the Atlantic Ocean's surface through the use of advanced sonar scanning. His team brought at least one of the five engines to the surface. In July 2013, it was confirmed through serial numbers (2044) that F-1 engine parts brought up from the depths of the Atlantic Ocean were from the Apollo 11 launch.
<h2>40th anniversary events.</h2>
On July 15, 2009, Life.com released a photo gallery of previously unpublished photos of the astronauts taken by "Life" photographer Ralph Morse prior to the Apollo 11 launch.
From July 16–24, 2009, NASA streamed the original mission audio on its website in real time 40 years to the minute after the events occurred.
In addition, it is in the process of restoring the video footage and has released a preview of key moments.
On July 20, 2009, the crew of Armstrong, Aldrin, and Collins met with U.S. President Barack Obama at the White House. "We expect that there is, as we speak, another generation of kids out there who are looking up at the sky and are going to be the next Armstrong, Collins and Aldrin", Obama said. "We want to make sure that NASA is going to be there for them when they want to take their journey."
The John F. Kennedy Presidential Library and Museum set up a Flash website that rebroadcasts the transmissions of Apollo 11 from launch to landing on the Moon.
A group of British scientists interviewed as part of the anniversary events reflected on the significance of the Moon landing:
It was carried out in a technically brilliant way with risks taken ... that would be inconceivable in the risk-averse world of today ... The Apollo programme is arguably the greatest technical achievement of mankind to date ... nothing since Apollo has come close [to] the excitement that was generated by those astronauts – Armstrong, Aldrin and the 10 others who followed them.
On August 7, 2009, an act of Congress awarded the three astronauts a Congressional Gold Medal, the highest civilian award in the United States. The bill was sponsored by Florida Sen. Bill Nelson and Florida Rep. Alan Grayson.
In July 2010, air-to-ground voice recordings and film footage shot in Mission Control during the Apollo 11 powered descent and landing was re-synchronised and released for the first time.
For young readers
NASA reports
Multimedia

</doc>
<doc id="663" url="https://en.wikipedia.org/wiki?curid=663" title="Apollo 8">
Apollo 8

Apollo 8, the second human spaceflight mission in the United States Apollo space program, was launched on December 21, 1968, and became the first manned spacecraft to leave Earth orbit, reach the Earth's Moon, orbit it and return safely to Earth. The three-astronaut crew — Commander Frank Borman, Command Module Pilot James Lovell, and Lunar Module Pilot William Anders — became the first humans to travel beyond low Earth orbit, the first to see Earth as a whole planet, the first to directly see the far side of the Moon, and then the first to witness Earthrise. The 1968 mission, the third flight of the Saturn V rocket and that rocket's first manned launch, was also the first human spaceflight launch from the Kennedy Space Center, Florida, located adjacent to Cape Canaveral Air Force Station.
The mission was originally planned as Apollo 9, to be performed in early 1969 as the second test of the complete Apollo spacecraft, including the Lunar Module and the Command/Service Module in an elliptical medium Earth orbit. But when the Lunar Module proved unready to make its first test in a lower Earth orbit in December 1968, it was decided in August to fly Apollo 8 in December as a more ambitious lunar orbital flight without the Lunar Module. This meant Borman's crew was scheduled to fly two to three months sooner than originally planned, leaving them a shorter time for training and preparation, thus placing more demands than usual on their time and discipline.
Apollo 8 took three days to travel to the Moon. It orbited ten times over the course of 20 hours, during which the crew made a Christmas Eve television broadcast where they read the first 10 verses from the Book of Genesis. At the time, the broadcast was the most watched TV program ever. Apollo 8's successful mission paved the way for Apollo 11 to fulfill U.S. President John F. Kennedy's goal of landing a man on the Moon before the end of the 1960s. The Apollo 8 astronauts returned to Earth on December 27, 1968, when their spacecraft splashed down in the Northern Pacific Ocean. The crew was named "Time" magazine's "Men of the Year" for 1968 upon their return.
<h2>Crew.</h2>
Lovell was originally the CMP on the back-up crew, with Michael Collins as the prime crew's CMP. However, Collins was replaced in July 1968, after suffering a cervical disc herniation that required surgery to repair.
This crew was unique among pre-shuttle era missions in that the commander was not the most experienced member of the crew, as Lovell had flown twice before, on Gemini VII and Gemini XII. This was also the first case of the rarity of an astronaut who had commanded a spaceflight mission subsequently flying as a non-commander, as Lovell had previously commanded Gemini XII.
<h3>Backup crew.</h3>
On a lunar mission, the Command Module Pilot (CMP) was assigned the role of navigator, while the Lunar Module Pilot (LMP) was assigned the role of flight engineer, responsible for monitoring all spacecraft systems, even if the flight didn't include a Lunar Module.
Edwin "Buzz" Aldrin was originally the backup LMP. When Lovell was rotated to the prime crew, no one with experience on CSM-103 (the specific spacecraft used for the mission) was available, so Aldrin was moved to CMP and Fred Haise brought in as backup LMP. Neil Armstrong went on to command Apollo 11, where Aldrin was returned to the LMP position and Collins was assigned as CMP. Haise was rotated out of the crew and onto the backup crew of Apollo 11 as LMP.
<h3>Mission control.</h3>
The Earth-based mission control teams for Apollo 8 consisted of astronauts assigned to the support crew, as well as non-astronaut flight directors and their staffs. The support crew members were not trained to fly the mission, but were able to stand in for astronauts in meetings and be involved in the minutiae of mission planning, while the prime and backup crews trained. They also served as CAPCOMs during the mission. For Apollo 8, these crew members included astronauts John S. Bull, Vance D. Brand, Gerald P. Carr, and Ken Mattingly. The mission control teams on Earth rotated in three shifts, each led by a flight director. The directors for Apollo 8 included Clifford E. Charlesworth (Green team), Glynn Lunney (Black team), and Milton Windler (Maroon team).
<h3>Mission insignia.</h3>
The triangular shape of the insignia symbolizes the shape of the Apollo Command Module (CM). It shows a red figure-8 looping around the Earth and Moon representing the mission number as well as the circumlunar nature of the mission. On the red number 8 are the names of the three astronauts.
The initial design of the insignia was developed by Jim Lovell. Lovell reportedly sketched the initial design while riding in the backseat of a T-38 flight from California to Houston, shortly after learning of the re-designation of the flight to become a lunar-orbital mission. The graphic design of the insignia was done by Houston artist and animator William Bradley.
<h2>Planning.</h2>
Apollo 4 and Apollo 6 had been "A" missions, unmanned tests of the Saturn V launch vehicle using an unmanned Block I production model of the Apollo Command and Service Module in Earth orbit. , scheduled for October 1968, would be a manned Earth-orbit flight of the CSM, completing the objectives for Mission "C".
Further missions depended on the readiness of the Lunar Module. Apollo 8 was planned as the "D" mission, to test the LM in a low Earth orbit in December 1968 by James McDivitt, David Scott and Russell Schweickart, while Borman's crew would fly the "E" mission, a more rigorous LM test in an elliptical medium Earth orbit as Apollo 9, in early 1969.
But production of the LM fell behind schedule, and when Apollo 8's LM arrived at the Kennedy Space Center in June 1968, significant defects were discovered, leading Grumman, the lead contractor for the LM, to predict that the first mission-ready LM would not be ready until at least February 1969. This would mean delaying the "D" and subsequent missions, endangering the program's goal of a lunar landing before the end of 1969.
George Low, the Manager of the Apollo Spacecraft Program Office, proposed a solution in August to keep the program on track despite the LM delay. Since the Command/Service Module (CSM) would be ready three months before the Lunar Module, a CSM-only mission could be flown in December 1968. Instead of just repeating the "C" mission flight of Apollo 7, this CSM could be sent all the way to the Moon, with the possibility of entering a lunar orbit. The new mission would also allow NASA to test lunar landing procedures that would otherwise have to wait until Apollo 10, the scheduled "F" mission. This also meant that the medium Earth orbit "E" mission could be dispensed with. The net result was that only the "D" mission had to be delayed.
Almost every senior manager at NASA agreed with this new mission, citing both confidence in the hardware and personnel, and the potential for a significant morale boost provided by a circumlunar flight. The only person who needed some convincing was James E. Webb, the NASA administrator. With the rest of his agency in support of the new mission, Webb eventually approved the mission change. The mission was officially changed from a "D" mission to a "C-Prime" lunar-orbit mission, but was still referred to in press releases as an Earth-orbit mission at Webb's direction. No public announcement was made about the change in mission until November 12, three weeks after Apollo 7's successful Earth-orbit mission and less than 40 days before launch.
With the change in mission for Apollo 8, Director of Flight Crew Operations Deke Slayton decided to swap the crews of the D and E missions. This swap also meant a swap of spacecraft, requiring Borman's crew to use CSM-103, while McDivitt's crew would use CSM-104.
On September 9, the crew entered the simulators to begin their preparation for the flight. By the time the mission flew, the crew had spent seven hours training for every actual hour of flight. Although all crew members were trained in all aspects of the mission, it was necessary to specialize. Borman, as commander, was given training on controlling the spacecraft during the re-entry. Lovell was trained on navigating the spacecraft in case communication was lost with the Earth. Anders was placed in charge of checking that the spacecraft was in working order.
Added pressure on the Apollo program to make its 1969 landing goal was provided by the Soviet Union's flight of some living creatures, including Russian tortoises, in a cislunar loop around the Moon on Zond 5 and return to Earth on September 21. There was speculation within NASA and the press that they might be preparing to launch cosmonauts on a similar circumlunar mission before the end of 1968.
The Apollo 8 crew, now living in the crew quarters at Kennedy Space Center, received a visit from Charles Lindbergh and his wife, Anne Morrow Lindbergh, the night before the launch. They talked about how, before his 1927 flight, Lindbergh had used a piece of string to measure the distance from New York City to Paris on a globe and from that calculated the fuel needed for the flight. The total was a tenth of the amount that the Saturn V would burn every second. The next day, the Lindberghs watched the launch of Apollo 8 from a nearby dune.
<h2>Saturn V.</h2>
The Saturn V rocket used by Apollo 8 was designated SA-503, or the "03rd" model of the Saturn V ("5") Rocket to be used in the Saturn-Apollo ("SA") program. When it was erected in the Vertical Assembly Building on December 20, 1967, it was thought that the rocket would be used for an unmanned Earth-orbit test flight carrying a boilerplate Command/Service Module. Apollo 6 had suffered several major problems during its April 1968 flight, including severe pogo oscillation during its first stage, two second stage engine failures, and a third stage that failed to reignite in orbit. Without assurances that these problems had been rectified, NASA administrators could not justify risking a manned mission until additional unmanned test flights proved that the Saturn V was ready.
Teams from the Marshall Space Flight Center (MSFC) went to work on the problems. Of primary concern was the pogo oscillation, which would not only hamper engine performance, but could exert significant g-forces on a crew. A task force of contractors, NASA agency representatives, and MSFC researchers concluded that the engines vibrated at a frequency similar to the frequency at which the spacecraft itself vibrated, causing a resonance effect that induced oscillations in the rocket. A system using helium gas to absorb some of these vibrations was installed.
Of equal importance was the failure of three engines during flight. Researchers quickly determined that a leaking hydrogen fuel line ruptured when exposed to vacuum, causing a loss of fuel pressure in engine two. When an automatic shutoff attempted to close the liquid hydrogen valve and shut down engine two, it accidentally shut down engine three's liquid oxygen due to a miswired connection. As a result, engine three failed within one second of engine two's shutdown. Further investigation revealed the same problem for the third-stage engine—a faulty igniter line. The team modified the igniter lines and fuel conduits, hoping to avoid similar problems on future launches.
The teams tested their solutions in August 1968 at the Marshall Space Flight Center. A Saturn stage IC was equipped with shock absorbing devices to demonstrate the team's solution to the problem of pogo oscillation, while a Saturn Stage II was retrofitted with modified fuel lines to demonstrate their resistance to leaks and ruptures in vacuum conditions. Once NASA administrators were convinced that the problems were solved, they gave their approval for a manned mission using SA-503.
The Apollo 8 spacecraft was placed on top of the rocket on September 21 and the rocket made the slow 3-mile (5 km) journey to the launch pad on October 9. Testing continued all through December until the day before launch, including various levels of readiness testing from December 5 through 11. Final testing of modifications to address the problems of pogo oscillation, ruptured fuel lines, and bad igniter lines took place on December 18, a mere three days before the scheduled launch.
<h2>Mission.</h2>
<h3>Parameter summary.</h3>
As the first manned spacecraft to orbit more than one celestial body, Apollo 8's profile had two different sets of orbital parameters, separated by a translunar injection maneuver.
Apollo lunar missions would begin with a nominal circular Earth parking orbit. Apollo 8 was launched into an initial orbit with an apogee of and a perigee of , with an inclination of 32.51° to the Equator, and an orbital period of 88.19 minutes. Propellant venting increased the apogee by over the 2 hours, 44 minutes and 30 seconds spent in the parking orbit.
This was followed by a Trans-Lunar Injection (TLI) burn of the S-IVB third stage for 318 seconds, accelerating the spacecraft from an orbital velocity of to the injection velocity of , which set a record for the highest speed, relative to Earth, that humans had ever traveled. This speed was slightly less than the Earth's escape velocity of , but put Apollo 8 into an elongated elliptical Earth orbit, to a point where the Moon's gravity would capture it.
The standard lunar orbit for Apollo missions was planned as a nominal circular orbit above the Moon's surface. Initial lunar orbit insertion was an ellipse with a perilune of and an apolune of , at an inclination of 12° from the lunar equator. This was then circularized at by , with an orbital period of 128.7 minutes. The effect of lunar mass concentrations ("masscons") on the orbit was found to be greater than initially predicted; over the course of the twenty-hour mission, the orbit was perturbated to by .
Apollo 8 achieved a maximum distance from Earth of .
<h3>Launch and trans-lunar injection.</h3>
Apollo 8 launched at 7:51:00 a.m. Eastern Standard Time on December 21, 1968, using the Saturn V's three stages to achieve Earth orbit. The S-IC first stage impacted the Atlantic Ocean at and the S-II second stage at . The S-IVB third stage injected the craft into Earth orbit, but remained attached to later perform the trans-lunar injection (TLI) burn that put the spacecraft on a trajectory to the Moon.
The Titan II launch vehicle used for the Gemini program had been notoriously rough-riding, and technicians promised the astronauts that the Saturn V, which was designed for the Apollo program rather than adapted from a missile, would have a much smoother ride. Lovell and Borman, both Gemini veterans, found this promise did not disappoint. During liftoff, they reported feeling nothing but a dull, muted rumble in the distance.
Once the vehicle reached Earth orbit, both the crew and Houston flight controllers spent the next 2 hours and 38 minutes checking that the spacecraft was in proper working order and ready for TLI. The proper operation of the S-IVB third stage of the rocket was crucial: in the last unmanned test, it had failed to re-ignite for TLI.
During the flight, three fellow astronauts served on the ground as Capsule Communicators (usually referred to as "CAPCOMs") on a rotating schedule. The CAPCOMs were the only people who regularly communicated with the crew. Michael Collins was the first CAPCOM on duty and at 2 hours, 27 minutes and 22 seconds after launch radioed, "Apollo 8. You are Go for TLI." This communication signified that Mission Control had given official permission for Apollo 8 to go to the Moon. Over the next 12 minutes before the TLI burn, the Apollo 8 crew continued to monitor the spacecraft and the S-IVB. The engine ignited on time and performed the TLI burn perfectly.
After the S-IVB had performed its required tasks, it was jettisoned. The crew then rotated the spacecraft to take some photographs of the spent stage and then practiced flying in formation with it. As the crew rotated the spacecraft, they had their first views of the Earth as they moved away from it. This marked the first time humans could view the whole Earth at once. Borman became worried that the S-IVB was staying too close to the Command/Service Module and suggested to Mission Control that the crew perform a separation maneuver. Mission Control first suggested pointing the spacecraft towards Earth and using the Reaction Control System (RCS) thrusters on the Service Module (SM) to add away from the Earth, but Borman did not want to lose sight of the S-IVB. After discussion, the crew and Mission Control decided to burn in this direction, but at instead. These discussions put the crew an hour behind their flight plan.
Five hours after launch, Mission Control sent a command to the S-IVB booster to vent its remaining fuel through its engine bell to change the booster's trajectory. This S-IVB would then pass the Moon and enter into a solar orbit, posing no further hazard to Apollo 8. The S-IVB subsequently went into a solar orbit with an inclination of 23.47° from the plane of the ecliptic, and an orbital period of 340.80 days. After the insertion into trans-Lunar orbit, the Saturn IVB third stage became a object. It will continue to orbit the Sun for many years.
The Apollo 8 crew were the first humans to pass through the Van Allen radiation belts, which extend up to from Earth. Scientists predicted that passing through the belts quickly at the spacecraft's high speed would cause a radiation dosage of no more than a chest X-ray, or 1 milligray (during a year, the average human receives a dose of 2 to 3 mGy). To record the actual radiation dosages, each crew member wore a Personal Radiation Dosimeter that transmitted data to Earth as well as three passive film dosimeters that showed the cumulative radiation experienced by the crew. By the end of the mission, the crew experienced an average radiation dose of 1.6 mGy.
<h3>Lunar trajectory.</h3>
Jim Lovell's main job as Command Module Pilot was as navigator. Although Mission Control performed all the actual navigation calculations, it was necessary to have a crew member serving as navigator so that the crew could return to Earth in case of loss of communication with Mission Control. Lovell navigated by star sightings using a sextant built in to the spacecraft, measuring the angle between a star and the Earth's (or the Moon's) horizon. This task was difficult, because a large cloud of debris around the spacecraft, formed by the venting S-IVB, made it hard to distinguish the stars.
By seven hours into the mission, the crew was about one hour and 40 minutes behind flight plan, because of the problems in moving away from the S-IVB and Lovell's obscured star sightings. The crew now placed the spacecraft into Passive Thermal Control (PTC), also called "barbecue roll", in which the spacecraft rotated about once per hour around its long axis to ensure even heat distribution across the surface of the spacecraft. In direct sunlight, the spacecraft could be heated to over while the parts in shadow would be . These temperatures could cause the heat shield to crack and propellant lines to burst. Because it was impossible to get a perfect roll, the spacecraft swept out a cone as it rotated. The crew had to make minor adjustments every half hour as the cone pattern got larger and larger.
The first mid-course correction came 11 hours into the flight. Testing on the ground had shown that the Service Propulsion System (SPS) engine had a small chance of exploding when burned for long periods unless its combustion chamber was "coated" first. Burning the engine for a short period would accomplish coating. This first correction burn was only 2.4 seconds and added about velocity prograde (in the direction of travel). This change was less than the planned , because of a bubble of helium in the oxidizer lines, which caused unexpectedly low propellant pressure. The crew had to use the small RCS thrusters to make up the shortfall. Two later planned mid-course corrections were canceled because the Apollo 8 trajectory was found to be perfect.
Eleven hours into the flight, the crew had been awake for more than 16 hours. Before launch, NASA had decided that at least one crew member should be awake at all times to deal with problems that might arise. Borman started the first sleep shift, but found sleeping difficult because of the constant radio chatter and mechanical noises.
About an hour after starting his sleep shift, Borman obtained permission from ground control to take a Seconal sleeping pill. The pill had little effect. Borman eventually fell asleep, and then awoke feeling ill. He vomited twice and had a bout of diarrhea; this left the spacecraft full of small globules of vomit and feces, which the crew cleaned up as well as they could. Borman initially did not want everyone to know about his medical problems, but Lovell and Anders wanted to inform Mission Control. The crew decided to use the Data Storage Equipment (DSE), which could tape voice recordings and telemetry and dump them to Mission Control at high speed. After recording a description of Borman's illness they asked Mission Control to check the recording, stating that they "would like an evaluation of the voice comments".
The Apollo 8 crew and Mission Control medical personnel held a conference using an unoccupied second-floor control room (there were two identical control rooms in Houston, on the second and third floors, only one of which was used during a mission). The conference participants concluded that there was little to worry about and that Borman's illness was either a 24-hour flu, as Borman thought, or a reaction to the sleeping pill. Researchers now believe that he was suffering from space-adaptation syndrome, which affects about a third of astronauts during their first day in space as their vestibular system adapts to weightlessness. Space-adaptation syndrome had not occurred on previous spacecraft (Mercury and Gemini), because those astronauts couldn't move freely in the small cabins of those spacecraft. The increased cabin space in the Apollo Command Module afforded astronauts greater freedom of movement, contributing to symptoms of space sickness for Borman and, later, astronaut Russell Schweickart during Apollo 9.
The cruise phase was a relatively uneventful part of the flight, except for the crew checking that the spacecraft was in working order and that they were on course. During this time, NASA scheduled a television broadcast at 31 hours after launch. The Apollo 8 crew used a 2 kg camera that broadcast in black-and-white only, using a Vidicon tube. The camera had two lenses, a very wide-angle (160°) lens, and a telephoto (9°) lens.
During this first broadcast, the crew gave a tour of the spacecraft and attempted to show how the Earth appeared from space. However, difficulties aiming the narrow-angle lens without the aid of a monitor to show what it was looking at made showing the Earth impossible. Additionally, the Earth image became saturated by any bright source without proper filters. In the end, all the crew could show the people watching back on Earth was a bright blob. After broadcasting for 17 minutes, the rotation of the spacecraft took the high-gain antenna out of view of the receiving stations on Earth and they ended the transmission with Lovell wishing his mother a happy birthday.
By this time, the crew had completely abandoned the planned sleep shifts. Lovell went to sleep 32½ hours into the flight—3½ hours before he had planned to. A short while later, Anders also went to sleep after taking a sleeping pill.
The crew was unable to see the Moon for much of the outward cruise. Two factors made the Moon almost impossible to see from inside the spacecraft: three of the five windows fogging up due to out-gassed oils from the silicone sealant, and the attitude required for the PTC. It was not until the crew had gone behind the Moon that they would be able to see it for the first time.
The Apollo 8 made a second television broadcast at 55 hours into the flight. This time, the crew rigged up filters meant for the still cameras so they could acquire images of the Earth through the telephoto lens. Although difficult to aim, as they had to maneuver the entire spacecraft, the crew was able to broadcast back to Earth the first television pictures of the Earth. The crew spent the transmission describing the Earth and what was visible and the colors they could see. The transmission lasted 23 minutes.
<h3>Lunar sphere of influence.</h3>
At about 55 hours and 40 minutes into the flight, the crew of Apollo 8 became the first humans to enter the gravitational sphere of influence of another celestial body. In other words, the effect of the Moon's gravitational force on Apollo 8 became stronger than that of the Earth. At the time it happened, Apollo 8 was from the Moon and had a speed of relative to the Moon. This historic moment was of little interest to the crew since they were still calculating their trajectory with respect to the launch pad at Kennedy Space Center. They would continue to do so until they performed their last mid-course correction, switching to a reference frame based on ideal orientation for the second engine burn they would make in lunar orbit. It was only 13 hours until they would be in lunar orbit.
The last major event before Lunar Orbit Insertion (LOI) was a second mid-course correction. It was in retrograde (against direction of travel) and slowed the spacecraft down by , effectively lowering the closest distance that the spacecraft would pass the moon. At exactly 61 hours after launch, about from the Moon, the crew burned the RCS for 11 seconds. They would now pass from the lunar surface.
At 64 hours into the flight, the crew began to prepare for Lunar Orbit Insertion-1 (LOI-1). This maneuver had to be performed perfectly, and due to orbital mechanics had to be on the far side of the Moon, out of contact with the Earth. After Mission Control was polled for a "go/no go" decision, the crew was told at 68 hours, they were Go and "riding the best bird we can find". At 68 hours and 58 minutes, the spacecraft went behind the Moon and out of radio contact with the Earth.
With 10 minutes before the LOI-1, the crew began one last check of the spacecraft systems and made sure that every switch was in the correct place. At that time, they finally got their first glimpses of the Moon. They had been flying over the unlit side, and it was Lovell who saw the first shafts of sunlight obliquely illuminating the lunar surface. The LOI burn was only two minutes away, so the crew had little time to appreciate the view.
<h3>Lunar orbit.</h3>
The SPS ignited at 69 hours, 8 minutes, and 16 seconds after launch and burned for 4 minutes and 13 seconds, placing the Apollo 8 spacecraft in orbit around the Moon. The crew described the burn as being the longest four minutes of their lives. If the burn had not lasted exactly the correct amount of time, the spacecraft could have ended up in a highly elliptical lunar orbit or even flung off into space. If it lasted too long they could have struck the Moon. After making sure the spacecraft was working, they finally had a chance to look at the Moon, which they would orbit for the next 20 hours.
On Earth, Mission Control continued to wait. If the crew had not burned the engine or the burn had not lasted the planned length of time, the crew would appear early from behind the Moon. However, this time came and went without Apollo 8 reappearing. Exactly at the calculated moment, the signal was received from the spacecraft, indicating it was in a orbit about the Moon.
After reporting on the status of the spacecraft, Lovell gave the first description of what the lunar surface looked like:
Lovell continued to describe the terrain they were passing over. One of the crew's major tasks was reconnaissance of planned future landing sites on the Moon, especially one in Mare Tranquillitatis that would be the Apollo 11 landing site. The launch time of Apollo 8 had been chosen to give the best lighting conditions for examining the site. A film camera had been set up in one of the spacecraft windows to record a frame every second of the Moon below. Bill Anders spent much of the next 20 hours taking as many photographs as possible of targets of interest. By the end of the mission the crew had taken 700 photographs of the Moon and 150 of the Earth.
Throughout the hour that the spacecraft was in contact with Earth, Borman kept asking how the data for the SPS looked. He wanted to make sure that the engine was working and could be used to return early to the Earth if necessary. He also asked that they receive a "go/no go" decision before they passed behind the Moon on each orbit.
As they reappeared for their second pass in front of the Moon, the crew set up the equipment to broadcast a view of the lunar surface. Anders described the craters that they were passing over. At the end of this second orbit they performed the 11-second LOI-2 burn of the SPS to circularize the orbit to .
Through the next two orbits, the crew continued to keep check of the spacecraft and to observe and photograph the Moon. During the third pass, Borman read a small prayer for his church. He had been scheduled to participate in a service at St. Christopher's Episcopal Church near Seabrook, Texas, but due to the Apollo 8 flight he was unable to. A fellow parishioner and engineer at Mission Control, Rod Rose, suggested that Borman read the prayer which could be recorded and then replayed during the service.
<h4>Earthrise.</h4>
When the spacecraft came out from behind the Moon for its fourth pass across the front, the crew witnessed "Earthrise" for the first time in human history (NASA's Lunar Orbiter 1 took the very first picture of an Earthrise from the vicinity of the Moon, on August 23, 1966). Borman saw the Earth emerging from behind the lunar horizon, and then called in excitement to the others, taking a black-and-white photograph as he did so. In the ensuing scramble Anders took "Earthrise", a more famous color photo, later picked by "Life" magazine as one of its hundred photos of the century. 
Due to the synchronous rotation of the Moon about the Earth, Earthrise is not generally visible from the lunar surface. Earthrise is generally only visible when orbiting the Moon, other than at selected places near the Moon's limb, where libration carries the Earth slightly above and below the lunar horizon.
Anders continued to take photographs while Lovell assumed control of the spacecraft so Borman could rest. Despite the difficulty resting in the cramped and noisy spacecraft, Borman was able to sleep for two orbits, awakening periodically to ask questions about their status. Borman awoke fully, however, when he started to hear his fellow crew members make mistakes. They were beginning to not understand questions and would have to ask for the answers to be repeated. Borman realized that everyone was extremely tired having not had a good night's sleep in over three days. Taking command, he ordered Anders and Lovell to get some sleep and that the rest of the flight plan regarding observing the Moon be scrubbed. At first Anders protested saying that he was fine, but Borman would not be swayed. At last Anders agreed as long as Borman would set up the camera to continue to take automatic shots of the Moon. Borman also remembered that there was a second television broadcast planned, and with so many people expected to be watching he wanted the crew to be alert. For the next two orbits Anders and Lovell slept while Borman sat at the helm. On subsequent Apollo missions, crews would avoid this situation by sleeping on the same schedule.
As they rounded the Moon for the ninth time, the second television transmission began. Borman introduced the crew, followed by each man giving his impression of the lunar surface and what it was like to be orbiting the Moon. Borman described it as being "a vast, lonely, forbidding expanse of nothing". Then, after talking about what they were flying over, Anders said that the crew had a message for all those on Earth. Each man on board read a section from the Biblical creation story from the Book of Genesis. Borman finished the broadcast by wishing a Merry Christmas to everyone on Earth. His message appeared to sum up the feelings that all three crewmen had from their vantage point in lunar orbit. Borman said, "And from the crew of Apollo 8, we close with good night, good luck, a Merry Christmas and God bless all of you—all of you on the good Earth."
The only task left for the crew at this point was to perform the Trans-Earth Injection (TEI), which was scheduled for 2½ hours after the end of the television transmission. The TEI was the most critical burn of the flight, as any failure of the SPS to ignite would strand the crew in lunar orbit, with little hope of escape. As with the previous burn, the crew had to perform the maneuver above the far side of the Moon, out of contact with Earth.
The burn occurred exactly on time. The spacecraft telemetry was reacquired as it re-emerged from behind the Moon at 89 hours, 28 minutes, and 39 seconds, the exact time calculated. When voice contact was regained, Lovell announced, "Please be informed, there is a Santa Claus", to which Ken Mattingly, the current CAPCOM, replied, "That's affirmative, you are the best ones to know." The spacecraft began its journey back to Earth on December 25, Christmas Day.
<h3>Unplanned manual re-alignment.</h3>
Later, Lovell used some otherwise idle time to do some navigational sightings, maneuvering the module to view various stars by using the computer keyboard. However, he accidentally erased some of the computer's memory, which caused the Inertial Measurement Unit (IMU) to think the module was in the same relative position it had been in before lift-off and fire the thrusters to "correct" the module's attitude.
Once the crew realized why the computer had changed the module's attitude, they realized they would have to re-enter data that would tell the computer its real position. It took Lovell ten minutes to figure out the right numbers, using the thrusters to get the stars Rigel and Sirius aligned, and another 15 minutes to enter the corrected data into the computer.
Sixteen months later, Lovell would once again have to perform a similar manual re-alignment, under more critical conditions, during the Apollo 13 mission, after that module's IMU had to be turned off to conserve energy. In his 1994 book, "Lost Moon: The Perilous Voyage of Apollo 13", Lovell wrote, "My training [on Apollo 8] came in handy!" In that book he dismissed the incident as a "planned experiment", requested by the ground crew. In subsequent interviews Lovell has acknowledged that the incident was an accident, caused by his mistake.
<h3>Cruise back to Earth and re-entry.</h3>
The cruise back to Earth was mostly a time for the crew to relax and monitor the spacecraft. As long as the trajectory specialists had calculated everything correctly, the spacecraft would re-enter two-and-half days after TEI and splashdown in the Pacific.
On Christmas afternoon, the crew made their fifth television broadcast. This time they gave a tour of the spacecraft, showing how an astronaut lived in space. When they finished broadcasting they found a small present from Deke Slayton in the food locker: a real turkey dinner with stuffing, in the same kind of pack that the troops in Vietnam received. Another Slayton surprise was a gift of three miniature bottles of brandy, that Borman ordered the crew to leave alone until after they landed. They remained unopened, even years after the flight. There were also small presents to the crew from their wives. The next day, at about 124 hours into the mission, the sixth and final TV transmission showed the mission's best video images of the earth, in a four-minute broadcast.
After two uneventful days the crew prepared for re-entry. The computer would control the re-entry and all the crew had to do was put the spacecraft in the correct attitude, blunt end forward. If the computer broke down, Borman would take over.
Once the Command Module was separated from the Service Module, the astronauts were committed to re-entry. Six minutes before they hit the top of the atmosphere, the crew saw the Moon rising above the Earth's horizon, just as had been predicted by the trajectory specialists. As they hit the thin outer atmosphere they noticed it was becoming hazy outside as glowing plasma formed around the spacecraft. The spacecraft started slowing down and the deceleration peaked at 6 g (59 m/s). With the computer controlling the descent by changing the attitude of the spacecraft, Apollo 8 rose briefly like a skipping stone before descending to the ocean. At the drogue parachute stabilized the spacecraft and was followed at by the three main parachutes. The spacecraft splashdown position was officially reported as in the North Pacific Ocean south of Hawaii.
When it hit the water, the parachutes dragged the spacecraft over and left it upside down, in what was termed Stable 2 position. About six minutes later the Command Module was righted into its normal apex-up splashdown orientation by the inflatable bag uprighting system. As they were buffeted by a swell, Borman was sick, waiting for the three flotation balloons to right the spacecraft. It was 43 minutes after splashdown before the first frogman from arrived, as the spacecraft had landed before sunrise. Forty-five minutes later, the crew was safe on the deck of the aircraft carrier.
<h2>Historical importance.</h2>
Apollo 8 came at the end of 1968, a year that had seen much upheaval in the United States and most of the world. Even though the year saw political assassinations, political unrest in the streets of Europe and America, and the Prague Spring, "Time" magazine chose the crew of Apollo 8 as its Men of the Year for 1968, recognizing them as the people who most influenced events in the preceding year. They had been the first people ever to leave the gravitational influence of the Earth and orbit another celestial body. They had survived a mission that even the crew themselves had rated as only having a fifty-fifty chance of fully succeeding. The effect of Apollo 8 can be summed up by a telegram from a stranger, received by Borman after the mission, that simply stated, "Thank you Apollo 8. You saved 1968."
One of the most famous aspects of the flight was the Earthrise picture that was taken as they came around for their fourth orbit of the Moon. This was the first time that humans had taken such a picture whilst actually behind the camera, and it has been credited with a role in inspiring the first Earth Day in 1970. It was selected as the first of "Life" magazine's "100 Photographs That Changed the World". Apollo 11 astronaut Michael Collins said, "Eight's momentous historic significance was foremost"; while many space historians, such as Robert K. Poole, see Apollo 8 as the most historically significant of all the Apollo missions.
The mission was the most widely covered by the media since the first American orbital flight, Mercury-Atlas 6 by John Glenn in 1962. There were 1200 journalists covering the mission, with the BBC coverage being broadcast in 54 countries in 15 different languages. The Soviet newspaper "Pravda" featured a quote from Boris Nikolaevich Petrov, Chairman of the Soviet Interkosmos program, who described the flight as an "outstanding achievement of American space sciences and technology". It is estimated that a quarter of the people alive at the time saw—either live or delayed—the Christmas Eve transmission during the ninth orbit of the Moon. The Apollo 8 broadcasts won an Emmy Award, the highest honor given by the Academy of Television Arts & Sciences.
Madalyn Murray O'Hair, an atheist, later caused controversy by bringing a lawsuit against NASA over the reading from Genesis. O'Hair wished the courts to ban American astronauts—who were all government employees—from public prayer in space. Though the case was rejected by the Supreme Court of the United States for lack of jurisdiction, it caused NASA to be skittish about the issue of religion throughout the rest of the Apollo program. Buzz Aldrin, on Apollo 11, self-communicated Presbyterian Communion on the surface of the Moon after landing; he refrained from mentioning this publicly for several years, and only obliquely referred to it at the time.
In 1969, the United States Postal Service issued a postage stamp (Scott catalogue #1371) commemorating the Apollo 8 flight around the Moon. The stamp featured a detail of the famous photograph of the Earthrise over the Moon taken by Anders on Christmas Eve, and the words, "In the beginning God ..." Just 18 days after the crew's return to Earth, they were featured during the 1969 Super Bowl pre-game show reciting the Pledge of Allegiance prior to the national anthem being performed by Anita Bryant.
<h2>Spacecraft location.</h2>
In January 1970, the spacecraft was delivered to Osaka, Japan, for display in the U.S. pavilion at Expo '70. It is now displayed at the Chicago Museum of Science and Industry, along with a collection of personal items from the flight donated by Lovell and the space suit worn by Frank Borman. Jim Lovell's Apollo 8 space suit is on public display in the Visitor Center at NASA's Glenn Research Center. Bill Anders's space suit is on display at the Science Museum in London, United Kingdom.
<h2>In popular culture.</h2>
Apollo 8's historic mission has been shown and referred to in several forms, both documentary and fiction. The various television transmissions and 16 mm footage shot by the crew of Apollo 8 was compiled and released by NASA in the 1969 documentary, "Debrief: Apollo 8", which was hosted by Burgess Meredith. In addition, Spacecraft Films released, in 2003, a three-disc DVD set containing all of NASA's TV and 16 mm film footage related to the mission including all TV transmissions from space, training and launch footage, and motion pictures taken in flight. Portions of the Apollo 8 mission can be seen in the 1989 documentary "For All Mankind", which won the Grand Jury Prize Documentary at the Sundance Film Festival. The television series "American Experience" aired a documentary, "Race to the Moon", in 2005 during season 18. The Apollo 8 mission was well-covered in the 2007 British documentary "In the Shadow of the Moon".
Portions of the Apollo 8 mission are dramatized in the 1998 miniseries "From the Earth to the Moon" episode "1968". The S-IVB stage of Apollo 8 was also portrayed as the location of an alien device in the 1970 "UFO" episode "Conflict".
At the Kennedy Space Center Visitor Complex's Apollo/Saturn V Center, the history of the U.S. space program leading up to the launch of Apollo 8 is the subject of a multi-screen multimedia presentation which also features the actual control panels used in the Firing Room for the launch.

</doc>
<doc id="664" url="https://en.wikipedia.org/wiki?curid=664" title="Astronaut">
Astronaut

An astronaut or cosmonaut is a person trained by a human spaceflight program to command, pilot, or serve as a crew member of a spacecraft. Although generally reserved for professional space travelers, the terms are sometimes applied to anyone who travels into space, including scientists, politicians, journalists, and tourists.
Starting in the 1950s up to 2002, astronauts were sponsored and trained exclusively by governments, either by the military or by civilian space agencies. With the suborbital flight of the privately funded SpaceShipOne in 2004, a new category of astronaut was created: the commercial astronaut.
<h2>Definition.</h2>
The criteria for what constitutes human spaceflight vary. The Fédération Aéronautique Internationale (FAI) Sporting Code for astronautics recognizes only flights that exceed an altitude of. In the United States, professional, military, and commercial astronauts who travel above an altitude of are awarded astronaut wings.
, a total of 532 people from 36 countries have reached or more in altitude, of which 529 reached low Earth orbit or beyond.
Of these, 24 people have traveled beyond Low Earth orbit, to either lunar or trans-lunar orbit or to the surface of the moon; three of the 24 did so twice: Jim Lovell, John Young and Eugene Cernan. The three astronauts who have not reached low Earth orbit are spaceplane pilots Joe Walker, Mike Melvill, and Brian Binnie.
, under the U.S. definition 538 people qualify as having reached space, above altitude. Of eight X-15 pilots who exceeded in altitude, only one exceeded 100 kilometers (about 62 miles).
Space travelers have spent over 41,790 man-days (114.5 man-years) in space, including over 100 astronaut-days of spacewalks. As of 2016, the man with the longest cumulative time in space is Gennady Padalka, who has spent 879 days in space. Peggy A. Whitson holds the record for the most time in space by a woman, 377 days.
<h2>Terminology.</h2>
In 1959, when both the United States and Soviet Union were planning, but had yet to launch humans into space, NASA Administrator T. Keith Glennan and his Deputy Administrator, Dr. Hugh Dryden, discussed whether spacecraft crew members should be called "astronauts" or "cosmonauts". Dryden preferred "cosmonaut", on the grounds that flights would occur in the "cosmos" (near space), while the "astro" prefix suggested flight to the stars. Most NASA Space Task Group members preferred "astronaut", which survived by common usage as the preferred American term. When the Soviet Union launched the first man into space, Yuri Gagarin in 1961, they chose a term which anglicizes to "cosmonaut".
<h3>English.</h3>
In English-speaking nations, a professional space traveler is called an "astronaut". The term derives from the Greek words "ástron" (ἄστρον), meaning "star", and "nautes" (ναύτης), meaning "sailor". The first known use of the term "astronaut" in the modern sense was by Neil R. Jones in his short story "The Death's Head Meteor" in 1930. The word itself had been known earlier. For example, in Percy Greg's 1880 book "Across the Zodiac", "astronaut" referred to a spacecraft. In "Les Navigateurs de l'Infini" (1925) of J.-H. Rosny aîné, the word "astronautique" (astronautic) was used. The word may have been inspired by "aeronaut", an older term for an air traveler first applied (in 1784) to balloonists. An early use in a non-fiction publication is Eric Frank Russell's poem "The Astronaut" in the November 1934 "Bulletin of the British Interplanetary Society".
The first known formal use of the term astronautics in the scientific community was the establishment of the annual International Astronautical Congress in 1950 and the subsequent founding of the International Astronautical Federation the following year.
NASA applies the term astronaut to any crew member aboard NASA spacecraft bound for Earth orbit or beyond. NASA also uses the term as a title for those selected to join its Astronaut Corps. The European Space Agency similarly uses the term astronaut for members of its Astronaut Corps.
<h3>Russian.</h3>
By convention, an astronaut employed by the Russian Federal Space Agency (or its Soviet predecessor) is called a "cosmonaut" in English texts. The word is an anglicisation of the Russian word "kosmonavt" ( ), one who works in space outside the Earth's atmosphere, a space traveler, which derives from the Greek words "kosmos" (κόσμος), meaning "universe", and "nautes" (ναύτης), meaning "sailor". Other countries of the former Eastern Bloc use variations of the Russian word "kosmonavt", such as the Polish "kosmonauta".
Coinage of the term "kosmonavt" has been credited to Soviet aeronautics pioneer Mikhail Tikhonravov (1900–1974). The first cosmonaut was Soviet Air Force pilot Yuri Gagarin, also the first person in space. Valentina Tereshkova, a Russian factory worker, was the first woman in space, as well as the first civilian among the Soviet cosmonaut or NASA astronaut corps to make a spaceflight. On March 14, 1995, Norman Thagard became the first American to ride to space on board a Russian launch vehicle, and thus became the first "American cosmonaut".
<h3>Chinese.</h3>
Official English-language texts issued by the government of China use "astronaut" while texts in Russian use космонавт ("cosmonaut"). In official Chinese-language texts, "yǔ háng yuán" (, "space navigating personnel") is used for astronauts and cosmonauts, and "háng tiān yuán" (, "space navigating personnel") is used for Chinese astronauts. The phrase "tài kōng rén" (, "spaceman") is often used in Hong Kong and Taiwan.
The term "taikonaut" is used by some English-language news media organizations for professional space travelers from China. The word has featured in the Longman and Oxford English dictionaries, the latter of which describes it as "a hybrid of the Chinese term "taikong" (space) and the Greek "naut" (sailor)"; the term became more common in 2003 when China sent its first astronaut Yang Liwei into space aboard the "Shenzhou 5" spacecraft. This is the term used by Xinhua News Agency in the English version of the Chinese "People's Daily" since the advent of the Chinese space program. The origin of the term is unclear; as early as May 1998, Chiew Lee Yih () from Malaysia, used it in newsgroups.
<h3>Other terms.</h3>
With the rise of space tourism, NASA and the Russian Federal Space Agency agreed to use the term "spaceflight participant" to distinguish those space travelers from professional astronauts on missions coordinated by those two agencies.
While no nation other than the Russian Federation (and previously the former Soviet Union), the United States, and China have launched a manned spacecraft, several other nations have sent people into space in cooperation with one of these countries. Inspired partly by these missions, other synonyms for astronaut have entered occasional English usage. For example, the term "spationaut" (French spelling: "spationaute") is sometimes used to describe French space travelers, from the Latin word "spatium" for "space", the Malay term "angkasawan" was used to describe participants in the Angkasawan program, and the Indian Space Research Organisation hope to launch a spacecraft in 2018 that would carry "vyomanauts", coined from the Sanskrit word for space.
<h2>Space travel milestones.</h2>
The first human in space was Soviet Yuri Gagarin, who was launched on April 12, 1961 aboard Vostok 1 and orbited around the Earth for 108 minutes. The first woman in space was Soviet Valentina Tereshkova, who launched on June 16, 1963 aboard Vostok 6 and orbited Earth for almost three days.
Alan Shepard became the first American and second person in space on May 5, 1961 on a 15-minute sub-orbital flight. The first American woman in space was Sally Ride, during Space Shuttle Challenger's mission STS-7, on June 18, 1983. In 1992 Mae Jemison became the first African American woman to travel in space aboard STS-47.
Cosmonaut Alexei Leonov was the first person to conduct an extravehicular activity (EVA), (commonly called a "spacewalk"), on March 18, 1965, on the Soviet Union's Voskhod 2 mission. This was followed two and a half months later by astronaut Ed White who made the first American EVA on NASA's Gemini 4 mission.
The first manned mission to orbit the Moon, "Apollo 8", included American William Anders who was born in Hong Kong, making him the first Asian-born astronaut in 1968.
The Soviet Union, through its Intercosmos program, allowed people from other "socialist" (i.e. Warsaw Pact and other Soviet-allied) countries to fly on its missions, with the notable exception of France participating in Soyuz TM-7. An example is Czechoslovak Vladimír Remek, the first cosmonaut from a country other than the Soviet Union or the United States, who flew to space in 1978 on a Soyuz-U rocket.
On July 23, 1980, Pham Tuan of Vietnam became the first Asian in space when he flew aboard Soyuz 37. Also in 1980, Cuban Arnaldo Tamayo Méndez became the first person of Hispanic and black African descent to fly in space, and in 1983, Guion Bluford became the first African American to fly into space. In April 1985, Taylor Wang became the first ethnic Chinese person in space. The first person born in Africa to fly in space was Patrick Baudry (France), in 1985. In 1985, Saudi Arabian Prince Sultan Bin Salman Bin AbdulAziz Al-Saud became the first Arab Muslim astronaut in space. In 1988, Abdul Ahad Mohmand became the first Afghan to reach space, spending nine days aboard the Mir space station.
With the larger number of seats available on the Space Shuttle, the U.S. began taking international astronauts. In 1983, Ulf Merbold of West Germany became the first non-US citizen to fly in a US spacecraft. In 1984, Marc Garneau became the first of 8 Canadian astronauts to fly in space (through 2010).
In 1985, Rodolfo Neri Vela became the first Mexican-born person in space. In 1991, Helen Sharman became the first Briton to fly in space.
In 2002, Mark Shuttleworth became the first citizen of an African country to fly in space, as a paying spaceflight participant. In 2003, Ilan Ramon became the first Israeli to fly in space, although he died during a re-entry accident.
On October 15, 2003, Yang Liwei became China's first astronaut on the Shenzhou 5 spacecraft.
<h3>Age milestones.</h3>
The youngest person to fly in space is Gherman Titov, who was 25 years old when he flew Vostok 2. (Titov was also the first person to suffer space sickness).
The oldest person who has flown in space is John Glenn, who was 77 when he flew on STS-95.
<h3>Duration and distance milestones.</h3>
The longest stay in space thus far has been 438 days, by Russian Valeri Polyakov.
As of 2006, the most spaceflights by an individual astronaut is seven, a record held by both Jerry L. Ross and Franklin Chang-Diaz. The farthest distance from Earth an astronaut has traveled was , when Jim Lovell, Jack Swigert, and Fred Haise went around the Moon during the Apollo 13 emergency.
<h3>Civilian and non-government milestones.</h3>
The first civilian in space was Valentina Tereshkova aboard Vostok 6 (she also became the first woman in space on that mission).
Tereshkova was only honorarily inducted into the USSR's Air Force, which had no female pilots whatsoever at that time. A month later, Joseph Albert Walker became the first American civilian in space when his X-15 Flight 90 crossed the line, qualifying him by the international definition of spaceflight. Walker had joined the US Army Air Force but was not a member during his flight. 
The first people in space who had never been a member of any country's armed forces were both Konstantin Feoktistov and Boris Yegorov aboard Voskhod 1.
The first non-governmental space traveler was Byron K. Lichtenberg, a researcher from the Massachusetts Institute of Technology who flew on STS-9 in 1983. In December 1990, Toyohiro Akiyama became the first paying space traveler as a reporter for Tokyo Broadcasting System, a visit to Mir as part of an estimated $12 million (USD) deal with a Japanese TV station, although at the time, the term used to refer to Akiyama was "Research Cosmonaut". Akiyama suffered severe space sickness during his mission, which affected his productivity.
The first self-funded space tourist was Dennis Tito on board the Russian spacecraft Soyuz TM-3 on April 28, 2001.
<h3>Self-funded travelers.</h3>
The first person to fly on an entirely privately funded mission was Mike Melvill, piloting SpaceShipOne flight 15P on a suborbital journey, although he was a test pilot employed by Scaled Composites and not an actual paying space tourist. Seven others have paid the Russian Space Agency to fly into space:
<h2>Training.</h2>
The first NASA astronauts were selected for training in 1959. Early in the space program, military jet test piloting and engineering training were often cited as prerequisites for selection as an astronaut at NASA, although neither John Glenn nor Scott Carpenter (of the Mercury Seven) had any university degree, in engineering or any other discipline at the time of their selection. Selection was initially limited to military pilots. The earliest astronauts for both America and the USSR tended to be jet fighter pilots, and were often test pilots.
Once selected, NASA astronauts go through twenty months of training in a variety of areas, including training for extravehicular activity in a facility such as NASA's Neutral Buoyancy Laboratory. Astronauts-in-training may also experience short periods of weightlessness in aircraft called the "vomit comet", the nickname given to a pair of modified KC-135s (retired in 2000 and 2004 respectively, and replaced in 2005 with a C-9) which perform parabolic flights. Astronauts are also required to accumulate a number of flight hours in high-performance jet aircraft. This is mostly done in T-38 jet aircraft out of Ellington Field, due to its proximity to the Johnson Space Center. Ellington Field is also where the Shuttle Training Aircraft is maintained and developed, although most flights of the aircraft are done out of Edwards Air Force Base.
Mission Specialist Educators, or "Educator Astronauts", were first selected in 2004, and as of 2007, there are three NASA Educator astronauts: Joseph M. Acaba, Richard R. Arnold, and Dorothy Metcalf-Lindenburger.
<h3>NASA candidacy requirements.</h3>
<h4>Mission Specialist Educator.</h4>
Barbara Morgan, selected as back-up teacher to Christa McAuliffe in 1985, is considered to be the first Educator astronaut by the media, but she trained as a mission specialist.
The Educator Astronaut program is a successor to the Teacher in Space program from the 1980s.
<h2>Health risks of space travel.</h2>
Astronauts are susceptible to a variety of health risks including decompression sickness, barotrauma, immunodeficiencies, loss of bone and muscle, loss of eyesight, orthostatic intolerance, sleep disturbances, and radiation injury. A variety of large scale medical studies are being conducted in space via the National Space and Biomedical Research Institute (NSBRI) to address these issues. Prominent among these is the Advanced Diagnostic Ultrasound in Microgravity Study in which astronauts (including former ISS commanders Leroy Chiao and Gennady Padalka) perform ultrasound scans under the guidance of remote experts to diagnose and potentially treat hundreds of medical conditions in space. This study's techniques are now being applied to cover professional and Olympic sports injuries as well as ultrasound performed by non-expert operators in medical and high school students. It is anticipated that remote guided ultrasound will have application on Earth in emergency and rural care situations, where access to a trained physician is often rare.
On December 31, 2012, a NASA-supported study reported that manned spaceflight may harm the brain and accelerate the onset of Alzheimer's disease.
In October 2015, the NASA Office of Inspector General issued a health hazards report related to space exploration, including a human mission to Mars.
<h2>Food and drink.</h2>
An astronaut on the International Space Station requires about 0.83 kilograms (1.83 pounds) weight of food inclusive of food packaging per meal each day. (The packaging for each meal weighs around 0.12 kilograms - 0.27 pounds) Longer-duration missions require more food.
Shuttle astronauts worked with nutritionists to select menus that appeal to their individual tastes. Five months before flight, menus are selected and analyzed for nutritional content by the shuttle dietician. Foods are tested to see how they will react in a reduced gravity environment. Caloric requirements are determined using a basal energy expenditure (BEE) formula.
On Earth, the average American uses about 35 gallons (132 liters) of water every day. On board the ISS astronauts limit water use to only about three gallons (11 liters) per day.
<h2>Insignia.</h2>
In Russia, cosmonauts are awarded Pilot-Cosmonaut of the Russian Federation upon completion of their missions, often accompanied with the award of Hero of the Russian Federation. This follows the practice established in the USSR where cosmonauts were usually awarded the title Hero of the Soviet Union.
At NASA, those who complete astronaut candidate training receive a silver lapel pin. Once they have flown in space, they receive a gold pin. U.S. astronauts who also have active-duty military status receive a special qualification badge, known as the Astronaut Badge, after participation on a spaceflight. The United States Air Force also presents an Astronaut Badge to its pilots who exceed in altitude.
<h2>Deaths.</h2>
Eighteen astronauts (fourteen men and four women) have lost their lives during four space flights. By nationality, thirteen were American (including one born in India), four were Russian (Soviet Union), and one was Israeli.
Eleven people (all men) have lost their lives training for spaceflight: eight Americans and three Russians. Six of these were in crashes of training jet aircraft, one drowned during water recovery training, and four were due to fires in pure oxygen environments.
The Space Mirror Memorial, which stands on the grounds of the John F. Kennedy Space Center Visitor Complex, commemorates the lives of the men and women who have died during spaceflight and during training in the space programs of the United States. In addition to twenty NASA career astronauts, the memorial includes the names of a U.S. Air Force X-15 test pilot, a U.S. Air Force officer who died while training for a then-classified military space program, and a civilian spaceflight participant.

</doc>
<doc id="665" url="https://en.wikipedia.org/wiki?curid=665" title="A Modest Proposal">
A Modest Proposal

A Modest Proposal for Preventing the Children of Poor People From Being a Burthen to Their Parents or Country, and for Making Them Beneficial to the Publick, commonly referred to as A Modest Proposal, is a Juvenalian satirical essay written and published anonymously by Jonathan Swift in 1729. Swift suggests that the impoverished Irish might ease their economic troubles by selling their children as food for rich gentlemen and ladies. This satirical hyperbole mocks heartless attitudes towards the poor, as well as British policy toward the Irish in general.
In English writing, the phrase "a modest proposal" is now conventionally an allusion to this style of straight-faced satire.
<h2>Details.</h2>
Swift goes to great lengths to support his argument, including a list of possible preparation styles for the children, and calculations showing the financial benefits of his suggestion. He uses methods of argument throughout his essay which lampoon the then-influential William Petty and the social engineering popular among followers of Francis Bacon. These lampoons include appealing to the authority of "a very knowing American of my acquaintance in London" and "the famous Psalmanazar, a native of the island Formosa" (who had already confessed to "not" being from Formosa in 1706). This essay is widely held to be one of the greatest examples of sustained irony in the history of the English language. Much of its shock value derives from the fact that the first portion of the essay describes the plight of starving beggars in Ireland, so that the reader is unprepared for the surprise of Swift's solution when he states, "A young healthy child well nursed, is, at a year old, a most delicious nourishing and wholesome food, whether stewed, roasted, baked, or boiled; and I make no doubt that it will equally serve in a fricassee, or a ragout."
In the tradition of Roman satire, Swift introduces the reforms he is actually suggesting by paralipsis:
<h2>Population solutions.</h2>
George Wittkowsky argued that Swift’s main target in "A Modest Proposal" was not the conditions in Ireland, but rather the can-do spirit of the times that led people to devise a number of illogical schemes that would purportedly solve social and economic ills. Swift was especially insulted by projects that tried to fix population and labour issues with a simple cure-all solution. A memorable example of these sorts of schemes "involved the idea of running the poor through a joint-stock company". In response, Swift's "Modest Proposal" was "a burlesque of projects concerning the poor" that were in vogue during the early 18th century.
"A Modest Proposal" also targets the calculating way people perceived the poor in designing their projects. The pamphlet targets reformers who "regard people as commodities". In the piece, Swift adopts the "technique of a political arithmetician" to show the utter ridiculousness of trying to prove any proposal with dispassionate statistics.
Critics differ about Swift's intentions in using this faux-mathematical philosophy. Edmund Wilson argues that statistically "the logic of the 'Modest proposal' can be compared with defense of crime (arrogated to Marx) in which he argues that crime takes care of the superfluous population". Wittkowsky counters that Swift's satiric use of statistical analysis is an effort to enhance his satire that "springs from a spirit of bitter mockery, not from the delight in calculations for their own sake".
<h2>Rhetoric.</h2>
Charles K. Smith argues that Swift's rhetorical style persuades the reader to detest the speaker and pity the Irish. Swift's specific strategy is twofold, using a "trap" to create sympathy for the Irish and a dislike of the narrator who, in the span of one sentence, "details vividly and with rhetorical emphasis the grinding poverty" but feels emotion solely for members of his own class. Swift's use of gripping details of poverty and his narrator's cool approach towards them create "two opposing points of view" that "alienate the reader, perhaps unconsciously, from a narrator who can view with 'melancholy' detachment a subject that Swift has directed us, rhetorically, to see in a much less detached way."
Swift has his proposer further degrade the Irish by using language ordinarily reserved for animals. Lewis argues that the speaker uses "the vocabulary of animal husbandry" to describe the Irish. Once the children have been commodified, Swift's rhetoric can easily turn "people into animals, then meat, and from meat, logically, into tonnage worth a price per pound".
Swift uses the proposer's serious tone to highlight the absurdity of his proposal. In making his argument, the speaker uses the conventional, textbook-approved order of argument from Swift's time (which was derived from the Latin rhetorician Quintilian). The contrast between the "careful control against the almost inconceivable perversion of his scheme" and "the ridiculousness of the proposal" create a situation in which the reader has "to consider just what perverted values and assumptions would allow such a diligent, thoughtful, and conventional man to propose so perverse a plan".
<h2>Influences.</h2>
Scholars have speculated about which earlier works Swift may have had in mind when he wrote "A Modest Proposal".
<h3>Tertullian's "Apology".</h3>
James Johnson argued that "A Modest Proposal" was largely influenced and inspired by Tertullian's "Apology": a satirical attack against early Roman persecution of Christianity. James William Johnson believes that Swift saw major similarities between the two situations. Johnson notes Swift's obvious affinity for Tertullian and the bold stylistic and structural similarities between the works "A Modest Proposal" and "Apology". In structure, Johnson points out the same central theme, that of cannibalism and the eating of babies as well as the same final argument, that "human depravity is such that men will attempt to justify their own cruelty by accusing their victims of being lower than human." Stylistically, Swift and Tertullian share the same command of sarcasm and language. In agreement with Johnson, Donald C. Baker points out the similarity between both authors' tones and use of irony. Baker notes the uncanny way that both authors imply an ironic "justification by ownership" over the subject of sacrificing children—Tertullian while attacking pagan parents, and Swift while attacking the English mistreatment of the Irish poor.
<h3>Defoe's "The Generous Projector".</h3>
It has also been argued that "A Modest Proposal" was, at least in part, a response to the 1728 essay "The Generous Projector or, A Friendly Proposal to Prevent Murder and Other Enormous Abuses, By Erecting an Hospital for Foundlings and Bastard Children" by Swift's rival Daniel Defoe.
<h3>Mandevilles Modest Defence of Publick Stews.</h3>
Bernard Mandeville's Modest Defence of Publick Stews asked to introduce public and state controlled bordellos. The 1726 paper acknowledges women's interests and - while not being a complete satirical text - has been discussed as well as an inspiration for Jonatan Swifts title. Mandeville had become famous with the Fable of The Bees and deliberations on private vices and public benefits in 1705 already.
<h2>Economic themes.</h2>
Robert Phiddian's article "Have you eaten yet? The Reader in A Modest Proposal" focuses on two aspects of "A Modest Proposal": the voice of Swift and the voice of the Proposer. Phiddian stresses that a reader of the pamphlet must learn to distinguish between the satiric voice of Jonathan Swift and the apparent economic projections of the Proposer. He reminds readers that "there is a gap between the narrator's meaning and the text's, and that a moral-political argument is being carried out by means of parody".
While Swift's proposal is obviously not a serious economic proposal, George Wittkowsky, author of "Swift's Modest Proposal: The Biography of an Early Georgian Pamphlet", argues that to understand the piece fully, it is important to understand the economics of Swift’s time. Wittowsky argues that not enough critics have taken the time to focus directly on the mercantilism and theories of labour in 18th century England. "[I]f one regards the "Modest Proposal" simply as a criticism of condition, about all one can say is that conditions were bad and that Swift's irony brilliantly underscored this fact".
<h3>"People are the riches of a nation".</h3>
At the start of a new industrial age in the 18th century, it was believed that "people are the riches of the nation", and there was a general faith in an economy that paid its workers low wages because high wages meant workers would work less. Furthermore, "in the mercantilist view no child was too young to go into industry". In those times, the "somewhat more humane attitudes of an earlier day had all but disappeared and the laborer had come to be regarded as a commodity".
Louis A. Landa presents Swift's "A Modest Proposal" as a critique of the popular and unjustified maxim of mercantilism in the 18th century that "people are the riches of a nation". Swift presents the dire state of Ireland and shows that mere population itself, in Ireland's case, did not always mean greater wealth and economy. The uncontrolled maxim fails to take into account that a person who does not produce in an economic or political way makes a country poorer, not richer. Swift also recognises the implications of such a fact in making mercantilist philosophy a paradox: the wealth of a country is based on the poverty of the majority of its citizens. Swift however, Landa argues, is not merely criticising economic maxims but also addressing the fact that England was denying Irish citizens their natural rights and dehumanising them by viewing them as a mere commodity.
<h2>Modern usage.</h2>
"A Modest Proposal" is included in many literature programs as an example of early modern western satire. It also serves as an exceptional introduction to the concept and use of argumentative language, lending itself well to secondary and post-secondary essay courses. Outside of the realm of English studies, "A Modest Proposal" is a relevant piece included in many comparative and global literature and history courses, as well as those of numerous other disciplines in the arts, humanities, and even the social sciences.
The essay has been emulated many times. In his book "A Modest Proposal" (1984), evangelical author Frank Schaeffer emulated Swift's work in social conservative polemic against abortion and euthanasia in a future dystopia that advocated recycling of aborted embryos and fetuses, as well as some disabled infants with compound intellectual, physical and physiological difficulties. (Such Baby Doe Rules cases were then a major concern of the pro-life movement of the early 1980s, which viewed selective treatment of those infants as disability discrimination.) In his book "A Modest Proposal for America" (2013), statistician Howard Friedman opens with a satirical reflection of the extreme drive to fiscal stability by ultra-conservatives.
A Modest Video Game Proposal is the title of an open letter sent by activist/former attorney Jack Thompson on October 10, 2005. He proposed that, if someone could "create, manufacture, distribute, and sell a video game in 2006" that allows players to play the scenario he has written, in which the character kills video game developers.
Hunter S. Thompson's "Fear and Loathing in America: The Brutal Odyssey of an Outlaw Journalist", which contains hundreds of private letters written by Thompson over the years, contains a letter in which he uses "A Modest Proposal"'s satire technique against the Vietnam War. Thompson writes a letter to a local Aspen newspaper informing them that, on Christmas Eve, he was going to use napalm to burn a number of dogs and hopefully any humans they find. This letter protests the burning of Vietnamese people occurring overseas.

</doc>
<doc id="666" url="https://en.wikipedia.org/wiki?curid=666" title="Alkali metal">
Alkali metal

The alkali metals are a group (column) in the periodic table consisting of the chemical elements lithium (Li), sodium (Na), potassium (K), rubidium (Rb), caesium (Cs), and francium (Fr). This group lies in the s-block of the periodic table of elements as all alkali metals have their outermost electron in an s-orbital: this shared electron configuration results in them having very similar characteristic properties. Indeed, the alkali metals provide the best example of group trends in properties in the periodic table, with elements exhibiting well-characterised homologous behaviour.
The alkali metals are all shiny, soft, highly reactive metals at standard temperature and pressure and readily lose their outermost electron to form cations with charge +1. They can all be cut easily with a knife due to their softness, exposing a shiny surface that tarnishes rapidly in air due to oxidation by atmospheric moisture and oxygen. Because of their high reactivity, they must be stored under oil to prevent reaction with air, and are found naturally only in salts and never as the free elements. Caesium, the fifth alkali metal, is the most reactive of all the metals. In the modern IUPAC nomenclature, the alkali metals comprise the group 1 elements, excluding hydrogen (H), which is nominally a group 1 element but not normally considered to be an alkali metal as it rarely exhibits behaviour comparable to that of the alkali metals. All the alkali metals react with water, with the heavier alkali metals reacting more vigorously than the lighter ones.
All of the discovered alkali metals occur in nature: in order of abundance, sodium is the most abundant, followed by potassium, lithium, rubidium, caesium, and finally francium, which is very rare due to its extremely high radioactivity; francium occurs only in the minutest traces in nature as an intermediate step in some obscure side branches of the natural decay chains. Experiments have been conducted to attempt the synthesis of ununennium (Uue), which is likely to be the next member of the group, but they have all met with failure. However, ununennium may not be an alkali metal due to relativistic effects, which are predicted to have a large influence on the chemical properties of superheavy elements; even if it does turn out to be an alkali metal, it is predicted to have some differences in physical and chemical properties from its lighter homologues.
Most alkali metals have many different applications. One of the best-known applications of the pure elements the use of rubidium and caesium in atomic clocks, of which caesium atomic clocks are the most accurate and precise representation of time. A common application of the compounds of sodium is the sodium-vapour lamp, which emits very efficient light. Table salt, or sodium chloride, has been used since antiquity. Sodium and potassium are also essential elements, having major biological roles as electrolytes, and although the other alkali metals are not essential, they also have various effects on the body, both beneficial and harmful.
<h2>Properties.</h2>
<h3>Physical and chemical.</h3>
The physical and chemical properties of the alkali metals can be readily explained by their having an ns valence electron configuration, which results in weak metallic bonding. Hence, all the alkali metals are soft and have low densities, melting and boiling points, as well as heats of sublimation, vaporisation, and dissociation. They all crystallise in the body-centered cubic crystal structure, and have distinctive flame colours because their outer s electron is very easily excited. The ns configuration also results in the alkali metals having very large atomic and ionic radii, as well as very high thermal and electrical conductivity. Their chemistry is dominated by the loss of their lone valence electron in the outermost s-orbital to form the +1 oxidation state, due to the ease of ionising this electron and the very high second ionisation energy. Most of the chemistry has been observed only for the first five members of the group. The chemistry of francium is not well established due to its extreme radioactivity; thus, the presentation of its properties here is limited. What little is known about francium shows that it is very close in behaviour to caesium, as expected. The physical properties of francium are even sketchier because the bulk element has never been observed; hence any data that may be found in the literature are certainly speculative extrapolations.
The alkali metals are more similar to each other than the elements in any other group are to each other. Indeed, the similarity is so great that it is quite difficult to separate potassium, rubidium, and caesium, due to their similar ionic radii; lithium and sodium are more distinct. For instance, when moving down the table, all known alkali metals show increasing atomic radius, decreasing electronegativity, increasing reactivity, and decreasing melting and boiling points as well as heats of fusion and vaporisation. In general, their densities increase when moving down the table, with the exception that potassium is less dense than sodium. One of the very few properties of the alkali metals that does not display a very smooth trend is their reduction potentials: lithium's value is anomalous, being more negative than the others. This is because the Li ion has a very high hydration energy in the gas phase: though the lithium ion disrupts the structure of water significantly, causing a higher change in entropy, this high hydration energy is enough to make the reduction potentials indicate it as being the most electropositive alkali metal, despite the difficulty of ionising it in the gas phase.
The stable alkali metals are all silver-coloured metals except for caesium, which has a pale golden tint: it is one of only three metals that are clearly coloured (the other two being copper and gold). Additionally, the heavy alkaline earth metals calcium, strontium, and barium, as well as the divalent lanthanides europium and ytterbium, are pale yellow, though the colour is much less prominent than it is for caesium. Their lustre tarnishes rapidly in air due to oxidation. They all crystallise in the body-centered cubic crystal structure, and have distinctive flame colours because their outer s electron is very easily excited. Indeed, these flame test colours are the most common way of identifying them since all their salts with common ions are soluble.
All the alkali metals are highly reactive and are never found in elemental forms in nature. Because of this, they are usually stored in mineral oil or kerosene (paraffin oil). They react aggressively with the halogens to form the alkali metal halides, which are white ionic crystalline compounds that are all soluble in water except lithium fluoride (LiF). The alkali metals also react with water to form strongly alkaline hydroxides and thus should be handled with great care. The heavier alkali metals react more vigorously than the lighter ones; for example, when dropped into water, caesium produces a larger explosion than potassium if the same number of moles of each metal is used. The alkali metals have the lowest first ionisation energies in their respective periods of the periodic table because of their low effective nuclear charge and the ability to attain a noble gas configuration by losing just one electron. Not only do the alkali metals react with water, but also with proton donors like alcohols and phenols, gaseous ammonia, and alkynes, the last demonstrating the phenomenal degree of their reactivity. Their great power as reducing agents makes them very useful in liberating other metals from their oxides or halides.
The second ionisation energy of all of the alkali metals is very high as it is in a full shell that is also closer to the nucleus; thus, they almost always lose a single electron, forming cations. The alkalides are an exception: they are unstable compounds which contain alkali metals in a −1 oxidation state, which is very unusual as before the discovery of the alkalides, the alkali metals were not expected to be able to form anions and were thought to be able to appear in salts only as cations. The alkalide anions have filled s-subshells, which gives them enough stability to exist. All the stable alkali metals except lithium are known to be able to form alkalides, and the alkalides have much theoretical interest due to their unusual stoichiometry and low ionisation potentials. Alkalides are chemically similar to the electrides, which are salts with trapped electrons acting as anions. A particularly striking example of an alkalide is "inverse sodium hydride", HNa (both ions being complexed), as opposed to the usual sodium hydride, NaH: it is unstable in isolation, due to its high energy resulting from the displacement of two electrons from hydrogen to sodium, although several derivatives are predicted to be metastable or stable.
In aqueous solution, the alkali metal ions form aqua ions of the formula [M(HO)], where "n" is the solvation number. Their coordination numbers and shapes agree well with those expected from their ionic radii. In aqueous solution the water molecules directly attached to the metal ion are said to belong to the first coordination sphere, also known as the first, or primary, solvation shell. The bond between a water molecule and the metal ion is a dative covalent bond, with the oxygen atom donating both electrons to the bond. Each coordinated water molecule may be attached by hydrogen bonds to other water molecules. The latter are said to reside in the second coordination sphere. However, for the alkali metal cations, the second coordination sphere is not well-defined as the +1 charge on the cation is not high enough to polarise the water molecules in the primary solvation shell enough for them to form strong hydrogen bonds with those in the second coordination sphere, producing a more stable entity. The solvation number for Li has been experimentally determined to be 4, forming the tetrahedral [Li(HO)]: while solvation numbers of 3 to 6 have been found for lithium aqua ions, solvation numbers less than 4 may be the result of the formation of contact ion-pairs, and the higher solvation numbers may be interpreted in terms of water molecules that approach [Li(HO)] through a face of the tetrahedron, though molecular dynamic simulations may indicate the existence of an octahedral hexaaqua ion. There are also probably six water molecules in the primary solvation sphere of the sodium ion, forming the octahedral [Na(HO)] ion. While it was previously thought that the heavier alkali metals also formed octahedral hexaaqua ions, it has since been found that potassium and rubidium probably form the [K(HO)] and [Rb(HO)] ions, which have the square antiprismatic structure, and that caesium forms the 12-coordinate [Cs(HO)] ion.
<h4>Lithium.</h4>
The chemistry of lithium shows several differences from that of the rest of the group as the small Li cation polarises anions and gives its compounds a more covalent character. Lithium and magnesium have a diagonal relationship due to their similar atomic radii, so that they show some similarities. For example, lithium forms a stable nitride, a property common among all the alkaline earth metals (magnesium's group) but unique among the alkali metals. In addition, among their respective groups, only lithium and magnesium form organometallic compounds with significant covalent character (e.g. LiMe and MgMe).
Lithium fluoride is the only alkali metal halide that is poorly soluble in water, and lithium hydroxide is the only alkali metal hydroxide that is not deliquescent. Conversely, lithium perchlorate and other lithium salts with large anions that cannot be polarised are much more stable than the analogous compounds of the other alkali metals, probably because Li has a high solvation energy. This effect also means that most simple lithium salts are commonly encountered in hydrated form, because the anhydrous forms are extremely hygroscopic: this allows salts like lithium chloride and lithium bromide to be used in dehumidifiers and air-conditioners.
<h4>Francium.</h4>
Francium is also predicted to show some differences due to its high atomic weight, causing its electrons to travel at considerable fractions of the speed of light and thus making relativistic effects more prominent. In contrast to the trend of decreasing electronegativities and ionisation energies of the alkali metals, francium's electronegativity and ionisation energy are predicted to be higher than caesium's due to the relativistic stabilisation of the 7s electrons; also, its atomic radius is expected to be abnormally low. Thus, contrary to expectation, caesium is the most reactive of the alkali metals, not francium. All known physical properties of francium also deviate from the clear trends going from lithium to caesium, such as the first ionisation energy, electron affinity, and anion polarisability, though due to the paucity of known data about francium many sources give extrapolated values, ignoring that relativistic effects make the trend from lithium to caesium become inapplicable at francium. Some of the few properties of francium that have been predicted taking relativity into account are the electron affinity (47.2 kJ/mol) and the enthalpy of dissociation of the Fr molecule (42.1 kJ/mol). The CsFr molecule is polarised as CsFr, showing that the 7s subshell of francium is much more strongly affected by relativistic effects than the 6s subshell of caesium. Additionally, francium superoxide (FrO) is expected to have significant covalent character, unlike the other alkali metal superoxides, because of bonding contributions from the 6p electrons of francium.
<h3>Nuclear.</h3>
All the alkali metals have odd atomic numbers; hence, their isotopes must be either odd–odd (both proton and neutron number are odd) or odd–even (proton number is odd, but neutron number is even). Odd–odd nuclei have even mass numbers, whereas odd–even nuclei have odd mass numbers. Odd–odd primordial nuclides are rare because most odd–odd nuclei are highly unstable with respect to beta decay, because the decay products are even–even, and are therefore more strongly bound, due to nuclear pairing effects.
Due to the great rarity of odd–odd nuclei, almost all the primordial isotopes of the alkali metals are odd–even (the exceptions being the light stable isotope lithium-6 and the long-lived radioisotope potassium-40). For a given odd mass number, there can be only a single beta-stable nuclide, since there is not a difference in binding energy between even–odd and odd–even comparable to that between even–even and odd–odd, leaving other nuclides of the same mass number (isobars) free to beta decay toward the lowest-mass nuclide. An effect of the instability of an odd number of either type of nucleons is that odd-numbered elements, such as the alkali metals, tend to have fewer stable isotopes than even-numbered elements. Of the 26 monoisotopic elements that have only a single stable isotope, all but one have an odd atomic number and all but one also have an even number of neutrons. Beryllium is the single exception to both rules, due to its low atomic number.
All of the alkali metals except lithium and caesium have at least one naturally occurring radioisotope: sodium-22 and sodium-24 are trace radioisotopes produced cosmogenically, potassium-40 and rubidium-87 have very long half-lives and thus occur naturally, and all isotopes of francium are radioactive. Caesium was also thought to be radioactive in the early 20th century, although it has no naturally occurring radioisotopes. (Francium had not been discovered yet at that time.) The natural long-lived radioisotope of potassium, potassium-40, makes up about 0.012% of natural potassium, and thus natural potassium is weakly radioactive. This natural radioactivity became a basis for a mistaken claim of the discovery for element 87 (the next alkali metal after caesium) in 1925. Natural rubidium is similarly slightly radioactive, with 27.83% being the long-lived radioisotope rubidium-87.
Caesium-137, with a half-life of 30.17 years, is one of the two principal medium-lived fission products, along with strontium-90, which are responsible for most of the radioactivity of spent nuclear fuel after several years of cooling, up to several hundred years after use. It constitutes most of the radioactivity still left from the Chernobyl accident. Caesium-137 undergoes high-energy beta decay and eventually becomes stable barium-137. It is a strong emitter of gamma radiation. Caesium-137 has a very low rate of neutron capture and cannot be feasibly disposed of in this way, but must be allowed to decay. Caesium-137 has been used as a tracer in hydrologic studies, analogous to the use of tritium. Small amounts of caesium-134 and caesium-137 were released into the environment during nearly all nuclear weapon tests and some nuclear accidents, most notably the Goiânia accident and the Chernobyl disaster. As of 2005, caesium-137 is the principal source of radiation in the zone of alienation around the Chernobyl nuclear power plant. Its chemical properties as one of the alkali metals make it one of most problematic of the short-to-medium-lifetime fission products because it easily moves and spreads in nature due to the high water solubility of its salts, and is taken up by the body, which mistakes it for its essential congeners sodium and potassium.
<h2>Periodic trends.</h2>
The alkali metals are more similar to each other than the elements in any other group are to each other. For instance, when moving down the table, all known alkali metals show increasing atomic radius, decreasing electronegativity, increasing reactivity, and decreasing melting and boiling points as well as heats of fusion and vaporisation. In general, their densities increase when moving down the table, with the exception that potassium is less dense than sodium.
<h3>Atomic and ionic radii.</h3>
The atomic radii of the alkali metals increase going down the group. Because of the shielding effect, when an atom has more than one electron shell, each electron feels electric repulsion from the other electrons as well as electric attraction from the nucleus. In the alkali metals, the outermost electron only feels a net charge of +1, as some of the nuclear charge (which is equal to the atomic number) is cancelled by the inner electrons; the number of inner electrons of an alkali metal is always one less than the nuclear charge. Therefore, the only factor which affects the atomic radius of the alkali metals is the number of electron shells. Since this number increases down the group, the atomic radius must also increase down the group.
The ionic radii of the alkali metals are much smaller than their atomic radii. This is because the outermost electron of the alkali metals is in a different electron shell than the inner electrons, and thus when it is removed the resulting atom has one fewer electron shell and is smaller. Additionally, the effective nuclear charge has increased, and thus the electrons are attracted more strongly towards the nucleus and the ionic radius decreases.
<h3>First ionisation energy.</h3>
The first ionisation energy of an element or molecule is the energy required to move the most loosely held electron from one mole of gaseous atoms of the element or molecules to form one mole of gaseous ions with electric charge +1. The factors affecting the first ionisation energy are the nuclear charge, the amount of shielding by the inner electrons and the distance from the most loosely held electron from the nucleus, which is always an outer electron in main group elements. The first two factors change the effective nuclear charge the most loosely held electron feels. Since the outermost electron of alkali metals always feels the same effective nuclear charge (+1), the only factor which affects the first ionisation energy is the distance from the outermost electron to the nucleus. Since this distance increases down the group, the outermost electron feels less attraction from the nucleus and thus the first ionisation energy decreases. (This trend is broken in francium due to the relativistic stabilisation and contraction of the 7s orbital, bringing francium's valence electron closer to the nucleus than would be expected from non-relativistic calculations. This makes francium's outermost electron feel more attraction from the nucleus, increasing its first ionisation energy slightly beyond that of caesium.)
The second ionisation energy of the alkali metals is much higher than the first as the second-most loosely held electron is part of a fully filled electron shell and is thus difficult to remove.
<h3>Reactivity.</h3>
The reactivities of the alkali metals increase going down the group. This is the result of a combination of two factors: the first ionisation energies and atomisation energies of the alkali metals. Because the first ionisation energy of the alkali metals decreases down the group, it is easier for the outermost electron to be removed from the atom and participate in chemical reactions, thus increasing reactivity down the group. The atomisation energy measures the strength of the metallic bond of an element, which falls down the group as the atoms increase in radius and thus the metallic bond must increase in length, making the delocalised electrons further away from the attraction of the nuclei of the heavier alkali metals. Adding the atomisation and first ionisation energies gives a quantity closely related to (but not equal to) the activation energy of the reaction of an alkali metal with another substance. This quantity decreases going down the group, and so does the activation energy; thus, chemical reactions can occur faster and the reactivity increases down the group.
<h3>Electronegativity.</h3>
Electronegativity is a chemical property that describes the tendency of an atom or a functional group to attract electrons (or electron density) towards itself. If the bond between sodium and chlorine in sodium chloride were covalent, the pair of shared electrons would be attracted to the chlorine because the effective nuclear charge on the outer electrons is +7 in chlorine but is only +1 in sodium. The electron pair is attracted so close to the chlorine atom that they are practically transferred to the chlorine atom (an ionic bond). However, if the sodium atom was replaced by a lithium atom, the electrons will not be attracted as close to the chlorine atom as before because the lithium atom is smaller, making the electron pair more strongly attracted to the closer effective nuclear charge from lithium. Hence, the larger alkali metal atoms (further down the group) will be less electronegative as the bonding pair is less strongly attracted towards them. As mentioned previously, francium is expected to be an exception.
Because of the higher electronegativity of lithium, some of its compounds have a more covalent character. For example, lithium iodide (LiI) will dissolve in organic solvents, a property of most covalent compounds. Lithium fluoride (LiF) is the only alkali halide that is not soluble in water, and lithium hydroxide (LiOH) is the only alkali metal hydroxide that is not deliquescent.
<h3>Melting and boiling points.</h3>
The melting point of a substance is the point where it changes state from solid to liquid while the boiling point of a substance (in liquid state) is the point where the vapour pressure of the liquid equals the environmental pressure surrounding the liquid and all the liquid changes state to gas. As a metal is heated to its melting point, the metallic bonds keeping the atoms in place weaken so that the atoms can move around, and the metallic bonds eventually break completely at the metal's boiling point. Therefore, the falling melting and boiling points of the alkali metals indicate that the strength of the metallic bonds of the alkali metals decreases down the group. This is because metal atoms are held together by the electromagnetic attraction from the positive ions to the delocalised electrons. As the atoms increase in size going down the group (because their atomic radius increases), the nuclei of the ions move further away from the delocalised electrons and hence the metallic bond becomes weaker so that the metal can more easily melt and boil, thus lowering the melting and boiling points. (The increased nuclear charge is not a relevant factor due to the shielding effect.)
<h3>Density.</h3>
The alkali metals all have the same crystal structure (body-centred cubic) and thus the only relevant factors are the number of atoms that can fit into a certain volume and the mass of one of the atoms, since density is defined as mass per unit volume. The first factor depends on the volume of the atom and thus the atomic radius, which increases going down the group; thus, the volume of an alkali metal atom increases going down the group. The mass of an alkali metal atom also increases going down the group. Thus, the trend for the densities of the alkali metals depends on their atomic weights and atomic radii; if figures for these two factors are known, the ratios between the densities of the alkali metals can then be calculated. The resultant trend is that the densities of the alkali metals increase down the table, with an exception at potassium. Due to having the lowest atomic weight of all the elements in their period and having the largest atomic radius for their periods, the alkali metals are the least dense metals in the periodic table. Lithium, sodium, and potassium are the only three metals in the periodic table that are less dense than water: in fact, lithium is the least dense known solid at room temperature.
<h2>Compounds.</h2>
The alkali metals form complete series of compounds with all usually encountered anions, which well illustrate group trends. These compounds can be described as involving the alkali metals losing electrons to acceptor species and forming monopositive ions. This description is most accurate for alkali halides and becomes less and less accurate as cationic and anionic charge increase, and as the anion becomes larger and more polarisable. For instance, ionic bonding gives way to metallic bonding along the series NaCl, NaO, NaS, NaP, NaAs, NaSb, NaBi, Na.
<h3>Hydroxides.</h3>
All the alkali metals react vigorously or explosively with cold water, producing an aqueous solution of a strongly basic alkali metal hydroxide and releasing hydrogen gas. This reaction becomes more vigorous going down the group: lithium reacts steadily with effervescence, but sodium and potassium can ignite and rubidium and caesium sink in water and generate hydrogen gas so rapidly that shock waves form in the water that may shatter glass containers. When an alkali metal is dropped into water, it produces an explosion, of which there are two separate stages. The metal reacts with the water first, breaking the hydrogen bonds in the water and producing hydrogen gas; this takes place faster for the more reactive heavier alkali metals. Second, the heat generated by the first part of the reaction often ignites the hydrogen gas, causing it to burn explosively into the surrounding air. This secondary hydrogen gas explosion produces the visible flame above the bowl of water, lake or other body of water, not the initial reaction of the metal with water (which tends to happen mostly under water). The alkali metal hydroxides are the most basic known hydroxides.
Recent research has suggested that the explosive behavior of alkali metals in water is driven by a Coulomb explosion rather than solely by rapid generation of hydrogen itself. All alkali metals melt as a part of the reaction with water. Water molecules ionise the bare metallic surface of the liquid metal, leaving a positively charged metal surface and negatively charged water ions. The attraction between the charged metal and water ions will rapidly increase the surface area, causing an exponential increase of ionisation. When the repulsive forces within the liquid metal surface exceeds the forces of the surface tension, it vigorously explodes.
The hydroxides themselves are the most basic hydroxides known, reacting with acids to give salts and with alcohols to give oligomeric alkoxides. They easily react with carbon dioxide to form carbonates or bicarbonates, or with hydrogen sulfide to form sulfides or bisulfides, and may be used to separate thiols from petroleum. They react with amphoteric oxides: for example, the oxides of aluminium, zinc, tin, and lead react with the alkali metal hydroxides to give aluminates, zincates, stannates, and plumbates. Silicon dioxide is acidic, and thus the alkali metal hydroxides can also attack silicate glass.
<h3>Intermetallic compounds.</h3>
The alkali metals form many intermetallic compounds with each other and the elements from groups 2 to 13 in the periodic table of varying stoichiometries, such as the sodium amalgams with mercury, including NaHg and NaHg. Some of these have ionic characteristics: taking the alloys with gold, the most electronegative of metals, as an example, NaAu and KAu are metallic, but RbAu and CsAu are semiconductors. NaK is an alloy of sodium and potassium that is very useful because it is liquid at room temperature, although precautions must be taken due to its extreme reactivity towards water and air. The eutectic mixture melts at −12.6 °C. An alloy of 41% caesium, 47% sodium, and 12% potassium has the lowest known melting point of any metal or alloy, −78 °C.
<h3>Compounds with the group 13 elements.</h3>
The intermetallic compounds of the alkali metals with the heavier group 13 elements (aluminium, gallium, indium, and thallium), such as NaTl, are poor conductors or semiconductors, unlike the normal alloys with the preceding elements, implying that the alkali metal involved has lost an electron to the Zintl anions involved. Nevertheless, while the elements in group 14 and beyond tend to form discrete anionic clusters, group 13 elements tend to form polymeric ions with the alkali metal cations located between the giant ionic lattice. For example, NaTl consists of a polymeric anion (—Tl—) with a covalent diamond cubic structure with Na ions located between the anionic lattice. The larger alkali metals cannot fit similarly into an anionic lattice and tend to force the heavier group 13 elements to form anionic clusters.
Boron is a special case, being the only nonmetal in group 13. The alkali metal borides tend to be boron-rich, involving appreciable boron–boron bonding involving deltahedral structures, and are thermally unstable due to the alkali metals having a very high vapour pressure at elevated temperatures. This makes direct synthesis problematic because the alkali metals do not react with boron below 700 °C, and thus this must be accomplished in sealed containers with the alkali metal in excess. Furthermore, exceptionally in this group, reactivity with boron decreases down the group: lithium reacts completely at 700 °C, but sodium at 900 °C and potassium not until 1200 °C, and the reaction is instantaneous for lithium but takes hours for potassium. Rubidium and caesium borides have not even been characterised. Various phases are known, such as LiB, NaB, NaB, and KB. Under high pressure the boron–boron bonding in the lithium borides changes from following Wade's rules to forming Zintl anions like the rest of group 13.
<h3>Compounds with the group 14 elements.</h3>
Lithium and sodium react with carbon to form acetylides, LiC and NaC, which can also be obtained by reaction of the metal with acetylene. Potassium, rubidium, and caesium react with graphite; their atoms are intercalated between the hexagonal graphite layers, forming graphite intercalation compounds of formulae MC (dark grey, almost black), MC (dark grey, almost black), MC (blue), MC (steel blue), and MC (bronze) (M = K, Rb, or Cs). These compounds are over 200 times more electrically conductive than pure graphite, suggesting that the valence electron of the alkali metal is transferred to the graphite layers (e.g. ). Upon heating of KC, the elimination of potassium atoms results in the conversion in sequence to KC, KC, KC and finally KC. KC is a very strong reducing agent and is pyrophoric and explodes on contact with water. While the large alkali metals (K, Rb, and Cs) initially form MC, the smaller ones initially form MC, and indeed they require reaction of the metals with graphite at high temperatures around 500 °C to form. Apart from this, the alkali metals are such strong reducing agents that they can even reduce buckminsterfullerene to produce solid fullerides MC; sodium, potassium, rubidium, and caesium can form fullerides where "n" = 2, 3, 4, or 6, and rubidium and caesium additionally can achieve "n" = 1.
When the alkali metals react with the heavier elements in the carbon group (silicon, germanium, tin, and lead), ionic substances with cage-like structures are formed, such as the silicides MSi (M = K, Rb, or Cs), which contains M and tetrahedral ions. The chemistry of alkali metal germanides, involving the germanide ion Ge and other cluster (Zintl) ions such as , , , and [(Ge)], is largely analogous to that of the corresponding silicides. Alkali metal stannides are mostly ionic, sometimes with the stannide ion (Sn), and sometimes with more complex Zintl ions such as , which appears in tetrapotassium nonastannide (KSn). The monatomic plumbide ion (Pb) is unknown, and indeed its formation is predicted to be energetically unfavourable; alkali metal plumbides have complex Zintl ions, such as . These alkali metal germanides, stannides, and plumbides may be produced by reducing germanium, tin, and lead with sodium metal in liquid ammonia.
<h3>Nitrides and pnictides.</h3>
Lithium, the lightest of the alkali metals, is the only alkali metal which reacts with nitrogen at standard conditions, and its nitride is the only stable alkali metal nitride. Nitrogen is an unreactive gas because breaking the strong triple bond in the dinitrogen molecule (N) requires a lot of energy. The formation of an alkali metal nitride would consume the ionisation energy of the alkali metal (forming M ions), the energy required to break the triple bond in N and the formation of N ions, and all the energy released from the formation of an alkali metal nitride is from the lattice energy of the alkali metal nitride. The lattice energy is maximised with small, highly charged ions; the alkali metals do not form highly charged ions, only forming ions with a charge of +1, so only lithium, the smallest alkali metal, can release enough lattice energy to make the reaction with nitrogen exothermic, forming lithium nitride. The reactions of the other alkali metals with nitrogen would not release enough lattice energy and would thus be endothermic, so they do not form nitrides at standard conditions. Sodium nitride (NaN) and potassium nitride (KN), while existing, are extremely unstable, being prone to decomposing back into their constituent elements, and cannot be produced by reacting the elements with each other at standard conditions. Steric hindrance forbids the existence of rubidium or caesium nitride. However, sodium and potassium form colourless azide salts involving the linear anion; due to the large size of the alkali metal cations, they are thermally stable enough to be able to melt before decomposing.
All the alkali metals react readily with phosphorus and arsenic to form phosphides and arsenides with the formula MPn (where M represents an alkali metal and Pn represents a pnictogen – phosphorus, arsenic, antimony, or bismuth). This is due to the greater size of the P and As ions, so that less lattice energy needs to be released for the salts to form. These are not the only phosphides and arsenides of the alkali metals: for example, potassium has nine different known phosphides, with formulae KP, KP, KP, KP, KP, KP, KP, KP, and KP. While most metals form arsenides, only the alkali and alkaline earth metals form mostly ionic arsenides. The structure of NaAs is complex with unusually short Na–Na distances of 328–330 pm which are shorter than in sodium metal, and this indicates that even with these electropositive metals the bonding cannot be straightforwardly ionic. Other alkali metal arsenides not conforming to the formula MAs are known, such as LiAs, which has a metallic lustre and electrical conductivity indicating the presence of some metallic bonding. The antimonides are unstable and reactive as the Sb ion is a strong reducing agent; reaction of them with acids form the toxic and unstable gas stibine (SbH). Indeed, they have some metallic properties, and the alkali metal antimonides of stoichiometry MSb involve antimony atoms bonded in a spiral Zintl structure. Bismuthides are not even wholly ionic; they are intermetallic compounds containing partially metallic and partially ionic bonds.
<h3>Oxides and chalcogenides.</h3>
All the alkali metals react vigorously with oxygen at standard conditions. They form various types of oxides, such as simple oxides (containing the O ion), peroxides (containing the ion, where there is a single bond between the two oxygen atoms), superoxides (containing the ion), and many others. Lithium burns in air to form lithium oxide, but sodium reacts with oxygen to form a mixture of sodium oxide and sodium peroxide. Potassium forms a mixture of potassium peroxide and potassium superoxide, while rubidium and caesium form the superoxide exclusively. Their reactivity increases going down the group: while lithium, sodium and potassium merely burn in air, rubidium and caesium are pyrophoric (spontaneously catch fire in air).
The smaller alkali metals tend to polarise the larger anions (the peroxide and superoxide) due to their small size. This attracts the electrons in the more complex anions towards one of its constituent oxygen atoms, forming an oxide ion and an oxygen atom. This causes lithium to form the oxide exclusively on reaction with oxygen at room temperature. This effect becomes drastically weaker for the larger sodium and potassium, allowing them to form the less stable peroxides. Rubidium and caesium, at the bottom of the group, are so large that even the least stable superoxides can form. Because the superoxide releases the most energy when formed, the superoxide is preferentially formed for the larger alkali metals where the more complex anions are not polarised. (The oxides and peroxides for these alkali metals do exist, but do not form upon direct reaction of the metal with oxygen at standard conditions.) In addition, the small size of the Li and O ions contributes to their forming a stable ionic lattice structure. Under controlled conditions, however, all the alkali metals, with the exception of francium, are known to form their oxides, peroxides, and superoxides. The alkali metal peroxides and superoxides are powerful oxidising agents. Sodium peroxide and potassium superoxide react with carbon dioxide to form the alkali metal carbonate and oxygen gas, which allows them to be used in submarine air purifiers; the presence of water vapour, naturally present in breath, makes the removal of carbon dioxide by potassium superoxide even more efficient. All the stable alkali metals except lithium can form red ozonides (MO) through low-temperature reaction of the powdered anhydrous hydroxide with ozone: the ozonides may be then extracted using liquid ammonia. They slowly decompose at standard conditions to the superoxides and oxygen, and hydrolyse immediately to the hydroxides when in contact with water. Potassium, rubidium, and caesium also form sesquioxides MO, which may be better considered peroxide disuperoxides, .
Rubidium and caesium can form a great variety of suboxides with the metals in formal oxidation states below +1. Rubidium can form RbO and RbO (copper-coloured) upon oxidation in air, while caesium forms an immense variety of oxides, such as the ozonide CsO and several brightly coloured suboxides, such as CsO (bronze), CsO (red-violet), CsO (violet), CsO (dark green), CsO, CsO, as well as CsO. The last of these may be heated under vacuum to generate CsO.
The alkali metals can also react analogously with the heavier chalcogens (sulfur, selenium, tellurium, and polonium), and all the alkali metal chalcogenides are known (with the exception of francium's). Reaction with an excess of the chalcogen can similarly result in lower chalcogenides, with chalcogen ions containing chains of the chalcogen atoms in question. For example, sodium can react with sulfur to form the sulfide (NaS) and various polysulfides with the formula NaS ("x" from 2 to 6), containing the ions. Due to the basicity of the Se and Te ions, the alkali metal selenides and tellurides are alkaline in solution; when reacted directly with selenium and tellurium, alkali metal polyselenides and polytellurides are formed along with the selenides and tellurides with the and ions. They may be obtained directly from the elements in liquid ammonia or when air is not present, and are colourless, water-soluble compounds that air oxidises quickly back to selenium or tellurium. The alkali metal polonides are all ionic compounds containing the Po ion; they are very chemically stable and can be produced by direct reaction of the elements at around 300–400 °C.
<h3>Halides, hydrides, and pseudohalides.</h3>
The alkali metals are among the most electropositive elements on the periodic table and thus tend to bond ionically to the most electronegative elements on the periodic table, the halogens (fluorine, chlorine, bromine, iodine, and astatine), forming salts known as the alkali metal halides. The reaction is very vigorous and can sometimes result in explosions. All twenty stable alkali metal halides are known; the unstable ones are not known, with the exception of sodium astatide, because of the great instability and rarity of astatine and francium. The most well-known of the twenty is certainly sodium chloride, otherwise known as common salt. All of the stable alkali metal halides have the formula MX where M is an alkali metal and X is a halogen. They are all white ionic crystalline solids that have high melting points. All the alkali metal halides are soluble in water except for lithium fluoride (LiF), which is insoluble in water due to its very high lattice enthalpy. The high lattice enthalpy of lithium fluoride is due to the small sizes of the Li and F ions, causing the electrostatic interactions between them to be strong: a similar effect occurs for magnesium fluoride, consistent with the diagonal relationship between lithium and magnesium.
The alkali metals also react similarly with hydrogen to form ionic alkali metal hydrides, where the hydride anion acts as a pseudohalide: these are often used as reducing agents, producing hydrides, complex metal hydrides, or hydrogen gas. Other pseudohalides are also known, notably the cyanides. These are isostructural to the respective halides except for lithium cyanide, indicating that the cyanide ions may rotate freely. Ternary alkali metal halide oxides, such as NaClO, KBrO (yellow), NaBrO, NaIO, and KBrO, are also known. The polyhalides are rather unstable, although those of rubidium and caesium are greatly stabilised by the feeble polarising power of these extremely large cations.
<h3>Coordination complexes.</h3>
Alkali metal cations do not usually form coordination complexes with simple Lewis bases due to their low charge of just +1 and their relatively large size; thus the Li ion forms most complexes and the heavier alkali metal ions form less and less (though exceptions occur for weak complexes). Lithium in particular has a very rich coordination chemistry in which it exhibits coordination numbers from 1 to 12, although octahedral hexacoordination is its preferred mode. In aqueous solution, the alkali metal ions exist as octahedral hexahydrate complexes ([M(HO))]), with the exception of the lithium ion, which due to its small size forms tetrahedral tetrahydrate complexes ([Li(HO))]); the alkali metals form these complexes because their ions are attracted by electrostatic forces of attraction to the polar water molecules. Because of this, anhydrous salts containing alkali metal cations are often used as desiccants. Alkali metals also readily form complexes with crown ethers (e.g. 12-crown-4 for Li, 15-crown-5 for Na, 18-crown-6 for K, and 21-crown-7 for Rb) and cryptands due to electrostatic attraction.
<h3>Ammonia solutions.</h3>
The alkali metals dissolve slowly in liquid ammonia, forming ammoniacal solutions of solvated M and e, which react to form hydrogen gas and the alkali metal amide (MNH, where M represents an alkali metal): this was first noted by Humphry Davy in 1809 and rediscovered by W. Weyl in 1864. The process may be speeded up by a catalyst. Similar solutions are formed by the heavy divalent alkaline earth metals calcium, strontium, barium, as well as the divalent lanthanides, europium and ytterbium. The amide salt is quite insoluble and readily precipitates out of solution, leaving intensely coloured ammonia solutions of the alkali metals. In 1907, Charles Krause identified the colour as being due to the presence of solvated electrons, which contribute to the high electrical conductivity of these solutions. At low concentrations (below 3 M), the solution is dark blue and has ten times the conductivity of aqueous sodium chloride; at higher concentrations (above 3 M), the solution is copper-coloured and has approximately the conductivity of liquid metals like mercury. In addition to the alkali metal amide salt and solvated electrons, such ammonia solutions also contain the alkali metal cation (M), the neutral alkali metal atom (M), diatomic alkali metal molecules (M) and alkali metal anions (M). These are unstable and eventually become the more thermodynamically stable alkali metal amide and hydrogen gas. Solvated electrons are powerful reducing agents and are often used in chemical synthesis.
<h3>Organometallic.</h3>
<h4>Organolithium.</h4>
Being the smallest alkali metal, lithium forms the widest variety of and most stable organometallic compounds, which are bonded covalently. Organolithium compounds are electrically non-conducting volatile solids or liquids that melt at low temperatures, and tend to form oligomers with the structure (RLi) where R is the organic group. As the electropositive nature of lithium puts most of the charge density of the bond on the carbon atom, effectively creating a carbanion, organolithium compounds are extremely powerful bases and nucleophiles. For use as bases, butyllithiums are often used and are commercially available. An example of an organolithium compound is methyllithium ((CHLi)), which exists in tetrameric ("x" = 4, tetrahedral) and hexameric ("x" = 6, octahedral) forms. Organolithium compounds, especially "n"-butyllithium, are useful reagents in organic synthesis, as might be expected given lithium's diagonal relationship with magnesium, which plays an important role in the Grignard reaction. For example, alkyllithiums and aryllithiums may be used to synthesise aldehydes and ketones by reaction with metal carbonyls. The reaction with nickel tetracarbonyl, for example, proceeds through an unstable acyl nickel carbonyl complex which then undergoes electrophilic substitution to give the desired aldehyde (using H as the electrophile) or ketone (using an alkyl halide) product.
Alkyllithiums and aryllithiums may also react with "N","N"-disubstituted amides to give aldehydes and ketones, and symmetrical ketones by reacting with carbon monoxide. They thermally decompose to eliminate a β-hydrogen, producing alkenes and lithium hydride: another route is the reaction of ethers with alkyl- and aryllithiums that act as strong bases. In non-polar solvents, aryllithiums react as the carbanions they effectively are, turning carbon dioxide to aromatic carboxylic acids (ArCOH) and aryl ketones to tertiary carbinols (Ar'C(Ar)OH). Finally, they may be used to synthesise other organometallic compounds through metal-halogen exchange.
<h4>Heavier alkali metals.</h4>
Unlike the organolithium compounds, the organometallic compounds of the heavier alkali metals are predominantly ionic. The application of organosodium compounds in chemistry is limited in part due to competition from organolithium compounds, which are commercially available and exhibit more convenient reactivity. The principal organosodium compound of commercial importance is sodium cyclopentadienide. Sodium tetraphenylborate can also be classified as an organosodium compound since in the solid state sodium is bound to the aryl groups. Organometallic compounds of the higher alkali metals are even more reactive than organosodium compounds and of limited utility. A notable reagent is Schlosser's base, a mixture of "n"-butyllithium and potassium "tert"-butoxide. This reagent reacts with propene to form the compound allylpotassium (KCHCHCH). "cis"-2-Butene and "trans"-2-butene equilibrate when in contact with alkali metals. Whereas isomerisation is fast with lithium and sodium, it is slow with the heavier alkali metals. The heavier alkali metals also favour the sterically congested conformation. Several crystal structures of organopotassium compounds have been reported, establishing that they, like the sodium compounds, are polymeric. Organosodium, organopotassium, organorubidium and organocaesium compounds are all mostly ionic and are insoluble (or nearly so) in nonpolar solvents.
Alkyl and aryl derivatives of sodium and potassium tend to react with air. They cause the cleavage of ethers, generating alkoxides. Unlike alkyllithium compounds, alkylsodiums and alkylpotassiums cannot be made by reacting the metals with alkyl halides because Wurtz coupling occurs:
As such, they have to be made by reacting alkylmercury compounds with sodium or potassium metal in inert hydrocarbon solvents. While methylsodium forms tetramers like methyllithium, methylpotassium is more ionic and has the nickel arsenide structure with discrete methyl anions and potassium cations.
The alkali metals and their hydrides react with acidic hydrocarbons, for example cyclopentadienes and terminal alkynes, to give salts. Liquid ammonia, ether, or hydrocarbon solvents are used, the most common of which being tetrahydrofuran. The most important of these compounds is sodium cyclopentadienide, NaCH, an important precursor to many transition metal cyclopentadienyl derivatives. Similarly, the alkali metals react with cyclooctatetraene in tetrahydrofuran to give alkali metal cyclooctatetraenides; for example, dipotassium cyclooctatetraenide (KCH) is an important precursor to many metal cyclooctatetraenyl derivatives, such as uranocene. The large and very weakly polarising alkali metal cations can stabilise large, aromatic, polarisable radical anions, such as the dark-green sodium naphthalenide, Na[CH•], a strong reducing agent.
<h2>Extensions.</h2>
Although francium is the heaviest alkali metal that has been discovered, there has been some theoretical work predicting the physical and chemical characteristics of the hypothetical heavier alkali metals. Being the first period 8 element, the undiscovered element ununennium (element 119) is predicted to be the next alkali metal after francium and behave much like their lighter congeners; however, it is also predicted to differ from the lighter alkali metals in some properties. Its chemistry is predicted to be closer to that of potassium or rubidium instead of caesium or francium. This is unusual as periodic trends, ignoring relativistic effects would predict ununennium to be even more reactive than caesium and francium. This lowered reactivity is due to the relativistic stabilisation of ununennium's valence electron, increasing ununennium's first ionisation energy and decreasing the metallic and ionic radii; this effect is already seen for francium. This assumes that ununennium will behave chemically as an alkali metal, which, although likely, may not be true due to relativistic effects. The relativistic stabilisation of the 8s orbital also increases ununennium's electron affinity far beyond that of caesium and francium; indeed, ununennium is expected to have an electron affinity higher than all the alkali metals lighter than it. Relativistic effects also cause a very large drop in the polarisability of ununennium. On the other hand, ununennium is predicted to continue the trend of melting points decreasing going down the group, being expected to have a melting point between 0 °C and 30 °C.
The stabilisation of ununennium's valence electron and thus the contraction of the 8s orbital cause its atomic radius to be lowered to 240 pm, very close to that of rubidium (247 pm), so that the chemistry of ununennium in the +1 oxidation state should be more similar to the chemistry of rubidium than to that of francium. On the other hand, the ionic radius of the Uue ion is predicted to be larger than that of Rb, because the 7p orbitals are destabilised and are thus larger than the p-orbitals of the lower shells. Ununennium may also show the +3 oxidation state, which is not seen in any other alkali metal, in addition to the +1 oxidation state that is characteristic of the other alkali metals and is also the main oxidation state of all the known alkali metals: this is because of the destabilisation and expansion of the 7p spinor, causing its outermost electrons to have a lower ionisation energy than what would otherwise be expected. Indeed, many ununennium compounds are expected to have a large covalent character, due to the involvement of the 7p electrons in the bonding.
Not as much work has been done predicting the properties of the alkali metals beyond ununennium. Although a simple extrapolation of the periodic table would put element 169, unhexennium, under ununennium, Dirac-Fock calculations predict that the next alkali metal after ununennium may actually be element 165, unhexpentium, which is predicted to have the electron configuration [Uuo] 5g 6f 7d 8s 8p 9s. Further calculations show that unhexpentium would follow the trend of increasing ionisation energy beyond caesium, having an ionisation energy comparable to that of sodium, and that it should also continue the trend of decreasing atomic radii beyond caesium, having an atomic radius comparable to that of potassium. However, the 7d electrons of unhexpentium may also be able to participate in chemical reactions along with the 9s electron, possibly allowing oxidation states beyond +1 and perhaps even making unhexpentium behave more like a boron group element or group 11 element than an alkali metal. Due to the alkali and alkaline earth metals both being s-block elements, these predictions for the trends and properties of ununennium and unhexpentium also mostly hold quite similarly for the corresponding alkaline earth metals unbinilium (Ubn) and unhexhexium (Uhh).
The probable properties of further alkali metals beyond unhexpentium have not been explored yet as of 2015; in fact, it is suspected that they may not be able to exist. In periods 8 and above of the periodic table, relativistic and shell-structure effects become so strong that extrapolations from lighter congeners become completely inaccurate. In addition, the relativistic and shell-structure effects (which stabilise the s-orbitals and destabilise and expand the d-, f-, and g-orbitals of higher shells) have opposite effects, causing even larger difference between relativistic and non-relativistic calculations of the properties of elements with such high atomic numbers. Interest in the chemical properties of ununennium and unhexpentium stems from the fact that both elements are located close to the expected locations of islands of stabilities, centered at elements 122 (Ubb) and 164 (Uhq).
<h2>Pseudo-alkali metals.</h2>
Many other substances are similar to the alkali metals in their tendency to form monopositive cations. Analogously to the pseudohalogens, they have sometimes been called "pseudo-alkali metals". These substances include some elements and many more polyatomic ions; the polyatomic ions are especially similar to the alkali metals in their large size and weak polarising power.
<h3>Hydrogen.</h3>
The element hydrogen, with one electron per neutral atom, is usually placed at the top of Group 1 of the periodic table for convenience, but hydrogen is not normally considered to be an alkali metal; when it is considered to be an alkali metal, it is because of its atomic properties and not its chemical properties. Under typical conditions, pure hydrogen exists as a diatomic gas consisting of two atoms per molecule (H); however, the alkali metals only form diatomic molecules (such as dilithium, Li) at high temperatures, when they are in the gaseous state.
Hydrogen, like the alkali metals, has one valence electron and reacts easily with the halogens, but the similarities end there. Its placement above lithium is primarily due to its electron configuration. It is sometimes placed above carbon due to their similar electronegativities or fluorine due to their similar chemical properties.
The first ionisation energy of hydrogen (1312.0 kJ/mol) is much higher than that of the alkali metals. As only one additional electron is required to fill in the outermost shell of the hydrogen atom, hydrogen often behaves like a halogen, forming the negative hydride ion, and is very occasionally considered to be a halogen on that basis. (The alkali metals can also form negative ions, known as alkalides, but these are little more than laboratory curiosities, being unstable.) An argument against this placement is that formation of hydride from hydrogen is endothermic, unlike the exothermic formation of halides from halogens. The radius of the H anion also does not fit the trend of increasing size going down the halogens: indeed, H is very diffuse because its single proton cannot easily control both electrons. It was expected for some time that liquid hydrogen would show metallic properties; while this has been shown to not be the case, under extremely high pressures, such as those found at the cores of Jupiter and Saturn, hydrogen does become metallic and behaves like an alkali metal; in this phase, it is known as metallic hydrogen. The electrical resistivity of liquid metallic hydrogen at 3000 K is approximately equal to that of liquid rubidium and caesium at 2000 K at the respective pressures when they undergo a nonmetal-to-metal transition.
The 1s electron configuration of hydrogen, while superficially similar to that of the alkali metals (ns), is unique because there is no 1p subshell. Hence it can lose an electron to form the hydron H, or gain one to form the hydride ion H. In the former case it resembles superficially the alkali metals; in the latter case, the halogens, but the differences due to the lack of a 1p subshell are important enough that neither group fits the properties of hydrogen well. Group 14 is also a good fit in terms of thermodynamic properties such as ionisation energy and electron affinity, but makes chemical nonsense because hydrogen cannot be tetravalent. Thus none of the three placements are entirely satisfactory, although group 1 is the most common placement (if one is chosen) because the hydron is by far the most important of all monatomic hydrogen species, being the foundation of acid-base chemistry. As an example of hydrogen's unorthodox properties stemming from its unusual electron configuration and small size, the hydrogen ion is very small (radius around 150 fm compared to the 50–220 pm size of most other atoms and ions) and so is nonexistent in condensed systems other than in association with other atoms or molecules. Indeed, transferring of protons between chemicals is the basis of acid-base chemistry. Also unique is hydrogen's ability to form hydrogen bonds, which are an effect of charge-transfer, electrostatic, and electron correlative contributing phenomena. While analogous lithium bonds are also known, they are mostly electrostatic. Nevertheless, hydrogen can take on the same structural role as the alkali metals in some molecular crystals, and has a close relationship with the lightest alkali metals (especially lithium).
<h3>Ammonium and derivatives.</h3>
The ammonium ion () has very similar properties to the heavier alkali metals, acting as an alkali metal intermediate between potassium and rubidium, and is often considered a close relative. For example, most alkali metal salts are soluble in water, a property which ammonium salts share. Ammonium is expected to behave stably as a metal ( ions in a sea of electrons) at very high pressures (though less than the typical pressure where transitions from insulating to metallic behaviour occur around, 100 GPa), and could possibly occur inside the ice giants Uranus and Neptune, which may have significant impacts on their interior magnetic fields. It has been estimated that the transition from a mixture of ammonia and dihydrogen molecules to metallic ammonium may occur at pressures just below 25 GPa. Under standard conditions, ammonium can form a metallic amalgam with mercury.
Other "pseudo-alkali metals" include the alkylammonium cations, in which some of the hydrogen atoms in the ammonium cation are replaced by alkyl or aryl groups. In particular, the quaternary ammonium cations () are very useful since they are permanently charged, and they are often used as an alternative to the expensive Cs to stabilise very large and very easily polarisable anions such as . Tetraalkylammonium hydroxides, like alkali metal hydroxides, are very strong bases that react with atmospheric carbon dioxide to form carbonates. Furthermore, the nitrogen atom may be replaced by a phosphorus, arsenic, or antimony atom, creating a phosphonium () or arsonium () cation that can itself be substituted similarly; indeed, stibonium () itself is not known, and only some of its organic derivatives are characterised.
<h3>Cobaltocene and derivatives.</h3>
Cobaltocene, Co(CH), is a metallocene, the cobalt analogue of ferrocene. It is a dark purple solid. Cobaltocene has 19 valence electrons, one more than usually found in organotransition metal complexes, such as its very stable relative, ferrocene, in accordance with the 18-electron rule. This additional electron occupies an orbital that is antibonding with respect to the Co–C bonds. Consequently, many chemical reactions of Co(CH) are characterized by its tendency to lose this "extra" electron, yielding a very stable 18-electron cation known as cobaltocenium. Many cobaltocenium salts coprecipitate with caesium salts, and cobaltocenium hydroxide is a strong base that absorbs atmospheric carbon dioxide to form cobaltocenium carbonate. Like the alkali metals, cobaltocene is a strong reducing agent, and decamethylcobaltocene is stronger still due to the combined inductive effect of the ten methyl groups. Cobalt may be substituted by its heavier congener rhodium to give rhodocene, an even stronger reducing agent. Iridocene (involving iridium) would presumably be still more potent, but is not very well-studied due to its instability.
<h3>Thallium.</h3>
Thallium is the heaviest stable element in group 13 of the periodic table. At the bottom of the periodic table, the inert pair effect is quite strong, because of the relativistic stabilisation of the 6s orbital and the decreasing bond energy as the atoms increase in size so that the amount of energy released in forming two more bonds is not worth the high ionisation energies of the 6s electrons. It displays the +1 oxidation state that all the known alkali metals display, and thallium compounds with thallium in its +1 oxidation state closely resemble the corresponding potassium or silver compounds stoichiometrically due to the similar ionic radii of the Tl (164 pm), K (152 pm) and Ag (129 pm) ions. It was sometimes considered an alkali metal in continental Europe (but not in England) in the years immediately following its discovery, and was placed just after caesium as the sixth alkali metal in Dmitri Mendeleev's 1869 periodic table and Julius Lothar Meyer's 1868 periodic table. (Mendeleev's 1871 periodic table and Meyer's 1870 periodic table put thallium in its current position in the boron group and left the space below caesium blank.) However, thallium also displays the oxidation state +3, which no known alkali metal displays (although ununennium, the undiscovered seventh alkali metal, is predicted to possibly display the +3 oxidation state). The sixth alkali metal is now considered to be francium. While Tl is stabilised by the inert pair effect, this inert pair of 6s electrons is still able to participate chemically, so that these electrons are stereochemically active in aqueous solution. Additionally, the thallium halides (except TlF) are quite insoluble in water, and TlI has an unusual structure because of the presence of the stereochemically active inert pair in thallium.
<h3>Copper, silver, and gold.</h3>
The group 11 metals (or coinage metals), copper, silver, and gold, are typically categorised as transition metals given they can form ions with incomplete d-shells. Physically, they have the relatively low melting points and high electronegativity values associated with post-transition metals. "The filled "d" subshell and free "s" electron of Cu, Ag, and Au contribute to their high electrical and thermal conductivity. Transition metals to the left of group 11 experience interactions between "s" electrons and the partially filled "d" subshell that lower electron mobility." Chemically, the group 11 metals behave like main-group metals in their +1 valence states, and are hence somewhat related to the alkali metals: this is one reason for their previously being labelled as "group IB", paralleling the alkali metals' "group IA". They are occasionally classified as post-transition metals. Their spectra are analogous to those of the alkali metals. Their monopositive ions are paramagnetic and contribute no colour to their salts, like those of the alkali metals.
In Mendeleev's 1871 periodic table, copper, silver, and gold are listed twice, once under group VIII (with the iron triad and platinum group metals), and once under group IB. Group IB was nonetheless parenthesised to note that it was tentative. Mendeleev's main criterion for group assignment was the maximum oxidation state of an element: on that basis, the group 11 elements could not be classified in group IB, due to the existence of copper(II) and gold(III) compounds being known at that time. However, eliminating group IB would make group I the only main group (group VIII was labelled a transition group) to lack an A–B bifurcation. Soon afterwards, a majority of chemists chose to classify these elements in group IB and remove them from group VIII for the resulting symmetry: this was the predominant classification until the rise of the modern medium-long 18-column periodic table, which separated the alkali metals and group 11 metals.
The coinage metals were traditionally regarded as a subdivision of the alkali metal group, due to them sharing the characteristic s electron configuration of the alkali metals (group 1: ps; group 11: ds). However, the similarities are largely confined to the stochiometries of the +1 compounds of both groups, and not their chemical properties. This stems from the filled d subshell providing a much weaker shielding effect on the outermost s electron than the filled p subshell, so that the coinage metals have much higher first ionisation energies and smaller ionic radii than do the corresponding alkali metals. Furthermore, they have higher melting points, hardnesses, and densities, and lower reactivities and solubilities in liquid ammonia, as well as having more covalent character in their compounds. Finally, the alkali metals are at the top of the electrochemical series, whereas the coinage metals are almost at the very bottom. The coinage metals' filled d shell is much more easily disrupted than the alkali metals' filled p shell, so that the second and third ionisation energies are lower, enabling higher oxidation states than +1 and a richer coordination chemistry, thus giving the group 11 metals clear transition metal character. Particularly noteworthy is gold forming ionic compounds with rubidium and caesium, in which it forms the auride ion (Au) which also occurs in solvated form in liquid ammonia solution: here gold behaves as a pseudohalogen because its 5d6s configuration has one electron less than the quasi-closed shell 5d6s configuration of mercury.
<h2>History.</h2>
Sodium compounds have been known since ancient times; salt (sodium chloride) has been an important commodity in human activities, as testified by the English word "salary", referring to "salarium", money paid to Roman soldiers for the purchase of salt. While potash has been used since ancient times, it was not understood for most of its history to be a fundamentally different substance from sodium mineral salts. Georg Ernst Stahl obtained experimental evidence which led him to suggest the fundamental difference of sodium and potassium salts in 1702, and Henri Louis Duhamel du Monceau was able to prove this difference in 1736. The exact chemical composition of potassium and sodium compounds, and the status as chemical element of potassium and sodium, was not known then, and thus Antoine Lavoisier did include the alkali in his list of chemical elements in 1789.
Pure potassium was first isolated in 1807 in England by Sir Humphry Davy, who derived it from caustic potash (KOH, potassium hydroxide) by the use of electrolysis of the molten salt with the newly invented voltaic pile. Previous attempts at electrolysis of the aqueous salt were unsuccessful due to potassium's extreme reactivity. Potassium was the first metal that was isolated by electrolysis. Later that same year, Davy reported extraction of sodium from the similar substance caustic soda (NaOH, lye) by a similar technique, demonstrating the elements, and thus the salts, to be different. Later that year, the first pieces of pure molten sodium metal were similarly prepared by Humphry Davy through the electrolysis of molten caustic soda (now called sodium hydroxide).
Petalite (LiAlSiO) was discovered in 1800 by the Brazilian chemist José Bonifácio de Andrada in a mine on the island of Utö, Sweden. However, it was not until 1817 that Johan August Arfwedson, then working in the laboratory of the chemist Jöns Jacob Berzelius, detected the presence of a new element while analysing petalite ore. This new element was noted by him to form compounds similar to those of sodium and potassium, though its carbonate and hydroxide were less soluble in water and more alkaline than the other alkali metals. Berzelius gave the unknown material the name ""lithion"/"lithina"", from the Greek word "λιθoς" (transliterated as "lithos", meaning "stone"), to reflect its discovery in a solid mineral, as opposed to potassium, which had been discovered in plant ashes, and sodium, which was known partly for its high abundance in animal blood. He named the metal inside the material ""lithium"". Lithium, sodium, and potassium were part of the discovery of periodicity, as they are among a series of triads of elements in the same group that were noted by Johann Wolfgang Döbereiner in 1850 as having similar properties.
Rubidium and caesium were the first elements to be discovered using the spectroscope, invented in 1859 by Robert Bunsen and Gustav Kirchhoff. The next year, they discovered caesium in the mineral water from Bad Dürkheim, Germany. Their discovery of rubidium came the following year in Heidelberg, Germany, finding it in the mineral lepidolite. The names of rubidium and caesium come from the most prominent lines in their emission spectra: a bright red line for rubidium (from the Latin word "rubidus", meaning dark red or bright red), and a sky-blue line for caesium (derived from the Latin word "caesius", meaning sky-blue).
Around 1865 John Newlands produced a series of papers where he listed the elements in order of increasing atomic weight and similar physical and chemical properties that recurred at intervals of eight; he likened such periodicity to the octaves of music. His version put all the alkali metals then known (lithium to caesium), as well as copper, silver, and thallium (which show the +1 oxidation state characteristic of the alkali metals), together into a group. His table placed hydrogen with the halogens.
After 1869, Dmitri Mendeleev proposed his periodic table placing lithium at the top of a group with sodium, potassium, rubidium, caesium, and thallium. Two years later, Mendeleev revised his table, placing hydrogen in group 1 above lithium, and also moving thallium to the boron group. In this 1871 version, copper, silver, and gold were placed twice, once as part of group IB, and once as part of a "group VIII" encompassing today's groups 8 to 11. After the introduction of the 18-column table, the group IB elements were moved to their current position in the d-block, while alkali metals were left in "group IA". Later the group's name was changed to "group 1" in 1988. The trivial name "alkali metals" comes from the fact that the hydroxides of the group 1 elements are all strong alkalis when dissolved in water.
There were at least four erroneous and incomplete discoveries before Marguerite Perey of the Curie Institute in Paris, France discovered francium in 1939 by purifying a sample of actinium-227, which had been reported to have a decay energy of 220 keV. However, Perey noticed decay particles with an energy level below 80 keV. Perey thought this decay activity might have been caused by a previously unidentified decay product, one that was separated during purification, but emerged again out of the pure actinium-227. Various tests eliminated the possibility of the unknown element being thorium, radium, lead, bismuth, or thallium. The new product exhibited chemical properties of an alkali metal (such as coprecipitating with caesium salts), which led Perey to believe that it was element 87, caused by the alpha decay of actinium-227. Perey then attempted to determine the proportion of beta decay to alpha decay in actinium-227. Her first test put the alpha branching at 0.6%, a figure that she later revised to 1%.
The next element below francium (eka-francium) in the periodic table would be ununennium (Uue), element 119. The synthesis of ununennium was first attempted in 1985 by bombarding a target of einsteinium-254 with calcium-48 ions at the superHILAC accelerator at Berkeley, California. No atoms were identified, leading to a limiting yield of 300 nb.
It is highly unlikely that this reaction will be able to create any atoms of ununennium in the near future, given the extremely difficult task of making sufficient amounts of einsteinium-254, which is favoured for production of ultraheavy elements because of its large mass, relatively long half-life of 270 days, and availability in significant amounts of several micrograms, to make a large enough target to increase the sensitivity of the experiment to the required level; einsteinium has not been found in nature and has only been produced in laboratories. However, given that ununennium is only the first period 8 element on the extended periodic table, it may well be discovered in the near future through other reactions. Currently, none of the period 8 elements have been discovered yet, and it is also possible, due to drip instabilities, that only the lower period 8 elements, up to around element 128, are physically possible. No attempts at synthesis have been made for any heavier alkali metals, such as unhexpentium, due to their extremely high atomic number: they would require new, more powerful technology to make.
<h2>Occurrence.</h2>
<h3>In the Solar System.</h3>
The Oddo–Harkins rule holds that elements with even atomic numbers are more common that those with odd atomic numbers, with the exception of hydrogen. This rule argues that elements with odd atomic numbers have one unpaired proton and are more likely to capture another, thus increasing their atomic number. In elements with even atomic numbers, protons are paired, with each member of the pair offsetting the spin of the other, enhancing stability. All the alkali metals have odd atomic numbers and they are not as common as the elements with even atomic numbers adjacent to them (the noble gases and the alkaline earth metals) in the Solar System. The heavier alkali metals are also less abundant than the lighter ones as the alkali metals from rubidium onward can only be synthesised in supernovae and not in stellar nucleosynthesis. Lithium is also much less abundant than sodium and potassium as it is poorly synthesised in both Big Bang nucleosynthesis and in stars: the Big Bang could only produce trace quantities of lithium, beryllium and boron due to the absence of a stable nucleus with 5 or 8 nucleons, and stellar nucleosynthesis could only pass this bottleneck by the triple-alpha process, fusing three helium nuclei to form carbon, and skipping over those three elements.
<h3>On Earth.</h3>
The Earth formed from the same cloud of matter that formed the Sun, but the planets acquired different compositions during the formation and evolution of the solar system. In turn, the natural history of the Earth caused parts of this planet to have differing concentrations of the elements. The mass of the Earth is approximately 5.98 kg. It is composed mostly of iron (32.1%), oxygen (30.1%), silicon (15.1%), magnesium (13.9%), sulfur (2.9%), nickel (1.8%), calcium (1.5%), and aluminium (1.4%); with the remaining 1.2% consisting of trace amounts of other elements. Due to mass segregation, the core region is believed to be primarily composed of iron (88.8%), with smaller amounts of nickel (5.8%), sulfur (4.5%), and less than 1% trace elements.
The alkali metals, due to their high reactivity, do not occur naturally in pure form in nature. They are lithophiles and therefore remain close to the Earth's surface because they combine readily with oxygen and so associate strongly with silica, forming relatively low-density minerals that do not sink down into the Earth's core. Potassium, rubidium and caesium are also incompatible elements due to their large ionic radii.
Sodium and potassium are very abundant in earth, both being among the ten most common elements in Earth's crust; sodium makes up approximately 2.6% of the Earth's crust measured by weight, making it the sixth most abundant element overall and the most abundant alkali metal. Potassium makes up approximately 1.5% of the Earth's crust and is the seventh most abundant element. Sodium is found in many different minerals, of which the most common is ordinary salt (sodium chloride), which occurs in vast quantities dissolved in seawater. Other solid deposits include halite, amphibole, cryolite, nitratine, and zeolite. Many of these solid deposits occur as a result of ancient seas evaporating, which still occurs now in places such as Utah's Great Salt Lake and the Dead Sea. Despite their near-equal abundance in Earth's crust, sodium is far more common than potassium in the ocean, both because potassium's larger size makes its salts less soluble, and because potassium is bound by silicates in soil and what potassium leaches is absorbed far more readily by plant life than sodium.
Despite its chemical similarity, lithium typically does not occur together with sodium or potassium due to its smaller size. Due to its relatively low reactivity, it can be found in seawater in large amounts; it is estimated that seawater is approximately 0.14 to 0.25 parts per million (ppm) or 25 micromolar. Its diagonal relationship with magnesium often allows it to replace magnesium in ferromagnesium minerals, where its crustal concentration is about 18 ppm, comparable to that of gallium and niobium. Commercially, the most important lithium mineral is spodumene, which occurs in large deposits worldwide.
Rubidium is approximately as abundant as zinc and more abundant than copper. It occurs naturally in the minerals leucite, pollucite, carnallite, zinnwaldite, and lepidolite, although none of these contain only rubidium and no other alkali metals. Caesium is more abundant than some commonly known elements, such as antimony, cadmium, tin, and tungsten, but is much less abundant than rubidium.
Francium-223, the only naturally occurring isotope of francium, is the product of the alpha decay of actinium-227 and can be found in trace amounts in uranium minerals. In a given sample of uranium, there is estimated to be only one francium atom for every 10 uranium atoms. It has been calculated that there is at most 30 g of francium in the earth's crust at any time, due to its extremely short half-life of 22 minutes.
<h2>Production and isolation.</h2>
The production of pure alkali metals is somewhat complicated due to their extreme reactivity with commonly used substances, such as water. From their silicate ores, all the stable alkali metals may be obtained the same way: sulfuric acid is first used to dissolve the desired alkali metal ion and aluminium(III) ions from the ore (leaching), whereupon basic precipitation removes aluminium ions from the mixture by precipitating it as the hydroxide. The remaining insoluble alkali metal carbonate is then precipitated selectively; the salt is then dissolved in hydrochloric acid to produce the chloride. The result is then left to evaporate and the alkali metal can then be isolated. Lithium and sodium are typically isolated through electrolysis from their liquid chlorides, with calcium chloride typically added to lower the melting point of the mixture. The heavier alkali metals, however, is more typically isolated in a different way, where a reducing agent (typically sodium for potassium and magnesium or calcium for the heaviest alkali metals) is used to reduce the alkali metal chloride. The liquid or gaseous product (the alkali metal) then undergoes fractional distillation for purification.
Lithium salts have to be extracted from the water of mineral springs, brine pools, and brine deposits. The metal is produced electrolytically from a mixture of fused lithium chloride and potassium chloride.
Sodium occurs mostly in seawater and dried seabed, but is now produced through electrolysis of sodium chloride by lowering the melting point of the substance to below 700 °C through the use of a Downs cell. Extremely pure sodium can be produced through the thermal decomposition of sodium azide. Potassium occurs in many minerals, such as sylvite (potassium chloride). Previously, potassium was generally made from the electrolysis of potassium chloride or potassium hydroxide, found extensively in places such as Canada, Russia, Belarus, Germany, Israel, United States, and Jordan, in a method similar to how sodium was produced in the late 1800s and early 1900s. It can also be produced from seawater. However, these methods are problematic because the potassium metal tends to dissolve in its molten chloride and vaporises significantly at the operating temperatures, potentially forming the explosive superoxide. As a result, pure potassium metal is now produced by reducing molten potassium chloride with sodium metal at 850 °C.
Although sodium is less reactive than potassium, this process works because at such high temperatures potassium is more volatile than sodium and can easily be distilled off, so that the equilibrium shifts towards the right to produce more potassium gas and proceeds almost to completion.
For several years in the 1950s and 1960s, a by-product of the potassium production called Alkarb was a main source for rubidium. Alkarb contained 21% rubidium while the rest was potassium and a small fraction of caesium. Today the largest producers of caesium, for example the Tanco Mine in Manitoba, Canada, produce rubidium as by-product from pollucite. Today, a common method for separating rubidium from potassium and caesium is the fractional crystallisation of a rubidium and caesium alum (Cs,Rb)Al(SO)·12HO, which yields pure rubidium alum after approximately 30 recrystallisations. The limited applications and the lack of a mineral rich in rubidium limit the production of rubidium compounds to 2 to 4 tonnes per year. Caesium, however, is not produced from the above reaction. Instead, the mining of pollucite ore is the main method of obtaining pure caesium, extracted from the ore mainly by three methods: acid digestion, alkaline decomposition, and direct reduction. Both metals are produced as by-products of lithium production: after 1958, when interest in lithium's thermonuclear properties increased sharply, the production of rubidium and caesium also increased correspondingly. Pure rubidium and caesium metals are produced by reducing their chlorides with calcium metal at 750 °C and low pressure.
As a result of its extreme rarity in nature, most francium is synthesised in the nuclear reaction Au + O → Fr + 5 n, yielding francium-209, francium-210, and francium-211. The greatest quantity of francium ever assembled to date is about 300,000 neutral atoms, which were synthesised using the nuclear reaction given above. When the only natural isotope francium-223 is specifically required, it is produced as the alpha daughter of actinium-227, itself produced synthetically from the neutron irradiation of natural radium-226, one of the daughters of natural uranium-238.
<h2>Applications.</h2>
Lithium, sodium, and potassium have many applications, while rubidium and caesium are very useful in academic contexts but do not have many applications yet. Lithium is often used in batteries, and lithium oxide can help process silica. Lithium stearate is a thickener and can be used to make lubricating greases; it is produced from lithium hydroxide, which is also used to absorb carbon dioxide in space capsules and submarines. Lithium chloride is used as a brazing alloy for aluminium parts. Metallic lithium is used in alloys with magnesium and aluminium to give very tough and light alloys.
Sodium compounds have many applications, the most well-known being sodium chloride as table salt. Sodium salts of fatty acids are uesd as soap. Pure sodium metal also has many applications, including use in sodium-vapour lamps, which produce very efficient light compared to other types of lighting, and can help smooth the surface of other metals. Being a strong reducing agent, it is often used to reduce many other metals, such as titanium and zirconium, from their chlorides. Furthermore, it is very useful as a heat-exchange liquid in fast breeder nuclear reactors due to its low melting point, viscosity, and cross-section towards neutron absorption.
Potassium compounds are often used as fertilisers as potassium is an important element for plant nutrition. Potassium hydroxide is a very strong base, and is used to control the pH of various substances. Potassium nitrate and potassium permanganate are often used as powerful oxidising agents. Potassium superoxide is used in breathing masks, as it reacts with carbon dioxide to give potassium carbonate and oxygen gas. Pure potassium metal is not often used, but its alloys with sodium may substitute for pure sodium in fast breeder nuclear reactors.
Rubidium and caesium are often used in atomic clocks. Caesium atomic clocks are extraordinarily accurate; if a clock had been made at the time of the dinosaurs, it would be off by less than four seconds (after 80 million years). For that reason, caesium atoms are used as the definition of the second. Rubidium ions are often used in purple fireworks, and caesium is often used in drilling fluids in the petroleum industry.
Francium has no commercial applications, but because of francium's relatively simple atomic structure, among other things, it has been used in spectroscopy experiments, leading to more information regarding energy levels and the coupling constants between subatomic particles. Studies on the light emitted by laser-trapped francium-210 ions have provided accurate data on transitions between atomic energy levels, similar to those predicted by quantum theory.
<h2>Biological role and precautions.</h2>
<h3>Metals.</h3>
Pure alkali metals are dangerously reactive with air and water and must be kept away from heat, fire, oxidising agents, acids, most organic compounds, halocarbons, plastics, and moisture. They also react with carbon dioxide and carbon tetrachloride, so that normal fire extinguishers are counterproductive when used on alkali metal fires. Some Class D dry powder extinguishers designed for metal fires are effective, depriving the fire of oxygen and cooling the alkali metal.
Experiments are usually conducted using only small quantities of a few grams in a fume hood. Small quantities of lithium may be disposed of by reaction with cool water, but the heavier alkali metals should be dissolved in the less reactive isopropanol. The alkali metals must be stored under mineral oil or an inert atmosphere. The inert atmosphere used may be argon or nitrogen gas, except for lithium, which reacts with nitrogen. Rubidium and caesium must be kept away from air, even under oil, because even a small amount of air diffused into the oil may trigger formation of the dangerously explosive peroxide; for the same reason, potassium should not be stored under oil in an oxygen-containing atmosphere for longer than 6 months.
<h3>Ions.</h3>
The bioinorganic chemistry of the alkali metal ions has been extensively reviewed.
Solid state crystal structures have been deternined for many complexes of alkali metal ions in small peptides, nucleic acid constituents, carbohydrates and ionophore complexes.
Lithium naturally only occurs in traces in biological systems and has no known biological role, but does have effects on the body when ingested. Lithium carbonate is used as a mood stabiliser in psychiatry to treat bipolar disorder (manic-depression) in daily doses of about 0.5 to 2 grams, although there are side-effects. Excessive ingestion of lithium causes drowsiness, slurred speech and vomiting, among other symptoms, and poisons the central nervous system, which is dangerous as the required dosage of lithium to treat bipolar disorder is only slightly lower than the toxic dosage. Its biochemistry, the way it is handled by the human body and studies using rats and goats suggest that it is an essential trace element, although the natural biological function of lithium in humans has yet to be identified.
Sodium and potassium occur in all known biological systems, generally functioning as electrolytes inside and outside cells. Sodium is an essential nutrient that regulates blood volume, blood pressure, osmotic equilibrium and pH; the minimum physiological requirement for sodium is 500 milligrams per day. Sodium chloride (also known as common salt) is the principal source of sodium in the diet, and is used as seasoning and preservative, such as for pickling and jerky; most of it comes from processed foods. The Dietary Reference Intake for sodium is 1.5 grams per day, but most people in the United States consume more than 2.3 grams per day, the minimum amount that promotes hypertension; this in turn causes 7.6 million premature deaths worldwide.
Potassium is the major cation (positive ion) inside animal cells, while sodium is the major cation outside animal cells. The concentration differences of these charged particles causes a difference in electric potential between the inside and outside of cells, known as the membrane potential. The balance between potassium and sodium is maintained by ion pumps in the cell membrane. The cell membrane potential created by potassium and sodium ions allows the cell to generate an action potential—a "spike" of electrical discharge. The ability of cells to produce electrical discharge is critical for body functions such as neurotransmission, muscle contraction, and heart function. Disruption of this balance may thus be fatal: for example, ingestion of large amounts of potassium compounds can lead to hyperkalemia strongly influencing the cardiovascular system. Potassium chloride is used in the United States for lethal injection executions.
Due to their similar atomic radii, rubidium and caesium in the body mimic potassium and are taken up similarly. Rubidium has no known biological role, but may help stimulate metabolism, and, similarly to caesium, replace potassium in the body causing potassium deficiency. Partial substitution is quite possible and rather non-toxic: a 70 kg person contains on average 0.36 g of rubidium, and an increase in this value by 50 to 100 times did not show negative effects in test persons. Rats can survive up to 50% substitution of potassium by rubidium. Rubidium (and to a much lesser extent caesium) can function as temporary cures for hypokalemia; while rubidium can adequately physiologically substitute potassium in some systems, caesium is never able to do so. There is only very limited evidence in the form of deficiency symptoms for rubidium being possibly essential in goats; even if this is true, the trace amounts usually present in food are more than enough.
Caesium compounds are rarely encountered by most people, but most caesium compounds are mildly toxic. Like rubidium, caesium tends to substitute potassium in the body, but is significantly larger and is therefore a poorer substitute. Excess caesium can lead to hypokalemia, arrythmia, and acute cardiac arrest, but such amounts would not ordinarily be encountered in natural sources. As such, caesium is not a major chemical environmental pollutant. The median lethal dose (LD) value for caesium chloride in mice is 2.3 g per kilogram, which is comparable to the LD values of potassium chloride and sodium chloride. Caesium chloride has been promoted as an alternative cancer therapy, but has been linked to the deaths of over 50 patients, on whom it was used as part of a scientifically unvalidated cancer treatment.
Radioisotopes of caesium require special precautions: the improper handling of caesium-137 gamma ray sources can lead to release of this radioisotope and radiation injuries. Perhaps the best-known case is the Goiânia accident of 1987, in which an improperly-disposed-of radiation therapy system from an abandoned clinic in the city of Goiânia, Brazil, was scavenged from a junkyard, and the glowing caesium salt sold to curious, uneducated buyers. This led to four deaths and serious injuries from radiation exposure. Together with caesium-134, iodine-131, and strontium-90, caesium-137 was among the isotopes distributed by the Chernobyl disaster which constitute the greatest risk to health. Radioisotopes of francium would presumably be dangerous as well due to their high decay energy and short half-life, but none have been produced in large enough amounts to pose any serious risk.

</doc>
<doc id="670" url="https://en.wikipedia.org/wiki?curid=670" title="Alphabet">
Alphabet

An alphabet is a standard set of letters (basic written symbols or graphemes) that is used to write one or more languages based on the general principle that the letters represent phonemes (basic significant sounds) of the spoken language. This is in contrast to other types of writing systems, such as syllabaries (in which each character represents a syllable) and logographies (in which each character represents a word, morpheme, or semantic unit).
The Proto-Canaanite script, later known as the Phoenician alphabet, is the first fully phonemic script. Thus the Phoenician alphabet is considered to be the first alphabet. The Phoenician alphabet is the ancestor of most modern alphabets, including Arabic, Greek, Latin, Cyrillic, Hebrew, and possibly Brahmic. According to terminology introduced by Peter T. Daniels, an "alphabet" is a script that represents both vowels and consonants as letters equally. In this narrow sense of the word the first "true" alphabet was the Greek alphabet, which was developed on the basis of the earlier Phoenician alphabet. In other alphabetic scripts such as the original Phoenician, Hebrew or Arabic, letters predominantly or exclusively represent consonants; such a script is also called an abjad. A third type, called abugida or alphasyllabary, is one where vowels are shown by diacritics or modifications of consonantal base letters, as in Devanagari and other South Asian scripts.
There are dozens of alphabets in use today, the most popular being the Latin alphabet (which was derived from the Greek). Many languages use modified forms of the Latin alphabet, with additional letters formed using diacritical marks. While most alphabets have letters composed of lines (linear writing), there are also exceptions such as the alphabets used in Braille.
Alphabets are usually associated with a standard ordering of letters. This makes them useful for purposes of collation, specifically by allowing words to be sorted in alphabetical order. It also means that their letters can be used as an alternative method of "numbering" ordered items, in such contexts as numbered lists and number placements.
<h2>Etymology.</h2>
The English word "alphabet" came into Middle English from the Late Latin word "alphabetum", which in turn originated in the Greek ἀλφάβητος ("alphabētos"), from "alpha" and "beta," the first two letters of the Greek alphabet. "Alpha" and "beta" in turn came from the first two letters of the Phoenician alphabet, "aleph" which meant "ox" and "bet" which meant "house".
Informally the term "ABCs" is sometimes used for the alphabet as in the alphabet song ("Now I know my ABCs" ...), and knowing one's ABCs for literacy, or as a metaphor for knowing the basics about anything.
<h2>History.</h2>
<h3>Ancient Northeast African and Middle Eastern scripts.</h3>
The history of the alphabet started in ancient Egypt. By the 27th century BC Egyptian writing had a set of some 24 hieroglyphs that are called uniliterals, to represent syllables that begin with a single consonant of their language, plus a vowel (or no vowel) to be supplied by the native speaker. These glyphs were used as pronunciation guides for logograms, to write grammatical inflections, and, later, to transcribe loan words and foreign names.
In the Middle Bronze Age an apparently "alphabetic" system known as the Proto-Sinaitic script appears in Egyptian turquoise mines in the Sinai peninsula dated to circa the 15th century BC, apparently left by Canaanite workers. In 1999, John and Deborah Darnell discovered an even earlier version of this first alphabet at Wadi el-Hol dated to circa 1800 BC and showing evidence of having been adapted from specific forms of Egyptian hieroglyphs that could be dated to circa 2000 BC, strongly suggesting that the first alphabet had been developed about that time. Based on letter appearances and names, it is believed to be based on Egyptian hieroglyphs. This script had no characters representing vowels, although originally it probably was a syllabary, but unneeded symbols were discarded. An alphabetic cuneiform script with 30 signs including three that indicate the following vowel was invented in Ugarit before the 15th century BC. This script was not used after the destruction of Ugarit.
The Proto-Sinaitic script eventually developed into the Phoenician alphabet, which is conventionally called "Proto-Canaanite" before ca. 1050 BC. The oldest text in Phoenician script is an inscription on the sarcophagus of King Ahiram. This script is the parent script of all western alphabets. By the tenth century two other forms can be distinguished, namely Canaanite and Aramaic. The Aramaic gave rise to the Hebrew script. The South Arabian alphabet, a sister script to the Phoenician alphabet, is the script from which the Ge'ez alphabet (an abugida) is descended. Vowelless alphabets, which are not true alphabets, are called abjads, currently exemplified in scripts including Arabic, Hebrew, and Syriac. The omission of vowels was not always a satisfactory solution and some "weak" consonants are sometimes used to indicate the vowel quality of a syllable (matres lectionis). These letters have a dual function since they are also used as pure consonants.
The Proto-Sinaitic or Proto-Canaanite script and the Ugaritic script were the first scripts with a limited number of signs, in contrast to the other widely used writing systems at the time, Cuneiform, Egyptian hieroglyphs, and Linear B. The Phoenician script was probably the first phonemic script and it contained only about two dozen distinct letters, making it a script simple enough for common traders to learn. Another advantage of Phoenician was that it could be used to write down many different languages, since it recorded words phonemically.
The script was spread by the Phoenicians across the Mediterranean. In Greece, the script was modified to add the vowels, giving rise to the ancestor of all alphabets in the West. The vowels have independent letter forms separate from the consonants, therefore it was the first true alphabet. The Greeks chose letters representing sounds that did not exist in Greek to represent the vowels. The vowels are significant in the Greek language, and the syllabical Linear B script that was used by the Mycenaean Greeks from the 16th century BC had 87 symbols including 5 vowels. In its early years, there were many variants of the Greek alphabet, a situation that caused many different alphabets to evolve from it.
<h3>European alphabets.</h3>
The Greek alphabet, in its Euboean form, was carried over by Greek colonists to the Italian peninsula, where it gave rise to a variety of alphabets used to write the Italic languages. One of these became the Latin alphabet, which was spread across Europe as the Romans expanded their empire. Even after the fall of the Roman state, the alphabet survived in intellectual and religious works. It eventually became used for the descendant languages of Latin (the Romance languages) and then for most of the other languages of Europe.
Some adaptations of the Latin alphabet are augmented with ligatures, such as æ in Danish and Icelandic and Ȣ in Algonquian; by borrowings from other alphabets, such as the thorn þ in Old English and Icelandic, which came from the Futhark runes; and by modifying existing letters, such as the eth ð of Old English and Icelandic, which is a modified "d". Other alphabets only use a subset of the Latin alphabet, such as Hawaiian, and Italian, which uses the letters "j, k, x, y" and "w" only in foreign words.
Another notable script is Elder Futhark, which is believed to have evolved out of one of the Old Italic alphabets. Elder Futhark gave rise to a variety of alphabets known collectively as the Runic alphabets. The Runic alphabets were used for Germanic languages from AD 100 to the late Middle Ages. Its usage is mostly restricted to engravings on stone and jewelry, although inscriptions have also been found on bone and wood. These alphabets have since been replaced with the Latin alphabet, except for decorative usage for which the runes remained in use until the 20th century.
The Old Hungarian script is a contemporary writing system of the Hungarians. It was in use during the entire history of Hungary, albeit not as an official writing system. From the 19th century it once again became more and more popular.
The Glagolitic alphabet was the initial script of the liturgical language Old Church Slavonic and became, together with the Greek uncial script, the basis of the Cyrillic script. Cyrillic is one of the most widely used modern alphabetic scripts, and is notable for its use in Slavic languages and also for other languages within the former Soviet Union. Cyrillic alphabets include the Serbian, Macedonian, Bulgarian, Russian and Urkrainian. The Glagolitic alphabet is believed to have been created by Saints Cyril and Methodius, while the Cyrillic alphabet was invented by Clement of Ohrid, who was their disciple. They feature many letters that appear to have been borrowed from or influenced by the Greek alphabet and the Hebrew alphabet.
<h3>Asian alphabets.</h3>
Beyond the logographic Chinese writing, many phonetic scripts are in existence in Asia. The Arabic alphabet, Hebrew alphabet, Syriac alphabet, and other abjads of the Middle East are developments of the Aramaic alphabet, but because these writing systems are largely consonant-based they are often not considered true alphabets.
Most alphabetic scripts of India and Eastern Asia are descended from the Brahmi script, which is often believed to be a descendant of Aramaic.
In Korea, the Hangul alphabet was created by Sejong the Great. Hangul is a unique alphabet: it is a featural alphabet, where many of the letters are designed from a sound's place of articulation (P to look like the widened mouth, L to look like the tongue pulled in, etc.); its design was planned by the government of the day; and it places individual letters in syllable clusters with equal dimensions, in the same way as Chinese characters, to allow for mixed-script writing (one syllable always takes up one type-space no matter how many letters get stacked into building that one sound-block).
Zhuyin (sometimes called "Bopomofo") is a semi-syllabary used to phonetically transcribe Mandarin Chinese in the Republic of China. After the later establishment of the People's Republic of China and its adoption of Hanyu Pinyin, the use of Zhuyin today is limited, but it is still widely used in Taiwan where the Republic of China still governs. Zhuyin developed out of a form of Chinese shorthand based on Chinese characters in the early 1900s and has elements of both an alphabet and a syllabary. Like an alphabet the phonemes of syllable initials are represented by individual symbols, but like a syllabary the phonemes of the syllable finals are not; rather, each possible final (excluding the medial glide) is represented by its own symbol. For example, "luan" is represented as ㄌㄨㄢ ("l-u-an"), where the last symbol ㄢ represents the entire final "-an". While Zhuyin is not used as a mainstream writing system, it is still often used in ways similar to a romanization system—that is, for aiding in pronunciation and as an input method for Chinese characters on computers and cellphones.
European alphabets, especially Latin and Cyrillic, have been adapted for many languages of Asia. Arabic is also widely used, sometimes as an abjad (as with Urdu and Persian) and sometimes as a complete alphabet (as with Kurdish and Uyghur).
<h2>Types.</h2>
The term "alphabet" is used by linguists and paleographers in both a wide and a narrow sense. In the wider sense, an alphabet is a script that is "segmental" at the phoneme level—that is, it has separate glyphs for individual sounds and not for larger units such as syllables or words. In the narrower sense, some scholars distinguish "true" alphabets from two other types of segmental script, abjads and abugidas. These three differ from each other in the way they treat vowels: abjads have letters for consonants and leave most vowels unexpressed; abugidas are also consonant-based, but indicate vowels with diacritics to or a systematic graphic modification of the consonants. In alphabets in the narrow sense, on the other hand, consonants and vowels are written as independent letters. The earliest known alphabet in the wider sense is the Wadi el-Hol script, believed to be an abjad, which through its successor Phoenician is the ancestor of modern alphabets, including Arabic, Greek, Latin (via the Old Italic alphabet), Cyrillic (via the Greek alphabet) and Hebrew (via Aramaic).
Examples of present-day abjads are the Arabic and Hebrew scripts; true alphabets include Latin, Cyrillic, and Korean hangul; and abugidas are used to write Tigrinya, Amharic, Hindi, and Thai. The Canadian Aboriginal syllabics are also an abugida rather than a syllabary as their name would imply, since each glyph stands for a consonant that is modified by rotation to represent the following vowel. (In a true syllabary, each consonant-vowel combination would be represented by a separate glyph.)
All three types may be augmented with syllabic glyphs. Ugaritic, for example, is basically an abjad, but has syllabic letters for . (These are the only time vowels are indicated.) Cyrillic is basically a true alphabet, but has syllabic letters for (я, е, ю); Coptic has a letter for . Devanagari is typically an abugida augmented with dedicated letters for initial vowels, though some traditions use अ as a zero consonant as the graphic base for such vowels.
The boundaries between the three types of segmental scripts are not always clear-cut. For example, Sorani Kurdish is written in the Arabic script, which is normally an abjad. However, in Kurdish, writing the vowels is mandatory, and full letters are used, so the script is a true alphabet. Other languages may use a Semitic abjad with mandatory vowel diacritics, effectively making them abugidas. On the other hand, the Phagspa script of the Mongol Empire was based closely on the Tibetan abugida, but all vowel marks were written after the preceding consonant rather than as diacritic marks. Although short "a" was not written, as in the Indic abugidas, one could argue that the linear arrangement made this a true alphabet. Conversely, the vowel marks of the Tigrinya abugida and the Amharic abugida (ironically, the original source of the term "abugida") have been so completely assimilated into their consonants that the modifications are no longer systematic and have to be learned as a syllabary rather than as a segmental script. Even more extreme, the Pahlavi abjad eventually became logographic. (See below.)
Thus the primary classification of alphabets reflects how they treat vowels. For tonal languages, further classification can be based on their treatment of tone, though names do not yet exist to distinguish the various types. Some alphabets disregard tone entirely, especially when it does not carry a heavy functional load, as in Somali and many other languages of Africa and the Americas. Such scripts are to tone what abjads are to vowels. Most commonly, tones are indicated with diacritics, the way vowels are treated in abugidas. This is the case for Vietnamese (a true alphabet) and Thai (an abugida). In Thai, tone is determined primarily by the choice of consonant, with diacritics for disambiguation. In the Pollard script, an abugida, vowels are indicated by diacritics, but the placement of the diacritic relative to the consonant is modified to indicate the tone. More rarely, a script may have separate letters for tones, as is the case for Hmong and Zhuang. For most of these scripts, regardless of whether letters or diacritics are used, the most common tone is not marked, just as the most common vowel is not marked in Indic abugidas; in Zhuyin not only is one of the tones unmarked, but there is a diacritic to indicate lack of tone, like the virama of Indic.
The number of letters in an alphabet can be quite small. The Book Pahlavi script, an abjad, had only twelve letters at one point, and may have had even fewer later on. Today the Rotokas alphabet has only twelve letters. (The Hawaiian alphabet is sometimes claimed to be as small, but it actually consists of 18 letters, including the ʻokina and five long vowels. However, Hawaiian Braille has only 13 letters.) While Rotokas has a small alphabet because it has few phonemes to represent (just eleven), Book Pahlavi was small because many letters had been "conflated"—that is, the graphic distinctions had been lost over time, and diacritics were not developed to compensate for this as they were in Arabic, another script that lost many of its distinct letter shapes. For example, a comma-shaped letter represented "g, d, y, k," or "j". However, such apparent simplifications can perversely make a script more complicated. In later Pahlavi papyri, up to half of the remaining graphic distinctions of these twelve letters were lost, and the script could no longer be read as a sequence of letters at all, but instead each word had to be learned as a whole—that is, they had become logograms as in Egyptian Demotic.
The largest segmental script is probably an abugida, Devanagari. When written in Devanagari, Vedic Sanskrit has an alphabet of 53 letters, including the "visarga" mark for final aspiration and special letters for "kš" and "jñ," though one of the letters is theoretical and not actually used. The Hindi alphabet must represent both Sanskrit and modern vocabulary, and so has been expanded to 58 with the "khutma" letters (letters with a dot added) to represent sounds from Persian and English. Thai has a total of 59 symbols, consisting of 44 consonants, 13 vowels and 2 syllabics, not including 4 diacritics for tone marks and one for vowel length.
The largest known abjad is Sindhi, with 51 letters. The largest alphabets in the narrow sense include Kabardian and Abkhaz (for Cyrillic), with 58 and 56 letters, respectively, and Slovak (for the Latin script), with 46. However, these scripts either count di- and tri-graphs as separate letters, as Spanish did with "ch" and "ll" until recently, or uses diacritics like Slovak "č".
The Georgian alphabet (Georgian: "ანბანი" "Anbani") is alphabetical writing system. It is the largest true alphabet where each letter is graphically independent with 33 letters. Original Georgian alphabet had 38 letters but 5 letters were removed in 19th century by Ilia Chavchavadze. The Georgian Alphabet is much closer to Greek than the other Caucasian alphabets. The numeric value runs parallel to the Greek one, the consonants without a Greek equivalent are organized at the end of the alphabet. Origins of the Alphabet are still unknown, some Armenian and Western scholars believe it was created by Mastots, other Georgian and Western, scholars are against this theory.
Syllabaries typically contain 50 to 400 glyphs, and the glyphs of logographic systems typically number from the many hundreds into the thousands. Thus a simple count of the number of distinct symbols is an important clue to the nature of an unknown script.
The Armenian alphabet (Armenian: Հայոց գրեր Hayots grer or Հայոց այբուբեն Hayots aybuben) is a graphically unique alphabetical writing system that has been used to write the Armenian language. It was introduced by Mesrob Mashdots around 405 AD, an Armenian linguist and ecclesiastical leader, and originally contained 36 letters. Two more letters, օ (o) and ֆ (f), were added in the Middle Ages. During the 1920s orthography reform, a new letter և (capital ԵՎ) was added, which was a ligature before ե+ւ, while the letter Ւ ւ was discarded and reintroduced as part of a new letter ՈՒ ու (which was a digraph before).
The Armenian word for "alphabet" is այբուբեն aybuben (Armenian pronunciation: [ɑjbubɛn]), named after the first two letters of the Armenian alphabet Ա այբ ayb and Բ բեն ben. The Armenian script's directionality is horizontal left-to-right, like the Latin and Greek alphabets.[3]
<h2>Alphabetical order.</h2>
Alphabets often come to be associated with a standard ordering of their letters, which can then be used for purposes of collation – namely for the listing of words and other items in what is called "alphabetical order".
The basic ordering of the Latin alphabet (A
B
C
D
E
F
G
H
I
J
K
L
M
N
O
P
Q
R
S
T
U
V
W
X
Y
Z), which is derived from the Northwest Semitic "Abgad" order, is well established, although languages using this alphabet have different conventions for their treatment of modified letters (such as the French "é", "à", and "ô") and of certain combinations of letters (multigraphs). In French, these are not considered to be additional letters for the purposes of collation. However, in Icelandic, the accented letters such as "á", "í", and "ö" are considered to be distinct letters of the alphabet. In Spanish, "ñ" is considered a separate letter, but accented vowels such as "á" and "é" are not. The "ll" and "ch" were also considered single letters, but in 1994 the Real Academia Española changed the collating order so that "ll" is between "lk" and "lm" in the dictionary and "ch" is between "cg" and "ci", and in 2010 the tenth congress of the Association of Spanish Language Academies changed it so they were no longer letters at all.
In German, words starting with "sch-" (which spells the German phoneme ) are inserted between words with initial "sca-" and "sci-" (all incidentally loanwords) instead of appearing after initial "sz", as though it were a single letter—in contrast to several languages such as Albanian, in which "dh-", "ë-", "gj-", "ll-", "rr-", "th-", "xh-" and "zh-" (all representing phonemes and considered separate single letters) would follow the letters "d", "e", "g", "l", "n", "r", "t", "x" and "z" respectively, as well as Hungarian and Welsh. Further, German words with umlaut are collated ignoring the umlaut—contrary to Turkish that adopted the graphemes ö and ü, and where a word like "tüfek", would come after "tuz", in the dictionary. An exception is the German telephone directory where umlauts are sorted like "ä" = "ae" since names as "Jäger" appear also with the spelling "Jaeger", and are not distinguished in the spoken language.
The Danish and Norwegian alphabets end with "æ"—"ø"—"å", whereas the Icelandic, Swedish and Finnish ones conventionally put "å"—"ä"—"ö" at the end.
It is unknown whether the earliest alphabets had a defined sequence. Some alphabets today, such as the Hanuno'o script, are learned one letter at a time, in no particular order, and are not used for collation where a definite order is required. However, a dozen Ugaritic tablets from the fourteenth century BC preserve the alphabet in two sequences. One, the "ABCDE" order later used in Phoenician, has continued with minor changes in Hebrew, Greek, Armenian, Gothic, Cyrillic, and Latin; the other, "HMĦLQ," was used in southern Arabia and is preserved today in Ethiopic. Both orders have therefore been stable for at least 3000 years.
Runic used an unrelated Futhark sequence, which was later simplified. Arabic uses its own sequence, although Arabic retains the traditional abjadi order for numbering.
The Brahmic family of alphabets used in India use a unique order based on phonology: The letters are arranged according to how and where they are produced in the mouth. This organization is used in Southeast Asia, Tibet, Korean hangul, and even Japanese kana, which is not an alphabet.
<h2>Names of letters.</h2>
The Phoenician letter names, in which each letter was associated with a word that begins with that sound (acrophony), continue to be used to varying degrees in Samaritan, Aramaic, Syriac, Hebrew, Greek and Arabic.
The names were abandoned in Latin, which instead referred to the letters by adding a vowel (usually e) before or after the consonant; the two exceptions were Y and Z, which were borrowed from the Greek alphabet rather than Etruscan, and were known as "Y Graeca" "Greek Y" (pronounced "I Graeca" "Greek I") and "zeta" (from Greek) – this discrepancy was inherited by many European languages, as in the term "zed" for Z in British English. Over time names sometimes shifted or were added, as in "double U" for W ("double V" in French), the English name for Y, and American "zee" for Z. Comparing names in English and French gives a clear reflection of the Great Vowel Shift: A, B, C and D are pronounced /eɪ, biː, siː, diː/ in today's English, but in contemporary French they are /a, be, se, de/. The French names (from which the English names are derived) preserve the qualities of the English vowels from before the Great Vowel Shift. By contrast, the names of F, L, M, N and S (/ɛf, ɛl, ɛm, ɛn, ɛs/) remain the same in both languages, because "short" vowels were largely unaffected by the Shift.
In Cyrillic originally the letters were given names based on Slavic words; this was later abandoned as well in favor of a system similar to that used in Latin.
<h2>Orthography and pronunciation.</h2>
When an alphabet is adopted or developed to represent a given language, an orthography generally comes into being, providing rules for the spelling of words in that language. In accordance with the principle on which alphabets are based, these rules will generally map letters of the alphabet to the phonemes (significant sounds) of the spoken language. In a perfectly phonemic orthography there would be a consistent one-to-one correspondence between the letters and the phonemes, so that a writer could predict the spelling of a word given its pronunciation, and a speaker would always know the pronunciation of a word given its spelling, and vice versa. However this ideal is not usually achieved in practice; some languages (such as Spanish and Finnish) come close to it, while others (such as English) deviate from it to a much larger degree.
The pronunciation of a language often evolves independently of its writing system, and writing systems have been borrowed for languages they were not designed for, so the degree to which letters of an alphabet correspond to phonemes of a language varies greatly from one language to another and even within a single language.
Languages may fail to achieve a one-to-one correspondence between letters and sounds in any of several ways:
National languages sometimes elect to address the problem of dialects by simply associating the alphabet with the national standard. However, with an international language with wide variations in its dialects, such as English, it would be impossible to represent the language in all its variations with a single phonetic alphabet.
Some national languages like Finnish, Turkish, Russian, Serbo-Croatian (Serbian, Croatian and Bosnian) and Bulgarian have a very regular spelling system with a nearly one-to-one correspondence between letters and phonemes. Strictly speaking, these national languages lack a word corresponding to the verb "to spell" (meaning to split a word into its letters), the closest match being a verb meaning to split a word into its syllables. Similarly, the Italian verb corresponding to 'spell (out)', "compitare", is unknown to many Italians because spelling is usually trivial, as Italian spelling is highly phonemic. In standard Spanish, one can tell the pronunciation of a word from its spelling, but not vice versa, as certain phonemes can be represented in more than one way, but a given letter is consistently pronounced. French, with its silent letters and its heavy use of nasal vowels and elision, may seem to lack much correspondence between spelling and pronunciation, but its rules on pronunciation, though complex, are actually consistent and predictable with a fair degree of accuracy.
At the other extreme are languages such as English, where the pronunciations of many words simply have to be memorized as they do not correspond to the spelling in a consistent way. For English, this is partly because the Great Vowel Shift occurred after the orthography was established, and because English has acquired a large number of loanwords at different times, retaining their original spelling at varying levels. Even English has general, albeit complex, rules that predict pronunciation from spelling, and these rules are successful most of the time; rules to predict spelling from the pronunciation have a higher failure rate.
Sometimes, countries have the written language undergo a spelling reform to realign the writing with the contemporary spoken language. These can range from simple spelling changes and word forms to switching the entire writing system itself, as when Turkey switched from the Arabic alphabet to a Latin-based Turkish alphabet.
The standard system of symbols used by linguists to represent sounds in any language, independently of orthography, is called the International Phonetic Alphabet.

</doc>
<doc id="673" url="https://en.wikipedia.org/wiki?curid=673" title="Atomic number">
Atomic number

In chemistry and physics, the atomic number of a chemical element (also known as its proton number) is the number of protons found in the nucleus of an atom of that element, and therefore identical to the charge number of the nucleus. It is conventionally represented by the symbol Z. The atomic number uniquely identifies a chemical element. In an uncharged atom, the atomic number is also equal to the number of electrons.
The atomic number, "Z", should not be confused with the mass number, "A", which is the number of nucleons, the total number of protons and neutrons in the nucleus of an atom. The number of neutrons, "N", is known as the neutron number of the atom; thus, "A" = "Z" + "N" (these quantities are always whole numbers). Since protons and neutrons have approximately the same mass (and the mass of the electrons is negligible for many purposes) and the mass defect of nucleon binding is always small compared to the nucleon mass, the atomic mass of any atom, when expressed in unified atomic mass units (making a quantity called the "relative isotopic mass"), is roughly (to within 1%) equal to the whole number "A".
Atoms with the same atomic number "Z" but different neutron numbers "N", and hence different atomic masses, are known as isotopes. A little more than three-quarters of naturally occurring elements exist as a mixture of isotopes (see monoisotopic elements), and the average isotopic mass of an isotopic mixture for an element (called the relative atomic mass) in a defined environment on Earth, determines the element's standard atomic weight. Historically, it was these atomic weights of elements (in comparison to hydrogen) that were the quantities measurable by chemists in the 19th century.
The conventional symbol "Z" comes from the German word meaning number/numeral/figure, which, prior to the modern synthesis of ideas from chemistry and physics, merely denoted an element's numerical place in the periodic table, whose order is approximately, but not completely, consistent with the order of the elements by atomic weights. Only after 1915, with the suggestion and evidence that this "Z" number was also the nuclear charge and a physical characteristic of atoms, did the word (and its English equivalent "atomic number") come into common use in this context.
<h2>History.</h2>
<h3>The periodic table and a natural number for each element.</h3>
Loosely speaking, the existence or construction of a periodic table of elements creates an ordering of the elements, and so they can be numbered in order.
Dmitri Mendeleev claimed that he arranged his first periodic tables in order of atomic weight ("Atomgewicht"). However, in consideration of the elements' observed chemical properties, he changed the order slightly and placed tellurium (atomic weight 127.6) ahead of iodine (atomic weight 126.9). This placement is consistent with the modern practice of ordering the elements by proton number, "Z", but that number was not known or suspected at the time.
A simple numbering based on periodic table position was never entirely satisfactory, however. Besides the case of iodine and tellurium, later several other pairs of elements (such as argon and potassium, cobalt and nickel) were known to have nearly identical or reversed atomic weights, thus requiring their placement in the periodic table to be determined by their chemical properties. However the gradual identification of more and more chemically similar lanthanide elements, whose atomic number was not obvious, led to inconsistency and uncertainty in the periodic numbering of elements at least from lutetium (element 71) onwards (hafnium was not known at this time). 
<h3>The Rutherford-Bohr model and van den Broek.</h3>
In 1911, Ernest Rutherford gave a model of the atom in which a central core held most of the atom's mass and a positive charge which, in units of the electron's charge, was to be approximately equal to half of the atom's atomic weight, expressed in numbers of hydrogen atoms. This central charge would thus be approximately half the atomic weight (though it was almost 25% different from the atomic number of gold ("Z" = 79, "A" = 197), the single element from which Rutherford made his guess). Nevertheless, in spite of Rutherford's estimation that gold had a central charge of about 100 (but was element Z = 79 on the periodic table), a month after Rutherford's paper appeared, Antonius van den Broek first formally suggested that the central charge and number of electrons in an atom was "exactly" equal to its place in the periodic table (also known as element number, atomic number, and symbolized "Z"). This proved eventually to be the case.
<h3>Moseley's 1913 experiment.</h3>
The experimental position improved dramatically after research by Henry Moseley in 1913. Moseley, after discussions with Bohr who was at the same lab (and who had used Van den Broek's hypothesis in his Bohr model of the atom), decided to test Van den Broek's and Bohr's hypothesis directly, by seeing if spectral lines emitted from excited atoms fitted the Bohr theory's postulation that the frequency of the spectral lines be proportional to the square of "Z".
To do this, Moseley measured the wavelengths of the innermost photon transitions (K and L lines) produced by the elements from aluminum ("Z" = 13) to gold ("Z" = 79) used as a series of movable anodic targets inside an x-ray tube. The square root of the frequency of these photons (x-rays) increased from one target to the next in an arithmetic progression. This led to the conclusion (Moseley's law) that the atomic number does closely correspond (with an offset of one unit for K-lines, in Moseley's work) to the calculated electric charge of the nucleus, i.e. the element number "Z". Among other things, Moseley demonstrated that the lanthanide series (from lanthanum to lutetium inclusive) must have 15 members—no fewer and no more—which was far from obvious from the chemistry at that time.
<h3>The proton and the idea of nuclear electrons.</h3>
In 1915 the reason for nuclear charge being quantized in units of Z, which were now recognized to be the same as the element number, was not understood. An old idea called Prout's hypothesis had postulated that the elements were all made of residues (or "protyles") of the lightest element hydrogen, which in the Bohr-Rutherford model had a single electron and a nuclear charge of one. However, as early as 1907 Rutherford and Thomas Royds had shown that alpha particles, which had a charge of +2, were the nuclei of helium atoms, which had a mass four times that of hydrogen, not two times. If Prout's hypothesis were true, something had to be neutralizing some of the charge of the hydrogen nuclei present in the nuclei of heavier atoms.
In 1917 Rutherford succeeded in generating hydrogen nuclei from a nuclear reaction between alpha particles and nitrogen gas, and believed he had proven Prout's law. He called the new heavy nuclear particles protons in 1920 (alternate names being proutons and protyles). It had been immediately apparent from the work of Moseley that the nuclei of heavy atoms have more than twice as much mass as would be expected from their being made of hydrogen nuclei, and thus there was required a hypothesis for the neutralization of the extra protons presumed present in all heavy nuclei. A helium nucleus was presumed to be composed of four protons plus two "nuclear electrons" (electrons bound inside the nucleus) to cancel two of the charges. At the other end of the periodic table, a nucleus of gold with a mass 197 times that of hydrogen, was thought to contain 118 nuclear electrons in the nucleus to give it a residual charge of + 79, consistent with its atomic number.
<h3>The discovery of the neutron makes Z the proton number.</h3>
All consideration of nuclear electrons ended with James Chadwick's discovery of the neutron in 1932. An atom of gold now was seen as containing 118 neutrons rather than 118 nuclear electrons, and its positive charge now was realized to come entirely from a content of 79 protons. After 1932, therefore, an element's atomic number Z was also realized to be identical to the proton number of its nuclei.
<h2>The symbol of Z.</h2>
The conventional symbol "Z" possibly comes from the German word (atomic number). However, prior to 1915, the word "Zahl" (simply "number") was used for an element's assigned number in the periodic table.
<h2>Chemical properties.</h2>
Each element has a specific set of chemical properties as a consequence of the number of electrons present in the neutral atom, which is "Z" (the atomic number). The configuration of these electrons follows from the principles of quantum mechanics. The number of electrons in each element's electron shells, particularly the outermost valence shell, is the primary factor in determining its chemical bonding behavior. Hence, it is the atomic number alone that determines the chemical properties of an element; and it is for this reason that an element can be defined as consisting of "any" mixture of atoms with a given atomic number.
<h2>New elements.</h2>
The quest for new elements is usually described using atomic numbers. As of 2010, elements with atomic numbers 1 to 118 have been observed. Synthesis of new elements is accomplished by bombarding target atoms of heavy elements with ions, such that the sum of the atomic numbers of the target and ion elements equals the atomic number of the element being created. In general, the half-life becomes shorter as atomic number increases, though an "island of stability" may exist for undiscovered isotopes with certain numbers of protons and neutrons.

</doc>
<doc id="674" url="https://en.wikipedia.org/wiki?curid=674" title="Anatomy">
Anatomy

Anatomy is the branch of biology concerned with the study of the structure of organisms and their parts. Anatomy is inherently tied to embryology, comparative anatomy, evolutionary biology, and phylogeny, as these are the processes by which anatomy is generated over immediate (embryology) and long (evolution) timescales. Human anatomy is one of the basic essential sciences of medicine.
The discipline of anatomy is divided into macroscopic and microscopic anatomy. Macroscopic anatomy, or gross anatomy, is the examination of an animal's body parts using unaided eyesight. Gross anatomy also includes the branch of superficial anatomy. Microscopic anatomy involves the use of optical instruments in the study of the tissues of various structures, known as histology, and also in the study of cells.
The history of anatomy is characterized by a progressive understanding of the functions of the organs and structures of the human body. Methods have also improved dramatically, advancing from the examination of animals by dissection of carcasses and cadavers (corpses) to 20th century medical imaging techniques including X-ray, ultrasound, and magnetic resonance imaging.
Anatomy and physiology, which study (respectively) the structure and function of organisms and their parts, make a natural pair of related disciplines, and they are often studied together.
<h2>Definition.</h2>
Derived from the Greek "anatemnō" "I cut up, cut open" from ἀνά "ana" "up", and τέμνω "temnō" "I cut", anatomy is the scientific study of the structure of organisms including their systems, organs and tissues. It includes the appearance and position of the various parts, the materials from which they are composed, their locations and their relationships with other parts. Anatomy is quite distinct from physiology and biochemistry, which deal respectively with the functions of those parts and the chemical processes involved. For example, an anatomist is concerned with the shape, size, position, structure, blood supply and innervation of an organ such as the liver; while a physiologist is interested in the production of bile, the role of the liver in nutrition and the regulation of bodily functions.
The discipline of anatomy can be subdivided into a number of branches including gross or macroscopic anatomy and microscopic anatomy. Gross anatomy is the study of structures large enough to be seen with the naked eye, and also includes superficial anatomy or surface anatomy, the study by sight of the external body features. Microscopic anatomy is the study of structures on a microscopic scale, including histology (the study of tissues), and embryology (the study of an organism in its immature condition).
Anatomy can be studied using both invasive and non-invasive methods with the goal of obtaining information about the structure and organization of organs and systems. Methods used include dissection, in which a body is opened and its organs studied, and endoscopy, in which a video camera-equipped instrument is inserted through a small incision in the body wall and used to explore the internal organs and other structures. Angiography using X-rays or magnetic resonance angiography are methods to visualize blood vessels.
The term "anatomy" is commonly taken to refer to human anatomy. However, substantially the same structures and tissues are found throughout the rest of the animal kingdom and the term also includes the anatomy of other animals. The term "zootomy" is also sometimes used to specifically refer to animals. The structure and tissues of plants are of a dissimilar nature and they are studied in plant anatomy.
<h2>Animal tissues.</h2>
The kingdom Animalia or metazoa, contains multicellular organisms that are heterotrophic and motile (although some have secondarily adopted a sessile lifestyle). Most animals have bodies differentiated into separate tissues and these animals are also known as eumetazoans. They have an internal digestive chamber, with one or two openings; the gametes are produced in multicellular sex organs, and the zygotes include a blastula stage in their embryonic development. Metazoans do not include the sponges, which have undifferentiated cells.
Unlike plant cells, animal cells have neither a cell wall nor chloroplasts. Vacuoles, when present, are more in number and much smaller than those in the plant cell. The body tissues are composed of numerous types of cell, including those found in muscles, nerves and skin. Each typically has a cell membrane formed of phospholipids, cytoplasm and a nucleus. All of the different cells of an animal are derived from the embryonic germ layers. Those simpler invertebrates which are formed from two germ layers of ectoderm and endoderm are called diploblastic and the more developed animals whose structures and organs are formed from three germ layers are called triploblastic. All of a triploblastic animal's tissues and organs are derived from the three germ layers of the embryo, the ectoderm, mesoderm and endoderm.
Animal tissues can be grouped into four basic types: connective, epithelial, muscle and nervous tissue.
<h3>Connective tissue.</h3>
Connective tissues are fibrous and made up of cells scattered among inorganic material called the extracellular matrix. Connective tissue gives shape to organs and holds them in place. The main types are loose connective tissue, adipose tissue, fibrous connective tissue, cartilage and bone. The extracellular matrix contains proteins, the chief and most abundant of which is collagen. Collagen plays a major part in organizing and maintaining tissues. The matrix can be modified to form a skeleton to support or protect the body. An exoskeleton is a thickened, rigid cuticle which is stiffened by mineralization, as in crustaceans or by the cross-linking of its proteins as in insects. An endoskeleton is internal and present in all developed animals, as well as in many of those less developed.
<h3>Epithelium.</h3>
Epithelial tissue is composed of closely packed cells, bound to each other by cell adhesion molecules, with little intercellular space. Epithelial cells can be squamous (flat), cuboidal or columnar and rest on a basal lamina, the upper layer of the basement membrane, the lower layer is the reticular lamina lying next to the connective tissue in the extracellular matrix secreted by the epithelial cells. There are many different types of epithelium, modified to suit a particular function. In the respiratory tract there is a type of ciliated epithelial lining; in the small intestine there are microvilli on the epithelial lining and in the large intestine there are intestinal villi. Skin consists of an outer layer of keratinized stratified squamous epithelium that covers the exterior of the vertebrate body. Keratinocytes make up to 95% of the cells in the skin. The epithelial cells on the external surface of the body typically secrete an extracellular matrix in the form of a cuticle. In simple animals this may just be a coat of glycoproteins. In more advanced animals, many glands are formed of epithelial cells.
<h3>Muscle tissue.</h3>
Muscle cells (myocytes) form the active contractile tissue of the body. Muscle tissue functions to produce force and cause motion, either locomotion or movement within internal organs. Muscle is formed of contractile filaments and is separated into three main types; smooth muscle, skeletal muscle and cardiac muscle. Smooth muscle has no striations when examined microscopically. It contracts slowly but maintains contractibility over a wide range of stretch lengths. It is found in such organs as sea anemone tentacles and the body wall of sea cucumbers. Skeletal muscle contracts rapidly but has a limited range of extension. It is found in the movement of appendages and jaws. Obliquely striated muscle is intermediate between the other two. The filaments are staggered and this is the type of muscle found in earthworms that can extend slowly or make rapid contractions. In higher animals striated muscles occur in bundles attached to bone to provide movement and are often arranged in antagonistic sets. Smooth muscle is found in the walls of the uterus, bladder, intestines, stomach, oesophagus, respiratory airways, and blood vessels. Cardiac muscle is found only in the heart, allowing it to contract and pump blood round the body.
<h3>Nervous tissue.</h3>
Nervous tissue is composed of many nerve cells known as neurons which transmit information. In some slow-moving radially symmetrical marine animals such as ctenophores and cnidarians (including sea anemones and jellyfish), the nerves form a nerve net, but in most animals they are organized longitudinally into bundles. In simple animals, receptor neurons in the body wall cause a local reaction to a stimulus. In more complex animals, specialized receptor cells such as chemoreceptors and photoreceptors are found in groups and send messages along neural networks to other parts of the organism. Neurons can be connected together in ganglia. In higher animals, specialized receptors are the basis of sense organs and there is a central nervous system (brain and spinal cord) and a peripheral nervous system. The latter consists of sensory nerves that transmit information from sense organs and motor nerves that influence target organs. The peripheral nervous system is divided into the somatic nervous system which conveys sensation and controls voluntary muscle, and the autonomic nervous system which involuntarily controls smooth muscle, certain glands and internal organs, including the stomach.
<h2>Vertebrate anatomy.</h2>
All vertebrates have a similar basic body plan and at some point in their lives, (mostly in the embryonic stage), share the major chordate characteristics; a stiffening rod, the notochord; a dorsal hollow tube of nervous material, the neural tube; pharyngeal arches; and a tail posterior to the anus. The spinal cord is protected by the vertebral column and is above the notochord and the gastrointestinal tract is below it. Nervous tissue is derived from the ectoderm, connective tissues are derived from mesoderm, and gut is derived from the endoderm. At the posterior end is a tail which continues the spinal cord and vertebrae but not the gut. The mouth is found at the anterior end of the animal, and the anus at the base of the tail. The defining characteristic of a vertebrate is the vertebral column, formed in the development of the segmented series of vertebrae. In most vertebrates the notochord becomes the nucleus pulposus of the intervertebral discs. However, a few vertebrates, such as the sturgeon and the coelacanth retain the notochord into adulthood. Jawed vertebrates are typified by paired appendages, fins or legs, which may be secondarily lost. The limbs of vertebrates are considered to be homologous because the same underlying skeletal structure was inherited from their last common ancestor. This is one of the arguments put forward by Charles Darwin to support his theory of evolution.
<h3>Fish anatomy.</h3>
The body of a fish is divided into a head, trunk and tail, although the divisions between the three are not always externally visible. The skeleton, which forms the support structure inside the fish, is either made of cartilage, in cartilaginous fish, or bone in bony fish. The main skeletal element is the vertebral column, composed of articulating vertebrae which are lightweight yet strong. The ribs attach to the spine and there are no limbs or limb girdles. The main external features of the fish, the fins, are composed of either bony or soft spines called rays, which with the exception of the caudal fins, have no direct connection with the spine. They are supported by the muscles which compose the main part of the trunk. The heart has two chambers and pumps the blood through the respiratory surfaces of the gills and on round the body in a single circulatory loop. The eyes are adapted for seeing underwater and have only local vision. There is an inner ear but no external or middle ear. Low frequency vibrations are detected by the lateral line system of sense organs that run along the length of the sides of fish, and these respond to nearby movements and to changes in water pressure.
Sharks and rays are basal fish with numerous primitive anatomical features similar to those of ancient fish, including skeletons composed of cartilage. Their bodies tend to be dorso-ventrally flattened, they usually have five pairs of gill slits and a large mouth set on the underside of the head. The dermis is covered with separate dermal placoid scales. They have a cloaca into which the urinary and genital passages open, but not a swim bladder. Cartilaginous fish produce a small number of large, yolky eggs. Some species are ovoviviparous and the young develop internally but others are oviparous and the larvae develop externally in egg cases.
The bony fish lineage shows more derived anatomical traits, often with major evolutionary changes from the features of ancient fish. They have a bony skeleton, are generally laterally flattened, have five pairs of gills protected by an operculum, and a mouth at or near the tip of the snout. The dermis is covered with overlapping scales. Bony fish have a swim bladder which helps them maintain a constant depth in the water column, but not a cloaca. They mostly spawn a large number of small eggs with little yolk which they broadcast into the water column.
<h3>Amphibian anatomy.</h3>
Amphibians are a class of animals comprising frogs, salamanders and caecilians. They are tetrapods, but the caecilians and a few species of salamander have either no limbs or their limbs are much reduced in size. Their main bones are hollow and lightweight and are fully ossified and the vertebrae interlock with each other and have articular processes. Their ribs are usually short and may be fused to the vertebrae. Their skulls are mostly broad and short, and are often incompletely ossified. Their skin contains little keratin and lacks scales, but contains many mucous glands and in some species, poison glands. The hearts of amphibians have three chambers, two atria and one ventricle. They have a urinary bladder and nitrogenous waste products are excreted primarily as urea. Amphibians breathe by means of buccal pumping, a pump action in which air is first drawn into the buccopharyngeal region through the nostrils. These are then closed and the air is forced into the lungs by contraction of the throat. They supplement this with gas exchange through the skin which needs to be kept moist.
In frogs the pelvic girdle is robust and the hind legs are much longer and stronger than the forelimbs. The feet have four or five digits and the toes are often webbed for swimming or have suction pads for climbing. Frogs have large eyes and no tail. Salamanders resemble lizards in appearance; their short legs project sideways, the belly is close to or in contact with the ground and they have a long tail. Caecilians superficially resemble earthworms and are limbless. They burrow by means of zones of muscle contractions which move along the body and they swim by undulating their body from side to side.
<h3>Reptile anatomy.</h3>
Reptiles are a class of animals comprising turtles, tuataras, lizards, snakes and crocodiles. They are tetrapods, but the snakes and a few species of lizard either have no limbs or their limbs are much reduced in size. Their bones are better ossified and their skeletons stronger than those of amphibians. The teeth are conical and mostly uniform in size. The surface cells of the epidermis are modified into horny scales which create a waterproof layer. Reptiles are unable to use their skin for respiration as do amphibians and have a more efficient respiratory system drawing air into their lungs by expanding their chest walls. The heart resembles that of the amphibian but there is a septum which more completely separates the oxygenated and deoxygenated bloodstreams. The reproductive system is designed for internal fertilization, with a copulatory organ present in most species. The eggs are surrounded by amniotic membranes which prevents them from drying out and are laid on land, or develop internally in some species. The bladder is small as nitrogenous waste is excreted as uric acid.
Turtles are notable for their protective shells. They have an inflexible trunk encased in a horny carapace above and a plastron below. These are formed from bony plates embedded in the dermis which are overlain by horny ones and are partially fused with the ribs and spine. The neck is long and flexible and the head and the legs can be drawn back inside the shell. Turtles are vegetarians and the typical reptile teeth have been replaced by sharp, horny plates. In aquatic species, the front legs are modified into flippers.
Tuataras superficially resemble lizards but the lineages diverged in the Triassic period. There is one living species, "Sphenodon punctatus". The skull has two openings (fenestrae) on either side and the jaw is rigidly attached to the skull. There is one row of teeth in the lower jaw and this fits between the two rows in the upper jaw when the animal chews. The teeth are merely projections of bony material from the jaw and eventually wear down. The brain and heart are more primitive than those of other reptiles, and the lungs have a single chamber and lack bronchi. The tuatara has a well-developed parietal eye on its forehead.
Lizards have skulls with only one fenestra on each side, the lower bar of bone below the second fenestra having been lost. This results in the jaws being less rigidly attached which allows the mouth to open wider. Lizards are mostly quadrupeds, with the trunk held off the ground by short, sideways-facing legs, but a few species have no limbs and resemble snakes. Lizards have moveable eyelids, eardrums are present and some species have a central parietal eye.
Snakes are closely related to lizards, having branched off from a common ancestral lineage during the Cretaceous period, and they share many of the same features. The skeleton consists of a skull, a hyoid bone, spine and ribs though a few species retain a vestige of the pelvis and rear limbs in the form of pelvic spurs. The bar under the second fenestra has also been lost and the jaws have extreme flexibility allowing the snake to swallow its prey whole. Snakes lack moveable eyelids, the eyes being covered by transparent "spectacle" scales. They do not have eardrums but can detect ground vibrations through the bones of their skull. Their forked tongues are used as organs of taste and smell and some species have sensory pits on their heads enabling them to locate warm-blooded prey.
Crocodilians are large, low-slung aquatic reptiles with long snouts and large numbers of teeth. The head and trunk are dorso-ventrally flattened and the tail is laterally compressed. It undulates from side to side to force the animal through the water when swimming. The tough keratinized scales provide body armour and some are fused to the skull. The nostrils, eyes and ears are elevated above the top of the flat head enabling them to remain above the surface of the water when the animal is floating. Valves seal the nostrils and ears when it is submerged. Unlike other reptiles, crocodilians have hearts with four chambers allowing complete separation of oxygenated and deoxygenated blood.
<h3>Bird anatomy.</h3>
Birds are tetrapods but though their hind limbs are used for walking or hopping, their front limbs are wings covered with feathers and adapted for flight. Birds are endothermic, have a high metabolic rate, a light skeletal system and powerful muscles. The long bones are thin, hollow and very light. Air sac extensions from the lungs occupy the centre of some bones. The sternum is wide and usually has a keel and the caudal vertebrae are fused. There are no teeth and the narrow jaws are adapted into a horn-covered beak. The eyes are relatively large, particularly in nocturnal species such as owls. They face forwards in predators and sideways in ducks.
The feathers are outgrowths of the epidermis and are found in localized bands from where they fan out over the skin. Large flight feathers are found on the wings and tail, contour feathers cover the bird's surface and fine down occurs on young birds and under the contour feathers of water birds. The only cutaneous gland is the single uropygial gland near the base of the tail. This produces an oily secretion that waterproofs the feathers when the bird preens. There are scales on the legs, feet and claws on the tips of the toes.
<h3>Mammal anatomy.</h3>
Mammals are a diverse class of animals, mostly terrestrial but some are aquatic and others have evolved flapping or gliding flight. They mostly have four limbs but some aquatic mammals have no limbs or limbs modified into fins and the forelimbs of bats are modified into wings. The legs of most mammals are situated below the trunk, which is held well clear of the ground. The bones of mammals are well ossified and their teeth, which are usually differentiated, are coated in a layer of prismatic enamel. The teeth are shed once (milk teeth) during the animal's lifetime or not at all, as is the case in cetaceans. Mammals have three bones in the middle ear and a cochlea in the inner ear. They are clothed in hair and their skin contains glands which secrete sweat. Some of these glands are specialized as mammary glands, producing milk to feed the young. Mammals breathe with lungs and have a muscular diaphragm separating the thorax from the abdomen which helps them draw air into the lungs. The mammalian heart has four chambers and oxygenated and deoxygenated blood are kept entirely separate. Nitrogenous waste is excreted primarily as urea.
Mammals are amniotes, and most are viviparous, giving birth to live young. The exception to this are the egg-laying monotremes, the platypus and the echidnas of Australia. Most other mammals have a placenta through which the developing foetus obtains nourishment, but in marsupials, the foetal stage is very short and the immature young is born and finds its way to its mother's pouch where it latches on to a nipple and completes its development.
<h4>Human anatomy.</h4>
Humans have the overall body plan of a mammal. Humans have a head, neck, trunk (which includes the thorax and abdomen), two arms and hands and two legs and feet.
Generally, students of certain biological sciences, paramedics, prosthetists and orthotists, physiotherapists, occupational therapists, nurses, and medical students learn gross anatomy and microscopic anatomy from anatomical models, skeletons, textbooks, diagrams, photographs, lectures and tutorials, and in addition, medical students generally also learn gross anatomy through practical experience of dissection and inspection of cadavers. The study of microscopic anatomy (or histology) can be aided by practical experience examining histological preparations (or slides) under a microscope.
Human anatomy, physiology and biochemistry are complementary basic medical sciences, which are generally taught to medical students in their first year at medical school. Human anatomy can be taught regionally or systemically; that is, respectively, studying anatomy by bodily regions such as the head and chest, or studying by specific systems, such as the nervous or respiratory systems. The major anatomy textbook, Gray's Anatomy, has been reorganized from a systems format to a regional format, in line with modern teaching methods. A thorough working knowledge of anatomy is required by physicians, especially surgeons and doctors working in some diagnostic specialties, such as histopathology and radiology.
Academic anatomists are usually employed by universities, medical schools or teaching hospitals. They are often involved in teaching anatomy, and research into certain systems, organs, tissues or cells.
<h2>Invertebrate anatomy.</h2>
Invertebrates constitute a vast array of living organisms ranging from the simplest unicellular eukaryotes such as "Paramecium" to such complex multicellular animals as the octopus, lobster and dragonfly. They constitute about 95% of the animal species. By definition, none of these creatures has a backbone. The cells of single-cell protozoans have the same basic structure as those of multicellular animals but some parts are specialized into the equivalent of tissues and organs. Locomotion is often provided by cilia or flagella or may proceed via the advance of pseudopodia, food may be gathered by phagocytosis, energy needs may be supplied by photosynthesis and the cell may be supported by an endoskeleton or an exoskeleton. Some protozoans can form multicellular colonies.
Metazoans are multicellular organism, different groups of cells of which have separate functions. The most basic types of metazoan tissues are epithelium and connective tissue, both of which are present in nearly all invertebrates. The outer surface of the epidermis is normally formed of epithelial cells and secretes an extracellular matrix which provides support to the organism. An endoskeleton derived from the mesoderm is present in echinoderms, sponges and some cephalopods. Exoskeletons are derived from the epidermis and is composed of chitin in arthropods (insects, spiders, ticks, shrimps, crabs, lobsters). Calcium carbonate constitutes the shells of molluscs, brachiopods and some tube-building polychaete worms and silica forms the exoskeleton of the microscopic diatoms and radiolaria. Other invertebrates may have no rigid structures but the epidermis may secrete a variety of surface coatings such as the pinacoderm of sponges, the gelatinous cuticle of cnidarians (polyps, sea anemones, jellyfish) and the collagenous cuticle of annelids. The outer epithelial layer may include cells of several types including sensory cells, gland cells and stinging cells. There may also be protrusions such as microvilli, cilia, bristles, spines and tubercles.
Marcello Malpighi, the father of microscopical anatomy, discovered that plants had tubules similar to those he saw in insects like the silk worm. He observed that when a ring-like portion of bark was removed on a trunk a swelling occurred in the tissues above the ring, and he unmistakably interpreted this as growth stimulated by food coming down from the leaves, and being captured above the ring.
<h3>Arthropod anatomy.</h3>
Arthropods comprise the largest phylum in the animal kingdom with over a million known invertebrate species.
Insects possess segmented bodies supported by a hard-jointed outer covering, the exoskeleton, made mostly of chitin. The segments of the body are organized into three distinct parts, a head, a thorax and an abdomen. The head typically bears a pair of sensory antennae, a pair of compound eyes, one to three simple eyes (ocelli) and three sets of modified appendages that form the mouthparts. The thorax has three pairs of segmented legs, one pair each for the three segments that compose the thorax and one or two pairs of wings. The abdomen is composed of eleven segments, some of which may be fused and houses the digestive, respiratory, excretory and reproductive systems. There is considerable variation between species and many adaptations to the body parts, especially wings, legs, antennae and mouthparts.
Spiders a class of arachnids have four pairs of legs; a body of two segments—a cephalothorax and an abdomen. Spiders have no wings and no antennae. They have mouthparts called chelicerae which are often connected to venom glands as most spiders are venomous. They have a second pair of appendages called pedipalps attached to the cephalothorax. These have similar segmentation to the legs and function as taste and smell organs. At the end of each male pedipalp is a spoon-shaped cymbium that acts to support the copulatory organ.
<h2>History.</h2>
<h3>Ancient.</h3>
Ancient Greek anatomy and physiology underwent great changes and advances throughout the early medieval world. Over time, this medical practice expanded by a continually developing understanding of the functions of organs and structures in the body. Phenomenal anatomical observations of the human body were made, which have contributed towards the understanding of the brain, eye, liver, reproductive organs and the nervous system.
The city of Alexandria was the stepping-stone for Greek anatomy and physiology. Alexandria not only housed the biggest library for medical records and books of the liberal arts in the world during the time of the Greeks, but was also home to many medical practitioners and philosophers. Great patronage of the arts and sciences from the Ptolemy rulers helped raise Alexandria up, further rivalling the cultural and scientific achievements of other Greek states.
Some of the most striking advances in early anatomy and physiology took place in Hellenistic Alexandria. Two of the most famous Greek anatomists and physiologists of the third century were Herophilus and Erasistratus. These two physicians helped pioneer human dissection for medical research. They also conducted vivisections on the cadavers of condemned criminals, which was considered taboo until the Renaissance – Herophilus was recognized as the first person to perform systematic dissections. Herophilus became known for his anatomical works making impressing contributions to many branches of anatomy and many other aspects of medicine. Some of the works included classifying the system of the pulse, the discovery that human arteries had thicker walls then veins, and that the atria were parts of the heart. Herophilus’s knowledge of the human body has provided vital input towards understanding the brain, eye, liver, reproductive organs and nervous system, and characterizing the course of disease. Erasistratus accurately described the structure of the brain, including the cavities and membranes, and made a distinction between its cerebrum and cerebellum During his study in Alexandria, Erasistratus was particularly concerned with studies of the circulatory and nervous systems. He was able to distinguish the sensory and the motor nerves in the human body and believed that air entered the lungs and heart, which was then carried throughout the body. His distinction between the arteries and veins – the arteries carrying the air through the body, while the veins carried the blood from the heart was a great anatomical discovery. Erasistratus was also responsible for naming and describing the function of the epiglottis and the valves of the heart, including the tricuspid. During the third century, Greek physicians were able to differentiate nerves from blood vessels and tendons and to realize that the nerves convey neural impulses. It was Herophilus who made the point that damage to motor nerves induced paralysis. Herophilus named the meninges and ventricles in the brain, appreciated the division between cerebellum and cerebrum and recognized that the brain was the "seat of intellect" and not a "cooling chamber" as propounded by Aristotle Herophilus is also credited with describing the optic, oculomotor, motor division of the trigeminal, facial, vestibulocochlear and hypoglossal nerves 
Great feats were made during the third century in both the digestive and reproductive systems. Herophilus was able to discover and describe not only the salivary glands, but the small intestine and liver. He showed that the uterus is a hollow organ and described the ovaries and uterine tubes. He recognized that spermatozoa were produced by the testes and was the first to identify the prostate gland.
In 1600 BCE, the Edwin Smith Papyrus, an Ancient Egyptian medical text, described the heart, its vessels, liver, spleen, kidneys, hypothalamus, uterus and bladder, and showed the blood vessels diverging from the heart. The Ebers Papyrus (c. 1550 BCE) features a "treatise on the heart", with vessels carrying all the body's fluids to or from every member of the body.
The anatomy of the muscles and skeleton is described in the "Hippocratic Corpus", an Ancient Greek medical work written by unknown authors. Aristotle described vertebrate anatomy based on animal dissection. Praxagoras identified the difference between arteries and veins. Also in the 4th century BCE, Herophilos and Erasistratus produced more accurate anatomical descriptions based on vivisection of criminals in Alexandria during the Ptolemaic dynasty.
In the 2nd century, Galen of Pergamum, an anatomist, clinician, writer and philosopher, wrote the final and highly influential anatomy treatise of ancient times. He compiled existing knowledge and studied anatomy through dissection of animals. He was one of the first experimental physiologists through his vivisection experiments on animals. Galen's drawings, based mostly on dog anatomy, became effectively the only anatomical textbook for the next thousand years. His work was known to Renaissance doctors only through Islamic Golden Age medicine until it was translated from the Greek some time in the 15th century.
<h3>Medieval to early modern.</h3>
Anatomy developed little from classical times until the sixteenth century; as the historian Marie Boas writes, "Progress in anatomy before the sixteenth century is as mysteriously slow as its development after 1500 is startlingly rapid". Between 1275 and 1326, the anatomists Mondino de Luzzi, Alessandro Achillini and Antonio Benivieni at Bologna carried out the first systematic human dissections since ancient times. Mondino's "Anatomy" of 1316 was the first textbook in the medieval rediscovery of human anatomy. It describes the body in the order followed in Mondino's dissections, starting with the abdomen, then the thorax, then the head and limbs. It was the standard anatomy textbook for the next century.
Leonardo da Vinci (1452–1519) was trained in anatomy by Andrea del Verrocchio. He made use of his anatomical knowledge in his artwork, making many sketches of skeletal structures, muscles and organs of humans and other vertebrates that he dissected.
Andreas Vesalius (1514–1564) (Latinized from Andries van Wezel), professor of anatomy at the University of Padua, is considered the founder of modern human anatomy. Originally from Brabant, Vesalius published the influential book "De humani corporis fabrica" ("the structure of the human body"), a large format book in seven volumes, in 1543. The accurate and intricately detailed illustrations, often in allegorical poses against Italianate landscapes, are thought to have been made by the artist Jan van Calcar, a pupil of Titian.
In England, anatomy was the subject of the first public lectures given in any science; these were given by the Company of Barbers and Surgeons in the 16th century, joined in 1583 by the Lumleian lectures in surgery at the Royal College of Physicians.
<h3>Late modern.</h3>
In the United States, medical schools began to be set up towards the end of the 18th century. Classes in anatomy needed a continual stream of cadavers for dissection and these were difficult to obtain. Philadelphia, Baltimore and New York were all renowned for body snatching activity as criminals raided graveyards at night, removing newly buried corpses from their coffins. A similar problem existed in Britain where demand for bodies became so great that grave-raiding and even anatomy murder were practised to obtain cadavers. Some graveyards were in consequence protected with watchtowers. The practice was halted in Britain by the Anatomy Act of 1832, while in the United States, similar legislation was enacted after the physician William S. Forbes of Jefferson Medical College was found guilty in 1882 of "complicity with resurrectionists in the despoliation of graves in Lebanon Cemetery".
The teaching of anatomy in Britain was transformed by Sir John Struthers, Regius Professor of Anatomy at the University of Aberdeen from 1863 to 1889. He was responsible for setting up the system of three years of "pre-clinical" academic teaching in the sciences underlying medicine, including especially anatomy. This system lasted until the reform of medical training in 1993 and 2003. As well as teaching, he collected many vertebrate skeletons for his museum of comparative anatomy, published over 70 research papers, and became famous for his public dissection of the Tay Whale. From 1822 the Royal College of Surgeons regulated the teaching of anatomy in medical schools. Medical museums provided examples in comparative anatomy, and were often used in teaching. Ignaz Semmelweis investigated puerperal fever and he discovered how it was caused. He noticed that the frequently fatal fever occurred more often in mothers examined by medical students than by midwives. The students went from the dissecting room to the hospital ward and examined women in childbirth. Semmelweis showed that when the trainees washed their hands in chlorinated lime before each clinical examination, the incidence of puerperal fever among the mothers could be reduced dramatically.
Before the era of modern medical procedures, the main means for studying the internal structure of the body were palpation and dissection. It was the advent of microscopy that opened up an understanding of the building blocks that constituted living tissues. Technical advances in the development of achromatic lenses increased the resolving power of the microscope and around 1839, Matthias Jakob Schleiden and Theodor Schwann identified that cells were the fundamental unit of organization of all living things. Study of small structures involved passing light through them and the microtome was invented to provide sufficiently thin slices of tissue to examine. Staining techniques using artificial dyes were established to help distinguish between different types of tissue. The fields of cytology and histology developed from here in the late 19th century. The invention of the electron microscope brought a great advance in resolution power and allowed research into the ultrastructure of cells and the organelles and other structures within them. About the same time, in the 1950s, the use of X-ray diffraction for studying the crystal structures of proteins, nucleic acids and other biological molecules gave rise to a new field of molecular anatomy.
Short wavelength electromagnetic radiation such as X-rays can be passed through the body and used in medical radiography to view interior structures that have different degrees of opaqueness. Nowadays, modern techniques such as magnetic resonance imaging, computed tomography, fluoroscopy and ultrasound imaging have enabled researchers and practitioners to examine organs, living or dead, in unprecedented detail. They are used for diagnostic and therapeutic purposes and provide information on the internal structures and organs of the body to a degree far beyond the imagination of earlier generations.
<h2>Bibliography.</h2>
"Main article:" Bibliography of anatomy

</doc>
<doc id="675" url="https://en.wikipedia.org/wiki?curid=675" title="Affirming the consequent">
Affirming the consequent

Affirming the consequent, sometimes called converse error, fallacy of the converse or confusion of necessity and sufficiency, is a formal fallacy of inferring the converse from the original statement. The corresponding argument has the general form:
An argument of this form is invalid, i.e., the conclusion can be false even when statements 1 and 2 are true. Since "P" was never asserted as the "only" sufficient condition for "Q", other factors could account for "Q" (while "P" was false).
To put it differently, if "P" implies "Q", the only inference that can be made is "non-Q" implies "non-P". ("Non-P" and "non-Q" designate the opposite propositions to "P" and "Q".) This is known as logical contraposition. Symbolically:
formula_1
The name "affirming the consequent" derives from the premise "Q", which affirms the "then" clause of the conditional premise.
<h2>Examples.</h2>
One way to demonstrate the invalidity of this argument form is with a counterexample with true premises but an obviously false conclusion. For example:
Owning Fort Knox is not the "only" way to be rich. Any number of other ways exist to be rich.
However, one can affirm with certainty that "if Bill Gates is not rich" ("non-Q") then "Bill Gates does not own Fort Knox" ("non-P"). This is the contrapositive of the first statement, and it must be true if and only if the original statement is true.
Arguments of the same form can sometimes seem superficially convincing, as in the following example:
But having the flu is not the "only" cause of a sore throat since many illnesses cause sore throat, such as the common cold or strep throat.
Affirming the consequent is commonly used in rationalization, and thus appears as a coping mechanism in some people.

</doc>
<doc id="676" url="https://en.wikipedia.org/wiki?curid=676" title="Andrei Tarkovsky">
Andrei Tarkovsky

Andrei Arsenyevich Tarkovsky (; 4 April 1932 – 29 December 1986) was a Soviet and Russian filmmaker, writer, film editor, film theorist, theatre and opera director.
Tarkovsky's films include "Ivan's Childhood" (1962), "Andrei Rublev" (1966), "Solaris" (1972), "Mirror" (1975), and "Stalker" (1979). He directed the first five of his seven feature films in the Soviet Union; his last two films, "Nostalghia" (1983) and "The Sacrifice" (1986), were produced in Italy and Sweden, respectively. His work is characterized by long takes, unconventional dramatic structure, distinctly authored use of cinematography, and spiritual and metaphysical themes. His contribution to cinema was so influential that works done in a similar way are described as Tarkovskian.
Ingmar Bergman said of Tarkovsky:"Tarkovsky for me is the greatest (director), the one who invented a new language, true to the nature of film, as it captures life as a reflection, life as a dream."
<h2>Life.</h2>
<h3>Childhood and early life.</h3>
Tarkovsky was born in the village of Zavrazhye in the Yuryevetsky District of the Ivanovo Industrial Oblast to poet and translator Arseny Alexandrovich Tarkovsky, native of Kirovohrad, Ukraine; and Maria Ivanova Vishnyakova, a graduate of the Maxim Gorky Literature Institute. Andrei's grandfather Aleksandr Tarkovsky (in ) was a Polish nobleman who worked as a bank clerk.
Tarkovsky spent his childhood in Yuryevets. He was described by childhood friends as active and popular, having many friends and being typically in the center of action. In 1937, his father left the family, subsequently volunteering for the army in 1941. Tarkovsky stayed with his mother, moving with her and his sister Marina to Moscow, where she worked as a proofreader at a printing press. In 1939, Tarkovsky enrolled at the Moscow School № 554. During the war, the three evacuated to Yuryevets, living with his maternal grandmother. In 1943, the family returned to Moscow. Tarkovsky continued his studies at his old school, where the poet Andrey Voznesensky was one of his class-mates. He studied piano at a music school and attended classes at an art school. The family lived on Shchipok Street in the Zamoskvorechye District in Moscow. From November 1947 to Spring 1948 he was in the hospital with tuberculosis. Many themes of his childhood – the evacuation, his mother and her two children, the withdrawn father, the time in the hospital – feature prominently in his film "Mirror".
Following high school graduation, from 1951 to 1952, Tarkovsky studied Arabic at the Oriental Institute in Moscow, a branch of the Academy of Sciences of the USSR. Although he already spoke some Arabic and was a successful student in his first semesters, he did not finish his studies and dropped out to work as a prospector for the Academy of Science Institute for Non-Ferrous Metals and Gold. He participated in a year-long research expedition to the river Kureikye near Turukhansk in the Krasnoyarsk Province. During this time in the Taiga, Tarkovsky decided to study film.
<h3>Film school student.</h3>
Upon returning from the research expedition in 1954, Tarkovsky applied at the State Institute of Cinematography (VGIK) and was admitted to the film directing program. He was in the same class as Irma Raush whom he married in April 1957.
The early Khrushchev era offered unique opportunities for young film directors. Before 1953, annual film production was low and most films were directed by veteran directors. After 1953, more films were produced, many of them by young directors. The Khrushchev Thaw relaxed Soviet social restrictions a bit and permitted a limited influx of European and North American literature, films and music. This allowed Tarkovsky to see films of the Italian neorealists, French New Wave, and of directors such as Kurosawa, Buñuel, Bergman, Bresson, Andrzej Wajda (whose film "Ashes and Diamonds" influenced Tarkovsky) and Mizoguchi. Tarkovsky absorbed the idea of the auteur as a necessary condition for creativity.
Tarkovsky's teacher and mentor was Mikhail Romm, who taught many film students who would later become influential film directors. In 1956, Tarkovsky directed his first student short film, "The Killers", from a short story of Ernest Hemingway. The short film "There Will Be No Leave Today" and the screenplay "Concentrate" followed in 1958 and 1959.
An important influence on Tarkovsky was the film director Grigori Chukhrai, who was teaching at the VGIK. Impressed by the talent of his student, Chukhrai offered Tarkovsky a position as assistant director for his film "Clear Skies". Tarkovsky initially showed interest but then decided to concentrate on his studies and his own projects.
During his third year at the VGIK, Tarkovsky met Andrei Konchalovsky. They found much in common as they liked the same film directors and shared ideas on cinema and films. In 1959, they wrote the script "Antarctica – Distant Country", which was later published in the "Moskovskij Komsomolets". Tarkovsky submitted the script to Lenfilm, but it was rejected. They were more successful with the script "The Steamroller and the Violin", which they sold to Mosfilm. This became Tarkovsky's graduation project, earning him his diploma in 1960 and winning First Prize at the New York Student Film Festival in 1961.
<h2>Career.</h2>
<h3>Film career in the Soviet Union.</h3>
Tarkovsky's first feature film was "Ivan's Childhood" in 1962. He had inherited the film from director Eduard Abalov, who had to abort the project. The film earned Tarkovsky international acclaim and won the Golden Lion award at the Venice Film Festival in the year 1962. In the same year, on 30 September, his first son Arseny (called Senka in Tarkovsky's diaries) Tarkovsky was born.
In 1965, he directed the film "Andrei Rublev" about the life of Andrei Rublev, the fifteenth-century Russian icon painter. "Andrei Rublev" was not, except for a single screening in Moscow in 1966, immediately released after completion due to problems with Soviet authorities. Tarkovsky had to cut the film several times, resulting in several different versions of varying lengths. A version of the film was presented at the Cannes Film Festival in 1969 and won the FIPRESCI prize. The film was widely released in the Soviet Union in a cut version in 1971.
He divorced his wife, Irma Raush, in June 1970. In the same year, he married Larissa Kizilova (née Egorkina), who had been a production assistant for the film "Andrei Rublev" (they had been living together since 1965). Their son, Andrei Andreyevich Tarkovsky, was born in the same year on 7 August.
In 1972, he completed "Solaris", an adaptation of the novel "Solaris" by Stanisław Lem. He had worked on this together with screenwriter Fridrikh Gorenshtein as early as 1968. The film was presented at the Cannes Film Festival, won the Grand Prix Spécial du Jury and the FIPRESCI prize, and was nominated for the Palme d'Or. From 1973 to 1974, he shot the film "Mirror", a highly autobiographical and unconventionally structured film drawing on his childhood and incorporating some of his father's poems. Tarkovsky had worked on the screenplay for this film since 1967, under the consecutive titles "Confession", "White day" and "A white, white day". From the beginning the film was not well received by Soviet authorities due to its content and its perceived elitist nature. Russian authorities placed the film in the "third category," a severely limited distribution, and only allowed it to be shown in third-class cinemas and workers' clubs. Few prints were made and the film-makers received no returns. Third category films also placed the film-makers in danger of being accused of wasting public funds, which could have serious effects on their future productivity. These difficulties are presumed to have made Tarkovsky play with the idea of going abroad and producing a film outside the Soviet film industry.
During 1975, Tarkovsky also worked on the screenplay "Hoffmanniana", about the German writer and poet E. T. A. Hoffmann. In December 1976, he directed "Hamlet", his only stage play, at the Lenkom Theatre in Moscow. The main role was played by Anatoly Solonitsyn, who also acted in several of Tarkovsky's films. At the end of 1978, he also wrote the screenplay "Sardor" together with the writer Aleksandr Misharin.
The last film Tarkovsky completed in the Soviet Union was "Stalker", inspired by the novel "Roadside Picnic" by the brothers Arkady and Boris Strugatsky. Tarkovsky had met the brothers first in 1971 and was in contact with them until his death in 1986. Initially he wanted to shoot a film based on their novel "Dead Mountaineer's Hotel" and he developed a raw script. Influenced by a discussion with Arkady Strugatsky he changed his plan and began to work on the script based on "Roadside Picnic". Work on this film began in 1976. The production was mired in troubles; improper development of the negatives had ruined all the exterior shots. Tarkovsky's relationship with cinematographer Georgy Rerberg deteriorated to the point where he hired Alexander Knyazhinsky as a new first cinematographer. Furthermore, Tarkovsky suffered a heart attack in April 1978, resulting in further delay. The film was completed in 1979 and won the Prize of the Ecumenical Jury at the Cannes Film Festival.
In the same year Tarkovsky also began the production of the film "The First Day" (Russian: Первый День "Pervyj Dyen′"), based on a script by his friend and long-term collaborator Andrei Konchalovsky. The film was set in 18th-century Russia during the reign of Peter the Great and starred Natalya Bondarchuk and Anatoli Papanov. To get the project approved by Goskino, Tarkovsky submitted a script that was different from the original script, omitting several scenes that were critical of the official atheism in the Soviet Union. After shooting roughly half of the film the project was stopped by Goskino after it became apparent that the film differed from the script submitted to the censors. Tarkovsky was reportedly infuriated by this interruption and destroyed most of the film.
<h3>Film career outside the Soviet Union.</h3>
During the summer of 1979, Tarkovsky traveled to Italy, where he shot the documentary "Voyage in Time" together with his long-time friend Tonino Guerra. Tarkovsky returned to Italy in 1980 for an extended trip during which he and Guerra completed the script for the film "Nostalghia".
Tarkovsky returned to Italy in 1982 to start shooting "Nostalghia". He did not return to his home country. As Mosfilm withdrew from the project, he had to complete the film with financial support provided by the Italian RAI. Tarkovsky completed the film in 1983. "Nostalghia" was presented at the Cannes Film Festival and won the FIPRESCI prize and the Prize of the Ecumenical Jury. Tarkovsky also shared a special prize called "Grand Prix du cinéma de creation" with Robert Bresson. Soviet authorities prevented the film from winning the Palme d'Or, a fact that hardened Tarkovsky's resolve to never work in the Soviet Union again. In the same year, he also staged the opera "Boris Godunov" at the Royal Opera House in London under the musical direction of Claudio Abbado.
He spent most of 1984 preparing the film "The Sacrifice". At a press conference in Milan on 10 July 1984, he announced that he would never return to the Soviet Union and would remain in Europe. At that time, his son Andrei Jr. was still in the Soviet Union and not allowed to leave the country.
During 1985, he shot the film "The Sacrifice" in Sweden. At the end of the year he was diagnosed with terminal lung cancer. In January 1986, he began treatment in Paris and was joined there by his son, who was finally allowed to leave the Soviet Union. "The Sacrifice" was presented at the Cannes Film Festival and received the Grand Prix Spécial du Jury, the FIPRESCI prize and the Prize of the Ecumenical Jury. As Tarkovsky was unable to attend due to his illness, the prizes were collected by his son, Andrei Jr.
In Tarkovsky's last entry (15 December 1986), he wrote: "But now I have no strength left – that is the problem". The diaries are sometimes also known as "" and were published posthumously in 1989 and in English in 1991.
Tarkovsky died in Paris on 29 December 1986. His funeral ceremony was held at the Alexander Nevsky Cathedral. He was buried on 3 January 1987 in the Russian Cemetery in Sainte-Geneviève-des-Bois in France. The inscription on his gravestone, which was created by the Russian sculptor Ernst Neizvestny, reads: "To the man who saw the Angel".
A controversy emerged in Russia in the early 1990s when it was alleged that Tarkovsky did not die of natural causes but was assassinated by the KGB. Evidence for this hypothesis includes testimonies by former KGB agents who claim that Viktor Chebrikov gave the order to eradicate Tarkovsky to curtail what the Soviet government and the KGB saw as anti-Soviet propaganda by Tarkovsky. Other evidence includes several memoranda that surfaced after the 1991 coup and the claim by one of Tarkovsky's doctors that his cancer could not have developed from a natural cause.
As Tarkovsky, his wife Larisa Tarkovskaya and actor Anatoli Solonitsyn all died from the very same type of lung cancer, Vladimir Sharun, sound designer in "Stalker", is convinced that they were all poisoned when shooting the film near a chemical plant.
<h3>Filmography.</h3>
Tarkovsky is mainly known as a film director. During his career he directed only seven feature films, as well as three shorts from his time at VGIK. He also wrote several screenplays. He furthermore directed the play "Hamlet" for the stage in Moscow, directed the opera "Boris Godunov" in London, and he directed a radio production of the short story "Turnabout" by William Faulkner. He also wrote "Sculpting in Time", a book on film theory.
Tarkovsky's first feature film was "Ivan's Childhood" in 1962. He then directed "Andrei Rublev" in 1966, "Solaris" in 1972, "Mirror" in 1975 and "Stalker" in 1979. The documentary "Voyage in Time" was produced in Italy in 1982, as was "Nostalghia" in 1983. His last film "The Sacrifice" was produced in Sweden in 1986. Tarkovsky was personally involved in writing the screenplays for all his films, sometimes with a cowriter. Tarkovsky once said that a director who realizes somebody else's screenplay without being involved in it becomes a mere illustrator, resulting in dead and monotonous films.
A book of 60 photos, "Instant Light, Tarkovsky Polaroids", taken by Tarkovsky in Russia and Italy between 1979 and 1984 was published in 2006. The collection was selected by Italian photographer Giovanni Chiaramonte and Tarkovsky's son Andrey A. Tarkovsky.
<h3>Awards.</h3>
Numerous awards were bestowed on Tarkovsky throughout his lifetime. At the Venice Film Festival he was awarded the Golden Lion for "Ivan's Childhood". At the Cannes Film Festival, he won the FIPRESCI prize four times, the Prize of the Ecumenical Jury three times (more than any other director), and the Grand Prix Spécial du Jury twice. He was also nominated for the Palme d'Or two times. In 1987, the British Academy of Film and Television Arts awarded the BAFTA Award for Best Foreign Language Film to "The Sacrifice".
Under the influence of Glasnost and Perestroika, Tarkovsky was finally recognized in the Soviet Union in the Autumn of 1986, shortly before his death, by a retrospective of his films in Moscow. After his death, an entire issue of the film magazine "Iskusstvo Kino" was devoted to Tarkovsky. In their obituaries, the film committee of the Council of Ministers of the USSR and the Union of Soviet Film Makers expressed their sorrow that Tarkovsky had to spend the last years of his life in exile.
Posthumously, he was awarded the Lenin Prize in 1990, one of the highest state honors in the Soviet Union. In 1989 the "Andrei Tarkovsky Memorial Prize" was established, with its first recipient being the Russian animator Yuriy Norshteyn. Since 1993, the Moscow International Film Festival awards the annual "Andrei Tarkovsky Award". In 1996 the Andrei Tarkovsky Museum opened in Yuryevets, his childhood town. A minor planet, 3345 Tarkovskij, discovered by Soviet astronomer Lyudmila Georgievna Karachkina in 1982, has also been named after him.
Tarkovsky has been the subject of several documentaries. Most notable is the 1988 documentary "Moscow Elegy", by Russian film director Alexander Sokurov. Sokurov's own work has been heavily influenced by Tarkovsky. The film consists mostly of narration over stock footage from Tarkovsky's films. "Directed by Andrei Tarkovsky" is 1988 documentary film by Michal Leszczylowski, an editor of the film "The Sacrifice". Film director Chris Marker produced the television documentary "One Day in the Life of Andrei Arsenevich" as an homage to Andrei Tarkovsky in 2000.
Ingmar Bergman was quoted as saying: "Tarkovsky for me is the greatest [of us all], the one who invented a new language, true to the nature of film, as it captures life as a reflection, life as a dream". Film historian Steven Dillon claims that much of subsequent film was deeply influenced by the films of Tarkovsky.
At the entrance to the Gerasimov Institute of Cinematography in Moscow, Russia there is a monument that includes statues of Tarkovsky, Gennady Shpalikov and Vasily Shukshin.
<h2>Concentrate.</h2>
Concentrate (, "Konsentrat") is a never-filmed 1958 screenplay by Russian film director Andrei Tarkovsky. The screenplay is based on Tarkovsky's year in the taiga as a member of a research expedition, prior to his enrollment in film school.
<h3>Plot.</h3>
"Concentrate" is about the leader of a geological expedition, who waits for the boat that brings back the concentrates collected by the expedition. The expedition is surrounded by mystery, and its purpose is a state secret. This screenplay refers to Tarkovsky's year in the taiga, where he was a member of a research expedition prior to enrolling at the film school.
<h3>Background.</h3>
Although some authors claim that the screenplay was filmed, according to Marina Tarkovskaya, Tarkovsky's sister (and wife of Aleksandr Gordon, a fellow student of Tarvosky during his film school years) the screenplay was never filmed. Tarkovsky wrote the screenplay during his entrance examination at the State Institute of Cinematography (VGIK) in a single sitting. He earned the highest possible grade, excellent () for this work. In 1994 fragments of the "Concentrate" were filmed and used in the documentary "Andrei Tarkovsky's Taiga Summer" by Marina Tarkovskaya and Aleksandr Gordon.
<h2>Hoffmanniana.</h2>
Hoffmanniana () is a never-filmed 1974 screenplay by Russian film director Andrei Tarkovsky. The screenplay is based on the life and work of German author E. T. A. Hoffmann. In 1974 an acquaintance from Tallinnfilm approached Tarkovsky to write a screenplay on a German theme. Tarkovsky considered Thomas Mann and E.T.A. Hoffmann, and also thought about Ibsen's "Peer Gynt". In the end Tarkovsky signed a contract for a script based on the life and work of Hoffmann. Tarkovsky planned to write the script during the summer of 1974 at his dacha. Writing was not without difficulty, less than a month before the deadline he had not written a single page. He finally finished the project in late 1974 and submitted the final script to Tallinnfilm in October.
Although the script was well received by the officials at Tallinnfilm, it was the consensus that no one but Tarkovsky would be able to direct it. The script was sent to Goskino in February 1976, and although approval was granted for proceeding with making the film the screenplay was never realized. In 1984, during the time of his exile in the West, Tarkovsky revisited the screenplay and made a few changes. He also considered to finally direct a film based on the screenplay but ultimately dropped this idea.
<h2>Influences.</h2>
Tarkovsky became a film director during the mid and late 1950s, a period referred to as the Khrushchev Thaw, during which Soviet society opened to foreign films, literature and music, among other things. This allowed Tarkovsky to see films of European, American and Japanese directors, an experience which influenced his own film making. His teacher and mentor at the film school, Mikhail Romm, allowed his students considerable freedom and emphasized the independence of the film director.
Tarkovsky was, according to Shavkat Abdusalmov, a fellow student at the film school, fascinated by Japanese films. He was amazed by how every character on the screen is exceptional and how everyday events such as a Samurai cutting bread with his sword are elevated to something special and put into the limelight. Tarkovsky has also expressed interest in the art of Haiku and its ability to create "images in such a way that they mean nothing beyond themselves."
Tarkovsky perceived that the art of cinema has only been truly mastered by very few filmmakers, stating in a 1970 interview with Naum Abramov that "they can be counted on the fingers of one hand." In 1972, Tarkovsky told film historian Leonid Kozlov his ten favorite films. The list includes: "Diary of a Country Priest" and "Mouchette" by Robert Bresson; "Winter Light", "Wild Strawberries", and "Persona" by Ingmar Bergman; "Nazarín" by Luis Buñuel; "City Lights" by Charlie Chaplin; "Ugetsu" by Kenji Mizoguchi; "Seven Samurai" by Akira Kurosawa, and "Woman in the Dunes" by Hiroshi Teshigahara. Among his favorite directors were Buñuel, Mizoguchi, Bergman, Bresson, Kurosawa, Michelangelo Antonioni, Jean Vigo, and Carl Theodor Dreyer.
With the exception of "City Lights", the list does not contain any films of the early silent era. The reason is that Tarkovsky saw film as an art as only a relatively recent phenomenon, with the early film-making forming only a prelude. The list has also no films or directors from Tarkovsky's native Russia, although he rated Soviet directors such as Boris Barnet, Sergei Parajanov and Alexander Dovzhenko highly.
Although strongly opposed to commercial cinema, in a famous exception Tarkovsky praised the blockbuster film "The Terminator", saying its "vision of the future and the relation between man and its destiny is pushing the frontier of cinema as an art". He was critical of the "brutality and low acting skills", but nevertheless impressed by this film.
<h2>Cinematic style.</h2>
Tarkovsky's films are characterized by metaphysical themes, extremely long takes, and memorable images of exceptional beauty. Recurring motifs are dreams, memory, childhood, running water accompanied by fire, rain indoors, reflections, levitation, and characters re-appearing in the foreground of long panning movements of the camera. He once said, "Juxtaposing a person with an environment that is boundless, collating him with a countless number of people passing by close to him and far away, relating a person to the whole world, that is the meaning of cinema.”
Tarkovsky incorporated levitation scenes into several of his films, most notably "Solaris". To him these scenes possess great power and are used for their photogenic value and magical inexplicability.
Water, clouds, and reflections were used by him for their surreal beauty and photogenic value, as well as their symbolism, such as waves or the forms of brooks or running water.
Bells and candles are also frequent symbols. These are symbols of film, sight and sound, and Tarkovsky's film frequently has themes of self-reflection.
Tarkovsky developed a theory of cinema that he called "sculpting in time". By this he meant that the unique characteristic of cinema as a medium was to take our experience of time and alter it. Unedited movie footage transcribes time in real time. By using long takes and few cuts in his films, he aimed to give the viewers a sense of time passing, time lost, and the relationship of one moment in time to another.
Up to, and including, his film "Mirror", Tarkovsky focused his cinematic works on exploring this theory. After "Mirror", he announced that he would focus his work on exploring the dramatic unities proposed by Aristotle: a concentrated action, happening in one place, within the span of a single day.
Several of Tarkovsky's films have color or black and white sequences. This first occurs in the otherwise monochrome "Andrei Rublev", which features a color epilogue of Rublev's authentic religious icon paintings. All of his films afterwards contain monochrome, and in "Stalker's" case sepia sequences, while otherwise being in color. In 1966, in an interview conducted shortly after finishing "Andrei Rublev", Tarkovsky dismissed color film as a "commercial gimmick" and cast doubt on the idea that contemporary films meaningfully use color. He claimed that in everyday life one does not consciously notice colors most of the time, and that color should therefore be used in film mainly to emphasize certain moments, but not all the time, as this distracts the viewer. To him, films in color were like moving paintings or photographs, which are too beautiful to be a realistic depiction of life.
<h3>Vadim Yusov.</h3>
Tarkovsky worked in close collaboration with cinematographer Vadim Yusov from 1958 to 1972, and much of the visual style of Tarkovsky's films can be attributed to this collaboration. Tarkovsky would spend two days preparing for Yusov to film a single long take, and due to the preparation, usually only a single take was needed.
<h3>Sven Nykvist.</h3>
In his last film, "The Sacrifice", Tarkovsky worked with cinematographer Sven Nykvist, who had worked closely with director Ingmar Bergman on many of Ingmar Bergman's films – multiple people who worked with Bergman worked on the production, notably lead actor Erland Josephson, who had acted for Tarkovsky in "Nostalghia". Nykvist complained that Tarkovsky would frequently look through the camera and even direct actors through it.
<h2>References.</h2>
Notes
Bibliography

</doc>
<doc id="677" url="https://en.wikipedia.org/wiki?curid=677" title="Ambiguity">
Ambiguity

Ambiguity is a type of uncertainty of meaning in which several interpretations are plausible. It is thus an attribute of any idea or statement whose intended meaning cannot be definitively resolved according to a rule or process with a finite number of steps. (The "ambi-" part of the name reflects an idea of "two" as in two meanings.)
The concept of ambiguity is generally contrasted with vagueness. In ambiguity, specific and distinct interpretations are permitted (although some may not be immediately obvious), whereas with information that is vague, it is difficult to form any interpretation at the desired level of specificity.
Context may play a role in resolving ambiguity. For example, the same piece of information may be ambiguous in one context and unambiguous in another.
<h2>Linguistic forms.</h2>
The lexical ambiguity of a word or phrase pertains to its having more than one meaning in the language to which the word belongs. "Meaning" here refers to whatever should be captured by a good dictionary. For instance, the word "bank" has several distinct lexical definitions, including "financial institution" and "edge of a river". Another example is as in "apothecary". One could say "I bought herbs from the apothecary". This could mean one actually spoke to the apothecary (pharmacist) or went to the apothecary (pharmacy).
The context in which an ambiguous word is used often makes it evident which of the meanings is intended. If, for instance, someone says "I buried $100 in the bank", most people would not think someone used a shovel to dig in the mud. However, some linguistic contexts do not provide sufficient information to disambiguate a used word.
Lexical ambiguity can be addressed by algorithmic methods that automatically associate the appropriate meaning with a word in context, a task referred to as word sense disambiguation.
The use of multi-defined words requires the author or speaker to clarify their context, and sometimes elaborate on their specific intended meaning (in which case, a less ambiguous term should have been used). The goal of clear concise communication is that the receiver(s) have no misunderstanding about what was meant to be conveyed. An exception to this could include a politician whose "weasel words" and obfuscation are necessary to gain support from multiple constituents with mutually exclusive conflicting desires from their candidate of choice. Ambiguity is a powerful tool of political science.
More problematic are words whose senses express closely related concepts. "Good", for example, can mean "useful" or "functional" ("That's a good hammer"), "exemplary" ("She's a good student"), "pleasing" ("This is good soup"), "moral" ("a good person" versus "the lesson to be learned from a story"), "righteous", etc. " I have a good daughter" is not clear about which sense is intended. The various ways to apply prefixes and suffixes can also create ambiguity ("unlockable" can mean "capable of being unlocked" or "impossible to lock").
Syntactic ambiguity arises when a sentence can have two (or more) different meanings because of the structure of the sentence—its syntax. This is often due to a modifying expression, such as a prepositional phrase, the application of which is unclear. "He ate the cookies on the couch", for example, could mean that he ate those cookies that were on the couch (as opposed to those that were on the table), or it could mean that he was sitting on the couch when he ate the cookies. "To get in, you will need an entrance fee of $10 or your voucher and your drivers' license." This could mean that you need EITHER ten dollars OR BOTH your voucher and your license. Or it could mean that you need your license AND you need EITHER ten dollars OR a voucher. Only rewriting the sentence, or placing appropriate punctuation can resolve a syntactic ambiguity.
For the notion of, and theoretic results about, syntactic ambiguity in artificial, formal languages (such as computer programming languages), see Ambiguous grammar.
Spoken language can contain many more types of ambiguities which are called phonological ambiguities, where there is more than one way to compose a set of sounds into words. For example, "ice cream" and "I scream". Such ambiguity is generally resolved according to the context. A mishearing of such, based on incorrectly resolved ambiguity, is called a mondegreen.
Semantic ambiguity happens when a sentence contains an ambiguous word or phrase—a word or phrase that has more than one meaning. In "We saw her duck" (example due to Richard Nordquist), the word "duck" can refer either
For example, "You could do with a new automobile. How about a test drive?" The clause "You could do with" presents a statement with such wide possible interpretation as to be essentially meaningless. Lexical ambiguity is contrasted with semantic ambiguity. The former represents a choice between a finite number of known and meaningful context-dependent interpretations. The latter represents a choice between any number of possible interpretations, none of which may have a standard agreed-upon meaning. This form of ambiguity is closely related to vagueness.
Linguistic ambiguity can be a problem in law, because the interpretation of written documents and oral agreements is often of paramount importance.
Philosophers (and other users of logic) spend a lot of time and effort searching for and removing (or intentionally adding) ambiguity in arguments because it can lead to incorrect conclusions and can be used to deliberately conceal bad arguments. For example, a politician might say "I oppose taxes which hinder economic growth", an example of a glittering generality. Some will think he opposes taxes in general because they hinder economic growth. Others may think he opposes only those taxes that he believes will hinder economic growth. In writing, the sentence can be rewritten to reduce possible misinterpretation, either by adding a comma after "taxes" (to convey the first sense) or by changing "which" to "that" (to convey the second sense) or by rewriting it in other ways. The devious politician hopes that each constituent will interpret the statement in the most desirable way, and think the politician supports everyone's opinion. However, the opposite can also be true – An opponent can turn a positive statement into a bad one if the speaker uses ambiguity (intentionally or not). The logical fallacies of amphiboly and equivocation rely heavily on the use of ambiguous words and phrases.
In Continental philosophy (particularly phenomenology and existentialism), there is much greater tolerance of ambiguity, as it is generally seen as an integral part of the human condition. Martin Heidegger argued that the relation between the subject and object is ambiguous, as is the relation of mind and body, and part and whole.[3] In Heidegger's phenomenology, Dasein is always in a meaningful world, but there is always an underlying background for every instance of signification. Thus, although some things may be certain, they have little to do with Dasein's sense of care and existential anxiety, e.g., in the face of death. In calling his work Being and Nothingness an "essay in phenomenological ontology" Jean-Paul Sartre follows Heidegger in defining the human essence as ambiguous, or relating fundamentally to such ambiguity. Simone de Beauvoir tries to base an ethics on Heidegger's and Sartre's writings (The Ethics of Ambiguity), where she highlights the need to grapple with ambiguity: "as long as philosophers and they [men] have thought, most of them have tried to mask it...And the ethics which they have proposed to their disciples have always pursued the same goal. It has been a matter of eliminating the ambiguity by making oneself pure inwardness or pure externality, by escaping from the sensible world or being engulfed by it, by yielding to eternity or enclosing oneself in the pure moment.".[4] Ethics cannot be based on the authoritative certainty given by mathematics and logic, or prescribed directly from the empirical findings of science. She states: "Since we do not succeed in fleeing it, let us, therefore, try to look the truth in the face. Let us try to assume our fundamental ambiguity. It is in the knowledge of the genuine conditions of our life that we must draw our strength to live and our reason for acting".[5] Other continental philosophers suggest that concepts such as life, nature, and sex are ambiguous.[6] Recently, Corey Anton has argued that we cannot be certain what is separate from or unified with something else: language, he asserts, divides what is not, in fact, separate.[7] Following Ernest Becker, he argues that the desire to 'authoritatively disambiguate' the world and existence have led to numerous ideologies and historical events such as genocide. On this basis, he argues that ethics must focus on 'dialectically integrating opposites' and balancing tension, rather than seeking a priori validation or certainty. Like the existentialists and phenomenologists, he sees the ambiguity of life as the basis of creativity.[8]
In literature and rhetoric, ambiguity can be a useful tool. Groucho Marx's classic joke depends on a grammatical ambiguity for its humor, for example: "Last night I shot an elephant in my pajamas. How he got in my pajamas, I'll never know". Songs and poetry often rely on ambiguous words for artistic effect, as in the song title "Don't It Make My Brown Eyes Blue" (where "blue" can refer to the color, or to sadness).
In narrative, ambiguity can be introduced in several ways: motive, plot, character. F. Scott Fitzgerald uses the latter type of ambiguity with notable effect in his novel The Great Gatsby.
Christianity and Judaism employ the concept of paradox synonymously with 'ambiguity'. Many Christians and Jews endorse Rudolf Otto's description of the sacred as 'mysterium tremendum et fascinans', the awe-inspiring mystery which fascinates humans.[dubious – discuss] The orthodox Catholic writer G. K. Chesterton regularly employed paradox to tease out the meanings in common concepts which he found ambiguous, or to reveal meaning often overlooked or forgotten in common phrases. (The title of one of his most famous books, Orthodoxy, itself employing such a paradox.)
Metonymy involves the use of the name of a subcomponent part as an abbreviation, or jargon, for the name of the whole object (for example "wheels" to refer to a car, or "flowers" to refer to beautiful offspring, an entire plant, or a collection of blooming plants). In modern vocabulary critical semiotics,[9] metonymy encompasses any potentially ambiguous word substitution that is based on contextual contiguity (located close together), or a function or process that an object performs, such as "sweet ride" to refer to a nice car. Metonym miscommunication is considered a primary mechanism of linguistic humour.[10]
<h2>Music.</h2>
In music, pieces or sections which confound expectations and may be or are interpreted simultaneously in different ways are ambiguous, such as some polytonality, polymeter, other ambiguous meters or rhythms, and ambiguous phrasing, or (Stein 2005, p. 79) any aspect of music. The music of Africa is often purposely ambiguous. To quote Sir Donald Francis Tovey (1935, p. 195), "Theorists are apt to vex themselves with vain efforts to remove uncertainty just where it has a high aesthetic value."
<h2>Visual art.</h2>
In visual art, certain images are visually ambiguous, such as the Necker cube, which can be interpreted in two ways. Perceptions of such objects remain stable for a time, then may flip, a phenomenon called multistable perception.
The opposite of such ambiguous images are impossible objects.
Pictures or photographs may also be ambiguous at the semantic level: the visual image is unambiguous, but the meaning and narrative may be ambiguous: is a certain facial expression one of excitement or fear, for instance?
<h2>Constructed language.</h2>
Some languages have been created with the intention of avoiding ambiguity, especially lexical ambiguity. Lojban and Loglan are two related languages which have been created for this, focusing chiefly on syntactic ambiguity as well. The languages can be both spoken and written. These languages are intended to provide a greater technical precision over big natural languages, although historically, such attempts at language improvement have been criticized. Languages composed from many diverse sources contain much ambiguity and inconsistency. The many exceptions to syntax and semantic rules are time-consuming and difficult to learn.
<h2>Computer science.</h2>
In computer science, the SI prefixes kilo-, mega- and giga- are used ambiguously to mean either the first three powers of 1000 (1000, 1000 and 1000) or the first three powers of 1024 (1024, 1024 and 1024), respectively. It is never used in python.
<h2>Mathematical notation.</h2>
Mathematical notation, widely used in physics and other sciences, avoids many ambiguities compared to expression in natural language. However, for various reasons, several lexical, syntactic and semantic ambiguities remain.
<h3>Names of functions.</h3>
The ambiguity in the style of writing a function should not be confused with a multivalued function, which can (and should) be defined in a deterministic and unambiguous way. Several special functions still do not have established notations. Usually, the conversion to another notation requires to scale the argument or the resulting value; sometimes, the same name of the function is used, causing confusions. Examples of such underestablished functions:
<h3>Expressions.</h3>
Ambiguous expressions often appear in physical and mathematical texts.
It is common practice to omit multiplication signs in mathematical expressions. Also, it is common to give the same name to a variable and a function, for example, formula_1. Then, if one sees formula_2, there is no way to distinguish whether it means formula_1 multiplied by formula_4, or function formula_5 evaluated at argument equal to formula_4. In each case of use of such notations, the reader is supposed to be able to perform the deduction and reveal the true meaning.
Creators of algorithmic languages try to avoid ambiguities. Many algorithmic languages (C++ and Fortran) require the character * as symbol of multiplication. The Wolfram Language used in Mathematica allows the user to omit the multiplication symbol, but requires square brackets to indicate the argument of a function; square brackets are not allowed for grouping of expressions. Fortran, in addition, does not allow use of the same name (identifier) for different objects, for example, function and variable; in particular, the expression f=f(x) is qualified as an error.
The order of operations may depend on the context. In most programming languages, the operations of division and multiplication have equal priority and are executed from left to right. Until the last century, many editorials assumed that multiplication is performed first, for example, formula_7 is interpreted as formula_8; in this case, the insertion of parentheses is required when translating the formulas to an algorithmic language. In addition, it is common to write an argument of a function without parenthesis, which also may lead to ambiguity.
Sometimes, one uses "italics" letters to denote elementary functions.
In the scientific journal style, the expression
formula_9
means
product of variables
formula_10,
formula_11,
formula_12 and
formula_13, although in a slideshow, it may mean formula_14.
A comma in subscripts and superscripts sometimes is omitted; it is also ambiguous notation.
If it is written formula_15, the reader should guess from the context, does it mean a single-index object, evaluated while the subscript is equal to product of variables
formula_16, formula_12 and formula_18, or it is indication to a trivalent tensor.
The writing of formula_15 instead of formula_20 may mean that the writer either is stretched in space (for example, to reduce the publication fees) or aims to increase number of publications without considering readers. The same may apply to any other use of ambiguous notations.
Subscripts are also used to denote the argument to a function, as in formula_21.
<h3>Examples of potentially confusing ambiguous mathematical expressions.</h3>
formula_22, which could be understood to mean either formula_23 or formula_24. In addition, formula_25 may mean formula_26, as formula_27 means formula_28 (see tetration).
formula_29, which by convention means formula_30, though it might be thought to mean formula_31, since formula_32 means formula_33.
formula_34, which arguably should mean formula_35 but would commonly be understood to mean formula_36 .
<h3>Notations in quantum optics and quantum mechanics.</h3>
It is common to define the coherent states in quantum optics with formula_37 and states with fixed number of photons with formula_38. Then, there is an "unwritten rule": the state is coherent if there are more Greek characters than Latin characters in the argument, and formula_39photon state if the Latin characters dominate. The ambiguity becomes even worse, if formula_40 is used for the states with certain value of the coordinate, and formula_41 means the state with certain value of the momentum, which may be used in books on quantum mechanics. Such ambiguities easy lead to confusions, especially if some normalized adimensional, dimensionless variables are used. Expression formula_42 may mean a state with single photon, or the coherent state with mean amplitude equal to 1, or state with momentum equal to unity, and so on. The reader is supposed to guess from the context.
<h3>Ambiguous terms in physics and mathematics.</h3>
Some physical quantities do not yet have established notations; their value (and sometimes even dimension, as in the case of the Einstein coefficients), depends on the system of notations. Many terms are ambiguous. Each use of an ambiguous term should be preceded by the definition, suitable for a specific case. Just like Ludwig Wittgenstein states in Tractatus Logico-Philosophicus: "... Only in the context of a proposition has a name meaning."
A highly confusing term is "gain". For example, the sentence "the gain of a system should be doubled", without context, means close to nothing.
It may mean that the ratio of the output voltage of an electric circuit to the input voltage should be doubled.
It may mean that the ratio of the output power of an electric or optical circuit to the input power should be doubled.
It may mean that the gain of the laser medium should be doubled, for example, doubling the population of the upper laser level in a quasi-two level system (assuming negligible absorption of the ground-state).
The term "intensity" is ambiguous when applied to light. The term can refer to any of irradiance, luminous intensity, radiant intensity, or radiance, depending on the background of the person using the term.
Also, confusions may be related with the use of atomic percent as measure of concentration of a dopant, or resolution of an imaging system, as measure of the size of the smallest detail which still can be resolved at the background of statistical noise. See also Accuracy and precision and its talk.
The Berry paradox arises as a result of systematic ambiguity in the meaning of terms such as "definable" or "nameable". Terms of this kind give rise to vicious circle fallacies. Other terms with this type of ambiguity are: satisfiable, true, false, function, property, class, relation, cardinal, and ordinal.
<h2>Mathematical interpretation of ambiguity.</h2>
In mathematics and logic, ambiguity can be considered to be an instance of the logical concept of underdetermination—for example, formula_43 leaves open what the value of "X" is—while its opposite is a self-contradiction, also called inconsistency, paradoxicalness, or oxymoron, or in mathematics an inconsistent system—such as formula_44, which has no solution.
Logical ambiguity and self-contradiction is analogous to visual ambiguity and impossible objects, such as the Necker cube and impossible cube, or many of the drawings of M. C. Escher.
<h2>Pedagogic use of ambiguous expressions.</h2>
Ambiguity can be used as a pedagogical trick, to force students to reproduce the deduction by themselves. Some textbooks
give the same name to the function and to its Fourier transform:
Rigorously speaking, such an expression requires that formula_46;
even if function formula_47 is a self-Fourier function, the expression should be written as
formula_48; however, it is assumed that
the shape of the function (and even its norm
formula_49) depend on the character used to denote its argument.
If the Greek letter is used, it is assumed to be a Fourier transform of another function,
The first function is assumed, if the expression in the argument contains more characters formula_50 or formula_51, than characters formula_52, and the second function is assumed in the opposite case. Expressions like formula_53 or formula_54 contain symbols formula_50 and formula_52 in equal amounts; they are ambiguous and should be avoided in serious deduction.

</doc>
<doc id="679" url="https://en.wikipedia.org/wiki?curid=679" title="Animal (disambiguation)">
Animal (disambiguation)

An animal is a multicellular, eukaryotic organism of the kingdom Animalia or Metazoa.
Animal or Animals may also refer to:

</doc>
<doc id="680" url="https://en.wikipedia.org/wiki?curid=680" title="Aardvark">
Aardvark

The aardvark ( ; "Orycteropus afer") is a medium-sized, burrowing, nocturnal mammal native to Africa. It is the only living species of the order Tubulidentata, although other prehistoric species and genera of Tubulidentata are known. Unlike other insectivores, it has a long pig-like snout, which is used to sniff out food. It roams over most of the southern two-thirds of the African continent, avoiding areas that are mainly rocky. A nocturnal feeder, it subsists on ants and termites, which it will dig out of their hills using its sharp claws and powerful legs. It also digs to create burrows in which to live and rear its young. It receives a "least concern" rating from the IUCN, although its numbers seem to be decreasing.
<h2>Naming and taxonomy.</h2>
<h3>Naming.</h3>
The aardvark is sometimes colloquially called "African ant bear", "anteater" (not to be confused with the South American anteater), or the "Cape anteater" after the Cape of Good Hope. The name "aardvark" () comes from earlier Afrikaans (erdvark) and means "earth pig" or "ground pig" ("aarde": earth/ground, "vark": pig), because of its burrowing habits (similar origin to the name groundhog). The name "Orycteropus" means burrowing foot, and the name "afer" refers to Africa. The name of the aardvarks's order, "Tubulidentata," comes from the tubule-style teeth.
<h3>Taxonomy.</h3>
The aardvark is not closely related to the pig; rather, it is the sole extant representative of the obscure mammalian order Tubulidentata, in which it is usually considered to form one variable species of the genus "Orycteropus", the sole surviving genus in the family Orycteropodidae. The aardvark is not closely related to the South American anteater, despite sharing some characteristics and a superficial resemblance. The similarities are based on convergent evolution. The closest living relatives of the aardvark are the elephant shrews, tenrecs and golden moles. Along with the sirenians, hyraxes, elephants, and their extinct relatives, these animals form the superorder Afrotheria. Studies of the brain have shown the similarities with Condylarthra, and given the clade's status as a wastebasket taxon it may mean some species traditionally classified as "condylarths" are actually stem-aardvarks.
<h3>Evolutionary history.</h3>
Based on fossils, Bryan Patterson has concluded that early relatives of the aardvark appeared in Africa around the end of the Paleocene. The ptolemaiidans, a mysterious clade of mammals with uncertain affinities, may actually be stem-aardvarks, either as a sister clade to Tubulidentata or as a grade leading to true tubulidentates.
The first unambiguous tubulidentate was probably "Myorycteropus africanus" from Kenyan Miocene deposits. The earliest example from the "Orycteropus" genus was the "Orycteropus mauritanicus" found in Algeria in deposits from the middle Miocene, with an equally aged version found in Kenya. Fossils from the aardvark have been dated to 5 million years, and have been located throughout Europe and the Near East.
The mysterious Pleistocene "Plesiorycteropus" from Madagascar was originally thought to be a tubulidentate that was descended from ancestors that entered the island during the Eocene. However, a number of subtle anatomical differences coupled with recent molecular evidence now lead researchers to believe that "Plesiorycteropus" is a relative of golden moles and tenrecs that achieved an aardvark-like appearance and ecological niche through convergent evolution.
<h3>Subspecies.</h3>
The aardvark has seventeen poorly defined subspecies listed:
<h2>Description.</h2>
The aardvark is vaguely pig-like in appearance. Its body is stout with a prominently arched back and is sparsely covered with coarse hairs. The limbs are of moderate length, with the rear legs being longer than the forelegs. The front feet have lost the pollex (or 'thumb'), resulting in four toes, while the rear feet have all five toes. Each toe bears a large, robust nail which is somewhat flattened and shovel-like, and appears to be intermediate between a claw and a hoof. Whereas the aardvark is considered digitigrade, it appears at time to be plantigrade. This confusion happens because when it squats it stands on its soles.
An aardvark's weight is typically between . An aardvark's length is usually between , and can reach lengths of when its tail (which can be up to ) is taken into account. It is tall at the shoulder, and has a girth of about . It is the largest member of the proposed clade Afroinsectiphilia. The aardvark is pale yellowish-gray in color and often stained reddish-brown by soil. The aardvark's coat is thin, and the animal's primary protection is its tough skin. Its hair is short on its head and tail; however its legs tend to have longer hair. The hair on the majority of its body is grouped in clusters of 3-4 hairs. The hair surrounding its nostrils is dense to help filter particulate matter out as it digs. Its tail is very thick at the base and gradually tapers.
<h3>Head.</h3>
The greatly elongated head is set on a short, thick neck, and the end of the snout bears a disc, which houses the nostrils. It contains a thin but complete zygomatic arch. The head of the aardvark contains many unique and different features. One of the most distinctive characteristics of the Tubulidentata is their teeth. Instead of having a pulp cavity, each tooth has a cluster of thin, hexagonal, upright, parallel tubes of vasodentin (a modified form of dentine), with individual pulp canals, held together by cementum. The number of columns is dependent on the size of the tooth, with the largest having about 1,500. The teeth have no enamel coating and are worn away and regrow continuously. The aardvark is born with conventional incisors and canines at the front of the jaw, which fall out and are not replaced. Adult aardvarks have only cheek teeth at the back of the jaw, and have a dental formula of: These remaining teeth are peg-like and rootless and are of unique composition. The teeth consist of 14 upper and 12 lower jaw molars. The nasal area of the aardvark is another unique area, as it contains ten nasal conchae, more than any other placental mammal.
The sides of the nostrils are thick with hair. The tip of the snout is highly mobile and is moved by modified mimetic muscles. The fleshy dividing tissue between its nostrils probably has sensory functions, but it is uncertain whether they are olfactory or vibratory in nature. Its nose is made up of more turbinate bones than any other mammal, with between 9 and 11, compared to dogs with 4 to 5. With a large quantity of turbinate bones, the aardvark has more space for the moist epithelium, which is the location of the olfactory bulb. The nose contains nine olfactory bulbs, more than any other mammal. Its keen sense of smell is not just from the quantity of bulbs in the nose but also in the development of the brain, as its olfactory lobe is very developed. The snout resembles an elongated pig snout. The mouth is small and tubular, typical of species that feed on ants and termites. The aardvark has a long, thin, snakelike, protruding tongue (as much as long) and elaborate structures supporting a keen sense of smell. The ears, which are very effective, are disproportionately long, about long. The eyes are small for its head, and consist only of rods.
<h3>Digestive system.</h3>
The aardvark's stomach has a muscular pyloric area that acts as a gizzard to grind swallowed food up, thereby rendering chewing unnecessary. Its cecum is large. Both sexes emit a strong smelling secretion from an anal gland. Its salivary glands are highly developed and almost completely ring the neck; their output is what causes the tongue to maintain its tackiness. The female has two pairs of teats in the inguinal region.
Genetically speaking, the aardvark is a living fossil, as its chromosomes are highly conserved, reflecting much of the early eutherian arrangement before the divergence of the major modern taxa.
<h2>Habitat and range.</h2>
Aardvarks are found in sub-Saharan Africa, where suitable habitat (savannas, grasslands, woodlands and bushland) and food (i.e., ants and termites) is available. They spend the daylight hours in dark underground burrows to avoid the heat of the day. The only major habitat that they are not present in is swamp forest, as the high water table precludes digging to a sufficient depth. They also avoid terrain rocky enough to cause problems with digging. They have been documented as high as in Ethiopia. They are present throughout sub-Saharan Africa all the way to South Africa with few exceptions. These exceptions include the coastal areas of Namibia, Ivory Coast, and Ghana. They are not found in Madagascar.
<h2>Ecology and behavior.</h2>
Aardvarks live for up to 23 years in captivity. Its keen hearing warns it of predators: lions, leopards, hunting dogs, hyenas, and pythons. Some humans also hunt aardvarks for meat. Aardvarks can dig fast or run in zigzag fashion to elude enemies, but if all else fails, they will strike with their claws, tail and shoulders, sometimes flipping onto their backs lying motionless except to lash out with all four feet. They are capable of causing substantial damage to unprotected areas of an attacker. They will also dig to escape as they can, when pressed, dig extremely quickly. Their thick skin also protects them to some extent.
<h3>Feeding.</h3>
The aardvark is nocturnal and is a solitary creature that feeds almost exclusively on ants and termites (formivore); the only fruit eaten by aardvarks is the aardvark cucumber. In fact, the cucumber and the aardvark have a symbiotic relationship as they eat the subterranean fruit, then defecate the seeds near their burrows, which then grow rapidly due to the loose soil and fertile nature of the area. The time spent in the intestine of the aardvark helps the fertility of the seed, and the fruit provides needed moisture for the aardvark. They avoid eating the African driver ant and red ants. Due to their stringent diet requirements, they require a large range to survive. An aardvark emerges from its burrow in the late afternoon or shortly after sunset, and forages over a considerable home range encompassing . While foraging for food, the aardvark will keep its nose to the ground and its ears pointed forward, which indicates that both smell and hearing are involved in the search for food. They zig-zag as they forage and will usually not repeat a route for 5–8 days as they appear to allow time for the termite nests to recover before feeding on it again.
During a foraging period, they will stop and dig a "V" shaped trench with their forefeet and then sniff it profusely as a means to explore their location. When a concentration of ants or termites is detected, the aardvark digs into it with its powerful front legs, keeping its long ears upright to listen for predators, and takes up an astonishing number of insects with its long, sticky tongue—as many as 50,000 in one night have been recorded. Its claws enable it to dig through the extremely hard crust of a termite or ant mound quickly. It avoids inhaling the dust by sealing the nostrils. When successful, the aardvark's long (up to ) tongue licks up the insects; the termites' biting, or the ants' stinging attacks are rendered futile by the tough skin. After an aardvark visit at a termite mound, other animals will visit to pick up all the leftovers. Termite mounds alone don't provide enough food for the aardvark, so they look for termites that are on the move. When these insects move, they can form columns long and these tend to provide easy pickings with little effort exerted by the aardvark. These columns are more common in areas of livestock or other hoofed animals. The trampled grass and dung attract termites from Odontotermes, Microtermes, and Pseudacanthotermes genera.
On a nightly basis they tend to be more active during the first portion of the night time (20:00-00:00); however, they don't seem to prefer bright or dark nights over the other. During adverse weather or if disturbed they will retreat to their burrow systems. They cover between per night; however, some studies have shown that they may traverse as far as in a night.
<h3>Vocalization.</h3>
The aardvark is a rather quiet animal. However, it does make soft grunting sounds as it forages and loud grunts as it makes for its tunnel entrance. It makes a bleating sound if frightened. When it is threatened it will make for one of its burrows. If one is not close it will dig a new one rapidly. This new one will be short and require the aardvark to back out when the coast is clear.
<h3>Movement.</h3>
The aardvark is known to be a good swimmer and has been witnessed successfully swimming in strong currents. It can dig a yard of tunnel in about five minutes, but otherwise moves fairly slowly.
When leaving the burrow at night, they pause at the entrance for about ten minutes, sniffing and listening. After this period of watchfulness, it will bound out and within seconds it will be away. It will then pause, prick its ears, twisting its head to listen, then jump and move off to start foraging.
Aside from digging out ants and termites, the aardvark also excavates burrows in which to live; of which they generally fall into three categories: burrows made while foraging, refuge and resting location, and permanent homes. Temporary sites are scattered around the home range and are used as refuges, while the main burrow is also used for breeding. Main burrows can be deep and extensive, have several entrances and can be as long as . These burrows can be large enough for a man to enter. The aardvark changes the layout of its home burrow regularly, and periodically moves on and makes a new one. The old burrows are an important part of the African wildlife scene. As they are vacated, then they are inhabited by smaller animals like the African wild dog, ant-eating chat, "Nycteris thebaica" and warthogs. Other animals that use them are hares, mongooses, hyenas, owls, pythons, and lizards. Without these refuges many animals would die during wildfire season. Only mothers and young share burrows; however, the aardvark is known to live in small family groups or as a solitary creature. If attacked in the tunnel, it will escape by digging out of the tunnel thereby placing the fresh fill between it and its predator, or if it decides to fight it will roll onto its back, and attack with its claws. The aardvark has been known to sleep in a recently excavated ant nest, which also serves as protection from its predators.
<h3>Reproduction.</h3>
Aardvarks pair only during the breeding season; after a gestation period of seven months, one cub weighing around is born during May–July. When born, the young has flaccid ears and many wrinkles. When nursing, it will nurse off each teat in succession. After two weeks, the folds of skin disappear and after three, the ears can be held upright. After 5–6 weeks, body hair starts growing. It is able to leave the burrow to accompany its mother after only two weeks, and is eating termites at 9 weeks and is weaned by 16 weeks. By three months of age the young has been weaned. At six months of age, it is able to dig its own burrows, but it will often remain with the mother until the next mating season, and is sexually mature from approximately two years of age.
<h2>Conservation.</h2>
Aardvarks were thought to have declining numbers, however, this is possibly due to the fact that they are not readily seen. There are no definitive counts because of their nocturnal and secretive habits; however, their numbers seem to be stable overall. They are not considered common anywhere in Africa, but due to their large range, they maintain sufficient numbers. There may be a slight decrease in numbers in eastern, northern, and western Africa. Southern African numbers are not decreasing. It receives an official designation from the IUCN as least concern. However, they are a species in a precarious situation, as they are so dependent on such specific food; therefore if a problem arises with the abundance of termites, the species as a whole would be affected drastically.
Aardvarks handle captivity well. The first zoo to have one was London Zoo in 1869, which had an animal from South Africa.
<h2>Mythology and popular culture.</h2>
In African folklore, the aardvark is much admired because of its diligent quest for food and its fearless response to soldier ants. Hausa magicians make a charm from the heart, skin, forehead, and nails of the aardvark, which they then proceed to pound together with the root of a certain tree. Wrapped in a piece of skin and worn on the chest, the charm is said to give the owner the ability to pass through walls or roofs at night. The charm is said to be used by burglars and those seeking to visit young girls without their parents' permission. Also, some tribes, such as the Margbetu, Ayanda, and Logo, will use aardvark teeth to make bracelets, which are regarded as good luck charms. The meat, which has a resemblance to pork, is eaten in certain cultures.
The Egyptian god Set is usually depicted with the head of an unidentified animal, whose similarity to an aardvark has been noted in scholarship.
The titular character of "Arthur", an animated television series for children based on a book series and produced by WGBH, shown in more than 180 countries, is an aardvark.
An aardvark features as the antagonist in the cartoon "The Ant and the Aardvark".
In the military, the Air Force supersonic fighter-bomber F-111/FB-111 was nicknamed the Aardvark because of its long nose resembling the animal. It also had similarities with its nocturnal missions flown at a very low level employing ordnance that could penetrate deep into the ground. In the US Navy, the squadron VF-114 was nicknamed the Aardvarks, flying F-4's and then F-14's. The squadron mascot was adapted from the animal in the comic strip B.C., which the F-4 was said to resemble.

</doc>
<doc id="681" url="https://en.wikipedia.org/wiki?curid=681" title="Aardwolf">
Aardwolf

The aardwolf ("Proteles cristata") is a small, insectivorous mammal, native to East and Southern Africa. Its name means "earth wolf" in Afrikaans and Dutch. It is also called "maanhaar jackal" (Afrikaans for "mane jackal") or "civet hyena", based on the secretions from their anal glands, reminiscent of civets. The aardwolf is in the same family as the hyenas. Unlike many of its relatives in the order Carnivora, the aardwolf does not hunt large animals. It eats insects, mainly termites – one aardwolf can eat about 250,000 termites during a single night, using its long, sticky tongue to capture them. The aardwolf lives in the shrublands of eastern and southern Africa – open lands covered with stunted trees and shrubs. It is nocturnal, resting in burrows during the day and emerging at night to seek food. Its diet consists mainly of termites and insect larvae.
<h2>Taxonomy.</h2>
The aardwolf is the only surviving species in the mammalian subfamily Protelinae. Disagreement exists as to whether the species is monotypic. or can be divided into subspecies "P. c. cristatus" of Southern Africa and "P. c. septentrionalis" of East Africa. Recent studies have shown that the aardwolf probably broke away from the rest of the hyena family early on; however, how early is still unclear, as the fossil record and genetic studies disagree by 10 million years.
The aardwolf is generally classified with the Hyaenidae, though it was formerly placed into the family Protelidae. Early on, scientists felt that it was merely mimicking the striped hyena, which subsequently led to the creation of the Protelidae.
<h2>Etymology.</h2>
The generic name "proteles" comes from two words both of Greek origin, "protos" and "teleos" which combined means "complete in front" because they have five toes on their front feet and four on the rear. The specific name, "cristatus", comes from Latin and means "provided with a comb", relating to their mane.
<h2>Physical characteristics.</h2>
The aardwolf resembles a very thin striped hyena, but with a more slender muzzle, black vertical stripes on a coat of yellowish fur, and a long, distinct mane down the midline of the neck and back. It also has one or two diagonal stripes down the fore- and hindquarters, along with several stripes on its legs. The mane is raised during confrontations to make the aardwolf appear larger. It is missing the throat spot that others in the family have. Its lower leg (from the knee down) is all black, and its tail is bushy with a black tip. The aardwolf is about long, excluding its bushy tail, which is about long, and stands about tall at the shoulders. An adult aardwolf weighs about , sometimes reaching . The aardwolves in the south of the continent tend to be smaller (about ), whereas the eastern version weighs more (around ). The front feet have five toes each, unlike the four-toed hyena. The teeth and skull are similar to those of other hyenas, though smaller, and its cheek teeth are specialised for eating insects. It does still have canines, but unlike other hyenas, these teeth are used primarily for fighting and defense. Its ears, which are large, are very similar to those of the striped hyena.
As an aardwolf ages, it normally loses some of its teeth, though this has little impact on its feeding habits due to the softness of the insects that it eats. The aardwolf's two anal glands secrete a musky fluid for marking territory and for communicating with other aardwolves.
<h2>Distribution and habitat.</h2>
Aardwolves live in open, dry plains and bushland, avoiding mountainous areas. Due to their specific food requirements, they are only found in regions where termites of the family Hodotermitidae occur. Termites of this family depend on dead and withered grass and are most populous in heavily grazed grasslands and savannahs, including farmland. For most of the year, aardwolves spend time in shared territories consisting of up to a dozen dens, which are occupied for six weeks at a time.
Two distinct populations occur, one in Southern Africa, and another in East and Northeast Africa. The species does not occur in the intermediary miombo forests.
An adult pair, along with their most recent offspring, occupies a territory of .
<h2>Behavior.</h2>
Aardwolves are shy and nocturnal, sleeping in underground burrows by day. They will, on occasion during the winter, become diurnal feeders. This happens during the coldest periods as they then stay in at night to conserve heat.
They have often been mistaken for solitary animals. In fact, they live as monogamous pairs with their young. If their territory is infringed upon, they will chase the intruder up to or to the border. If the intruder is caught, which rarely happens, a fight occurs, which is accompanied by soft clucking, hoarse barking, and a type of roar. The majority of incursions occur during mating season, when they can occur once or twice per week. When food is scarce, the stringent territorial system may be abandoned and as many as three pairs may occupy a single territory.
The territory is marked by both sexes, as they both have developed anal glands from which they extrude a black substance that is smeared on rocks or grass stalks in 5-mm-long streaks. They often mark near termite mounds within their territory every 20 minutes or so. If they are patrolling their territorial boundaries, the marking frequency increases drastically, to once every . At this rate, an individual may mark 60 marks per hour, and upwards of 200 per night.
An aardwolf pair may have up to 10 dens, and numerous middens, within their territory. When they deposit feces at their middens, they dig a small hole and then cover it with sand. Their dens are usually abandoned aardvark, springhare, or porcupine dens, or on occasion they are crevices in rocks. They also dig their own dens, or enlarge dens started by springhares. They typically will only use one or two dens at a time, rotating through all of their dens every six months. During the summer, they may rest outside their den during the night, and sleep underground during the heat of the day.
Aardwolves are not fast runners nor are they particularly adept at fighting off predators. Therefore, when threatened, the aardwolf attempts to mislead its foe by doubling back on its tracks. If confronted, it raises its mane in an attempt to appear more menacing. It also emits a foul-smelling liquid from its anal glands.
<h3>Feeding.</h3>
The aardwolf feeds primarily on termites and more specifically on "Trinervitermes". This genus of termites has different species throughout the aardwolf's range. In East Africa, they eat "T. bettonianus", and in central Africa, they eat "T. rhodesiensis", and finally in southern Africa, they eat "T. trinervoides". Their technique consists of licking them off the ground as opposed to the aardvark, which digs into the mound. They locate their food by sound and also from the scent secreted by the soldier termites. An aardwolf may consume up to 250,000 termites per night using its sticky, long tongue. They do not destroy the termite mound or consume the entire colony, thus ensuring that the termites can rebuild and provide a continuous supply of food. They often memorize the location of such nests and return to them every few months. During certain seasonal events, such as the onset of the rainy season and the cold of midwinter, the primary termites become scarce, so the need for other foods becomes pronounced. During these times, the southern aardwolf seeks out "Hodotermes mossambicus", a type of harvester termite active in the afternoon, which explains some of their diurnal behavior in the winter. The eastern aardwolf, during the rainy season, gets variety by subsisting on termites from the genera "Odontotermes" and "Macrotermes". They are also known to feed on other insects, larvae, eggs, and occasionally small mammals and birds, but these constitute a very small percentage of their total diet. Unlike other hyenas, aardwolves do not scavenge or kill larger animals. Contrary to popular myths, aardwolves do not eat carrion, and if they are seen eating while hunched over a dead carcass, it is actually eating larvae and beetles. Also, contrary to some sources, they do not like meat, unless it is finely ground or cooked for them. The adult aardwolf was formerly assumed to forage in small groups, but more recent research has shown that they are primarily solitary foragers, necessary because of the scarcity of their insect prey. Their primary source, "Trinervitermes", forages in small but dense patches of . While foraging, the aardwolf can cover about per hour, which translates to per summer night and per winter night.
<h3>Breeding.</h3>
Their breeding season varies depending on location, but normally takes place during autumn or spring. In South Africa, breeding occurs in early July. During the breeding season, unpaired male aardwolves search their own territory, as well as others, for a female with which to mate. Dominant males also mate opportunistically with the females of less dominant neighboring aardwolves, which can result in conflict between rival males. Dominant males even go a step further and as the breeding season approaches, they make increasingly greater and greater incursions onto weaker males' territories. As the female comes into oestrus, they add pasting to their tricks inside of the other territories, sometimes doing so more in rivals' territories than their own. Females also, when given the opportunity, mate with the dominant male, which increases the chances of the dominant male guarding "his" cubs with her. Gestation lasts between 89 and 92 days, producing two to five cubs (most often two or three) during the rainy season (November–December), when termites are more active. They are born with their eyes open, but initially are helpless, and weigh around . The first six to eight weeks are spent in the den with their parents. The male may spend up to six hours a night watching over the cubs while the female is out looking for food. After three months, they begin supervised foraging, and by four months are normally independent, though they often share a den with their mother until the next breeding season. By the time the next set of cubs is born, the older cubs have moved on. Aardwolves generally achieve sexual maturity at one and a half to two years of age.
<h2>Conservation.</h2>
The aardwolf has not seen decreasing numbers and they are relatively widespread throughout eastern Africa. They are not common throughout their range, as they maintain a density of no more than 1 per square kilometer, if the food is good. Because of these factors, the IUCN has rated the aardwolf as least concern. In some areas, they are persecuted by man because of the mistaken belief that they prey on livestock; however, they are actually beneficial to the farmers because they eat termites that are detrimental. In other areas, the farmers have recognized this, but they are still killed, on occasion, for their fur. Dogs and insecticides are also common killers of the aardwolf.
<h2>Interaction with humans.</h2>
Aardwolfs are common sights at zoos. Frankfurt Zoo in Germany was home to the oldest recorded aardwolf in captivity at 18 years and 11 months.

</doc>
<doc id="682" url="https://en.wikipedia.org/wiki?curid=682" title="Adobe">
Adobe

Adobe (, ; , ultimately from Coptic via Arabic) is a building material made from earth and often organic material. Adobe means mudbrick in Spanish, but in some English speaking regions of Spanish heritage it refers to any kind of earth construction, as most adobe buildings are similar in appearance to cob and rammed earth buildings. Adobe is among the earliest building materials, and is used throughout the world.
<h2>Description.</h2>
Adobe bricks are most often made into units weighing less than 100 pounds and small enough that they can quickly air dry individually without cracking and subsequently assembled, with the application of adobe mud, to bond the individual bricks into a structure. Modern methods of construction allow the pouring of whole adobe walls that are reinforced with steel.
<h2>Strength.</h2>
In dry climates, adobe structures are extremely durable, and account for some of the oldest existing buildings in the world. Adobe buildings offer significant advantages due to their greater thermal mass, but they are known to be particularly susceptible to earthquake damage if they are not somehow reinforced. Cases where adobe structures were widely damaged during earthquakes include the 1976 Guatemala earthquake, the 2003 Bam earthquake and the 2010 Chile earthquake.
<h2>Distribution.</h2>
Buildings made of sun-dried earth are common throughout the world (Middle East, Western Asia, North Africa, West Africa, South America, southwestern North America, Spain, and Eastern Europe.) Adobe had been in use by indigenous peoples of the Americas in the Southwestern United States, Mesoamerica, and the Andes for several thousand years. Puebloan peoples built their adobe structures with handfuls or basketfuls of adobe, until the Spanish introduced them to making bricks. Adobe bricks were used in Spain from the Late Bronze and Iron Ages (eighth century BCE onwards). Its wide use can be attributed to its simplicity of design and manufacture, and economics.
A distinction is sometimes made between the smaller "adobes", which are about the size of ordinary baked bricks, and the larger "adobines", some of which may be one to two yards (1–2 m) long.
<h2>Etymology.</h2>
The word "adobe" has existed for around 4000 years with relatively little change in either pronunciation or meaning. The word can be traced from the Middle Egyptian (c. 2000 BC) word "ɟbt" "mudbrick." Middle Egyptian evolved into Late Egyptian, Demotic or "pre-Coptic", and finally to Coptic (c. 600 BC), where it appeared as τωωβε . This was borrowed into Arabic as "aṭ-ṭawbu" or "aṭ-ṭūbu", with the definite article "al-" attached, "tuba", which was assimilated into the Old Spanish language as "adobe" , probably via Mozarabic. English borrowed the word from Spanish in the early 18th century.
In more modern English usage, the term "adobe" has come to include a style of architecture popular in the desert climates of North America, especially in New Mexico.
<h2>Composition.</h2>
An adobe brick is a composite material made of earth mixed with water and an organic material such as straw or dung. The soil composition typically contains sand, silt and clay. Straw is useful in binding the brick together and allowing the brick to dry evenly, thereby preventing cracking due to uneven shrinkage rates through the brick. Dung offers the same advantage. The most desirable soil texture for producing the mud of adobe is 15% clay, 10-30% silt and 55-75% fine sand. Another source quotes 15-25% clay and the remainder sand and coarser particles up to cobbles with no deleterious effect. Modern adobe is stabilized with either emulsified asphalt or Portland cement up to 10% by weight.
No more than half the clay content should be expansive clays with the remainder non-expansive illite or kaolinite. Too much expansive clay results in uneven drying through the brick resulting in cracking, while too much kaolinite will make a weak brick. Typically the soils of the Southwest United States, where such construction is in use, are an adequate composition.
<h2>Material properties.</h2>
Adobe walls are load bearing, i.e. they carry their own weight into the foundation rather than by another structure, hence the adobe must have sufficient compressive strength. In the United States, most building codes call for a minimum compressive strength of 300 lbf/in (2.07 newton/mm) for the adobe block. Adobe construction should be designed so as to avoid lateral structural loads that would cause bending loads. The building codes require the building sustain a 1 g lateral acceleration earthquake load. Such an acceleration will cause lateral loads on the walls, resulting in shear and bending and inducing tensile stresses. To withstand such loads, the codes typically call for a tensile modulus of rupture strength of at least 50 lbf/in (0.345 newton/mm) for the finished block.
In addition to being an inexpensive material with a small resource cost, adobe can serve as a significant heat reservoir due to the thermal properties inherent in the massive walls typical in adobe construction. In climates typified by hot days and cool nights, the high thermal mass of adobe mediates the high and low temperatures of the day, moderating the living space temperature. The massive walls require a large and relatively long input of heat from the sun (radiation) and from the surrounding air (convection) before they warm through to the interior. After the sun sets and the temperature drops, the warm wall will then continue to transfer heat to the interior for several hours due to the time-lag effect. Thus, a well-planned adobe wall of the appropriate thickness is very effective at controlling inside temperature through the wide daily fluctuations typical of desert climates, a factor which has contributed to its longevity as a building material.
Thermodynamic material properties are sparsely quoted. The thermal resistance of adobe is quoted as having an R-value of R = 0.41 hr-ft-°F/(Btu-in) and a conductivity of 0.57 W/(m-K) quoted from another source. A third source provides the following properties: conductivity=0.30 Btu/(hr-ft-°F); heat capacity=0.24 Btu/(lbm-°F); density=106 lbm/ft (1700 kg/m). To determine the total R-value of a wall for example, multiply R by the thickness of the wall. From knowledge of the adobe density, heat capacity and a diffusivity value, the conductivity is found to be k = 0.20 Btu/(hr-ft-°F) or 0.35 W/(m-K). The heat capacity is commonly quoted as c = 0.20 Btu/(lbm*F) or 840 joules/(kg-K). The density is 95 lbm/ft or 1520 kg/m. The thermal diffusivity is calculated to be 0.0105 ft/hr or 2.72x10 m/s.
<h2>Uses.</h2>
<h3>Poured and puddled adobe walls.</h3>
Poured and puddled adobe (puddled clay, piled earth) today called "cob", is made by placing soft adobe in layers, rather than making by individual dried bricks or using a form. Puddle is a general term for a clay or clay and sand based material worked into a dense, plastic state. These are the oldest methods of building with adobe in the Americas until holes in the ground were used as forms and then later wooden forms used to make individual bricks were introduced by the Spanish.
<h3>Adobe bricks.</h3>
Bricks made from adobe are usually made by pressing the mud mixture into an open timber frame. In North America, the brick is typically about in size. The mixture is molded into the frame, which is then is removed after initial setting. After drying for a few hours, the bricks are turned on edge to finish drying. Slow drying in shade reduces cracking.
The same mixture, without straw, is used to make mortar and often plaster on interior and exterior walls. Some ancient cultures used lime-based cement for the plaster to protect against rain damage.
Depending on the form into which the mixture is pressed, adobe can encompass nearly any shape or size, provided drying is even and the mixture includes reinforcement for larger bricks. Reinforcement can include manure, straw, cement, rebar or wooden posts. Experience has shown straw, cement, or manure added to a standard adobe mixture can all produce a stronger, more crack-resistant brick. A test is done on the soil content first. To do so, a sample of the soil is mixed into a clear container with some water, creating an almost completely saturated liquid. The container is shaken vigorously for one minute. It is then allowed to settle for a day until the soil has settled into layers. Heavier particles settle out first, sand above, silt above that and very fine clay and organic matter will stay in suspension for days. After the water has cleared, percentages of the various particles can be determined. Fifty to 60 percent sand and 35 to 40 percent clay will yield strong bricks. The Cooperative State Research, Education, and Extension Service at New Mexico State University recommends a mix of not more than 1/3 clay, not less than 1/2 sand, and never more than 1/3 silt.
<h3>Adobe wall construction.</h3>
The ground supporting an adobe structure should be compressed, as the weight of adobe wall is significant and foundation settling may cause cracking of the wall. Footing depth is to below the ground frost level. The footing and stem wall are commonly 24 and 14 inches thick, respectively. Modern construction codes call for the use of reinforcing steel in the footing and stem wall. Adobe bricks are laid by course. Adobe walls usually never rise above two stories as they are load bearing and adobe has low structural strength. When creating window and door openings, a lintel is placed on top of the opening to support the bricks above. Atop the last courses of brick, bond beams made of heavy wood beams or modern reinforced concrete are laid to provide a horizontal bearing plate for the roof beams and to redistribute lateral earthquake loads to shear walls more able to carry the forces. To protect the interior and exterior adobe walls, finishes such as mud plaster, whitewash or stucco can be applied. These protect the adobe wall from water damage, but need to be reapplied periodically. Alternatively, the walls can be finished with other nontraditional plasters that provide longer protection. Bricks made with stabilized adobe generally do not need protection of plasters.
<h3>Adobe roof.</h3>
The traditional adobe roof has been constructed using a mixture of soil/clay, water, sand and organic materials. The mixture was then formed and pressed into wood forms, producing rows of dried earth bricks that would then be laid across a support structure of wood and plastered into place with more adobe.
Depending on the materials available, a roof may be assembled using wood or metal beams to create a framework to begin layering adobe bricks. Depending on the thickness of the adobe bricks, the framework has been preformed using a steel framing and a layering of a metal fencing or wiring over the framework to allow an even load as masses of adobe are spread across the metal fencing like cob and allowed to air dry accordingly. This method was demonstrated with an adobe blend heavily impregnated with cement to allow even drying and prevent cracking.
The more traditional flat adobe roofs are functional only in dry climates that are not exposed to snow loads. The heaviest wooden beams, called vigas, lie atop the wall. Across the vigas lie smaller members called latillas and upon those brush is then laid. Finally, the adobe layer is applied.
To construct a flat adobe roof, beams of wood were laid to span the building, the ends of which were attached to the tops of the walls. Once the vigas, latillas and brush are laid, adobe bricks are placed. An adobe roof is often laid with bricks slightly larger in width to ensure a greater expanse is covered when placing the bricks onto the roof. Following each individual brick should be a layer of adobe mortar, recommended to be at least thick to make certain there is ample strength between the brick’s edges and also to provide a relative moisture barrier during rain. 
Depending on the materials, adobe roofs can be inherently fire-proof. The construction of a chimney can greatly influence the construction of the roof supports, creating an extra need for care in choosing the materials. The builders can make an adobe chimney by stacking simple adobe bricks in a similar fashion as the surrounding walls.
<h2>Adobe around the world.</h2>
The largest structure ever made from adobe is the Arg-é Bam built by the Achaemenid Empire. Other large adobe structures are the Huaca del Sol in Peru, with 100 million signed bricks and the "ciudellas" of Chan Chan and Tambo Colorado, both in Peru.

</doc>
<doc id="683" url="https://en.wikipedia.org/wiki?curid=683" title="Adventure">
Adventure

An adventure is an exciting or unusual experience. It may also be a bold, usually risky undertaking, with an uncertain outcome. Adventures may be activities with some potential for physical danger such as traveling, exploring, skydiving, mountain climbing, scuba diving, river rafting or participating in extreme sports. The term also broadly refers to any enterprise that is potentially fraught with physical, financial or psychological risk, such as a business venture, or other major life undertakings.
<h2>Motivation.</h2>
Adventurous experiences create psychological arousal, which can be interpreted as negative (e.g. fear) or positive (e.g. flow), and which can be detrimental as stated by the Yerkes-Dodson law. For some people, adventure becomes a major pursuit in and of itself. According to adventurer André Malraux, in his "La Condition Humaine" (1933), "If a man is not ready to risk his life, where is his dignity?". Similarly, Helen Keller stated that "Life is either a daring adventure or nothing."
Outdoor adventurous activities are typically undertaken for the purposes of recreation or excitement: examples are adventure racing and adventure tourism. Adventurous activities can also lead to gains in knowledge, such as those undertaken by explorers and pioneers – the British adventurer Jason Lewis, for example, uses adventures to draw global sustainability lessons from living within finite environmental constraints on expeditions to share with schoolchildren. Adventure education intentionally uses challenging experiences for learning.
<h2>Adventure in mythology and fiction.</h2>
Some of the oldest and most widespread stories in the world are stories of adventure such as Homer's "The Odyssey". Mythologist Joseph Campbell discussed his notion of the monomyth in his book, "The Hero with a Thousand Faces". Campbell proposed that the heroic mythological stories from culture to culture followed a similar underlying pattern, starting with the "call to adventure", followed by a hazardous journey, and eventual triumph.
The knight errant was the form the "adventure seeker" character took in the late Middle Ages.
The adventure novel exhibits these "protagonist on adventurous journey" characteristics as do many popular feature films, such as "Star Wars" and "Raiders of the Lost Ark".

</doc>
<doc id="689" url="https://en.wikipedia.org/wiki?curid=689" title="Asia">
Asia

Asia () is Earth's largest and most populous continent, located primarily in the eastern and northern hemispheres and sharing the continental landmass of Eurasia with the continent of Europe. Asia covers an area of 44,579,000 square kilometers, about 30% of Earth's total land area and 8.7% of the Earth's total surface area. The continent, which has long been home to the majority of the human population, was the site of many of the first civilizations. Asia is notable for not only its overall large size and population, but also dense and large settlements as well as vast barely populated regions within the continent of 4.4 billion people.
In general terms, Asia is bounded on the east by the Pacific Ocean, on the south by the Indian Ocean and on the north by the Arctic Ocean. The western boundary with Europe is a historical and cultural construct, as there is no clear physical and geographical separation between them. The most commonly accepted boundaries place Asia to the east of the Suez Canal, the Ural River, and the Ural Mountains, and south of the Caucasus Mountains and the Caspian and Black Seas.
China and India alternated in being the largest economies in the world from 1 to 1800 A.D. China was a major economic power and attracted many to the east, and for many the legendary wealth and prosperity of the ancient culture of India personified Asia, attracting European commerce, exploration and colonialism. The accidental discovery of America by Columbus in search for India demonstrates this deep fascination. The Silk Road became the main East-West trading route in the Asian hitherland while the Straits of Malacca stood as a major sea route. Asia has exhibited economic dynamism (particularly East Asia) as well as robust population growth during the 20th century, but overall population growth has since fallen. Asia was the birthplace of most of the world's mainstream religions including Christianity, Islam, Judaism, Hinduism, Buddhism, Confucianism, Taoism (or Daoism), Jainism, Sikhism, Zoroastranism, as well as many other religions.
Given its size and diversity, the concept of Asia—a name dating back to classical antiquity—may actually have more to do with human geography than physical geography. Asia varies greatly across and within its regions with regard to ethnic groups, cultures, environments, economics, historical ties and government systems. It also has a mix of many different climates ranging from the equatorial south via the hot desert in the Middle East, temperate areas in the east and the extremely continental centre to vast subarctic and polar areas in Siberia.
<h2>Definition and boundaries.</h2>
<h3>Asia-Africa boundary.</h3>
The boundary between Asia and Africa is the Red Sea, the Gulf of Suez, and the Suez Canal. This makes Egypt a transcontinental country, with the Sinai peninsula in Asia and the remainder of the country in Africa.
<h3>Asia–Europe boundary.</h3>
The border between Asia and Europe was historically defined by European academics. The Don River became unsatisfactory to northern Europeans when Peter the Great, king of the Tsardom of Russia, defeating rival claims of Sweden and the Ottoman Empire to the eastern lands, and armed resistance by the tribes of Siberia, synthesized a new Russian Empire extending to the Ural Mountains and beyond, founded in 1721. The major geographical theorist of the empire was actually a former Swedish prisoner-of-war, taken at the Battle of Poltava in 1709 and assigned to Tobolsk, where he associated with Peter's Siberian official, Vasily Tatishchev, and was allowed freedom to conduct geographical and anthropological studies in preparation for a future book.
In Sweden, five years after Peter's death, in 1730 Philip Johan von Strahlenberg published a new atlas proposing the Urals as the border of Asia. The Russians were enthusiastic about the concept, which allowed them to keep their European identity in geography. Tatishchev announced that he had proposed the idea to von Strahlenberg. The latter had suggested the Emba River as the lower boundary. Over the next century various proposals were made until the Ural River prevailed in the mid-19th century. The border had been moved perforce from the Black Sea to the Caspian Sea into which the Ural River projects. The border between the Black Sea and the Caspian is usually placed along the crest of the Caucasus Mountains, although it is sometimes placed further north.
<h3>Asia–Oceania boundary.</h3>
The border between Asia and the loosely defined region of Oceania is usually placed somewhere in the Malay Archipelago. The terms Southeast Asia and Oceania, devised in the 19th century, have had several vastly different geographic meanings since their inception. The chief factor in determining which islands of the Malay Archipelago are Asian has been the location of the colonial possessions of the various empires there (not all European). Lewis and Wigen assert, "The narrowing of 'Southeast Asia' to its present boundaries was thus a gradual process."
<h3>Ongoing definition.</h3>
Geographical Asia is a cultural artifact of European conceptions of the world, beginning with the Ancient Greeks, being imposed onto other cultures, an imprecise concept causing endemic contention about what it means. Asia is larger and more culturally diverse than Europe. It does not exactly correspond to the cultural borders of its various types of constituents.
From the time of Herodotus a minority of geographers have rejected the three-continent system (Europe, Africa, Asia) on the grounds that there is no or is no substantial physical separation between them. For example, Sir Barry Cunliffe, the emeritus professor of European archeology at Oxford, argues that Europe has been geographically and culturally merely "the western excrescence of the continent of Asia". Geographically, Asia is the major eastern constituent of the continent of Eurasia with Europe being a northwestern peninsula of the landmass. Asia, Europe and Africa make up a single continuous landmass - Afro-Eurasia (except for the Suez Canal) and share a common continental shelf. Almost all of Europe and the better part of Asia sit atop the Eurasian Plate, adjoined on the south by the Arabian and Indian Plate and with the easternmost part of Siberia (east of the Chersky Range) on the North American Plate.
<h2>Etymology.</h2>
The English word, "Asia," was originally a concept of Greek civilization. The place name, "Asia", in various forms in a large number of modern languages is of unknown ultimate provenience. Its etymology and language of origin are uncertain. It appears to be one of the most ancient of recorded names. A number of theories have been published. English Asia can be traced through the formation of English literature to Latin literature, where it has the same form, Asia. Whether all uses and all forms of the name derive also from the Latin of the Roman Empire is much less certain.
<h3>Bronze Age.</h3>
Before Greek poetry, the Aegean Sea area was in a Greek Dark Age, at the beginning of which syllabic writing was lost and alphabetic writing had not begun. Prior to then in the Bronze Age the records of the Assyrian Empire, the Hittite Empire and the various Mycenaean states of Greece mention a region undoubtedly Asia, certainly in Anatolia, including if not identical to Lydia. These records are administrative and do not include poetry.
The Mycenaean states were destroyed about 1200 BC by unknown agents although one school of thought assigns the Dorian invasion to this time. The burning of the palaces baked clay diurnal administrative records written in a Greek syllabic script called Linear B, deciphered by a number of interested parties, most notably by a young World War II cryptographer, Michael Ventris, subsequently assisted by the scholar, John Chadwick. A major cache discovered by Carl Blegen at the site of ancient Pylos included hundreds of male and female names formed by different methods.
Some of these are of women held in servitude (as study of the society implied by the content reveals). They were used in trades, such as cloth-making, and usually came with children. The epithet, lawiaiai, "captives," associated with some of them identifies their origin. Some are ethnic names. One in particular, aswiai, identifies "women of Asia." Perhaps they were captured in Asia, but some others, Milatiai, appear to have been of Miletus, a Greek colony, which would not have been raided for slaves by Greeks. Chadwick suggests that the names record the locations where these foreign women were purchased. The name is also in the singular, Aswia, which refers both to the name of a country and to a female of it. There is a masculine form, aswios. This Aswia appears to have been a remnant of a region known to the Hittites as Assuwa, centered on Lydia, or "Roman Asia." This name, "Assuwa", has been suggested as the origin for the name of the continent "Asia". The Assuwa league was a confederation of states in western Anatolia, defeated by the Hittites under Tudhaliya I around 1400 BC.
Alternatively, the etymology of the term may be from the Akkadian word "(w)aṣû(m)", which means 'to go outside' or 'to ascend', referring to the direction of the sun at sunrise in the Middle East and also likely connected with the Phoenician word "asa" meaning east. This may be contrasted to a similar etymology proposed for "Europe", as being from Akkadian "erēbu(m)" 'to enter' or 'set' (of the sun).
T.R. Reid supports this alternative etymology, noting that the ancient Greek name must have derived from "asu", meaning 'east' in Assyrian ("ereb" for "Europe" meaning 'west'). The ideas of "Occidental" (form Latin "Occidens" 'setting') and "Oriental" (from Latin "Oriens" for 'rising') are also European invention, synonymous with "Western" and "Eastern". Reid further emphasizes that it explains the Western point of view of placing all the peoples and cultures of Asia into a single classification, almost as if there were a need for setting the distinction between Western and Eastern civilizations on the Eurasian continent. Ogura Kazuo and Tenshin Okakura are two outspoken Japanese figures on the subject.
<h3>Classical antiquity.</h3>
Latin Asia and Greek Ἀσία appear to be the same word. Roman authors translated Ἀσία as Asia. The Romans named a province Asia, which roughly corresponds with modern-day central-western Turkey. There was an Asia Minor and an Asia Major located in modern-day Iraq. As the earliest evidence of the name is Greek, it is likely circumstantially that Asia came from Ἀσία, but ancient transitions, due to the lack of literary contexts, are difficult to catch in the act. The most likely vehicles were the ancient geographers and historians, such as Herodotus, who were all Greek. Ancient Greek certainly evidences early and rich uses of the name.
The first continental use of Asia is attributed to Herodotus (about 440 BC), not because he innovated it, but because his "Histories" are the earliest surviving prose to describe it in any detail. He defines it carefully, mentioning the previous geographers whom he had read, but whose works are now missing. By it he means Anatolia and the Persian Empire, in contrast to Greece and Egypt. Herodotus comments that he is puzzled as to why three women's names were "given to a tract which is in reality one" (Europa, Asia, and Libya, referring to Africa), stating that most Greeks assumed that Asia was named after the wife of Prometheus (i.e. Hesione), but that the Lydians say it was named after Asies, son of Cotys, who passed the name on to a tribe at Sardis. In Greek mythology, "Asia" ("Ἀσία") or "Asie" ("Ἀσίη") was the name of a "Nymph or Titan goddess of Lydia."
In ancient Greek religion, places were under the care of female divinities, parallel to guardian angels. The poets detailed their doings and generations in allegoric language salted with entertaining stories, which subsequently playwrights transformed into classical Greek drama and became "Greek mythology." For example, Hesiod mentions the daughters of Tethys and Ocean, among whom are a "holy company", "who with the Lord Apollo and the Rivers have youths in their keeping." Many of these are geographic: Doris, Rhodea, Europa, Asia. Hesiod explains:"For there are three-thousand neat-ankled daughters of Ocean who are dispersed far and wide, and in every place alike serve the earth and the deep waters." The Iliad (attributed by the ancient Greeks to Homer) mentions two Phrygians (the tribe that replaced the Luvians in Lydia) in the Trojan War named Asios (an adjective meaning "Asian"); and also a marsh or lowland containing a marsh in Lydia as ασιος.
<h2>History.</h2>
The history of Asia can be seen as the distinct histories of several peripheral coastal regions: East Asia, South Asia, Southeast Asia and the Middle East, linked by the interior mass of the Central Asian steppes.
The coastal periphery was home to some of the world's earliest known civilizations, each of them developing around fertile river valleys. The civilizations in Mesopotamia, the Indus Valley and the Yellow River shared many similarities. These civilizations may well have exchanged technologies and ideas such as mathematics and the wheel. Other innovations, such as writing, seem to have been developed individually in each area. Cities, states and empires developed in these lowlands.
The central steppe region had long been inhabited by horse-mounted nomads who could reach all areas of Asia from the steppes. The earliest postulated expansion out of the steppe is that of the Indo-Europeans, who spread their languages into the Middle East, South Asia, and the borders of China, where the Tocharians resided. The northernmost part of Asia, including much of Siberia, was largely inaccessible to the steppe nomads, owing to the dense forests, climate and tundra. These areas remained very sparsely populated.
The center and the peripheries were mostly kept separated by mountains and deserts. The Caucasus and Himalaya mountains and the Karakum and Gobi deserts formed barriers that the steppe horsemen could cross only with difficulty. While the urban city dwellers were more advanced technologically and socially, in many cases they could do little in a military aspect to defend against the mounted hordes of the steppe. However, the lowlands did not have enough open grasslands to support a large horsebound force; for this and other reasons, the nomads who conquered states in China, India, and the Middle East often found themselves adapting to the local, more affluent societies.
The Islamic Caliphate took over the Middle East and Central Asia during the Muslim conquests of the 7th century. The Mongol Empire conquered a large part of Asia in the 13th century, an area extending from China to Europe. Before the Mongol invasion, Song dynasty reportedly had approximately 120 million citizens; the 1300 census which followed the invasion reported roughly 60 million people.
The Black Death, one of the most devastating pandemics in human history, is thought to have originated in the arid plains of central Asia, where it then travelled along the Silk Road.
The Russian Empire began to expand into Asia from the 17th century, and would eventually take control of all of Siberia and most of Central Asia by the end of the 19th century. The Ottoman Empire controlled Anatolia, the Middle East, North Africa and the Balkans from the 16th century onwards. In the 17th century, the Manchu conquered China and established the Qing Dynasty. The Islamic Mughal Empire and the Hindu Maratha Empire controlled much of India in the 16th and 18th centuries respectively.
<h2>Geography and climate.</h2>
Asia is the largest continent on Earth. It covers 8.8% of the Earth's total surface area (or 30% of its land area), and has the largest coastline, at . Asia is generally defined as comprising the eastern four-fifths of Eurasia. It is located to the east of the Suez Canal and the Ural Mountains, and south of the Caucasus Mountains (or the Kuma–Manych Depression) and the Caspian and Black Seas. It is bounded on the east by the Pacific Ocean, on the south by the Indian Ocean and on the north by the Arctic Ocean. Asia is subdivided into 48 countries, two of them (Russia and Turkey) having part of their land in Europe.
Asia has extremely diverse climates and geographic features. Climates range from arctic and subarctic in Siberia to tropical in southern India and Southeast Asia. It is moist across southeast sections, and dry across much of the interior. Some of the largest daily temperature ranges on Earth occur in western sections of Asia. The monsoon circulation dominates across southern and eastern sections, due to the presence of the Himalayas forcing the formation of a thermal low which draws in moisture during the summer. Southwestern sections of the continent are hot. Siberia is one of the coldest places in the Northern Hemisphere, and can act as a source of arctic air masses for North America. The most active place on Earth for tropical cyclone activity lies northeast of the Philippines and south of Japan. The Gobi Desert is in Mongolia and the Arabian Desert stretches across much of the Middle East. The Yangtze River in China is the longest river in the continent. The Himalayas between Nepal and China is the tallest mountain range in the world. Tropical rainforests stretch across much of southern Asia and coniferous and deciduous forests lie farther north.
<h3>Climate change.</h3>
A survey carried out in 2010 by global risk analysis farm Maplecroft identified 16 countries that are extremely vulnerable to climate change. Each nation's vulnerability was calculated using 42 socio, economic and environmental indicators, which identified the likely climate change impacts during the next 30 years. The Asian countries of Bangladesh, India, Vietnam, Thailand, Pakistan and Sri Lanka were among the 16 countries facing extreme risk from climate change. Some shifts are already occurring. For example, in tropical parts of India with a semi-arid climate, the temperature increased by 0.4 °C between 1901 and 2003.
A 2013 study by the International Crops Research Institute for the Semi-Arid Tropics (ICRISAT) aimed to find science-based, pro-poor approaches and techniques that would enable Asia's agricultural systems to cope with climate change, while benefitting poor and vulnerable farmers. The study's recommendations ranged from improving the use of climate information in local planning and strengthening weather-based agro-advisory services, to stimulating diversification of rural household incomes and providing incentives to farmers to adopt natural resource conservation measures to enhance forest cover, replenish groundwater and use renewable energy.
<h2>Economy.</h2>
Asia has the second largest nominal GDP of all continents, after Europe, but the largest when measured in purchasing power parity. As of 2011, the largest economies in Asia are China, Japan, India, South Korea and Indonesia. Based on Global Office Locations 2011, Asia dominated the office locations with 4 of top 5 being in Asia, Hong Kong, Singapore, Tokyo, Seoul and Shanghai. Around 68 percent of international firms have office in Hong Kong.
In the late 1990s and early 2000s, the economies of the China and India have been growing rapidly, both with an average annual growth rate of more than 8%. Other recent very-high-growth nations in Asia include Israel, Malaysia, Indonesia, Bangladesh, Pakistan, Thailand, Vietnam, Mongolia, Uzbekistan, Cyprus and the Philippines, and mineral-rich nations such as Kazakhstan, Turkmenistan, Iran, Brunei, United Arab Emirates, Qatar, Kuwait, Saudi Arabia, Bahrain and Oman.
According to economic historian Angus Maddison in his book "The World Economy: A Millennial Perspective", India had the world's largest economy during 0 BCE and 1000 BCE. China was the largest and most advanced economy on earth for much of recorded history, until the British Empire (excluding India) overtook it in the mid-19th century. For several decades in the late twentieth century Japan was the largest economy in Asia and second-largest of any single nation in the world, after surpassing the Soviet Union (measured in net material product) in 1986 and Germany in 1968. (NB: A number of supernational economies are larger, such as the European Union (EU), the North American Free Trade Agreement (NAFTA) or APEC). This ended in 2010 when China overtook Japan to become the world's second largest economy.
In the late 1980s and early 1990s, Japan's GDP was almost as large (current exchange rate method) as that of the rest of Asia combined. In 1995, Japan's economy nearly equaled that of the USA as the largest economy in the world for a day, after the Japanese currency reached a record high of 79 yen/US$. Economic growth in Asia since World War II to the 1990s had been concentrated in Japan as well as the four regions of South Korea, Taiwan, Hong Kong and Singapore located in the Pacific Rim, known as the Asian tigers, which have now all received developed country status, having the highest GDP per capita in Asia.
It is forecasted that India will overtake Japan in terms of nominal GDP by 2020. By 2027, according to Goldman Sachs, China will have the largest economy in the world. Several trade blocs exist, with the most developed being the Association of Southeast Asian Nations.
Asia is the largest continent in the world by a considerable margin, and it is rich in natural resources, such as petroleum, forests, fish, water, rice, copper and silver. Manufacturing in Asia has traditionally been strongest in East and Southeast Asia, particularly in China, Taiwan, South Korea, Japan, India, the Philippines, and Singapore. Japan and South Korea continue to dominate in the area of multinational corporations, but increasingly the PRC and India are making significant inroads. Many companies from Europe, North America, South Korea and Japan have operations in Asia's developing countries to take advantage of its abundant supply of cheap labour and relatively developed infrastructure.
According to Citigroup 9 of 11 Global Growth Generators countries came from Asia driven by population and income growth. They are Bangladesh, China, India, Indonesia, Iraq, Mongolia, Philippines, Sri Lanka and Vietnam. Asia has four main financial centers: Tokyo, Hong Kong, Singapore and Shanghai. Call centers and business process outsourcing (BPOs) are becoming major employers in India and the Philippines due to the availability of a large pool of highly skilled, English-speaking workers. The increased use of outsourcing has assisted the rise of India and the China as financial centers. Due to its large and extremely competitive information technology industry, India has become a major hub for outsourcing.
In 2010, Asia had 3.3 million millionaires (people with net worth over US$1 million excluding their homes), slightly below North America with 3.4 million millionaires. Last year Asia had toppled Europe.
Citigroup in The Wealth Report 2012 stated that Asian centa-millionaire overtook North America's wealth for the first time as the world's "economic center of gravity" continued moving east. At the end of 2011, there were 18,000 Asian people mainly in Southeast Asia, China and Japan who have at least $100 million in disposable assets, while North America with 17,000 people and Western Europe with 14,000 people.
<h2>Tourism.</h2>
With growing Regional Tourism with domination of Chinese visitors, MasterCard has released Global Destination Cities Index 2013 with 10 of 20 are dominated by Asia and Pacific Region Cities and also for the first time a city of a country from Asia (Bangkok) set in the top-ranked with 15.98 international visitors.
<h2>Demographics.</h2>
East Asia had by far the strongest overall Human Development Index (HDI) improvement of any region in the world, nearly doubling average HDI attainment over the past 40 years, according to the report's analysis of health, education and income data. China, the second highest achiever in the world in terms of HDI improvement since
1970, is the only country on the "Top 10 Movers" list due to income rather than health or education achievements. Its per capita income increased a stunning 21-fold over the last four decades, also lifting hundreds of millions out of income poverty. Yet it was not among the region's top performers in improving school enrollment and life expectancy.
<br>Nepal, a South Asian country, emerges as one of the world's fastest movers since 1970 mainly due to health and education achievements. Its present life expectancy is 25 years longer than in the 1970s. More than four of every five children of school age in Nepal now attend primary school, compared to just one in five 40 years ago.
<br> Japan and South Korea ranked highest among the countries grouped on the HDI (number 11 and 12 in the world, which are in the "very high human development" category), followed by Hong Kong (21) and Singapore (27). Afghanistan (155) ranked lowest amongst Asian countries out of the 169 countries assessed.
<h3>Languages.</h3>
Asia is home to several language families and many language isolates. Most Asian countries have more than one language that is natively spoken. For instance, according to Ethnologue, more than 600 languages are spoken in Indonesia, more than 800 languages spoken in India, and more than 100 are spoken in the Philippines. China has many languages and dialects in different provinces.
<h3>Religions.</h3>
Many of the world's major religions have their origins in Asia, including the five most practiced in the world (excluding irreligion), which are Christianity, Islam, Hinduism, Chinese folk religion (classified as Confucianism and Taoism), and Buddhism respectively. Asian mythology is complex and diverse. The story of the Great Flood for example, as presented to Christians in the Old Testament in the narrative of Noah, is first found in Mesopotamian mythology, in the "Epic of Gilgamesh". Hindu mythology tells about an Avatar of the God Vishnu in the form of a fish who warned Manu of a terrible flood. In ancient Chinese mythology, Shan Hai Jing, the Chinese ruler Da Yu, had to spend 10 years to control a deluge which swept out most of ancient China and was aided by the goddess Nüwa who literally fixed the broken sky through which huge rains were pouring.
<h4>Abrahamic.</h4>
The Abrahamic religions of Judaism, Christianity, Islam and Bahá'í Faith originated in West Asia.
Judaism, the oldest of the Abrahamic faiths, is practiced primarily in Israel, the birthplace and historical homeland of the Hebrew nation which today consists equally of those Israelites who remained in Asia/North Africa and those who returned from diaspora in Europe, North America, and other regions, though sizable communities continue to live abroad. Jews are the predominant ethnic group in Israel (75.6%) numbering at about about 6.1 million, although the levels of adherence to Jewish religion are unspecified. Outside of Israel there are small ancient communities of Jewish still live in Turkey (17,400), Azerbaijan (9,100), Iran (8,756), India (5,000) and Uzbekistan (4,000).
Christianity is a widespread religion in Asia with more than 286 million adherents according to Pew Research Center in 2010, and nearly 364 million according to Britannica Book of the Year 2014. constituting around 12.6% of the total population of Asia. In the Philippines and East Timor, Roman Catholicism is the predominant religion; it was introduced by the Spaniards and the Portuguese, respectively. In Armenia, Cyprus, Georgia and Asian Russia, Eastern Orthodoxy is the predominant religion. Various Christian denominations have adherents in portions of the Middle East, as well as China and India. Saint Thomas Christians in India trace their origins to the evangelistic activity of Thomas the Apostle in the 1st century.
Islam, which originated in Saudi Arabia, is the largest and most widely spread religion in Asia with at least 1 billion Muslims. With 12.7% of the world Muslim population, the country currently with the largest Muslim population in the world is Indonesia, followed by Pakistan, India, Bangladesh, Iran and Turkey. Mecca, Medina and to a lesser extent Jerusalem are the holiest cities for Islam in all the world. These religious sites attract large numbers of devotees from all over the world, particularly during the Hajj and Umrah seasons. Iran is the largest Shi'a country and Pakistan has the largest Ahmadiyya population.
The Bahá'í Faith originated in Asia, in Iran (Persia), and spread from there to the Ottoman Empire, Central Asia, India, and Burma during the lifetime of Bahá'u'lláh. Since the middle of the 20th century, growth has particularly occurred in other Asian countries, because Bahá'í activities in many Muslim countries has been severely suppressed by authorities. Lotus Temple is a big Baha'i Temple in India.
<h4>Indian and East Asian religions.</h4>
Almost all Asian religions have philosophical character and Asian philosophical traditions cover a large spectrum of philosophical thoughts and writings. Indian philosophy includes Hindu philosophy and Buddhist philosophy. They include elements of nonmaterial pursuits, whereas another school of thought from India, Cārvāka, preached the enjoyment of the material world. The religions of Hinduism, Buddhism, Jainism and Sikhism originated in India, South Asia. In East Asia, particularly in China and Japan, Confucianism, Taoism and Zen Buddhism took shape.
As of 2012, Hinduism has around 1.1 billion adherents. The faith represents around 25% of Asia's population and is the second largest religion in Asia. However, it is mostly concentrated in South Asia. Over 80% of the populations of both India and Nepal adhere to Hinduism, alongside significant communities in Bangladesh, Pakistan, Bhutan, Sri Lanka and Bali, Indonesia. Many overseas Indians in countries such as Burma, Singapore and Malaysia also adhere to Hinduism.
Buddhism has a great following in mainland Southeast Asia and East Asia. Buddhism is the religion of the majority of the populations of Cambodia (96%), Thailand (95%), Burma (80%–89%), Japan (36%–96%), Bhutan (75%–84%), Sri Lanka (70%), Laos (60%–67%) and Mongolia (53%–93%). Large Buddhist populations also exist in Singapore (33%–51%), Taiwan (35%–93%), South Korea (23%–50%), Malaysia (19%–21%), Nepal (9%–11%), Vietnam (10%–75%), China (20%–50%), North Korea (1.5%–14%), and small communities in India and Bangladesh. In many Chinese communities, Mahayana Buddhism is easily syncretized with Taoism, thus exact religious statistics is difficult to obtain and may be understated or overstated. The Communist-governed countries of China, Vietnam and North Korea are officially atheist, thus the number of Buddhists and other religious adherents may be under-reported.
Jainism is found mainly in India and in oversea Indian communities such as the United States and Malaysia.
Sikhism is found in Northern India and amongst overseas Indian communities in other parts of Asia, especially Southeast Asia.
Confucianism is found predominantly in Mainland China, South Korea, Taiwan and in overseas Chinese populations.
Taoism is found mainly in Mainland China, Taiwan, Malaysia and Singapore. Taoism is easily syncretized with Mahayana Buddhism for many Chinese, thus exact religious statistics is difficult to obtain and may be understated or overstated.
<h2>Modern conflicts.</h2>
Some of the events pivotal in the Asia territory related to the relationship with the outside world in the post-Second World War were:
<h2>Culture.</h2>
<h3>Nobel prizes.</h3>
The polymath Rabindranath Tagore, a Bengali poet, dramatist, and writer from Santiniketan, now in West Bengal, India, became in 1913 the first Asian Nobel laureate. He won his Nobel Prize in Literature for notable impact his prose works and poetic thought had on English, French, and other national literatures of Europe and the Americas. He is also the writer of the national anthems of Bangladesh and India.
Other Asian writers who won Nobel Prize for literature include Yasunari Kawabata (Japan, 1968), Kenzaburō Ōe (Japan, 1994), Gao Xingjian (China, 2000), Orhan Pamuk (Turkey, 2006), and Mo Yan (China, 2012). Some may consider the American writer, Pearl S. Buck, an honorary Asian Nobel laureate, having spent considerable time in China as the daughter of missionaries, and based many of her novels, namely "The Good Earth" (1931) and "The Mother" (1933), as well as the biographies of her parents of their time in China, "The Exile" and "Fighting Angel", all of which earned her the Literature prize in 1938.
Also, Mother Teresa of India and Shirin Ebadi of Iran were awarded the Nobel Peace Prize for their significant and pioneering efforts for democracy and human rights, especially for the rights of women and children. Ebadi is the first Iranian and the first Muslim woman to receive the prize. Another Nobel Peace Prize winner is Aung San Suu Kyi from Burma for her peaceful and non-violent struggle under a military dictatorship in Burma. She is a nonviolent pro-democracy activist and leader of the National League for Democracy in Burma (Myanmar) and a noted prisoner of conscience. She is a Buddhist and was awarded the Nobel Peace Prize in 1991. Chinese dissident Liu Xiaobo was awarded the Nobel Peace Prize for "his long and non-violent struggle for fundamental human rights in China" on 8 October 2010. He is the first Chinese citizen to be awarded a Nobel Prize of any kind while residing in China. In 2014, Kailash Satyarthi from India and Malala Yousafzai from Pakistan were awarded the Nobel Peace Prize "for their struggle against the suppression of children and young people and for the right of all children to education".
Sir C. V. Raman is the first Asian to get a Nobel prize in Sciences. He won the Nobel Prize in Physics "for his work on the scattering of light and for the discovery of the effect named after him".
Japan has won the most Nobel Prizes of any Asian nation with 24 followed by India which has won 13.
Amartya Sen, (born 3 November 1933) is an Indian economist who was awarded the 1998 Nobel Memorial Prize in Economic Sciences for his contributions to welfare economics and social choice theory, and for his interest in the problems of society's poorest members.
Other Asian Nobel Prize winners include Subrahmanyan Chandrasekhar, Abdus Salam, Robert Aumann, Menachem Begin, Aaron Ciechanover, Avram Hershko, Daniel Kahneman, Shimon Peres, Yitzhak Rabin, Ada Yonath, Yasser Arafat, José Ramos-Horta and Bishop Carlos Filipe Ximenes Belo of Timor Leste, Kim Dae-jung, and 13 Japanese scientists. Most of the said awardees are from Japan and Israel except for Chandrasekhar and Raman (India), Salam (Pakistan), Arafat (Palestinian Territories), Kim (South Korea), and Horta and Belo (Timor Leste).
In 2006, Dr. Muhammad Yunus of Bangladesh was awarded the Nobel Peace Prize for the establishment of Grameen Bank, a community development bank that lends money to poor people, especially women in Bangladesh. Dr. Yunus received his PhD in economics from Vanderbilt University, United States. He is internationally known for the concept of micro credit which allows poor and destitute people with little or no collateral to borrow money. The borrowers typically pay back money within the specified period and the incidence of default is very low.
The Dalai Lama has received approximately eighty-four awards over his spiritual and political career. On 22 June 2006, he became one of only four people ever to be recognized with Honorary Citizenship by the Governor General of Canada. On 28 May 2005, he received the Christmas Humphreys Award from the Buddhist Society in the United Kingdom. Most notable was the Nobel Peace Prize, presented in Oslo, Norway on 10 December 1989.
<h2>Political geography.</h2>
Within the above-mentioned states are several partially recognized countries with limited to no international recognition. None of them are members of the UN:
<h2>See also.</h2>
References to articles:
Special topics:
Lists:

</doc>
<doc id="690" url="https://en.wikipedia.org/wiki?curid=690" title="Aruba">
Aruba

Aruba ( ; ) is a constituent country of the Kingdom of the Netherlands in the southern Caribbean Sea, located about west of the main part of the Lesser Antilles and north of the coast of Venezuela. It measures long from its northwestern to its southeastern end and across at its widest point. Together with Bonaire and Curaçao, Aruba forms a group referred to as the ABC islands. Collectively, Aruba and the other Dutch islands in the Caribbean are often called the Dutch Caribbean.
Aruba is one of the four countries that form the Kingdom of the Netherlands, along with the Netherlands, Curaçao and Sint Maarten. The citizens of these countries all share a single nationality: Dutch. Aruba has no administrative subdivisions, but, for census purposes, is divided into eight regions. Its capital is Oranjestad.
Unlike much of the Caribbean region, Aruba has a dry climate and an arid, cactus-strewn landscape. This climate has helped tourism as visitors to the island can reliably expect warm, sunny weather. It has a land area of and is densely populated, with a total of 102,484 inhabitants at the 2010 Census. It lies outside Hurricane Alley.
<h2>History.</h2>
Aruba's first inhabitants are thought to have been Caquetío Amerindians from the Arawak tribe, who migrated there from Venezuela to escape attacks by the Caribs. Fragments of the earliest known Indian settlements date back to 1000 AD. As sea currents made canoe travel to other Caribbean islands difficult, Caquetio culture remained more closely associated with that of mainland South America.
Europeans first learned of Aruba following the explorations for Spain by Amerigo Vespucci and Alonso de Ojeda in the summer of 1499. Both described Aruba as an "island of giants", remarking on the comparatively large stature of the native Caquetíos compared to Europeans. Gold was not discovered on Aruba for another 300 years. Vespucci returned to Spain with stocks of cotton and brazilwood from the island and described houses built into the ocean. Vespucci and Ojeda's tales spurred interest in Aruba, and Spaniards soon colonized the island.
Because it had low rainfall, Aruba was not considered profitable for the plantation system and the economics of the slave trade.
Aruba was colonized by Spain for over a century. "Simas", the "Cacique", or chief, in Aruba, welcomed the first Catholic priests in Aruba, who gave him a wooden cross as a gift. In 1508, the Spanish Crown appointed Alonso de Ojeda as its first Governor of Aruba, as part of "Nueva Andalucía". Arawaks spoke the "broken Spanish" which their ancestors had learned on Hispaniola.
Another governor appointed by Spain was Juan Martínez de Ampiés. A "cédula real" decreed in November 1525 gave Ampiés, factor of Española, the right to repopulate Aruba. In 1528, Ampiés was replaced by a representative of the House of Welser.
The Dutch statutes have applied to Aruba since 1629. The Netherlands acquired Aruba in 1636. Since 1636, Aruba has been under Dutch administration, initially governed by Peter Stuyvesant, later appointed to New Amsterdam (New York City). Stuyvesant was on a special mission in Aruba in November and December 1642. The island was included under the Dutch West India Company (W.I.C.) administration, as "New Netherland and Curaçao", from 1648 to 1664. In 1667 the Dutch administration appointed an Irishman as "Commandeur" in Aruba.
The Dutch took control 135 years after the Spanish, leaving the Arawaks to farm and graze livestock, and used the island as a source of meat for other Dutch possessions in the Caribbean.
During the Napoleonic wars, the British Empire took control over the island, between 1799 and 1802, and between 1804 and 1816, before handing it back to the Dutch. 
During World War II with the occupation of the Netherlands in 1940 the oil facilities in Aruba came under the administration of the Dutch government-in-exile in London, and Aruba continued to supply oil to the British and their allies.
<h3>Move towards independence.</h3>
In August 1947, Aruba presented its first "Staatsreglement" (constitution), for Aruba's "status aparte" as an autonomous state within the Kingdom of the Netherlands. By 1954, the Charter of the Kingdom of the Netherlands was established, providing a framework for relations between Aruba and the rest of the Kingdom.
In 1972, at a conference in Suriname, Betico Croes (MEP), a politician from Aruba, proposed a "sui-generis" Dutch Commonwealth of four states: Aruba, the Netherlands, Suriname and the Netherlands Antilles, each to have its own nationality. C. Yarzagaray, a parliamentary member representing the AVP political party, proposed a referendum so that the people of Aruba could choose whether they wanted total independence or "Status Aparte" as a full autonomous state under the Crown.
Croes worked in Aruba to inform and prepare the people of Aruba for independence. In 1976, he appointed a committee that chose the national flag and anthem, introducing them as symbols of Aruba's sovereignty and independence. He set 1981 as a target date for independence. In March 1977, the first Referendum for Self Determination was held with the support of the United Nations; 82% of the participants voted for independence.
The Island Government of Aruba assigned the Institute of Social Studies in The Hague to prepare a study for independence; it was titled "Aruba en Onafhankelijkheid, achtergronden, modaliteiten en mogelijkheden; een rapport in eerste aanleg" (Aruba and independence, backgrounds, modalities and opportunities; a preliminary report) (1978). At the conference in The Hague in 1981, Aruba's independence was set for the year 1991.
In March 1983, Aruba reached an official agreement within the Kingdom for its independence, to be developed in a series of steps as the Crown granted increasing autonomy. In August 1985 Aruba drafted a constitution that was unanimously approved. On 1 January 1986, after elections were held for its first parliament, Aruba seceded from the Netherlands Antilles; it officially became a country of the Kingdom of the Netherlands. Full independence was projected in 1996.
After his death in 1986, Croes was proclaimed "Libertador di Aruba". At a convention in The Hague in 1990, at the request of Aruba's Prime Minister, the governments of Aruba, the Netherlands, and the Netherlands Antilles postponed indefinitely its transition to full independence. The article scheduling Aruba's complete independence was rescinded in 1995, although the process could be revived after another referendum.
<h2>Geography.</h2>
Aruba is a generally flat, riverless island in the Leeward Antilles island arc of the Lesser Antilles in the southern part of the Caribbean. It has white sandy beaches on the western and southern coasts of the island, relatively sheltered from fierce ocean currents. This is where most tourist development has occurred. The northern and eastern coasts, lacking this protection, are considerably more battered by the sea and have been left largely untouched by humans.
The hinterland of the island features some rolling hills, the best known of which are called Hooiberg at and Mount Jamanota, the highest on the island at above sea level. Oranjestad, the capital, is located at .
To the east of Aruba are Bonaire and Curaçao, two island territories which once formed the southwest part of the Netherlands Antilles. This group of islands is sometimes called the ABC islands. They are located on the South American continental shelf and therefore geographically listed as part of South America.
The Natural Bridge was a large, naturally formed limestone bridge on the island's north shore. It was a popular tourist destination until its collapse in 2005.
<h3>Cities and towns.</h3>
The island, with a population of just over 100,000 inhabitants, does not have major cities. However, most of the island's population resides in or surrounding the two major city-like districts of Oranjestad (Capital) and San Nicolaas. Furthermore, the island is divided into six districts, which are:
<h3>Fauna.</h3>
The island of Aruba, being isolated from the main land of South America, has helped the evolution of multiple endemic animals. The island provides a habitat for the endemic Aruban Whiptail and Aruba Rattlesnake, as well as endemic subspecies of Burrowing Owl and Brown-throated Parakeet.
The rattlesnake and the owl are printed on the Aruban currency.
<h3>Flora.</h3>
The flora of Aruba differs from the typical tropical island vegetation. Xeric scrublands are common, with various forms of cacti, thorny shrubs and evergreens. With the most known plant being the Aloe vera, which has a place on the Coat of Arms of Aruba.
<h3>Climate.</h3>
In the Köppen climate classification, Aruba has a tropical semi-arid climate. Mean monthly temperature in Oranjestad varies little from to , moderated by constant trade winds from the Atlantic Ocean, which comes from north-east. Yearly precipitation barely exceeds in Oranjestad.
<h2>Demographics.</h2>
The population is estimated to be 75% mixed European/Amerindian, 15% Black and 10% other ethnicities.
The Arawak heritage is stronger on Aruba than on most Caribbean islands. Although no full-blooded Aboriginals remain, the features of the islanders clearly indicate their genetic Arawak heritage. Most of the population is descended from Caquetio Indians and Dutch and to a lesser extent of Africans, Spanish, Portuguese, English, French, and Sephardic Jewish ancestors.
Recently, there has been substantial immigration to the island from neighboring American and Caribbean nations, possibly attracted by the higher paid jobs. In 2007, new immigration laws were introduced to help control the growth of the population by restricting foreign workers to a maximum of three years residency on the island.
Demographically, Aruba has felt the impact of its proximity to Venezuela. Many of Aruba's families are descended from Venezuelan immigrants. There is a seasonal increase of Venezuelans living in second homes.
<h3>Language.</h3>
The official languages are Dutch and – since 2003 – Papiamento. Papiamento is the predominant language on Aruba. It is a creole language, spoken on Aruba, Bonaire, and Curaçao, that incorporates words from Portuguese, West African languages, Dutch, and Spanish. English is known by many; its usage has grown due to tourism. Other common languages spoken, based on the size of their community, are Portuguese, Chinese, German, Spanish, and French.
In recent years, the government of Aruba has shown an increased interest in acknowledging the cultural and historical importance of its native language. Although spoken Papiamento is fairly similar among the several Papiamento-speaking islands, there is a big difference in written Papiamento. The orthography differs per island and even per group of people. Some are more oriented towards Portuguese and use the equivalent spelling (e.g. "y" instead of "j"), where others are more oriented towards Dutch.
The book "The Buccaneers of America", first published in 1678, states through eyewitness account that the natives on Aruba spoke "Spanish". The oldest government official statement written in Papiamento dates from 1803. Around 12.6% of the population today speaks Spanish.
Aruba has four newspapers published in Papiamento: "Diario", "Bon Dia", "Solo di Pueblo" and "Awe Mainta"; and three in English: "Aruba Daily", "Aruba Today" and "The News". "Amigoe" is a newspaper published in Dutch. Aruba also has 18 radio stations (two AM and 16 FM) and three local television stations (Telearuba, Aruba Broadcast Company and Channel 22).
<h3>Regions.</h3>
For census purposes, Aruba is divided into eight regions, which have no administrative functions:
<h2>Government.</h2>
As a constituent country of the Kingdom of the Netherlands, Aruba's politics take place within a framework of a 21-member Parliament and an eight-member Cabinet. The governor of Aruba is appointed for a six-year term by the monarch, and the prime minister and deputy prime minister are elected by the Staten (or "Parlamento") for four-year terms. The Staten is made up of 21 members elected by direct, popular vote to serve a four-year term.
Together with the Netherlands, the countries of Aruba, Curaçao and Sint Maarten form the Kingdom of the Netherlands. As they share the same Dutch citizenship, these four countries still also share the Dutch passport as the Kingdom of the Netherlands passport. As Aruba, Curaçao and Sint Maarten have small populations, the three countries had to limit immigration. To protect their population, they have the right to control the admission and expulsion of people from the Netherlands.
Aruba is designated as a member of the Overseas Countries and Territories (OCT) and is thus officially not a part of the European Union, though Aruba can and does receive support from the European Development Fund.
<h3>Politics.</h3>
The Aruban legal system is based on the Dutch model. In Aruba, legal jurisdiction lies with the "Gerecht in Eerste Aanleg" (Court of First Instance) on Aruba, the "Gemeenschappelijk Hof van Justitie van Aruba, Curaçao, Sint Maarten en van Bonaire, Sint Eustatius en Saba" (Joint Court of Justice of Aruba, Curaçao, Sint Maarten, and of Bonaire, Sint Eustatius and Saba) and the "Hoge Raad der Nederlanden" (Supreme Court of Justice of the Netherlands). The "Korps Politie Aruba" (Aruba Police Force) is the island's law enforcement agency and operates district precincts in Oranjestad, Noord, San Nicolaas, and Santa Cruz, where it is headquartered.
Deficit spending has been a staple in Aruba's history, and modestly high inflation has been present as well. By 2006, the government's debt had grown to 1.883 billion Aruban florins. Aruba received some development aid from the Dutch government each year through 2009, as part of a deal (signed as "Aruba's Financial Independence") in which the Netherlands gradually reduced its financial help to the island each successive year.
In 2006, the Aruban government changed several tax laws to reduce the deficit. Direct taxes have been converted to indirect taxes as proposed by the IMF. A 3% tax has been introduced on sales and services, while income taxes have been lowered and revenue taxes for business reduced by 20%. The government compensated workers with 3.1% for the effect that the B.B.O. would have on the inflation for 2007.
<h2>Education.</h2>
Aruba's educational system is patterned after the Dutch system of education.
The Government of Aruba finances the public national education system.
There are private schools including the International School of Aruba and Schakel College.
There are two medical schools Aureus University School of Medicine and Xavier University School of Medicine, as well as its own national university, the University of Aruba.
<h2>Economy.</h2>
Aruba has one of the highest standards of living in the Caribbean region. There is a low unemployment rate.
The GDP per capita for Aruba was estimated to be $28,924 in 2014; among the highest in the Caribbean and the Americas. Its main trading partners are Colombia, the United States, Venezuela, and the Netherlands.
The island's economy has been dominated by three main industries: tourism, aloe export, and petroleum refining (The Lago Oil and Transport Company and the Arend Petroleum Maatschappij Shell Co.). Before the "Status Aparte" (a separate completely autonomous country/state within the Kingdom), oil processing was the dominant industry in Aruba despite expansion of the tourism sector. Today, the influence of the oil processing business is minimal. The size of the agriculture and manufacturing sectors also remains minimal.
The official exchange rate of the Aruban florin is pegged to the US dollar at 1.79 florins to 1 USD. Because of this fact, and due to a large number of American tourists, many businesses operate using US dollars instead of florins, especially in the hotel and resort districts.
<h3>Tourism.</h3>
About three quarters of the Aruban gross national product is earned through tourism or related activities. Most tourists are from the United States (predominantly from the north-east US), the Netherlands and South America, mainly Venezuela and Colombia.
As part of the Kingdom of the Netherlands, citizens of the Netherlands can travel with relative ease to Aruba and other islands of the Dutch Antilles. No visas are needed for Dutch citizens, only a passport, and although the currency used in Aruba is different (the Netherlands uses the Euro), money can be easily exchanged at a local bank for Aruban Florins.
For the facilitation of the passengers whose destination is the United States, the United States Department of Homeland Security (DHS), U.S. Customs and Border Protection (CBP) full pre-clearance facility in Aruba has been in effect since 1 February 2001 with the expansion in the Queen Beatrix Airport. United States and Aruba have had the agreement since 1986. It began as a USDA and Customs post. Since 2008, Aruba has been the only island to have this service for private flights.
<h3>Military.</h3>
In 1999, the U.S. Department of Defense established a Forward Operating Location (FOL) at the airport.
There is also a small Dutch marines base by Savaneta containing approximately 120 Dutch Marines and about 100 AruMil forces.
<h2>Culture.</h2>
On 18 March, Aruba celebrates its National Day. In 1976, Aruba presented its National Anthem (Aruba Dushi Tera) and Flag.
Aruba has a varied culture. According to the "Bureau Burgelijke Stand en Bevolkingsregister" (BBSB), in 2005 there were ninety-two different nationalities living on the island. Dutch influence can still be seen, as in the celebration of "Sinterklaas" on 5 and 6 December and other national holidays like 27 April, when in Aruba and the rest of the Kingdom of the Netherlands the King's birthday or "Dia di Rey" (Koningsdag) is celebrated.
Christmas and New Year's Eve are celebrated with the typical music and songs for gaitas for Christmas and the Dande for New Year, and "ayaca", "ponche crema", ham, and other typical foods and drinks. Millions of florins worth of fireworks are burnt at midnight on New Year's Eve. On 25 January, Betico Croes' birthday is celebrated. Dia di San Juan is celebrated on June 24.
Besides Christmas, the religious holy days of the Feast of the Ascension and Good Friday are holidays on the island.
The holiday of Carnaval is also an important one in Aruba, as it is in many Caribbean and Latin American countries, and, like Mardi Gras, that goes on for weeks. Its celebration in Aruba started, around the 1950s, influenced by the inhabitants from Venezuela and the nearby islands (Curaçao, St. Vincent, Trinidad, Barbados, St. Maarten and Anguilla) who came to work for the Oil refinery. Over the years the Carnival Celebration has changed and now starts from the beginning of January till the Tuesday before Ash Wednesday with a large parade on the last Sunday of the festivities (Sunday before Ash Wednesday).
Tourism from the United States has recently increased the visibility of American culture on the island, with such celebrations as Halloween and Thanksgiving Day in November.
<h2>Infrastructure.</h2>
Aruba's Queen Beatrix International Airport is located near Oranjestad. According to the Aruba Airport Authority, almost 1.7 million travelers used the airport in 2005, 61% of whom were Americans.
Aruba has two ports, Barcadera and Playa, which are located in Oranjestad and Barcadera. The Port of Playa services all the cruise-ship lines, including Royal Caribbean, Carnival Cruise Lines, NCL, Holland America Line, Disney Cruise Line and others. Nearly one million tourists enter this port per year. Aruba Ports Authority, owned and operated by the Aruban government, runs these seaports.
Arubus is a government-owned bus company. Its buses operate from 3:30 a.m. until 12:30 a.m., 365 days a year. Small private vans also provide transportation services in certain areas such Hotel Area, San Nicolaas, Santa Cruz and Noord.
A street car service runs on rails on the Mainstreet.
<h3>Utilities.</h3>
Water-en Energiebedrijf Aruba, N.V. (W.E.B.) produces potable industrial water at the world's third largest desalination plant. Average daily consumption in Aruba is about .
<h3>Communications.</h3>
There are three telecommunications providers: Setar, a government-based company, Mio Wireless and Digicel, both of which are privately owned. Setar is the provider of services such as internet, video conferencing, GSM wireless technology and land lines. Digicel is Setar's competitor in wireless technology using the GSM platform, and Mio Wireless provides wireless technology and services using CDMA.

</doc>
<doc id="691" url="https://en.wikipedia.org/wiki?curid=691" title="Articles of Confederation">
Articles of Confederation

The Articles of Confederation, formally the Articles of Confederation and Perpetual Union, was an agreement among all thirteen original states in the United States of America that served as its first constitution. Its drafting by a committee appointed by the Second Continental Congress began on July 12, 1776, and an approved version was sent to the states for ratification in late 1777. The formal ratification by all thirteen states was completed in early 1781. Government under the Articles was superseded by a new constitution and federal form of government in 1789.
Even unratified, the Articles provided a system for the Continental Congress to direct the American Revolutionary War, conduct diplomacy with Europe and deal with territorial issues and Native American relations. Nevertheless, the weakness of the government created by the Articles became a matter of concern for key nationalists. On March 4, 1789, the general government under the Articles was replaced with the federal government under the United States Constitution. The new Constitution provided for a much stronger federal government by establishing a chief executive (the President), courts, and taxing powers.
<h2>Background and context.</h2>
The political push to increase cooperation among the then-loyal colonies began with the Albany Congress in 1754 and Benjamin Franklin's proposed Albany Plan of Union, an inter-colonial collaboration to help solve mutual local problems. The Articles of Confederation would bear some resemblance to it. Over the next two decades, some of the basic concepts it addressed would strengthen and others would weaken, particularly the degree of deserved loyalty to the crown. With civil disobedience resulting in coercive, and what the colonials perceived as intolerable acts of Parliament, and armed conflict resulting in dissidents being proclaimed rebels and outside the King's protection, any loyalty remaining shifted toward independence and how to achieve it. In 1775, with events outpacing communications, the Second Continental Congress began acting as the provisional government to run the American Revolutionary War and gain the colonies their collective independence.
It was an era of constitution writing—most states were busy at the task—and leaders felt the new nation must have a written constitution, even though other nations did not. During the war, Congress exercised an unprecedented level of political, diplomatic, military and economic authority. It adopted trade restrictions, established and maintained an army, issued fiat money, created a military code and negotiated with foreign governments.
To transform themselves from outlaws into a legitimate nation, the colonists needed international recognition for their cause and foreign allies to support it. In early 1776, Thomas Paine argued in the closing pages of the first edition of "Common Sense" that the “custom of nations” demanded a formal declaration of American independence if any European power were to mediate a peace between the Americans and Great Britain. The monarchies of France and Spain in particular could not be expected to aid those they considered rebels against another legitimate monarch. Foreign courts needed to have American grievances laid before them persuasively in a “manifesto” which could also reassure them that the Americans would be reliable trading partners. Without such a declaration, Paine concluded, “[t]he custom of all courts is against us, and will be so, until, by an independence, we take rank with other nations.”
Beyond improving their existing association, the records of the Second Continental Congress show that the need for a declaration of independence was intimately linked with the demands of international relations. On June 7, 1776, Richard Henry Lee introduced a resolution before the Continental Congress declaring the colonies independent; at the same time he also urged Congress to resolve “to take the most effectual measures for forming foreign Alliances” and to prepare a plan of confederation for the newly independent states. Congress then created three overlapping committees to draft the Declaration, a Model Treaty, and the Articles of Confederation. The Declaration announced the states' entry into the international system; the model treaty was designed to establish amity and commerce with other states; and the Articles of Confederation, which established “a firm league” among the thirteen free and independent states, constituted an international agreement to set up central institutions for the conduct of vital domestic and foreign affairs.
<h2>Drafting.</h2>
On June 12, 1776, a day after appointing a committee to prepare a draft of the Declaration of Independence, the Second Continental Congress resolved to appoint a committee of 13 to prepare a draft of a constitution for a union of the states. The committee met repeatedly, and chairman John Dickinson presented their results to the Congress on July 12, 1776. There were long debates on such issues as sovereignty, the exact powers to be given the confederate government, whether to have a judiciary, and voting procedures. The final draft of the Articles was prepared in the summer of 1777 and the Second Continental Congress approved them for ratification by the individual states on November 15, 1777, after a year of debate.
In practice, the Articles were in use beginning in 1777; the final draft of the Articles served as the de facto system of government used by the Congress ("the United States in Congress assembled") until it became de jure by final ratification on March 1, 1781; at which point Congress became the Congress of the Confederation. Under the Articles, the states retained sovereignty over all governmental functions not specifically relinquished to the national government. The individual articles set the rules for current and future operations of the United States government. It was made capable of making war and peace, negotiating diplomatic and commercial agreements with foreign countries, and deciding disputes between the states, including their additional and contested western territories. Article XIII stipulated that "their provisions shall be inviolably observed by every state" and "the Union shall be perpetual".
John Dickinson's and Benjamin Franklin's handwritten drafts of the Articles of Confederation are housed at the National Archives in Washington, DC.
<h2>Operation.</h2>
The Articles were created by delegates from the states in the Second Continental Congress out of a need to have "a plan of confederacy for securing the freedom, sovereignty, and independence of the United States." After the war, nationalists, especially those who had been active in the Continental Army, complained that the Articles were too weak for an effective government. There was no president, no executive agencies, no judiciary and no tax base. The absence of a tax base meant that there was no way to pay off state and national debts from the war years except by requesting money from the states, which seldom arrived.
In 1788, with the approval of Congress, the Articles were replaced by the United States Constitution and the new government began operations in 1789.
<h2>Ratification.</h2>
Congress began to move for ratification of the Articles of Confederation in 1777:
The document could not become officially effective until it was ratified by all 13 states. The first state to ratify was Virginia on December 16, 1777; the thirteenth state to ratify was Maryland on February 2, 1781. A ceremonial confirmation of this thirteenth, final ratification took place in the Congress on March 1, 1781 at high noon.
Dates of ratification are:
The ratification process dragged on for several years, stalled by the refusal or additional conditions by landed states to rescind their claims to lands in the West. Maryland was the last holdout; it refused to go along until the landed states, especially Virginia, had indicated they were prepared to cede their claims west of the Ohio River to the Union. It took a little over three years for all states to ratify.
The Articles provided for a blanket acceptance of the Province of Quebec (referred to as "Canada" in the Articles) into the United States if it chose to do so. It did not, and the subsequent Constitution carried no such special provision of admission.
<h2>Article summaries.</h2>
The Articles of Confederation contain a preamble, thirteen articles, a conclusion, and a signatory section. The preamble declares that the states "agree to certain articles of Confederation and perpetual Union."
What follows here summarizes the purpose and content of each of the thirteen articles.
While still at war with Britain, the revolution's leaders were divided between forming a national government with powers either strong and centralized (the "federalists"), or strictly limited (the "anti federalists"). The Continental Congress compromised by dividing sovereignty between the states and the central government, with a unicameral legislature that protected the liberty of the individual states. It empowered Congress to regulate military and monetary affairs, for example, but provided no mechanism to compel the States to comply with requests for either troops or funding. This left the military vulnerable to inadequate funding, supplies, or even food.
<h2>End of the Revolutionary War.</h2>
The Treaty of Paris (1783), which ended hostilities with Great Britain, languished in Congress for months because several state representatives failed to attend sessions of the national legislature to ratify it. Yet Congress had no power to enforce attendance. In September 1783, George Washington complained that Congress was paralyzed. Many revolutionaries had gone to their respective home countries after the war, and local government and self-rule seemed quite satisfactory.
<h2>Function.</h2>
<h3>The Army.</h3>
The Articles supported the Congressional direction of the Continental Army, and allowed the states to present a unified front when dealing with the European powers. As a tool to build a centralized war-making government, they were largely a failure: Historian Bruce Chadwick wrote:
The Continental Congress, before the Articles were approved, had promised soldiers a pension of half pay for life. However Congress had no power to compel the states to fund this obligation, and as the war wound down after the victory at Yorktown the sense of urgency to support the military was no longer a factor. No progress was made in Congress during the winter of 1783–84. General Henry Knox, who would later become the first Secretary of War under the Constitution, blamed the weaknesses of the Articles for the inability of the government to fund the army. The army had long been supportive of a strong union. Knox wrote:
As Congress failed to act on the petitions, Knox wrote to Gouverneur Morris, four years before the Philadelphia Convention was convened, "As the present Constitution is so defective, why do not you great men call the people together and tell them so; that is, to have a convention of the States to form a better Constitution."
Once the war had been won, the Continental Army was largely disbanded. A very small national force was maintained to man the frontier forts and to protect against Native American attacks. Meanwhile, each of the states had an army (or militia), and 11 of them had Navies. The wartime promises of bounties and land grants to be paid for service were not being met. In 1783, George Washington defused the Newburgh conspiracy, but riots by unpaid Pennsylvania veterans forced Congress to leave Philadelphia temporarily.
The Congress from time to time during the Revolutionary War requisitioned troops from the states. Any contributions were voluntary, and in the debates of 1788 the Federalists (who supported the proposed new Constitution) claimed that state politicians acted unilaterally, and contributed when the Continental army protected their state's interests. The Anti-Federalists claimed that state politicians understood their duty to the Union and contributed to advance its needs. Dougherty (2009) concludes that generally the States' behavior validated the Federalist analysis. This helps explain why the Articles of Confederation needed reforms.
<h3>Foreign policy.</h3>
Even after peace had been achieved in 1783, the weakness of the Confederation government frustrated the ability of the government to conduct foreign policy. In 1789, Thomas Jefferson, concerned over the failure to fund an American naval force to confront the Barbary pirates, wrote to James Monroe, "It will be said there is no money in the treasury. There never will be money in the treasury till the Confederacy shows its teeth. The states must see the rod.”
Furthermore, the Jay–Gardoqui Treaty with Spain in 1789 also showed weakness in foreign policy. In this treaty — which was never ratified due to its immense unpopularity — the United States was to give up rights to use the Mississippi River for 25 years, which would have economically strangled the settlers west of the Appalachian Mountains. Finally, due to the Confederation's military weakness, it could not compel the British army to leave frontier forts which were on American soil — forts which, in 1783, the British promised to leave, but which they delayed leaving pending U.S. implementation of other provisions such as ending action against Loyalists and allowing them to seek compensation. This incomplete British implementation of the Treaty of Paris (1783) was superseded by the implementation of Jay's Treaty in 1795 under the new U.S. Constitution.
<h3>Taxation and commerce.</h3>
Under the Articles of Confederation, the central government's power was kept quite limited. The Confederation Congress could make decisions, but lacked enforcement powers. Implementation of most decisions, including modifications to the Articles, required unanimous approval of all thirteen state legislatures.
Congress was denied any powers of taxation: it could only request money from the states. The states often failed to meet these requests in full, leaving both Congress and the Continental Army chronically short of money. As more money was printed by Congress, the continental dollars depreciated. In 1779, George Washington wrote to John Jay, who was serving as the president of the Continental Congress, "that a wagon load of money will scarcely purchase a wagon load of provisions." Mr. Jay and the Congress responded in May by requesting $45 million from the States. In an appeal to the States to comply, Jay wrote that the taxes were "the price of liberty, the peace, and the safety of yourselves and posterity." He argued that Americans should avoid having it said "that America had no sooner become independent than she became insolvent" or that "her infant glories and growing fame were obscured and tarnished by broken contracts and violated faith." The States did not respond with any of the money requested from them.
Congress had also been denied the power to regulate either foreign trade or interstate commerce and, as a result, all of the States maintained control over their own trade policies. The states and the Confederation Congress both incurred large debts during the Revolutionary War, and how to repay those debts became a major issue of debate following the War. Some States paid off their war debts and others did not. Federal assumption of the states' war debts became a major issue in the deliberations of the Constitutional Convention.
<h3>Accomplishments of the Confederation.</h3>
Nevertheless, the Confederation Congress did take two actions with long-lasting impact. The Land Ordinance of 1785 and Northwest Ordinance created territorial government, set up protocols for the admission of new states and the division of land into useful units, and set aside land in each township for public use. This system represented a sharp break from imperial colonization, as in Europe, and provided the basis for the rest of American continental expansion through the 19th Century.
The Land Ordinance of 1785 established both the general practices of land surveying in the west and northwest and the land ownership provisions used throughout the later westward expansion beyond the Mississippi River. Frontier lands were surveyed into the now-familiar squares of land called the township (36 square miles), the section (one square mile), and the quarter section (160 acres). This system was carried forward to most of the States west of the Mississippi (excluding areas of Texas and California that had already been surveyed and divided up by the Spanish Empire). Then, when the Homestead Act was enacted in 1867, the quarter section became the basic unit of land that was granted to new settler-farmers.
The Northwest Ordinance of 1787 noted the agreement of the original states to give up northwestern land claims, organized the Northwest Territory and thus cleared the way for the entry of five new states and part of a sixth to the Union. To be specific, Massachusetts, Connecticut, New York, Pennsylvania, and Virginia gave up all of their claims to land north of the Ohio River and west of the (present) western border of Pennsylvania. Over several decades a number of new states were formed from this land: Ohio, Indiana, Illinois, Michigan, and Wisconsin, and the part of Minnesota east of the Mississippi River. The Northwest Ordinance of 1787 also made great advances in the abolition of slavery. New states admitted to the union in said territory would never be slave states.
<h2>The United States of America under the Articles.</h2>
The peace treaty left the United States independent and at peace but with an unsettled governmental structure. The Articles envisioned a permanent confederation, but granted to the Congress—the only federal institution—little power to finance itself or to ensure that its resolutions were enforced. There was no president and no national court. Although historians generally agree that the Articles were too weak to hold the fast-growing nation together, they do give credit to the settlement of the western issue, as the states voluntarily turned over their lands to national control.
By 1783, with the end of the British blockade, the new nation was regaining its prosperity. However, trade opportunities were restricted by the mercantilism of the British and French empires. The ports of the British West Indies were closed to all staple products which were not carried in British ships. France and Spain established similar policies. Simultaneously, new manufacturers faced sharp competition from British products which were suddenly available again. Political unrest in several states and efforts by debtors to use popular government to erase their debts increased the anxiety of the political and economic elites which had led the Revolution. The apparent inability of the Congress to redeem the public obligations (debts) incurred during the war, or to become a forum for productive cooperation among the states to encourage commerce and economic development, only aggravated a gloomy situation. In 1786–87, Shays' Rebellion, an uprising of dissidents in western Massachusetts against the state court system, threatened the stability of state government.
The Continental Congress printed paper money which was so depreciated that it ceased to pass as currency, spawning the expression "not worth a continental". Congress could not levy taxes and could only make requisitions upon the States. Less than a million and a half dollars came into the treasury between 1781 and 1784, although the governors had been asked for two million in 1783 alone.
When John Adams went to London in 1785 as the first representative of the United States, he found it impossible to secure a treaty for unrestricted commerce. Demands were made for favors and there was no assurance that individual states would agree to a treaty. Adams stated it was necessary for the States to confer the power of passing navigation laws to Congress, or that the States themselves pass retaliatory acts against Great Britain. Congress had already requested and failed to get power over navigation laws. Meanwhile, each State acted individually against Great Britain to little effect. When other New England states closed their ports to British shipping, Connecticut hastened to profit by opening its ports.
By 1787 Congress was unable to protect manufacturing and shipping. State legislatures were unable or unwilling to resist attacks upon private contracts and public credit. Land speculators expected no rise in values when the government could not defend its borders nor protect its frontier population.
The idea of a convention to revise the Articles of Confederation grew in favor. Alexander Hamilton realized while serving as Washington's top aide that a strong central government was necessary to avoid foreign intervention and allay the frustrations due to an ineffectual Congress. Hamilton led a group of like-minded nationalists, won Washington's endorsement, and convened the Annapolis Convention in 1786 to petition Congress to call a constitutional convention to meet in Philadelphia to remedy the long-term crisis.
<h2>Signatures.</h2>
The Second Continental Congress approved the Articles for distribution to the states on November 15, 1777. A copy was made for each state and one was kept by the Congress. On November 28, the copies sent to the states for ratification were unsigned, and the cover letter, dated November 17, had only the signatures of Henry Laurens and Charles Thomson, who were the President and Secretary to the Congress.
The Articles, however, were unsigned, and the date was blank. Congress began the signing process by examining their copy of the Articles on June 27, 1778. They ordered a final copy prepared (the one in the National Archives), and that delegates should inform the secretary of their authority for ratification.
On July 9, 1778, the prepared copy was ready. They dated it, and began to sign. They also requested each of the remaining states to notify its delegation when ratification was completed. On that date, delegates present from New Hampshire, Massachusetts, Rhode Island, Connecticut, New York, Pennsylvania, Virginia and South Carolina signed the Articles to indicate that their states had ratified. New Jersey, Delaware and Maryland could not, since their states had not ratified. North Carolina and Georgia also didn't sign that day, since their delegations were absent.
After the first signing, some delegates signed at the next meeting they attended. For example, John Wentworth of New Hampshire added his name on August 8. John Penn was the first of North Carolina's delegates to arrive (on July 10), and the delegation signed the Articles on July 21, 1778.
The other states had to wait until they ratified the Articles and notified their Congressional delegation. Georgia signed on July 24, New Jersey on November 26, and Delaware on February 12, 1779. Maryland refused to ratify the Articles until every state had ceded its western land claims.
On February 2, 1781, the much-awaited decision was taken by the Maryland General Assembly in Annapolis. As the last piece of business during the afternoon Session, "among engrossed Bills" was "signed and sealed by Governor Thomas Sim Lee in the Senate Chamber, in the presence of the members of both Houses... an Act to empower the delegates of this state in Congress to subscribe and ratify the articles of confederation" and perpetual union among the states. The Senate then adjourned "to the first Monday in August next." The decision of Maryland to ratify the Articles was reported to the Continental Congress on February 12. The confirmation signing of the Articles by the two Maryland delegates took place in Philadelphia at noon time on March 1, 1781 and was celebrated in the afternoon. With these events, the Articles were entered into force and the United States of America came into being as a sovereign federal state.
Congress had debated the Articles for over a year and a half, and the ratification process had taken nearly three and a half years. Many participants in the original debates were no longer delegates, and some of the signers had only recently arrived. The Articles of Confederation and Perpetual Union were signed by a group of men who were never present in the Congress at the same time.
<h3>Signers.</h3>
The signers and the states they represented were:
Connecticut
Delaware
Georgia
Maryland
Massachusetts Bay
New Hampshire
New Jersey
New York
North Carolina
Pennsylvania
Rhode Island and Providence Plantations
South Carolina
Virginia
Roger Sherman (Connecticut) was the only person to sign all four great state papers of the United States: the Continental Association, the United States Declaration of Independence, the Articles of Confederation and the United States Constitution.
Robert Morris (Pennsylvania) signed three of the great state papers of the United States: the United States Declaration of Independence, the Articles of Confederation and the United States Constitution.
John Dickinson (Delaware), Daniel Carroll (Maryland) and Gouverneur Morris (New York), along with Sherman and Robert Morris, were the only five people to sign both the Articles of Confederation and the United States Constitution (Gouverneur Morris represented Pennsylvania when signing the Constitution).
<h2>Presidents of the Congress.</h2>
The following list is of those who led the Congress of the Confederation under the Articles of Confederation as the Presidents of the United States in Congress Assembled. Under the Articles, the president was the presiding officer of Congress, chaired the Committee of the States when Congress was in recess, and performed other administrative functions. He was not, however, an executive in the way the successor President of the United States is a chief executive, since all of the functions he executed were under the direct control of Congress.
"For a full list of Presidents of the Congress Assembled and Presidents under the two Continental Congresses before the Articles, see President of the Continental Congress."
<h2>Gallery.</h2>
Images of an original draft of the Articles of Confederation stored at the United States National Archive.
<h2>Revision and replacement.</h2>
On January 21, 1786, the Virginia Legislature, following James Madison's recommendation, invited all the states to send delegates to Annapolis, Maryland to discuss ways to reduce interstate conflict. At what came to be known as the Annapolis Convention, the few state delegates in attendance endorsed a motion that called for all states to meet in Philadelphia in May 1787 to discuss ways to improve the Articles of Confederation in a "Grand Convention." Although the states' representatives to the Constitutional Convention in Philadelphia were only authorized to amend the Articles, the representatives held secret, closed-door sessions and wrote a new constitution. The new Constitution gave much more power to the central government, but characterization of the result is disputed. The general goal of the authors was to get close to a republic as defined by the philosophers of the Age of Enlightenment, while trying to address the many difficulties of the interstate relationships. Historian Forrest McDonald, using the ideas of James Madison from "Federalist 39", describes the change this way:
In May 1786, Charles Pinckney of South Carolina proposed that Congress revise the Articles of Confederation. Recommended changes included granting Congress power over foreign and domestic commerce, and providing means for Congress to collect money from state treasuries. Unanimous approval was necessary to make the alterations, however, and Congress failed to reach a consensus. The weakness of the Articles in establishing an effective unifying government was underscored by the threat of internal conflict both within and between the states, especially after Shays' Rebellion threatened to topple the state government of Massachusetts.
Historian Ralph Ketcham comments on the opinions of Patrick Henry, George Mason, and other Anti-Federalists who were not so eager to give up the local autonomy won by the revolution:
Historians have given many reasons for the perceived need to replace the articles in 1787. Jillson and Wilson (1994) point to the financial weakness as well as the norms, rules and institutional structures of the Congress, and the propensity to divide along sectional lines.
Rakove (1988) identifies several factors that explain the collapse of the Confederation. The lack of compulsory direct taxation power was objectionable to those wanting a strong centralized state or expecting to benefit from such power. It could not collect customs after the war because tariffs were vetoed by Rhode Island. Rakove concludes that their failure to implement national measures "stemmed not from a heady sense of independence but rather from the enormous difficulties that all the states encountered in collecting taxes, mustering men, and gathering supplies from a war-weary populace." The second group of factors Rakove identified derived from the substantive nature of the problems the Continental Congress confronted after 1783, especially the inability to create a strong foreign policy. Finally, the Confederation's lack of coercive power reduced the likelihood for profit to be made by political means, thus potential rulers were uninspired to seek power.
When the war ended in 1783, certain special interests had incentives to create a new "merchant state," much like the British state people had rebelled against. In particular, holders of war scrip and land speculators wanted a central government to pay off scrip at face value and to legalize western land holdings with disputed claims. Also, manufacturers wanted a high tariff as a barrier to foreign goods, but competition among states made this impossible without a central government.
<h3>Legitimacy of closing down.</h3>
Political scientist David C. Hendrickson writes that two prominent political leaders in the Confederation, John Jay of New York and Thomas Burke of North Carolina believed that "the authority of the congress rested on the prior acts of the several states, to which the states gave their voluntary consent, and until those obligations were fulfilled, neither nullification of the authority of congress, exercising its due powers, nor secession from the compact itself was consistent with the terms of their original pledges."
According to Article XIII of the Confederation, any alteration had to be approved unanimously: 
[T]he Articles of this Confederation shall be inviolably observed by every State, and the Union shall be perpetual; nor shall any alteration at any time hereafter be made in any of them; unless such alteration be agreed to in a Congress of the United States, and be afterwards confirmed by the legislatures of every State.
On the other hand, Article VII of the proposed Constitution stated that it would become effective after ratification by a mere nine states, without unanimity:
The Ratification of the Conventions of nine States, shall be sufficient for the Establishment of this Constitution between the States so ratifying the Same.
The apparent tension between these two provisions was addressed at the time, and remains a topic of scholarly discussion. In 1788, James Madison remarked (in "Federalist No. 40") that the issue had become moot: "As this objection...has been in a manner waived by those who have criticised the powers of the convention, I dismiss it without further observation." Nevertheless, it is an interesting historical and legal question whether opponents of the Constitution could have plausibly attacked the Constitution on that ground. At the time, there were state legislators who argued that the Constitution was not an alteration of the Articles of Confederation, but rather would be a complete replacement so the unanimity rule did not apply. Moreover, the Confederation had proven woefully inadequate and therefore was supposedly no longer binding.
Modern scholars such as Francisco Forrest Martin agree that the Articles of Confederation had lost its binding force because many states had violated it, and thus "other states-parties did not have to comply with the Articles' unanimous consent rule". In contrast, law professor Akhil Amar suggests that there may not have really been any conflict between the Articles of Confederation and the Constitution on this point; Article VI of the Confederation specifically allowed side deals among states, and the Constitution could be viewed as a side deal until all states ratified it.
<h3>Final months.</h3>
On July 3, 1788 the Congress received New Hampshire's all-important ninth ratification of the proposed Constitution, thus, according to its terms, establishing it as the new framework of governance for the ratifying states. The following day delegates considered a bill to admit Kentucky into the Union as a sovereign state. The discussion ended with Congress making the determination that, in light of this development, it would be "unadvisable" to admit Kentucky into the Union, as it could do so "under the Articles of Confederation" only, but not "under the Constitution".
By the end of July 1788, 11 of the 13 states had ratified the new Constitution. Congress continued to convene under the Articles with a quorum until October. On Saturday, September 13, 1788, the Confederation Congress voted the resolve to implement the new Constitution, and on Monday, September 15 published an announcement that the new Constitution had been ratified by the necessary nine states, set the first Wednesday in February 1789 for the presidential electors to meet and select a new president, and set the first Wednesday of March 1789 as the day the new government would take over and the government under the Articles of Confederation would come to an end.
On that same September 13, it determined that New York would remain the national capital.

</doc>
<doc id="694" url="https://en.wikipedia.org/wiki?curid=694" title="Asia Minor (disambiguation)">
Asia Minor (disambiguation)

Asia Minor is an alternative name for Anatolia, the westernmost protrusion of Asia, comprising the majority of the Republic of Turkey. It may also refer to:

</doc>
<doc id="696" url="https://en.wikipedia.org/wiki?curid=696" title="Aa River">
Aa River

Aa is the name of a large number of small European rivers. Aa originated from an Indo-European word meaning water, and it can be seen in the German "Ach" or "Aach" or the North Germanic "A" or "Aa".

</doc>
<doc id="698" url="https://en.wikipedia.org/wiki?curid=698" title="Atlantic Ocean">
Atlantic Ocean

The Atlantic Ocean is the second largest of the world's oceanic divisions, following the Pacific Ocean. With a total area of about , it covers approximately 20 percent of the Earth's surface and about 29 percent of its water surface area. Its name refers to Atlas of Greek mythology, making the Atlantic the "Sea of Atlas".
The oldest known mention of "Atlantic" is in "The Histories" of Herodotus around 450 BC (Hdt. 1.202.4): "Atlantis thalassa" (Greek: Ἀτλαντὶς θάλασσα; English: Sea of Atlas). The term Ethiopic Ocean, derived from Ethiopia, was applied to the southern Atlantic as late as the mid-19th century. Before Europeans discovered other oceans, their term "ocean" was synonymous with the waters beyond the Strait of Gibraltar that are now known as the Atlantic. The early Greeks believed this ocean to be a gigantic river encircling the world.
The Atlantic Ocean occupies an elongated, S-shaped basin extending longitudinally between Eurasia and Africa to the east, and the Americas to the west. As one component of the interconnected global ocean, it is connected in the north to the Arctic Ocean, to the Pacific Ocean in the southwest, the Indian Ocean in the southeast, and the Southern Ocean in the south (other definitions describe the Atlantic as extending southward to Antarctica). The equator subdivides it into the North Atlantic Ocean and South Atlantic Ocean.
<h2>Geography.</h2>
The Atlantic Ocean is bounded on the west by North and South America. It connects to the Arctic Ocean through the Denmark Strait, Greenland Sea, Norwegian Sea and Barents Sea. To the east, the boundaries of the ocean proper are Europe: the Strait of Gibraltar (where it connects with the Mediterranean Sea–one of its marginal seas–and, in turn, the Black Sea, both of which also touch upon Asia) and Africa.
In the southeast, the Atlantic merges into the Indian Ocean. The 20° East meridian, running south from Cape Agulhas to Antarctica defines its border. Some authorities show it extending south to Antarctica, while others show it bounded at the 60° parallel by the Southern Ocean.
In the southwest, the Drake Passage connects it to the Pacific Ocean. The man-made Panama Canal links the Atlantic and Pacific. Besides those mentioned, other large bodies of water that form part of the Atlantic are the Caribbean Sea, the Gulf of Mexico, Hudson Bay, the Mediterranean Sea, the North Sea, the Baltic Sea, and the Celtic Sea.
Covering approximately 22% of Earth's surface, the Atlantic is second in size to the Pacific. With its adjacent seas, it occupies an area of about ; without them, it has an area of . The land that drains into the Atlantic covers four times that of either the Pacific or Indian oceans. The volume of the Atlantic with its adjacent seas is 354,700,000 cubic kilometres (85,100,000 cu mi) and without them 323,600,000 cubic kilometres (77,640,000 cu mi).
The average depth of the Atlantic with its adjacent seas, is ; without them it is . The greatest depth, Milwaukee Deep with , is in the Puerto Rico Trench.
<h2>Ocean floor.</h2>
The principal feature of the bathymetry (bottom topography) is a submarine mountain range called the Mid-Atlantic Ridge. It extends from Iceland in the north to approximately 58° South latitude, reaching a maximum width of about . A great rift valley also extends along the ridge over most of its length. The depth of water at the apex of the ridge is less than in most places, while the bottom of the ridge is three times as deep. Several peaks rise above the water and form islands. The South Atlantic Ocean has an additional submarine ridge, the Walvis Ridge.
The Mid-Atlantic Ridge separates the Atlantic Ocean into two large troughs with depths from . Transverse ridges running between the continents and the Mid-Atlantic Ridge divide the ocean floor into numerous basins. Some of the larger basins are the Blake, Guiana, North American, Cape Verde, and Canaries basins in the North Atlantic. The largest South Atlantic basins are the Angola, Cape, Argentina, and Brazil basins.
The deep ocean floor is thought to be fairly flat with occasional deeps, abyssal plains, trenches, seamounts, basins, plateaus, canyons, and some guyots. Various shelves along the margins of the continents constitute about 11% of the bottom topography with few deep channels cut across the continental rise.
Ocean floor trenches and seamounts:
Ocean sediments are composed of:
The North Atlantic rifting process started in the Early Jurassic therefore it is older than South Atlantic, that created after the split between South America and Africa in the Early Cretaceous. Synrift deposits are seen in England, Spain, Portugal, Morocco and Angola.
From October to June the surface is usually covered with sea ice in the Labrador Sea, Denmark Strait, and Baltic Sea. A clockwise warm-water gyre occupies the northern Atlantic, and a counter-clockwise warm-water gyre appears in the southern Atlantic. The Mid-Atlantic Ridge, a rugged north-south centreline for the entire Atlantic basin, first discovered by the Challenger Expedition dominates the ocean floor. This was formed by the vulcanism that also formed the ocean floor and the islands rising from it.
The Atlantic has irregular coasts indented by numerous bays, gulfs, and seas. These include the Norwegian Sea, Baltic Sea, North Sea, Labrador Sea, Black Sea, Gulf of Saint Lawrence, Bay of Fundy, Gulf of Maine, Mediterranean Sea, Gulf of Mexico, and Caribbean Sea.
<h2>Water characteristics.</h2>
On average, the Atlantic is the saltiest major ocean; surface water salinity in the open ocean ranges from 33 to 37 parts per thousand (3.3 – 3.7%) by mass and varies with latitude and season. Evaporation, precipitation, river inflow and sea ice melting influence surface salinity values. Although the lowest salinity values are just north of the equator (because of heavy tropical rainfall), in general the lowest values are in the high latitudes and along coasts where large rivers enter. Maximum salinity values occur at about 25° north and south, in subtropical regions with low rainfall and high evaporation.
Surface water temperatures, which vary with latitude, current systems, and season and reflect the latitudinal distribution of solar energy, range from below to over . Maximum temperatures occur north of the equator, and minimum values are found in the polar regions. In the middle latitudes, the area of maximum temperature variations, values may vary by .
The Atlantic Ocean consists of four major water masses. The North and South Atlantic central waters make up the surface. The sub-Antarctic intermediate water extends to depths of . The North Atlantic Deep Water reaches depths of as much as . The Antarctic Bottom Water occupies ocean basins at depths greater than 4,000 meters.
Within the North Atlantic, ocean currents isolate the Sargasso Sea, a large elongated body of water, with above average salinity. The Sargasso Sea contains large amounts of seaweed and is also the spawning ground for both the European eel and the American eel.
The Coriolis effect circulates North Atlantic water in a clockwise direction, whereas South Atlantic water circulates counter-clockwise. The south tides in the Atlantic Ocean are semi-diurnal; that is, two high tides occur during each 24 lunar hours. In latitudes above 40° North some east-west oscillation occurs.
<h2>Climate.</h2>
Climate is influenced by the temperatures of the surface waters and water currents as well as winds. Because of the ocean's great capacity to store and release heat, maritime climates are more moderate and have less extreme seasonal variations than inland climates. Precipitation can be approximated from coastal weather data and air temperature from water temperatures.
The oceans are the major source of the atmospheric moisture that is obtained through evaporation. Climatic zones vary with latitude; the warmest zones stretch across the Atlantic north of the equator. The coldest zones are in high latitudes, with the coldest regions corresponding to the areas covered by sea ice. Ocean currents influence climate by transporting warm and cold waters to other regions. The winds that are cooled or warmed when blowing over these currents influence adjacent land areas.
The Gulf Stream and its northern extension towards Europe, the North Atlantic Drift, for example, warms the atmosphere of the British Isles and north-western Europe and influences weather and climate as far south as the northern Mediterranean. The cold water currents contribute to heavy fog off the coast of eastern Canada (the Grand Banks of Newfoundland area) and Africa's north-western coast. 
In general, winds transport moisture and air over land areas. Hurricanes develop in the southern part of the North Atlantic Ocean (Hurricanes are rare in the South Atlantic Ocean). More local particular weather examples could be found in examples such as the Azores High, Benguela Current, and Nor'easter.
<h3>Natural hazards.</h3>
Icebergs are common from February to August in the Davis Strait, Denmark Strait, and the northwestern Atlantic and have been spotted as far south as Bermuda and Madeira. Ships are subject to superstructure icing in the extreme north from October to May. Persistent fog can be a maritime hazard from May to September, as can hurricanes north of the equator (May to December).
The United States' southeast coast has a long history of shipwrecks due to its many shoals and reefs. The Virginia and North Carolina coasts were particularly dangerous.
The Bermuda Triangle is popularly believed to be the site of numerous aviation and shipping incidents because of unexplained and supposedly mysterious causes, but Coast Guard records do not support this belief.
Hurricanes are also a natural hazard in the Atlantic, but mainly in the northern part of the ocean, rarely tropical cyclones form in the southern parts. Hurricanes usually form between 1 June and 30 November of every year.
<h2>History.</h2>
The Atlantic Ocean appears to be the second youngest of the five oceans. It did not exist prior to 130 million years ago, when the continents that formed from the breakup of the ancestral super continent Pangaea were drifting apart. The Atlantic has been extensively explored since the earliest settlements along its shores.
The Norsemen, the Portuguese and the Spanish were the first to explore and to cross it systematically, from Europe to the Americas, as well as to its islands and archipelagos, and from the North Atlantic to the South Atlantic. It was after the voyages of Christopher Columbus in 1492, at the service of Castile (later Spain), that the Americas became well known in Europe and European exploration rapidly accelerated, leading to many new trade routes and the colonization of the Americas.
As a result, the Atlantic became and remains the major artery between Europe and the Americas (known as transatlantic trade). Scientific explorations include the Challenger expedition, the German Meteor expedition, Columbia University's Lamont-Doherty Earth Observatory and the United States Navy Hydrographic Office.
The Atlantic Ocean was named by the ancient Greeks after either Atlas the Titan or the Atlas Mountains named for him; both involve the concept of holding up the sky. Transatlantic travel played a major role in the expansion of Western civilization into the Americas. It is the Atlantic that separates the "Old World" from the "New World".
In modern times, some idioms refer to the ocean in a humorously diminutive way as the Pond, describing both the geographical and cultural divide between North America and Europe, in particular between the English-speaking nations of both continents. Many Irish or British people refer to the United States and Canada as "across the pond", and vice versa. It is a major trade route for many different countries in the world.
The "Black Atlantic" refers to the role of this ocean in shaping black people's history, especially through the Atlantic slave trade. Irish migration to the US is meant when the term "The Green Atlantic" is used. The term "Red Atlantic" has been used in reference to the Marxian concept of an Atlantic working class, as well as to the Atlantic experience of indigenous Americans.
<h2>Economy.</h2>
The Atlantic has contributed significantly to the development and economy of surrounding countries. Besides major transatlantic transportation and communication routes, the Atlantic offers abundant petroleum deposits in the sedimentary rocks of the continental shelves. The Atlantic hosts the world's richest fishing resources, especially in the waters covering the shelves. The major fish are cod, haddock, hake, herring, and mackerel.
The most productive areas include the Grand Banks of Newfoundland, the Nova Scotia shelf, Georges Bank off Cape Cod, the Bahama Banks, the waters around Iceland, the Irish Sea, the Dogger Bank of the North Sea, and the Falkland Banks. Eel, lobster, and whales appear in great quantities. Various international treaties attempt to reduce pollution caused by environmental threats such as oil spills, marine debris, and the incineration of toxic wastes at sea.
The Atlantic harbours petroleum and gas fields, fish, marine mammals (seals and whales), sand and gravel aggregates, placer deposits, polymetallic nodules, and precious stones.
Gold deposits are a mile or two under water on the ocean floor, however the deposits are also encased in rock that must be mined through. Currently, there is no cost-effective way to mine or extract gold from the ocean to make a profit.
<h2>Environmental issues.</h2>
Endangered marine species include the manatee, seals, sea lions, turtles, and whales. Drift net fishing can kill dolphins, albatrosses and other seabirds (petrels, auks), hastening the fish stock decline and contributing to international disputes. Municipal pollution comes from the eastern United States, southern Brazil, and eastern Argentina; oil pollution in the Caribbean Sea, Gulf of Mexico, Lake Maracaibo, Mediterranean Sea, and North Sea; and industrial waste and municipal sewage pollution in the Baltic Sea, North Sea, and Mediterranean Sea.
In 2005, there was some concern that warm northern European currents were slowing down.
On 7 June 2006, Florida's wildlife commission voted to take the manatee off the state's endangered species list. Some environmentalists worry that this could erode safeguards for the popular sea creature.
Marine pollution is a generic term for the entry into the ocean of potentially hazardous chemicals or particles. The biggest culprits are rivers and with them many agriculture fertilizer chemicals as well as livestock and human waste. The excess of oxygen-depleting chemicals leads to hypoxia and the creation of a dead zone.
Marine debris, which is also known as marine litter, describes human-created waste floating in a body of water. Oceanic debris tends to accumulate at the centre of gyres and coastlines, frequently washing aground where it is known as beach litter.

</doc>
<doc id="700" url="https://en.wikipedia.org/wiki?curid=700" title="Arthur Schopenhauer">
Arthur Schopenhauer

Arthur Schopenhauer (; 22 February 1788 – 21 September 1860) was a German philosopher. He is best known for his 1818 work "The World as Will and Representation", in which he characterizes the phenomenal world as the product of a blind, insatiable, and malignant metaphysical will. Proceeding from the transcendental idealism of Immanuel Kant, Schopenhauer developed an atheistic metaphysical and ethical system that has been described as an exemplary manifestation of philosophical pessimism, rejecting the contemporaneous post-Kantian philosophies of German idealism. Schopenhauer was among the first thinkers in Western philosophy to share and affirm significant tenets of Eastern philosophy (e.g., asceticism, the world-as-appearance), having initially arrived at similar conclusions as the result of his own philosophical work. His writing on aesthetics, morality, and psychology would exert important influence on thinkers and artists throughout the 19th and 20th centuries.
Though his work failed to garner substantial attention during his life, Schopenhauer has had a posthumous impact across various disciplines, including philosophy, literature, and science. Those who have cited his influence include Friedrich Nietzsche, Richard Wagner, Leo Tolstoy, Ludwig Wittgenstein, Erwin Schrödinger, Sigmund Freud, Gustav Mahler, Joseph Campbell, Albert Einstein, Carl Jung, Thomas Mann, Jorge Luis Borges, and Samuel Beckett, among others.
<h2>Life.</h2>
Schopenhauer was born on 22 February 1788, in the city of Danzig (then part of the Polish–Lithuanian Commonwealth; present day Gdańsk, Poland) on Heiligegeistgasse (known in the present day as Św. Ducha 47), the son of Johanna Schopenhauer (née Trosiener) and Heinrich Floris Schopenhauer, both descendants of wealthy German patrician families. When Danzig became part of Prussia in 1793, Heinrich moved to Hamburg, although his firm continued trading in Danzig. As early as 1799, Arthur started playing the flute. In 1805, Schopenhauer's father died, possibly by suicide. Arthur endured two long years of drudgery as a merchant in honor of his dead father, but his mother soon moved with his sister Adele to Weimar—then the centre of German literature—to pursue her writing career. He dedicated himself wholly to studies at the Gotha gymnasium () in Saxe-Gotha-Altenburg, but left in disgust after seeing one of the masters lampooned.
By that time, Johanna Schopenhauer had already opened her famous salon, and Arthur was not compatible with what he considered its vain and ceremonious ways. He was also disgusted by the ease with which his mother had forgotten his father's memory. He left to become a student at the University of Göttingen in 1809. There he studied metaphysics and psychology under Gottlob Ernst Schulze, the author of "Aenesidemus", who advised him to concentrate on Plato and Immanuel Kant. In Berlin, from 1811 to 1812, he had attended lectures by the prominent post-Kantian philosopher Johann Gottlieb Fichte and the theologian Friedrich Schleiermacher.
Schopenhauer had a notably strained relationship with his mother Johanna. He wrote his first book, "On the Fourfold Root of the Principle of Sufficient Reason", while at university. His mother informed him that the book was incomprehensible and it was unlikely that anyone would ever buy a copy. In a fit of temper Arthur Schopenhauer told her that his work would be read long after the "rubbish" she wrote would have been totally forgotten. In fact, although they considered her novels of dubious quality, the Brockhaus publishing firm held her in high esteem because they consistently sold well. Hans Brockhaus later recalled that, when she brought them some of her son's work, his predecessors "saw nothing in this manuscript, but wanted to please one of our best-selling authors by publishing her son's work. We published more and more of her son Arthur's work and today nobody remembers Johanna, but her son's works are in steady demand and contribute to Brockhaus'[s] reputation." He kept large portraits of the pair in his office in Leipzig for the edification of his new editors.
In 1814, Schopenhauer began his seminal work "The World as Will and Representation" ("Die Welt als Wille und Vorstellung"). He finished it in 1818 and Brockhaus published it that December. In Dresden in 1819, Schopenhauer fathered, with a servant, an illegitimate daughter who was born and died the same year. In 1820, Schopenhauer became a lecturer at the University of Berlin. He scheduled his lectures to coincide with those of the famous philosopher G. W. F. Hegel, whom Schopenhauer described as a "clumsy charlatan." However, only five students turned up to Schopenhauer's lectures, and he dropped out of academia. A late essay, "On University Philosophy", expressed his resentment towards the work conducted in academies.
While in Berlin, Schopenhauer was named as a defendant in a lawsuit initiated by a woman named Caroline Marquet. She asked for damages, alleging that Schopenhauer had pushed her. According to Schopenhauer's court testimony, she deliberately annoyed him by raising her voice while standing right outside his door. Marquet alleged that the philosopher had assaulted and battered her after she refused to leave his doorway. Her companion testified that she saw Marquet prostrate outside his apartment. Because Marquet won the lawsuit, Schopenhauer made payments to her for the next twenty years. When she died, he wrote on a copy of her death certificate, "Obit anus, abit onus" ("The old woman dies, the burden is lifted"). In 1819 the fortunes of his mother and sister, and himself, were threatened by the failure of the firm in Danzig in which his father had been a director and shareholder. His sister accepted a compromise compensation package of 70 per cent, but Schopenhauer angrily refused this, and eventually recovered 9400 thalers.
In 1821, he fell in love with nineteen-year-old opera singer, Caroline Richter (called Medon), and had a relationship with her for several years, but did not marry her. When he was forty-three years old, he took interest in seventeen-year-old Flora Weiss but she rejected him as recorded in her diary.
In 1831, a cholera epidemic broke out in Berlin and Schopenhauer left the city. Schopenhauer settled permanently in Frankfurt in 1833, where he remained for the next twenty-seven years, living alone except for a succession of pet poodles named Atman and Butz. The numerous notes that he made during these years, amongst others on aging, were published posthumously under the title "Senilia". Schopenhauer had a robust constitution, but in 1860 his health began to deteriorate. He died of pulmonary-respiratory failure, on 21 September 1860 while sitting at home on his couch. He was 72.
<h2>Thought.</h2>
<h3>Philosophy of the "Will".</h3>
A key focus of Schopenhauer was his investigation of individual motivation. Before Schopenhauer, Hegel had popularized the concept of "Zeitgeist", the idea that society consisted of a collective consciousness that moved in a distinct direction, dictating the actions of its members. Schopenhauer, a reader of both Kant and Hegel, criticized their logical optimism and the belief that individual morality could be determined by society and reason. Schopenhauer believed that humans were motivated by only their own basic desires, or ("Will to Live"), which directed all of mankind.
For Schopenhauer, human desire was futile, illogical, directionless, and, by extension, so was all human action in the world. Einstein paraphrased his views as follows: "Man can indeed do what he wants, but he cannot will what he wants." In this sense, he adhered to the Fichtean principle of idealism: "The world is "for" a subject." This idealism so presented, immediately commits it to an ethical attitude, unlike the purely epistemological concerns of Descartes and Berkeley. To Schopenhauer, the Will is a malignant, metaphysical existence that controls not only the actions of individual, intelligent agents, but ultimately all observable phenomena—an evil to be terminated via mankind's duties: asceticism and chastity. He is credited with one of the most famous opening lines of philosophy: "The world is my representation." Will, for Schopenhauer, is what Kant called the "thing-in-itself." Friedrich Nietzsche was greatly influenced by this idea of Will, while developing it in a different direction.
<h3>Art and aesthetics.</h3>
For Schopenhauer, human desiring, "willing," and craving cause suffering or pain. A temporary way to escape this pain is through aesthetic contemplation (a method comparable to Zapffe's ""Sublimation""). Aesthetic contemplation allows one to escape this pain—albeit temporarily—because it stops one perceiving the world as mere presentation. Instead, one no longer perceives the world as an object of perception (therefore as subject to the Principle of Sufficient Grounds; time, space and causality) from which one is separated; rather one becomes one with that perception: ""one can thus no longer separate the perceiver from the perception"" ("The World as Will and Representation", section 34). From this immersion with the world one no longer views oneself as an individual who suffers in the world due to one's individual will but, rather, becomes a ""subject of cognition"" to a perception that is ""Pure, will-less, timeless"" (section 34) where the essence, "ideas," of the world are shown. Art is the practical consequence of this brief aesthetic contemplation as it attempts to depict one's immersion with the world, thus tries to depict the essence/pure ideas of the world. Music, for Schopenhauer, was the purest form of art because it was the one that depicted the will itself without it appearing as subject to the Principle of Sufficient Grounds, therefore as an individual object. According to Daniel Albright, "Schopenhauer thought that music was the only art that did not merely copy ideas, but actually embodied the will itself."
He deemed music a timeless, universal language comprehended everywhere, that can imbue global enthusiasm, if in possession of a significant melody.
<h3>Mathematics.</h3>
Schopenhauer's realist views on mathematics are evident in his criticism of the contemporary attempts to prove the parallel postulate in Euclidean geometry. Writing shortly before the discovery of hyperbolic geometry demonstrated the logical independence of the axiom—and long before the general theory of relativity revealed that it does not necessarily express a property of physical space—Schopenhauer criticized mathematicians for trying to use indirect concepts to prove what he held to be directly evident from perception.
Throughout his writings, Schopenhauer criticized the logical derivation of philosophies and mathematics from mere concepts, instead of from intuitive perceptions.
Although Schopenhauer could see no justification for trying to prove Euclid's parallel postulate, he did see a reason for examining another of Euclid's axioms.
This follows Kant's reasoning.
<h3>Ethics.</h3>
Schopenhauer's moral theory proposed that only compassion can drive moral acts. According to Schopenhauer, compassion alone is the good of the object of the acts, that is, they cannot be inspired by either the prospect of personal utility or the feeling of duty. Mankind can also be guided by egoism and malice. Egotistic acts are those guided by self-interest, desire for pleasure or happiness. Schopenhauer believed most of our deeds belong to this class. Acts of malice are different from egotistic acts. As in the case of acts of compassion, these do not target personal utility. Their aim is to cause damage to others, independently of personal gains. He believed, like Swami Vivekananda in the unity of all with one-self and also believed that ego is the origin of pain and conflicts, that reduction of ego frames the moral principles.
<h4>Punishment.</h4>
According to Schopenhauer, whenever we make a choice, "We assume as necessary that decision was preceded by something from which it ensued, and which we call the ground or reason, or more accurately the motive, of the resultant action." Choices are not made freely. Our actions are necessary and determined because "every human being, even every animal, after the motive has appeared, must carry out the action which alone is in accordance with his inborn and immutable character." A definite action inevitably results when a particular motive influences a person's given, unchangeable character.
The State, Schopenhauer claimed, punishes criminals to prevent future crimes. It does so by placing "beside every possible motive for committing a wrong a more powerful motive for leaving it undone, in the inescapable punishment. Accordingly, the criminal code is as complete a register as possible of counter-motives to all criminal actions that can possibly be imagined..."
Should capital punishment be legal? "For safeguarding the lives of citizens," he asserted, "capital punishment is therefore absolutely necessary." "The murderer," wrote Schopenhauer, "who is condemned to death according to the law must, it is true, be now used as a mere "means", and with complete right. For public security, which is the principal object of the State, is disturbed by him; indeed it is abolished if the law remains unfulfilled. The murderer, his life, his person, must be the "means" of fulfilling the law, and thus of re-establishing public security." Schopenhauer disagreed with those who would abolish capital punishment. "Those who would like to abolish it should be given the answer: 'First remove murder from the world, and then capital punishment ought to follow.' "
People, according to Schopenhauer, cannot be improved. They can only be influenced by strong motives that overpower criminal motives. Schopenhauer declared that "real moral reform is not at all possible, but only determent from the deed..."
He claimed this doctrine was not original to him. Previously, it appeared in the writings of Plato, Seneca, Hobbes, Pufendorf, and Anselm Feuerbach. Schopenhauer declared that their teaching was corrupted by subsequent errors and therefore was in need of clarification.
<h4>God.</h4>
Even though Schopenhauer ended his treatise on the freedom of human will with the postulate of everyone's responsibility for their character and, consequently, acts—the responsibility following from one's being the Will as noumenon (from which also all the characters and creations come)—he considered his views incompatible with theism, on grounds of fatalism and, more generally, responsibility for evil. In Schopenhauer's philosophy the dogmas of Christianity lose their significance, and the "Last Judgment" is no longer preceded by anything—"The world is itself the Last Judgment on it." Whereas God, if he existed, would be evil.
<h3>Psychology.</h3>
Philosophers have not traditionally been impressed by the tribulations of sex, but Schopenhauer addressed it and related concepts forthrightly:
He named a force within man that he felt took invariable precedence over reason: the Will to Live or Will to Life ("Wille zum Leben"), defined as an inherent drive within human beings, and indeed all creatures, to stay alive; a force that inveigles us into reproducing.
Schopenhauer refused to conceive of love as either trifling or accidental, but rather understood it as an immensely powerful force that lay unseen within man's psyche and dramatically shaped the world:
These ideas foreshadowed the discovery of evolution, Freud's concepts of the libido and the unconscious mind, and evolutionary psychology in general.
<h3>Political and social thought.</h3>
<h4>Politics.</h4>
Schopenhauer's politics were, for the most part, an echo of his system of ethics (the latter being expressed in "Die beiden Grundprobleme der Ethik", available in English as two separate books, "On the Basis of Morality" and "On the Freedom of the Will"). Ethics also occupies about one quarter of his central work, "The World as Will and Representation".
In occasional political comments in his "Parerga and Paralipomena" and "Manuscript Remains", Schopenhauer described himself as a proponent of limited government. What was essential, he thought, was that the state should "leave each man free to work out his own salvation," and so long as government was thus limited, he would "prefer to be ruled by a lion than one of [his] fellow rats" — i.e., by a monarch, rather than a democrat. Schopenhauer shared the view of Thomas Hobbes on the necessity of the state, and of state action, to check the destructive tendencies innate to our species. He also defended the independence of the legislative, judicial and executive branches of power, and a monarch as an impartial element able to practise justice (in a practical and everyday sense, not a cosmological one). He declared monarchy as "that which is natural to man" for "intelligence has always under a monarchical government a much better chance against its irreconcilable and ever-present foe, stupidity" and disparaged republicanism as "unnatural as it is unfavourable to the higher intellectual life and the arts and sciences."
Schopenhauer, by his own admission, did not give much thought to politics, and several times he writes proudly of how little attention he had paid "to political affairs of [his] day." In a life that spanned several revolutions in French and German government, and a few continent-shaking wars, he did indeed maintain his aloof position of "minding not the times but the eternities." He wrote many disparaging remarks about Germany and the Germans. A typical example is, "For a German it is even good to have somewhat lengthy words in his mouth, for he thinks slowly, and they give him time to reflect."
Schopenhauer attributed civilizational primacy to the northern "white races" due to their sensitivity and creativity (except for the ancient Egyptians and Hindus whom he saw as equal):
The highest civilization and culture, apart from the ancient Hindus and Egyptians, are found exclusively among the white races; and even with many dark peoples, the ruling caste or race is fairer in colour than the rest and has, therefore, evidently immigrated, for example, the Brahmans, the Incas, and the rulers of the South Sea Islands. All this is due to the fact that necessity is the mother of invention because those tribes that emigrated early to the north, and there gradually became white, had to develop all their intellectual powers and invent and perfect all the arts in their struggle with need, want and misery, which in their many forms were brought about by the climate. This they had to do in order to make up for the parsimony of nature and out of it all came their high civilization.
Despite this, he was adamantly against differing treatment of races, was fervently anti-slavery, and supported the abolitionist movement in the United States. He describes the treatment of "[our] innocent black brothers whom force and injustice have delivered into [the slave-master's] devilish clutches" as "belonging to the blackest pages of mankind's criminal record."
Schopenhauer additionally maintained a marked metaphysical and political anti-Judaism. Schopenhauer argued that Christianity constituted a revolt against the materialistic basis of Judaism, exhibiting an Indian-influenced ethics reflecting the Aryan-Vedic theme of spiritual "self-conquest." This he saw as opposed to what he held to be the ignorant drive toward earthly utopianism and superficiality of a worldly Jewish spirit:
While all other religions endeavor to explain to the people by symbols the metaphysical significance of life, the religion of the Jews is entirely immanent and furnishes nothing but a mere war-cry in the struggle with other nations.
<h4>Views on women.</h4>
In Schopenhauer's 1851 essay "On Women", he expressed his opposition to what he called "Teutonico-Christian stupidity" of reflexive unexamined reverence ("abgeschmackten Weiberveneration") for the female. Schopenhauer wrote that "Women are directly fitted for acting as the nurses and teachers of our early childhood by the fact that they are themselves childish, frivolous and short-sighted." He opined that women are deficient in artistic faculties and sense of justice, and expressed opposition to monogamy. Indeed, Rodgers and Thompson in "Philosophers Behaving Badly" call Schopenhauer "a misogynist without rival in...Western philosophy." He claimed that "woman is by nature meant to obey." The essay does give some compliments, however: that "women are decidedly more sober in their judgment than [men] are," and are more sympathetic to the suffering of others.
Schopenhauer's controversial writings have influenced many, from Friedrich Nietzsche to nineteenth-century feminists. Schopenhauer's biological analysis of the difference between the sexes, and their separate roles in the struggle for survival and reproduction, anticipates some of the claims that were later ventured by sociobiologists and evolutionary psychologists.
After the elderly Schopenhauer sat for a sculpture portrait by Elisabet Ney, he told Richard Wagner's friend Malwida von Meysenbug, "I have not yet spoken my last word about women. I believe that if a woman succeeds in withdrawing from the mass, or rather raising herself above the mass, she grows ceaselessly and more than a man."
<h4>Heredity and eugenics.</h4>
Schopenhauer believed that personality and intellect were inherited. He quotes Horace's saying, "From the brave and good are the brave descended" ("Odes", iv, 4, 29) and Shakespeare's line from "Cymbeline", "Cowards father cowards, and base things sire base" (IV, 2) to reinforce his hereditarian argument.
Mechanistically, Schopenhauer believed that a person inherits his level of intellect through his mother, and personal character through one's father.
This belief in heritability of traits informed Schopenhauer's view of love – placing it at the highest level of importance. For Schopenhauer the "final aim of all love intrigues, be they comic or tragic, is really of more importance than all other ends in human life. What it all turns upon is nothing less than the composition of the next generation... It is not the weal or woe of any one individual, but that of the human race to come, which is here at stake." This view of the importance for the species of whom we choose to love was reflected in his views on eugenics or good breeding. Here Schopenhauer wrote:
With our knowledge of the complete unalterability both of character and of mental faculties, we are led to the view that a real and thorough improvement of the human race might be reached not so much from outside as from within, not so much by theory and instruction as rather by the path of generation. Plato had something of the kind in mind when, in the fifth book of his "Republic", he explained his plan for increasing and improving his warrior caste. If we could castrate all scoundrels and stick all stupid geese in a convent, and give men of noble character a whole harem, and procure men, and indeed thorough men, for all girls of intellect and understanding, then a generation would soon arise which would produce a better age than that of Pericles.
In another context, Schopenhauer reiterated his antidemocratic-eugenic thesis: "If you want Utopian plans, I would say: the only solution to the problem is the despotism of the wise and noble members of a genuine aristocracy, a genuine nobility, achieved by mating the most magnanimous men with the cleverest and most gifted women. This proposal constitutes my Utopia and my Platonic Republic." Analysts (e.g., Keith Ansell-Pearson) have suggested that Schopenhauer's advocacy of anti-egalitarianism and eugenics influenced the neo-aristocratic philosophy of Friedrich Nietzsche, who initially considered Schopenhauer his mentor.
<h4>Animal welfare.</h4>
As a consequence of his monistic philosophy, Schopenhauer was very concerned about the welfare of animals. For him, all individual animals, including humans, are essentially the same, being phenomenal manifestations of the one underlying Will. The word "will" designated, for him, force, power, impulse, energy, and desire; it is the closest word we have that can signify both the real essence of all external things and also our own direct, inner experience. Since every living thing possesses will, then humans and animals are fundamentally the same and can recognize themselves in each other. For this reason, he claimed that a good person would have sympathy for animals, who are our fellow sufferers.
Compassion for animals is intimately associated with goodness of character, and it may be confidently asserted that he who is cruel to living creatures cannot be a good man.
Nothing leads more definitely to a recognition of the identity of the essential nature in animal and human phenomena than a study of zoology and anatomy.
The assumption that animals are without rights and the illusion that our treatment of them has no moral significance is a positively outrageous example of Western crudity and barbarity. Universal compassion is the only guarantee of morality.
In 1841, he praised the establishment, in London, of the Society for the Prevention of Cruelty to Animals, and also the Animals' Friends Society in Philadelphia. Schopenhauer even went so far as to protest against the use of the pronoun "it" in reference to animals because it led to the treatment of them as though they were inanimate things. To reinforce his points, Schopenhauer referred to anecdotal reports of the look in the eyes of a monkey who had been shot and also the grief of a baby elephant whose mother had been killed by a hunter.
He was very attached to his succession of pet poodles. Schopenhauer criticized Spinoza's belief that animals are to be used as a mere means for the satisfaction of humans.
<h4>Views on homosexuality and pederasty.</h4>
In the third, expanded edition of "The World as Will and Representation" (1859), Schopenhauer added an appendix to his chapter on the "Metaphysics of Sexual Love". He also wrote that homosexuality did have the benefit of preventing ill-begotten children. Concerning this, he stated that "the vice we are considering appears to work directly against the aims and ends of nature, and that in a matter that is all important and of the greatest concern to her, it must in fact serve these very aims, although only indirectly, as a means for preventing greater evils." Shrewdly anticipating the interpretive distortion, on the part of the popular mind, of his attempted scientific "explanation" of pederasty as personal "advocacy" (when he had otherwise described the act, in terms of spiritual ethics, as an "objectionable aberration"), Schopenhauer sarcastically concludes the appendix with the statement that "by expounding these paradoxical ideas, I wanted to grant to the professors of philosophy a small favour, for they are very disconcerted by the ever-increasing publicization of my philosophy which they so carefully concealed. I have done so by giving them the opportunity of slandering me by saying that I defend and commend pederasty."
<h3>Intellectual interests and affinities.</h3>
<h4>Indology.</h4>
Schopenhauer read the Latin translation of the ancient Hindu texts, The Upanishads, which French writer Anquetil du Perron had translated from the Persian translation of Prince Dara Shikoh entitled "Sirre-Akbar" ("The Great Secret"). He was so impressed by their philosophy that he called them "the production of the highest human wisdom," and believed they contained superhuman concepts. The Upanishads was a great source of inspiration to Schopenhauer. Writing about them, he said:
It is the most satisfying and elevating reading (with the exception of the original text) which is possible in the world; it has been the solace of my life and will be the solace of my death.
It is well known that the book "Oupnekhat" (Upanishad) always lay open on his table, and he invariably studied it before sleeping at night. He called the opening up of Sanskrit literature "the greatest gift of our century," and predicted that the philosophy and knowledge of the Upanishads would become the cherished faith of the West.
Schopenhauer was first introduced to the 1802 Latin Upanishad translation through Friedrich Majer. They met during the winter of 1813–1814 in Weimar at the home of Schopenhauer's mother according to the biographer Sanfranski. Majer was a follower of Herder, and an early Indologist. Schopenhauer did not begin a serious study of the Indic texts, however, until the summer of 1814. Sansfranski maintains that between 1815 and 1817, Schopenhauer had another important cross-pollination with Indian thought in Dresden. This was through his neighbor of two years, Karl Christian Friedrich Krause. Krause was then a minor and rather unorthodox philosopher who attempted to mix his own ideas with that of ancient Indian wisdom. Krause had also mastered Sanskrit, unlike Schopenhauer, and the two developed a professional relationship. It was from Krause that Schopenhauer learned meditation and received the closest thing to expert advice concerning Indian thought.
Most noticeable, in the case of Schopenhauer’s work, was the significance of the Chandogya Upanishad, whose Mahavakya, Tat Tvam Asi is mentioned throughout "The World as Will and Representation".
<h4>Buddhism.</h4>
Schopenhauer noted a correspondence between his doctrines and the Four Noble Truths of Buddhism. Similarities centered on the principles that life involves suffering, that suffering is caused by desire (taṇhā), and that the extinction of desire leads to liberation. Thus three of the four "truths of the Buddha" correspond to Schopenhauer's doctrine of the will. In Buddhism, however, while greed and lust are always unskillful, desire is ethically variable – it can be skillful, unskillful, or neutral.
For Schopenhauer, Will had ontological primacy over the intellect; in other words, desire is understood to be prior to thought. Schopenhauer felt this was similar to notions of puruṣārtha or goals of life in Vedānta Hinduism.
In Schopenhauer's philosophy, denial of the will is attained by either:
However, Buddhist nirvāṇa is not equivalent to the condition that Schopenhauer described as denial of the will. Nirvāṇa is not the extinguishing of the "person" as some Western scholars have thought, but only the "extinguishing" (the literal meaning of nirvana) of the flames of greed, hatred, and delusion that assail a person's character. Occult historian Joscelyn Godwin (1945– ) stated, "It was Buddhism that inspired the philosophy of Arthur Schopenhauer, and, through him, attracted Richard Wagner. This Orientalism reflected the struggle of the German Romantics, in the words of Leon Poliakov, to "free themselves from Judeo-Christian fetters." In contradistinction to Godwin's claim that Buddhism inspired Schopenhauer, the philosopher himself made the following statement in his discussion of religions:
If I wished to take the results of my philosophy as the standard of truth, I should have to concede to Buddhism pre-eminence over the others. In any case, it must be a pleasure to me to see my doctrine in such close agreement with a religion that the majority of men on earth hold as their own, for this numbers far more followers than any other. And this agreement must be yet the more pleasing to me, inasmuch as "in my philosophizing I have certainly not been under its influence" [emphasis added]. For up till 1818, when my work appeared, there was to be found in Europe only a very few accounts of Buddhism.
Buddhist philosopher Nishitani Keiji, however, sought to distance Buddhism from Schopenhauer. While Schopenhauer's philosophy may sound rather mystical in such a summary, his methodology was resolutely empirical, rather than speculative or transcendental:
Philosophy ... is a science, and as such has no articles of faith; accordingly, in it nothing can be assumed as existing except what is either positively given empirically, or demonstrated through indubitable conclusions.
Also note:
This actual world of what is knowable, in which we are and which is in us, remains both the material and the limit of our consideration.
The argument that Buddhism affected Schopenhauer’s philosophy more than any other Dharmic faith loses more credence when viewed in light of the fact that Schopenhauer did not begin a serious study of Buddhism until after the publication of "The World as Will and Representation" in 1818. Scholars have started to revise earlier views about Schopenhauer's discovery of Buddhism. Proof of early interest and influence, however, appears in Schopenhauer's 1815/16 notes (transcribed and translated by Urs App) about Buddhism. They are included in a recent case study that traces Schopenhauer's interest in Buddhism and documents its influence. Other scholarly work questions how similar Schopenhauer's philosophy actually is to Buddhism.
<h2>Influences.</h2>
Schopenhauer said he was influenced by the Upanishads, Immanuel Kant and Plato. References to Eastern philosophy and religion appear frequently in his writing. As noted above, he appreciated the teachings of the Buddha and even called himself a Buddhist. He said that his philosophy could not have been conceived before these teachings were available.
Concerning the Upanishads and Vedas, he writes in "The World as Will and Representation":
If the reader has also received the benefit of the Vedas, the access to which by means of the Upanishads is in my eyes the greatest privilege which this still young century (1818) may claim before all previous centuries, if then the reader, I say, has received his initiation in primeval Indian wisdom, and received it with an open heart, he will be prepared in the very best way for hearing what I have to tell him. It will not sound to him strange, as to many others, much less disagreeable; for I might, if it did not sound conceited, contend that every one of the detached statements which constitute the Upanishads, may be deduced as a necessary result from the fundamental thoughts which I have to enunciate, though those deductions themselves are by no means to be found there.
Among Schopenhauer's other influences were: Shakespeare, Jean-Jacques Rousseau, John Locke, Thomas Reid, Baruch Spinoza, Matthias Claudius, George Berkeley, David Hume, and René Descartes.
<h2>Critique of Kant and Hegel.</h2>
<h3>Critique of the Kantian philosophy.</h3>
Schopenhauer accepted Kant's double-aspect of the universe – the phenomenal (world of experience) and the noumenal (the true world, independent of experience). Some commentators suggest that Schopenhauer claimed that the noumenon, or thing-in-itself, was the basis for Schopenhauer's concept of the will. Other commentators suggest that Schopenhauer considered will to be only a subset of the "thing-in-itself" class, namely that which we can most directly experience.
Schopenhauer's identification of the Kantian "noumenon" (i.e., the actually existing entity) with what he termed "will" deserves some explanation. The noumenon was what Kant called the "Ding an sich" (the Thing in Itself), the reality that is the foundation of our sensory and mental representations of an external world. In Kantian terms, those sensory and mental representations are mere phenomena. Schopenhauer departed from Kant in his description of the relationship between the phenomenon and the noumenon. According to Kant, things-in-themselves ground the phenomenal representations in our minds; Schopenhauer, on the other hand, believed that phenomena and noumena are two different sides of the same coin. Noumena do not "cause" phenomena, but rather phenomena are simply the way by which our minds perceive the noumena, according to the principle of sufficient reason. This is explained more fully in Schopenhauer's doctoral thesis, "On the Fourfold Root of the Principle of Sufficient Reason" (1813).
Schopenhauer's second major departure from Kant's epistemology concerns the body. Kant's philosophy was formulated as a response to the radical philosophical skepticism of David Hume, who claimed that causality could not be observed empirically. Schopenhauer begins by arguing that Kant's demarcation between external objects, knowable only as phenomena, and the Thing in Itself of noumenon, contains a significant omission. There is, in fact, one physical object we know more intimately than we know any object of sense perception: our own body.
We know our human bodies have boundaries and occupy space, the same way other objects known only through our named senses do. Though we seldom think of our body as a physical object, we know even before reflection that it shares some of an object's properties. We understand that a watermelon cannot successfully occupy the same space as an oncoming truck; we know that if we tried to repeat the experiment with our own body, we would obtain similar results – we know this even if we do not understand the physics involved.
We know that our consciousness inhabits a physical body, similar to other physical objects only known as phenomena. Yet our consciousness is not commensurate with our body. Most of us possess the power of voluntary motion. We usually are not aware of the breathing of our lungs or the beating of our heart unless somehow our attention is called to them. Our ability to control either is limited. Our kidneys command our attention on their schedule rather than one we choose. Few of us have any idea what our liver is doing right now, though this organ is as needful as lungs, heart, or kidneys. The conscious mind is the servant, not the master, of these and other organs. These organs have an agenda the conscious mind did not choose, and over which it has limited power.
When Schopenhauer identifies the "noumenon" with the desires, needs, and impulses in us that we name "will," what he is saying is that we participate in the reality of an otherwise unachievable world outside the mind through will. We cannot "prove" that our mental picture of an outside world corresponds with a reality by reasoning; through will, we know – without thinking – that the world can stimulate us. We suffer fear, or desire: these states arise involuntarily; they arise prior to reflection; they arise even when the conscious mind would prefer to hold them at bay. The rational mind is, for Schopenhauer, a leaf borne along in a stream of pre-reflective and largely unconscious emotion. That stream is will, and through will, if not through logic, we can participate in the underlying reality beyond mere phenomena. It is for this reason that Schopenhauer identifies the "noumenon" with what we call our will.
In his criticism of Kant, Schopenhauer claimed that sensation and understanding are separate and distinct abilities. Yet, for Kant, an object is known through each of them. Kant wrote: "[T]here are two stems of human knowledge ... namely, sensibility and understanding, objects being given by the former [sensibility] and thought by the latter [understanding]." Schopenhauer disagreed. He asserted that mere sense impressions, not objects, are given by sensibility. According to Schopenhauer, objects are intuitively perceived by understanding and are discursively thought by reason (Kant had claimed that (1) the understanding thinks objects through concepts and that (2) reason seeks the unconditioned or ultimate answer to "why?"). Schopenhauer said that Kant's mistake regarding perception resulted in all of the obscurity and difficult confusion that is exhibited in the Transcendental Analytic section of his critique.
Lastly, Schopenhauer departed from Kant in how he interpreted the Platonic ideas. In "The World as Will and Representation" Schopenhauer explicitly stated:
...Kant used the word [Idea] wrongly as well as illegitimately, although Plato had already taken possession of it, and used it most appropriately.
Instead Schopenhauer relied upon the Neoplatonist interpretation of the biographer Diogenes Laërtius from "Lives and Opinions of Eminent Philosophers". In reference to Plato’s Ideas, Schopenhauer quotes Laërtius verbatim in an explanatory footnote.
Diogenes Laërtius (III, 12) Plato ideas in natura velut exemplaria dixit subsistere; cetera his esse similia, ad istarum similitudinem consistencia.
<h3>Critique of Hegel.</h3>
Schopenhauer expressed his dislike for the philosophy of his contemporary Georg Wilhelm Friedrich Hegel many times in his published works. The following quotations are typical:
In his Foreword to the first edition of his work "Die beiden Grundprobleme der Ethik", Schopenhauer suggested that he had shown Hegel to have fallen prey to the "Post hoc ergo propter hoc" fallacy.
Schopenhauer suggested that Hegel's works were filled with "castles of abstraction," and that Hegel used deliberately impressive but ultimately vacuous verbiage. He also thought that his glorification of church and state were designed for personal advantage and had little to do with the search for philosophical truth. For instance, the Right Hegelians interpreted Hegel as viewing the Prussian state of his day as perfect and the goal of all history up until then.
<h2>Criticism of Schopenhauer's personal life.</h2>
The British philosopher and historian Bertrand Russell deemed Schopenhauer an insincere person, because judging by his life:
Bryan Magee points out that "the answer to such shallow, but not uncommon criticism" is found in a quotation from Schopenhauer:
<h2>Influence.</h2>
Schopenhauer has had a massive influence upon later thinkers, though more so in the arts (especially literature and music) and psychology than in philosophy. His popularity peaked in the early twentieth century, especially during the Modernist era, and waned somewhat thereafter. Nevertheless, a number of recent publications have reinterpreted and modernised the study of Schopenhauer. His theory is also being explored by some modern philosophers as a precursor to evolutionary theory and modern evolutionary psychology.
Russian writer and philosopher Leo Tolstoy was greatly influenced by Schopenhauer. After reading Schopenhauer's "The World as Will and Representation", Tolstoy gradually became converted to the ascetic morality upheld in that work as the proper spiritual path for the upper classes: "Do you know what this summer has meant for me? Constant raptures over Schopenhauer and a whole series of spiritual delights which I've never experienced before. ... no student has ever studied so much on his course, and learned so much, as I have this summer"
Richard Wagner, writing in his autobiography, remembered his first impression that Schopenhauer left on him (when he read "World as Will and Representation"):
Wagner also commented on that "serious mood, which was trying to find ecstatic expression" created by Schopenhauer inspired the conception of Tristan und Isolde. See also Influence of Schopenhauer on Tristan und Isolde.
Friedrich Nietzsche owed the awakening of his philosophical interest to reading "The World as Will and Representation" and admitted that he was one of the few philosophers that he respected, dedicating to him his essay "Schopenhauer als Erzieher" one of his "Untimely Meditations".
Jorge Luis Borges remarked that the reason he had never attempted to write a systematic account of his world view, despite his penchant for philosophy and metaphysics in particular, was because Schopenhauer had already written it for him.
As a teenager, Ludwig Wittgenstein adopted Schopenhauer's epistemological idealism. However, after his study of the philosophy of mathematics, he rejected epistemological idealism for Gottlob Frege's conceptual realism. In later years, Wittgenstein was highly dismissive of Schopenhauer, describing him as an ultimately shallow thinker: "Schopenhauer has quite a crude mind... where real depth starts, his comes to an end."
The philosopher Gilbert Ryle read Schopenhauer's works as a student, but later largely forgot them, only to unwittingly recycle ideas from Schopenhauer in his "The Concept of Mind" (1949).

</doc>
<doc id="701" url="https://en.wikipedia.org/wiki?curid=701" title="Angola">
Angola

Angola , officially the Republic of Angola ( ; Kikongo, Kimbundu and Umbundu: "Repubilika ya Ngola"), is a country in Southern Africa. It is the seventh-largest country in Africa, and is bordered by Namibia to the south, the Democratic Republic of the Congo to the north and east, Zambia to the east, and the Atlantic Ocean to west. The exclave province of Cabinda has borders with the Republic of the Congo and the Democratic Republic of the Congo. The capital and largest city of Angola is Luanda.
Although its territory has been inhabited since the Paleolithic Era, modern Angola originates in Portuguese colonization, which began with, and was for centuries limited to, coastal settlements and trading posts established beginning in the 16th century. In the 19th century, European settlers slowly and hesitantly began to establish themselves in the interior. As a Portuguese colony, Angola did not encompass its present borders until the early 20th century, following resistance by groups such as the Cuamato, the Kwanyama and the Mbunda. Independence was achieved in 1975 under communist rule backed by the Soviet Union after the protracted liberation war. That same year, Angola descended into an intense civil war that lasted until 2002. It has since become a relatively stable unitary presidential republic.
Angola has vast mineral and petroleum reserves, and its economy is among the fastest growing in the world, especially since the end of the civil war. In spite of this, the standard of living remains low for the majority of the population, and life expectancy and infant mortality rates in Angola are among the worst in the world. Angola's economic growth is highly uneven, with the majority of the nation's wealth concentrated in a disproportionately small sector of the population.
Angola is a member state of the United Nations, OPEC, African Union, the Community of Portuguese Language Countries, the Latin Union and the Southern African Development Community. A highly multiethnic country, Angola's 25.8 million people span various tribal groups, customs, and traditions. Angolan culture reflects centuries of Portuguese rule, namely in the predominance of the Portuguese language and Roman Catholicism, combined with diverse indigenous influences.
<h2>Etymology.</h2>
The name "Angola" comes from the Portuguese colonial name "Reino de Angola (Kingdom of Angola)", appearing as early as Dias de Novais's 1571 charter. The toponym was derived by the Portuguese from the title "ngola" held by the kings of Ndongo. Ndongo was a kingdom in the highlands, between the Kwanza and Lukala Rivers, nominally tributary to the king of Kongo but which was seeking greater independence during the 16th century.
<h2>History.</h2>
<h3>Early migrations and political units.</h3>
Khoi and San hunter-gatherers are the earliest known modern human inhabitants of the area. They were largely absorbed or replaced by Bantu peoples during the Bantu migrations, though small numbers remain in parts of southern Angola to the present day. The Bantu came from the north, probably from somewhere near the present-day Republic of Cameroon.
During this time, the Bantu established a number of political units ("kingdoms", "empires") in most parts of what today is Angola. The best known of these is the Kingdom of the Kongo that had its centre in the northwest of contemporary Angola, but included important regions in the west of present-day Democratic Republic and Republic of Congo and in southern Gabon. It established trade routes with other trading cities and civilisations up and down the coast of southwestern and West Africa and even with the Great Zimbabwe Mutapa Empire, but engaged in little or no transoceanic trade. To its south lay the Kingdom of Ndongo, from which the area of the later Portuguese colony was sometimes known as Dongo.
<h3>Portuguese colonization.</h3>
The region now known as Angola was reached by the Portuguese explorer Diogo Cão in 1484. The year before, the Portuguese had established relations with the Kingdom of Kongo, which stretched at the time from modern Gabon in the north to the Kwanza River in the south. The Portuguese established their primary early trading post at Soyo, which is now the northernmost city in Angola apart from the Cabinda enclave. Paulo Dias de Novais founded São Paulo de Loanda (Luanda) in 1575 with a hundred families of settlers and four hundred soldiers. Benguela was fortified in 1587 and elevated to a township in 1617.
The Portuguese established several other settlements, forts, and trading posts along the Angolan coast, principally trading in Angolan slaves for Brazilian plantations. Local slave dealers provided a large number of slaves for the Portuguese Empire, usually sold in exchange for manufactured goods from Europe. This part of the Atlantic slave trade continued until after Brazil's independence in the 1820s.
Despite Portugal's nominal claims, as late as the 19th century, their control over the interior country of Angola was minimal. In the 16th century Portugal gained control of the coast through a series of treaties and wars. Life for European colonists was difficult and progress slow. Iliffe notes that "Portuguese records of Angola from the 16th century show that a great famine occurred on average every seventy years; accompanied by epidemic disease, it might kill one-third or one-half of the population, destroying the demographic growth of a generation and forcing colonists back into the river valleys".
Amid the Portuguese Restoration War, the Dutch occupied Luanda in 1641, using alliances with local peoples against Portuguese holdings elsewhere. A fleet under Salvador de Sá retook Luanda for Portugal in 1648; reconquest of the rest of the territory was completed by 1650. New treaties with Kongo were signed in 1649; others with Njinga's Kingdom of Matamba and Ndongo followed in 1656. The conquest of Pungo Andongo in 1671 was the last major Portuguese expansion from Luanda, as attempts to invade Kongo in 1670 and Matamba in 1681 failed. Portugal also expanded inward from Benguela, but until the late 19th century the inroads from Luanda and Benguela were very limited. Portugal had neither the intention nor the means to carry out a large scale territorial occupation and colonization.
Development of the hinterland began after the Berlin Conference in 1885 fixed the colony's borders, and British and Portuguese investment fostered mining, railways, and agriculture based on various forced-labour and voluntary labour systems.(See also Chibalo.) Full Portuguese administrative control of the hinterland did not establish itself until the beginning of the 20th century. Portugal had a minimalist presence in Angola for nearly five hundred years, and early calls for independence provoked little reaction amongst the population who had no social identity related to the territory as a whole. More overtly political and "nationalist" organisations first appeared in the 1950s and began to make demands for self-determination, especially in international forums such as the Non-Aligned Movement.
The Portuguese régime, meanwhile, refused to accede to the demands for independence, provoking an armed conflict that started in 1961 when freedom fighters attacked both white and black civilians in cross-border operations in northeastern Angola. The war came to be known as the Colonial War. In this struggle, the principal protagonists included the People's Movement for the Liberation of Angola (MPLA), founded in 1956, the National Front for the Liberation of Angola (FNLA), which appeared in 1961, and the National Union for the Total Independence of Angola (UNITA), founded in 1966. After many years of conflict that weakened all of the insurgent parties, Angola gained its independence on 11 November 1975, after the 1974 coup d'état in Lisbon, Portugal, which overthrew the Portuguese régime headed by Marcelo Caetano.
Portugal's new revolutionary leaders began in 1974 a process of political change at home and accepted independence for its former colonies abroad. In Angola a fight for dominance broke out immediately between the three nationalist movements. The events prompted a mass exodus of Portuguese citizens, creating up to 300 000 destitute Portuguese refugees—the "retornados". The new Portuguese government tried to mediate an understanding between the three competing movements, and succeeded in getting them to agree, on paper, to form a common government. But in the end none of the African parties respected the commitments they had made, and military force resolved the issue.
<h3>Independence and civil war.</h3>
After it gained independence in November 1975, Angola experienced a devastating civil war which lasted several decades (with some interludes). It claimed millions of lives and produced many refugees; it didn't end until 2002.
Following negotiations held in Portugal, itself experiencing severe social and political turmoil and uncertainty due to the April 1974 revolution, Angola's three main guerrilla groups agreed to establish a transitional government in January 1975. Within two months, however, the FNLA, MPLA and UNITA had started fighting each other and the country began splitting into zones controlled by rival armed political groups. The MPLA gained control of the capital Luanda and much of the rest of the country. With the support of the United States, Zaïre and South Africa intervened militarily in favour of the FNLA and UNITA with the intention of taking Luanda before the declaration of independence. In response, Cuba intervened in favor of the MPLA (see: Cuba in Angola), which became a flash point for the Cold War.
With Cuban support, the MPLA held Luanda and declared independence on 11 November 1975, with Agostinho Neto becoming the first president, though the civil war continued. At this time, most of the half-million Portuguese who lived in Angola – and who had accounted for the majority of the skilled workers in public administration, agriculture, industries and trade – fled the country, leaving its once prosperous and growing economy in a state of bankruptcy.
For most of 1975–1990, the MPLA organised and maintained a socialist régime. In 1990, when the Cold War ended, MPLA abandoned its ties to the Marxist–Leninist ideology and declared social democracy to be its official ideology, going on to win the 1992 general election. However, eight opposition parties rejected the elections as rigged, sparking the Halloween massacre.
<h3>Ceasefire with UNITA.</h3>
On 22 March 2002, Jonas Savimbi, the leader of UNITA, was killed in combat with government troops. The two sides reached a cease-fire shortly afterwards. UNITA gave up its armed wing and assumed the role of major opposition party, although in the knowledge that under the present regime a legitimate democratic election was impossible. Although the political situation of the country began to stabilize, regular democratic processes were not established until the elections in Angola in 2008 and 2012 and the adoption of a new Constitution of Angola in 2010, all of which strengthened the prevailing Dominant-party system. MPLA head officials continue e.g. to be given senior positions in top-level companies or other fields, although a few outstanding UNITA figures are given some of the economic as well as the military share.
Angola has a serious humanitarian crisis, the result of the prolonged war, the abundance of minefields, the continued political, and to a much lesser degree, military activities in favour of the independence of the northern exclave of Cabinda, carried out in the context of the protracted Cabinda Conflict by the Frente para a Libertação do Enclave de Cabinda, (FLEC), but most of all, the depradation of the country's rich mineral resources by the régime. While most of the internally displaced have now settled around the capital, in the so-called "musseques", the general situation for Angolans remains desperate.
Drought, in 2016, is the worst global food crisis in Southern Africa for 25 years. Drought affects 1.4 million people across seven of Angola’s 18 provinces. Food prices have risen and acute malnutrition rates have doubled, with more than 95,000 children being affected. Food insecurity is expected to worsen from July to the end of the year.
<h2>Geography.</h2>
At , Angola is the world's twenty-third largest country. It is comparable in size to Mali, or twice the size of France or Texas. It lies mostly between latitudes 4° and 18°S, and longitudes 12° and 24°E.
Angola is bordered by Namibia to the south, Zambia to the east, the Democratic Republic of the Congo to the north-east, and the South Atlantic Ocean to the west. The coastal exclave of Cabinda in the north, borders the Republic of the Congo to the north, and the Democratic Republic of the Congo to the south. Angola's capital, Luanda, lies on the Atlantic coast in the northwest of the country.
<h2>Climate.</h2>
Angola has three seasons, a dry season which lasts from May to October, a transitional season with some rain from November to January and a hot, rainy season from February to April. April is the wettest month.
<h2>Politics.</h2>
Angola's motto is "Virtus Unita Fortior", a Latin phrase meaning "Virtue is stronger when united". The Angolan government is composed of three branches of government: executive, legislative, and judicial. The executive branch of the government is composed of the President, the Vice-Presidents and the Council of Ministers. The legislative branch comprises a 220-seat unicameral legislature elected from both provincial and nationwide constituencies. For decades, political power has been concentrated in the presidency.
The Constitution of 2010 establishes the broad outlines of government structure and delineates the rights and duties of citizens. The legal system is based on Portuguese and customary law but is weak and fragmented, and courts operate in only 12 of more than 140 municipalities. A Supreme Court serves as the appellate tribunal; a Constitutional Court does not hold the powers of judicial review. Governors of the 18 provinces are appointed by the president.
After the end of the Civil War the regime came under pressure from within as well as from the international community to become more democratic and less authoritarian. Its reaction was to implement a number of changes without substantially changing its character.
Angola is classified as 'not free' by Freedom House in the Freedom in the World 2014 report. The report noted that the August 2012 parliamentary elections, in which the ruling Popular Movement for the Liberation of Angola won more than 70% of the vote, suffered from serious flaws, including outdated and inaccurate voter rolls. Voter turnout dropped from 80% in 2008 to 60%.
Angola scored poorly on the 2013 Ibrahim Index of African Governance. It was ranked 39 out of 52 sub-Saharan African countries, scoring particularly badly in the areas of participation and human rights, sustainable economic opportunity, and human development. The Ibrahim Index uses a number of variables to compile its list which reflects the state of governance in Africa.
The new constitution, adopted in 2010, further sharpened the authoritarian character of the regime. In the future, there will be no presidential elections; the president and the vice-president of the political party which wins the parliamentary elections automatically become president and vice-president of Angola. Through a variety of mechanisms, the state president controls all the other organs of the state, so that separation of powers is not maintained. As a consequence, Angola no longer has a presidential system in the sense of the systems existing, e.g., in the USA or in France. In terms of the classifications used in constitutional law, its regime is considered one of several authoritarian regimes in Africa.
On 16 October 2014, Angola was elected for the second time as a non-permanent member of the UN Security Council, with 190 favourable votes out of 193. The mandate begins on 1 January 2015 and lasts for two years.
Also in that month, the country took on the leadership of the Group of African Ministers and Governors at the International Monetary Fund and the World Bank, following the debates at the annual meetings of both entities.
Since January 2014 the Republic of Angola has held the presidency of the International Conference on the Great Lakes Region (ICGLR). In 2015, the executive secretary of ICGLR, Ntumba Luaba, said that Angola is the example to be followed by members of the organization, because of the significant progress made over the 12 years of peace, particularly in terms of socioeconomic and political-military stability.
<h3>Military.</h3>
The Angolan Armed Forces (AAF) is headed by a Chief of Staff who reports to the Minister of Defense. There are three divisions—the Army (Exército), Navy (Marinha de Guerra, MGA), and National Air Force (Força Aérea Nacional, FAN). Total manpower is about 110,000. Its equipment includes Russian-manufactured fighters, bombers, and transport planes. There are also Brazilian-made EMB-312 Tucano for training role, Czech-made L-39 for training and bombing role, Czech Zlin for training role and a variety of western made aircraft such as C-212\Aviocar, Sud Aviation Alouette III, etc. A small number of AAF personnel are stationed in the Democratic Republic of the Congo (Kinshasa) and the Republic of the Congo (Brazzaville).
<h3>Police.</h3>
The National Police departments are Public Order, Criminal Investigation, Traffic and Transport, Investigation and Inspection of Economic Activities, Taxation and Frontier Supervision, Riot Police and the Rapid Intervention Police. The National Police are in the process of standing up an air wing, which will provide helicopter support for operations. The National Police are developing their criminal investigation and forensic capabilities. The force has an estimated 6,000 patrol officers, 2,500 taxation and frontier supervision officers, 182 criminal investigators and 100 financial crimes detectives and around 90 economic activity inspectors.
The National Police have implemented a modernization and development plan to increase the capabilities and efficiency of the total force. In addition to administrative reorganization, modernization projects include procurement of new vehicles, aircraft and equipment, construction of new police stations and forensic laboratories, restructured training programs and the replacement of AKM rifles with 9 mm Uzis for officers in urban areas.
<h3>Justice.</h3>
In 2014, a new penal code took effect in Angola. The classification of money-laundering as a crime is one of the novelties in the new legislation.
<h2>Administrative divisions.</h2>
, Angola is divided into eighteen provinces ("províncias") and 162 municipalities. The municipalities are further divided into 559 communes (townships). The provinces are:
<h3>Exclave of Cabinda.</h3>
With an area of approximately , the Northern Angolan province of Cabinda is unusual in being separated from the rest of the country by a strip, some wide, of the Democratic Republic of Congo along the lower Congo river. Cabinda borders the Congo Republic to the north and north-northeast and the DRC to the east and south. The town of Cabinda is the chief population center.
According to a 1995 census, Cabinda had an estimated population of 600,000, approximately 400,000 of whom live in neighboring countries. Population estimates are, however, highly unreliable. Consisting largely of tropical forest, Cabinda produces hardwoods, coffee, cocoa, crude rubber and palm oil. The product for which it is best known, however, is its oil, which has given it the nickname, "the Kuwait of Africa". Cabinda's petroleum production from its considerable offshore reserves now accounts for more than half of Angola's output. Most of the oil along its coast was discovered under Portuguese rule by the Cabinda Gulf Oil Company (CABGOC) from 1968 onwards.
Ever since Portugal handed over sovereignty of its former overseas province of Angola to the local independence groups (MPLA, UNITA, and FNLA), the territory of Cabinda has been a focus of separatist guerrilla actions opposing the Government of Angola (which has employed its military forces, the FAA—Forças Armadas Angolanas) and Cabindan separatists. The Front for the Liberation of the Enclave of Cabinda-Armed Forces of Cabinda (FLEC-FAC) announced a virtual Federal Republic of Cabinda under the Presidency of N'Zita Henriques Tiago. One of the characteristics of the Cabindan independence movement is its constant fragmentation, into smaller and smaller factions.
<h2>Economy.</h2>
Angola has a rich subsoil heritage, from diamonds, oil, gold, copper, and a rich wildlife (dramatically impoverished during the civil war), forest, and fossils. Since independence, oil and diamonds have been the most important economic resource. Smallholder and plantation agriculture have dramatically dropped because of the Angolan Civil War, but have begun to recover after 2002. The transformation industry that had come into existence in the late colonial period collapsed at independence, because of the exodus of most of the ethnic Portuguese population, but has begun to reemerge with updated technologies, partly because of the influx of new Portuguese entrepreneurs. Similar developments can be verified in the service sector.
Overall, Angola's economy has in recent years moved on from the disarray caused by a quarter-century of civil war to become the fastest-growing economy in Africa and one of the fastest in the world, with an average GDP growth of 20 percent between 2005 and 2007. In the period 2001–10, Angola had the world's highest annual average GDP growth, at 11.1 percent. In 2004, the Eximbank approved a $2 billion line of credit to Angola. The loan was to be used to rebuild Angola's infrastructure, and also to limited the influence of the International Monetary Fund in the country. China is Angola's biggest trade partner and export destination as well as the fourth-largest importer. Bilateral trade reached $27.67 billion in 2011, up 11.5% year-on-year. China's imports, mainly crude oil and diamonds, increased 9.1% to $24.89 billion while China's exports, including mechanical and electrical products, machinery parts and construction materials, surged 38.8%. The oil glut led to a local unleaded gasoline "pricetag" of £0.37 per gallon.
"The Economist" reported in 2008 that diamonds and oil make up 60% of Angola's economy, almost all of the country's revenue and are its dominant exports. Growth is almost entirely driven by rising oil production which surpassed in late 2005 and was expected to grow to by 2007. Control of the oil industry is consolidated in Sonangol Group, a conglomerate owned by the Angolan government. In December 2006, Angola was admitted as a member of OPEC. However, operations in diamond mines include partnerships between state-run Endiama and mining companies such as ALROSA which continue operations in Angola. The economy grew 18% in 2005, 26% in 2006 and 17.6% in 2007. However, due to the global recession the economy contracted an estimated −0.3% in 2009. The security brought about by the 2002 peace settlement has led to the resettlement of 4 million displaced persons, thus resulting in large-scale increases in agriculture production.
Although the country's economy has developed significantly since it achieved political stability in 2002, mainly thanks to the fast-rising earnings of the oil sector, Angola faces huge social and economic problems. These are in part a result of the almost continual state of conflict from 1961 onwards, although the highest level of destruction and socio-economic damage took place after the 1975 independence, during the long years of civil war. However, high poverty rates and blatant social inequality are chiefly the outcome of a combination of a persistent political authoritarianism, of "neo-patrimonial" practices at all levels of the political, administrative, military, and economic apparatuses, and of a pervasive corruption. The main beneficiary of this situation is a social segment constituted during the last decades, around the political, administrative, economic, and military power holders, which has accumulated (and continues accumulating) enormous wealth. "Secondary beneficiaries" are the middle strata which are about to become social classes. However, overall almost half the population has to be considered as poor, but in this respect there are dramatic differences between the countryside and the cities (where by now slightly more than 50% of the people live).
An inquiry carried out in 2008 by the Angolan Instituto Nacional de Estatística has it that in the rural areas roughly 58% must be classified as "poor", according to UN norms, but in the urban areas only 19%, while the overall rate is 37%. In the cities, a majority of families, well beyond those officially classified as poor, have to adopt a variety of survival strategies. At the same time, in urban areas social inequality is most evident, and assumes extreme forms in the capital, Luanda. In the Human Development Index Angola constantly ranks in the bottom group.
According to The Heritage Foundation, a conservative American think tank, oil production from Angola has increased so significantly that Angola now is China's biggest supplier of oil. “China has extended three multibillion dollar lines of credit to the Angolan government; two loans of $2 billion from China Exim Bank, one in 2004, the second in 2007, as well as one loan in 2005 of $2.9 billion from China International Fund Ltd.” Growing oil revenues have also created opportunities for corruption: according to a recent Human Rights Watch report, 32 billion US dollars disappeared from government accounts from 2007 to 2010. Furthermore, Sonangol, the state run oil company, has control of 51% of Cabinda’s oil. Due to this market control the company ends up determining the profit given to the government and the taxes paid. The council of foreign affairs states that the World Bank mentioned that Sonangol " is a taxpayer, it carries out quasi-fiscal activities, it invests public funds, and, as concessionaire, it is a sector regulator. This multifarious work program creates conflicts of interest and characterizes a complex relationship between Sonangol and the government that weakens the formal budgetary process and creates uncertainty as regards the actual fiscal stance of the state."
Before independence in 1975, Angola was a breadbasket of southern Africa and a major exporter of bananas, coffee and sisal, but three decades of civil war (1975–2002) destroyed fertile countryside, left it littered with landmines and drove millions into the cities. The country now depends on expensive food imports, mainly from South Africa and Portugal, while more than 90% of farming is done at thefamily and subsistence level. Thousands of Angolan small-scale farmers are trapped in poverty.
The enormous differences between the regions pose a serious structural problem for the Angolan economy, illustrated by the fact that about one third of economic activities are concentrated in Luanda and neighbouring Bengo province, while several areas of the interior suffer economic stagnation and even regression.
One of the economic consequences of the social and regional disparities is a sharp increase in Angolan private investments abroad. The small fringe of Angolan society where most of the accumulation takes place seeks to spread its assets, for reasons of security and profit. For the time being, the biggest share of these investments is concentrated in Portugal where the Angolan presence (including that of the family of the state president) in banks as well as in the domains of energy, telecommunications, and mass media has become notable, as has the acquisition of vineyards and orchards as well as of touristic enterprises.
Sub-Saharan Africa nations are globally achieving impressive improvements in well-being, according to a report by Tony Blair Africa Governance Initiative and The Boston Consulting Group. Angola has upgraded critical infrastructure, an investment made possible by funds from the nation's development of oil resources. According to this report, just slightly more than ten years after the end of the civil war Angola's standard of living has overall greatly improved. Life expectancy, which was just 46 years in 2002, reached 51 in 2011. Mortality rates for children fell from 25 percent in 2001 to 19 percent in 2010 and the number of students enrolled in primary school has tripled since 2001. However, at the same time the social and economic inequality that has characterised the country since long has not diminished, but on the contrary deepened in all respects.
With a stock of assets corresponding to 70 billion Kz (6.8 billion USD), Angola is now the third largest financial market in sub-Saharan Africa, surpassed only by Nigeria and South Africa. According to the Angolan Minister of Economy, Abraão Gourgel, the financial market of the country grew modestly from 2002 and now lies in third place at the level of sub-Saharan Africa.
Angola's economy is expected to grow by 3.9 percent in 2014 said the International Monetary Fund (IMF). According to the Fund, robust growth in the non-oil economy, mainly driven by a very good performance in the agricultural sector, is expected to offset a temporary drop in oil production.
Angola's financial system is maintained by the National Bank of Angola and managed by governor . According to a study on the banking sector, carried out by Deloitte, the monetary policy led by Banco Nacional de Angola (BNA), the Angolan national bank, allowed a decrease in the inflation rate put at 7.96% in December 2013, which contributed to the sector's growth trend. According to estimates released by Angola's central bank, the country's economy should grow at an annual average rate of 5 percent over the next four years, boosted by the increasing participation of the private sector.
On 19 December 2014, the Capital Market in Angola started. BODIVA (Angola Securities and Debt Stock Exchange, in English) received the secondary public debt market, and it is expected to start the corporate debt market by 2015, but the stock market should only be a reality in 2016.
<h3>Agriculture.</h3>
Agriculture and forestry is an area of opportunity for the country. “Angola requires 4.5 million tonnes a year of grain but only grows about 55% of the corn it needs, 20% of the rice and just 5% of its required wheat”(African economic Outlook) but “less than 3 percent of Angola's abundant fertile land is cultivated and the economic potential of the forestry sector remains largely unexploited” (World Bank). From this fact we can appreciate the capacity that Angola has to increase production not only for the national market but also for the international one. Investing in this sector can help reduce unemployment and more specifically in the rural areas. This will undoubted have consequences on the living standard of rural civilians.
<h3>Transport.</h3>
Transport in Angola consists of:
Travel on highways outside of towns and cities in Angola (and in some cases within) is often not best advised for those without four-by-four vehicles. While a reasonable road infrastructure has existed within Angola, time and the war have taken their toll on the road surfaces, leaving many severely potholed, littered with broken asphalt. In many areas drivers have established alternate tracks to avoid the worst parts of the surface, although careful attention must be paid to the presence or absence of landmine warning markers by the side of the road. The Angolan government has contracted the restoration of many of the country's roads. The road between Lubango and Namibe, for example, was completed recently with funding from the European Union, and is comparable to many European main routes. Completing the road infrastructure is likely to take some decades, but substantial efforts are already being made.
Transport is an important aspect in Angola because it is strategically located and it could become a regional logistics hub. In addition Angola has some of the most important and biggest ports and so it is vital to connect them to the interior of the country as well as to neighbouring countries.
<h3>Telecommunications.</h3>
The telecommunications industry is considered one of the main strategic sectors in Angola.
In October 2014, the building of an optic fiber underwater cable was announced. This project aims to turn Angola into a continental hub, thus improving Internet connections both nationally and internationally.
On 11 March 2015, the First Angolan Forum of Telecommunications and Information Technology was held, in Luanda under the motto "The challenges of telecommunications in the current context of Angola". The purpose of this forum was to promote the debate on topical issues on telecommunications in Angola and worldwide. A study about this sector was also presented at this forum, and some of its conclusions were: Angola had the first telecommunications operator in Africa to test the High Speed Internet technology (LTE-Advanced with speeds up to 400Mbit/s); It has a mobile penetration rate of about 75%; There are about 3.5 million smartphones in the Angolan market; There are about of optical fiber installed in the country.
The first Angolan satellite, AngoSat-1, will be ready for launch into orbit in 2017 and it will ensure telecommunications throughout the country. According to Aristides Safeca, Secretary of State for Telecommunications, the satellite will provide telecommunications services, TV, internet and e-government and will remain into orbit "at best" for 18 years.
<h3>Technology.</h3>
The management of the domain '.ao' on web pages, will go from Portugal to Angola in 2015, following the approval of a new legislation by the Angolan Government. The joint decree of the minister of Telecommunications and Information Technologies, José Carvalho da Rocha, and the minister of Science and Technology, Maria Cândida Pereira Teixeira, states that "under the massification" of that Angolan domain, "conditions are created for the transfer of the domain root '.ao' of Portugal to Angola".
<h2>Demographics.</h2>
Angola has a population of 24,383,301 inhabitants according to the preliminary results of its 2014 census, the first one conducted or carried out since 15 December 1970. It is composed of Ovimbundu (language Umbundu) 37%, Ambundu (language Kimbundu) 23%, Bakongo 13%, and 32% other ethnic groups (including the Chokwe, the Ovambo, the Ganguela and the Xindonga) as well as about 2% "mestiços" (mixed European and African), 1.6% Chinese and 1% European. The Ambundu and Ovimbundu ethnic groups combined form a majority of the population, at 62%. The population is forecast to grow to over 60 million people to 2050, 2.7 times the 2014 population. However, on March 23, 2016, official data revealed by Angola's National Statistic Institute - Instituto Nacional de Estatística (INE), states that Angola has a population of 25.789.024 inhabitants.
It is estimated that Angola was host to 12,100 refugees and 2,900 asylum seekers by the end of 2007. 11,400 of those refugees were originally from the Democratic Republic of Congo, who arrived in the 1970s. there were an estimated 400,000 Democratic Republic of the Congo migrant workers, at least 220,000 Portuguese, and about 259,000 Chinese living in Angola.
Since 2003, more than 400,000 Congolese migrants have been expelled from Angola. Prior to independence in 1975, Angola had a community of approximately 350,000 Portuguese, but the vast majority left after independence and the ensuing civil war. However, Angola has recovered its Portuguese minority in recent years; currently, there are about 200,000 registered with the consulates, and increasing due to the debt crisis in Portugal and the relative prosperity in Angola. The Chinese population stands at 258,920, mostly composed of temporary migrants. Also, there is a small Brazilian community of about 5,000 people.
The total fertility rate of Angola is 5.54 children born per woman (2012 estimates), the 11th highest in the world.
<h3>Languages.</h3>
The languages in Angola are those originally spoken by the different ethnic groups and Portuguese, introduced during the Portuguese colonial era. The most widely spoken indigenous languages are Umbundu, Kimbundu, and Kikongo, in that order. Portuguese is the official language of the country.
Mastery of the official language is probably more extended in Angola than it is elsewhere in Africa, and this certainly applies to its use in everyday life. Moreover, and above all, the proportion of native (or near-native) speakers of the language of the former colonizer, become official after independence, is no doubt considerably higher than in any other African country.
There are three intertwined historical reasons for this situation.
As a consequence of all this, the African "lower middle class" which at that stage formed in Luanda and other cities began to prevent their children from learning the local African language, in order to guarantee that they learned Portuguese as their native language. At the same time, the white and "mestiço" population, where some knowledge of African languages could previously often be found, neglected this aspect more and more, to the point of frequently ignoring it totally.
These tendencies continued and grew under the rule of the MPLA whose main social roots are exactly in those social segments where the mastery of Portuguese as well as the proportion of native Portuguese speakers was highest. This became a political side issue, as FNLA and UNITA, given their regional constituencies, came out in favour of a greater attention to the African languages, and as the FNLA favoured French over Portuguese.
The dynamics of the language situation, as described above, were additionally fostered by the massive migrations triggered by the Civil War. Ovimbundu, the most populous ethnic group and the most affected by the war, appeared in great numbers in urban areas outside their areas, especially in Luanda and surroundings. At the same time, a majority of the Bakongo who had fled to the Democratic Republic of Congo in the early 1960s, or of their children and grandchildren, returned to Angola, but mostly did not settle in their original "habitat", but in the cities—and again above all in Luanda. As a consequence, more than half the population is now living in the cities which, from the linguistic point of view, have become highly heterogeneous. This means, of course, that Portuguese as the overall national language of communication is by now of paramount importance, and that the role of the African languages is steadily decreasing among the urban population—a trend which is beginning to spread into rural areas as well.
The exact numbers of those fluent in Portuguese or who speak Portuguese as a first language are unknown, although a census is expected to be carried out in July–August 2013. Quite a number of voices demand the recognition of "Angolan Portuguese" as a specific variant, comparable to those spoken in Portugal or in Brazil. However, while there exists a certain number of idiomatic particularities in everyday Portuguese, as spoken by Angolans, it remains to be seen whether or not the Angolan government comes to the conclusion that these particularities constitute a configuration that justifies the claim to be a new language variant.
<h3>Religion.</h3>
There are about 1000 mostly Christian religious communities in Angola. While reliable statistics are nonexistent, estimates have it that more than half of the population are Catholics, while about a quarter adhere to the Protestant churches introduced during the colonial period: the Congregationalists mainly among the Ovimbundu of the Central Highlands and the coastal region to its West, the Methodists concentrating on the Kimbundu speaking strip from Luanda to Malanje, the Baptists almost exclusively among the Bakongo of the Northwest (now present in Luanda as well) and dispersed Adventists, Reformed and Lutherans. In Luanda and region there subsists a nucleus of the "syncretic" Tocoists and in the northwest a sprinkling of Kimbanguism can be found, spreading from the Congo/Zaïre. Since independence, hundreds of Pentecostal and similar communities have sprung up in the cities, where by now about 50% of the population is living; several of these communities/churches are of Brazilian origin.
The U.S. Department of State estimates the Muslim population at 80,000–90,000, while the Islamic Community of Angola puts the figure closer to 500,000. Muslims consist largely of migrants from West Africa and the Middle East (especially Lebanon), although some are local converts. The Angolan government does not legally recognize any Muslim organizations and often shuts down mosques or prevents their construction.
In a study assessing nations' levels of religious regulation and persecution with scores ranging from 0 to 10 where 0 represented low levels of regulation or persecution, Angola was scored 0.8 on Government Regulation of Religion, 4.0 on Social Regulation of Religion, 0 on Government Favoritism of Religion and 0 on Religious Persecution.
Foreign missionaries were very active prior to independence in 1975, although since the beginning of the anti-colonial fight in 1961 the Portuguese colonial authorities expelled a series of Protestant missionaries and closed mission stations based on the belief that the missionaries were inciting pro-independence sentiments. Missionaries have been able to return to the country since the early 1990s, although security conditions due to the civil war have prevented them until 2002 from restoring many of their former inland mission stations.
The Catholic Church and some major Protestant denominations mostly keep to themselves in contrast to the "New Churches" which actively proselytize. Catholics, as well as some major Protestant denominations, provide help for the poor in the form of crop seeds, farm animals, medical care and education.
<h2>Culture.</h2>
In Angola, there is a Culture Ministry that is managed by Culture Minister Rosa Maria Martins da Cruz e Silva. Portugal has been present in Angola for 400 years, occupied the territory in the 19th and early 20th century, and ruled over it for about 50 years. As a consequence, both countries share cultural aspects: language (Portuguese) and main religion (Roman Catholic Christianity). The "substrate" of Angolan culture is African, mostly Bantu, while Portuguese culture has been imported. The diverse ethnic communities – the Ovimbundu, Ambundu, Bakongo, Chokwe, Mbunda and other peoples – maintain to varying degrees their own cultural traits, traditions and languages, but in the cities, where slightly more than half of the population now lives, a mixed culture has been emerging since colonial times – in Luanda since its foundation in the 16th century. In this urban culture, the Portuguese heritage has become more and more dominant. An African influence is evident in music and dance, and is moulding the way in which Portuguese is spoken, but is almost disappearing from the vocabulary. This process is well reflected in contemporary Angolan literature, especially in the works of Pepetela and Ana Paula Ribeiro Tavares.
Leila Lopes, Miss Angola 2011, was crowned Miss Universe 2011 in Brazil on 12 September 2011 making her the first Angolan to win the pageant.
In 2014, Angola resume the National Festival of Angolan Culture (FENACULT), after a 25-years break. The festival took place in all the provincial capitals of the country between 30 August and 20 September and had as theme "Culture as a Factor of Peace and Development".
<h2>Health.</h2>
Epidemics of cholera, malaria, rabies and African hemorrhagic fevers like Marburg hemorrhagic fever, are common diseases in several parts of the country. Many regions in this country have high incidence rates of tuberculosis and high HIV prevalence rates. Dengue, filariasis, leishmaniasis, and onchocerciasis (river blindness) are other diseases carried by insects that also occur in the region. Angola has one of the highest infant mortality rates in the world and one of the world's lowest life expectancies. A 2007 survey concluded that low and deficient niacin status was common in Angola. Demographic and Health Surveys is currently conducting several surveys in Angola on malaria, domestic violence and more.
In September 2014, the Angolan Institute for Cancer Control (IACC) was created by presidential decree, and it will integrate the National Health Service in Angola. The purpose of this new center is to ensure the health and medical care in oncology, policy implementation, programs and plans for prevention and specialized treatment. This cancer institute will be assumed as a reference institution in the central and southern regions of Africa.
In 2014, Angola launched a national campaign of vaccination against measles, extended to every child under ten years old and aiming to go to all 18 provinces in the country. The measure is part of the Strategic Plan for the Elimination of Measles 2014–2020 created by the Angolan Ministry of Health which includes strengthening routine immunization, a proper dealing with measles cases, national campaigns, introducing a second dose of vaccination in the national routine vaccination calendar and active epidemiological surveillance for measles. This campaign took place together with the vaccination against polio and vitamin A supplementation.
A yellow fever outbreak in Angola began in December 2015. Nearly 4000 people were suspected of being infected as of August 2016 when the outbreak began to subside. As many as 369 may have died from yellow fever. The outbreak began in the capital of Luanda but spread to at least 16 of the 18 provinces in the country. This outbreak of the yellow fever is the worst in the southern African country in three decades.
<h2>Education.</h2>
Although by law education in Angola is compulsory and free for eight years, the government reports that a percentage of students are not attending due to a lack of school buildings and teachers. Students are often responsible for paying additional school-related expenses, including fees for books and supplies.
In 1999, the gross primary enrollment rate was 74 percent and in 1998, the most recent year for which data are available, the net primary enrollment rate was 61 percent. Gross and net enrollment ratios are based on the number of students formally registered in primary school and therefore do not necessarily reflect actual school attendance. There continue to be significant disparities in enrollment between rural and urban areas. In 1995, 71.2 percent of children ages 7 to 14 years were attending school. It is reported that higher percentages of boys attend school than girls. During the Angolan Civil War (1975–2002), nearly half of all schools were reportedly looted and destroyed, leading to current problems with overcrowding.
The Ministry of Education hired 20,000 new teachers in 2005 and continued to implement teacher trainings. Teachers tend to be underpaid, inadequately trained, and overworked (sometimes teaching two or three shifts a day). Some teachers may reportedly demand payment or bribes directly from their students. Other factors, such as the presence of landmines, lack of resources and identity papers, and poor health prevent children from regularly attending school. Although budgetary allocations for education were increased in 2004, the education system in Angola continues to be extremely under-funded.
According to estimates by the UNESCO Institute for Statistics, the adult literacy rate in 2011 was 70.4%. 82.9% of males and 54.2% of women are literate as of 2001. Since independence from Portugal in 1975, a number of Angolan students continued to be admitted every year at high schools, polytechnical institutes, and universities in Portugal, Brazil and Cuba through bilateral agreements; in general, these students belong to the elites.
In September 2014, the Angolan Ministry of Education announced an investment of 16 million Euros in the computerization of over 300 classrooms across the country. The project also includes training teachers at a national level, "as a way to introduce and use new information technologies in primary schools, thus reflecting an improvement in the quality of teaching."
In 2010, the Angolan government started building the Angolan Media Libraries Network, distributed throughout several provinces in the country to facilitate the people's access to information and knowledge. Each site has a bibliographic archive, multimedia resources and computers with Internet access, as well as areas for reading, researching and socializing. The plan envisages the establishment of one media library in each Angolan province by 2017. The project also includes the implementation of several media libraries, in order to provide the several contents available in the fixed media libraries to the most isolated populations in the country. At this time, the mobile media libraries are already operating in the provinces of Luanda, Malanje, Uíge, Cabinda and Lunda South. As for REMA, the provinces of Luanda, Benguela, Lubango and Soyo have currently working media libraries.
<h2>Sports.</h2>
Angola is the top basketball team of FIBA Africa, and a regular competitor at the Summer Olympic Games and the FIBA World Cup. The Angola national football team qualified for the 2006 FIFA World Cup, as this was their first appearance on the World Cup finals stage. They were eliminated after one defeat and two draws in the group stage. They won 3 COSAFA Cups and finished runner up in 2011 African Nations Championship. Angola has participated in the World Women's Handball Championship for several years. The country has also appeared in the Summer Olympics for seven years and both compete and have hosted the FIRS Roller Hockey World Cup. Angola is also often believed to have historic roots in the martial art "Capoeira Angola" and "Batuque" which were practiced by enslaved African Angolans transported as part of the Atlantic slave trade.

</doc>
<doc id="704" url="https://en.wikipedia.org/wiki?curid=704" title="Demographics of Angola">
Demographics of Angola

This article is about the demographic features of the population of Angola, including population density, ethnicity, education level, health of the populace, economic status, religious affiliations and other aspects of the population.
According to 2014 census data, Angola had a population of 24.3 million inhabitants in 2014.
Ethnically, there are three main groups, each speaking a Bantu language: the Ovimbundu who represent 37% of the population, the (Ambundu) with 25%, and the Bakongo 13%. Other numerically important groups include the closely interrelated Chokwe and Lunda, the Ganguela and Nyaneka-Khumbi (in both cases classification terms that stand for a variety of small groups), the Ovambo, the Herero, the Xindonga and scattered residual groups of Khoisan. In addition, mixed race (European and African) people amount to about 2%, with a small (1%) population of whites, mainly ethnically Portuguese.
As a former overseas territory of Portugal until 1975, Angola possesses a Portuguese population of over 200,000, a number that has been growing from 2000 onwards, because of Angola's growing demand for qualified human resources. Besides the Portuguese, significant numbers of people from other European and from diverse Latin American countries (especially Brazil) can be found. From the 2000s, many Chinese have settled and started up small businesses, while at least as many have come as workers for large enterprises (construction or other). Observers claim that the Chinese community in Angola might include as many as 300,000 persons at the end of 2010, but reliable statistics are not at this stage available. In 1974/75, over 25,000 Cuban soldiers arrived in Angola to help the MPLA forces during the decolonization conflict. Once this was over, a massive development cooperation in the field of health and education brought in numerous civil personnel from Cuba. However, only a very small percentage of all these people has remained in Angola, either for personal reasons (intermarriage) or as professionals (e.g., medical doctors).
The largest religious denomination is Roman Catholicism, to which adheres about half the population. Roughly 26% are followers of traditional forms of Protestantism (Congregationals, Methodists, Baptista, Lutherans, Reformed), but over the last decades there has in addition been a growth of Pentecostal communities and African Initiated Churches. In 2006, one out of 221 people were Jehovah's Witnesses. Blacks from Mali, Nigeria and Senegal are mostly Sunnite Muslims, but do not make up more than 1 - 2% of the population. By now few Angolans retain African traditional religions following different ethnic faiths.
<h2>Population.</h2>
According to the 2010 revision of the World Population Prospects the total population was 19 082 000 in 2010, compared to only 4 148 000 in 1950. The proportion of children below the age of 15 in 2010 was 46.6%, 50.9% was between 15 and 65 years of age, while 2.5% was 65 years or older
Structure of the population (DHS 2011) (Males 19 707, Females 20 356 = 40 063) :
<h2>Vital statistics.</h2>
Registration of vital events is in Angola not complete. The Population Department of the United Nations prepared the following estimates.
<h3>Fertility and Births.</h3>
Total Fertility Rate (TFR) and Crude Birth Rate (CBR):
<h2>CIA World Factbook demographic statistics.</h2>
The following demographic statistics are from the CIA World Factbook, unless otherwise indicated.
<h3>Population.</h3>
<h4>Population growth.</h4>
The population is growing by 2.184% annually. There are 44.51 births and 24.81 deaths per 1,000 citizens. The net migration rate is 2.14 migrants per 1,000 citizens. The fertility rate of Angola is 5.97 children born per woman as of 2011. The infant mortality rate is 184.44 deaths for every 1,000 live births with 196.55 deaths for males and 171.72 deaths for females for every 1,000 live births. Life expectancy at birth is 37.63 years; 36.73 years for males and 38.57 years for females.
<h3>Health.</h3>
According to the CIA World Factbook, 2% of adults (aged 15–49) are living with HIV/AIDS (as of 2009). The risk of contracting disease is very high. There are food and waterborne diseases, bacterial and protozoal diarrhea, hepatitis A, and typhoid fever; vectorborne diseases, malaria, African trypanosomiasis (sleeping sickness); respiratory disease: meningococcal meningitis, and schistosomiasis, a water contact disease, as of 2005.
<h3>Ethnic groups.</h3>
Roughly 37% of Angolans are Ovimbundu, 25% are Ambundu, 13% are Bakongo, 2% are mestiço, 1-2% are white Africans, and people from other African ethnicities make up 22% of Angola's population.
<h3>Religions.</h3>
Angola is a majority Christian country. Reliable statistics don't exist, but well over 80% belong in principle to a Christian church or community, although many of them don't practice their religion and are in fact non believers. More than half of the Christians (whether practising or not) are Roman Catholic, the remaining ones comprising members of traditional Protestant churches as well as of new, often Pentecostal communities. Only 1 - 2% are Muslims - generally immigrants from other African countries. Traditional indigenous religions are practized by a very small minority, generally in peripheral rural societies; however, some traditional beliefs are held by a substantial number of Christians.
<h3>Education.</h3>
Literacy is quite low, with 67.4% of the population over the age of 15 able to read and write in Portuguese. 82.9% of males and 54.2% of women are literate as of 2001.
<h3>Languages.</h3>
Portuguese is the official language of Angola, but Bantu and other African languages are also widely spoken. In fact, Kikongo, Kimbundu, Umbundu, Tuchokwe, Nganguela, and Ukanyama have the official status of "national languages". The mastery of Portuguese is widespread; in the cities the overwhelming majority are either fluent in Portuguese or have at least a reasonable working knowledge of this language; an increasing minority are native Portuguese speakers and have a poor, if any, knowledge of an African language.

</doc>
<doc id="705" url="https://en.wikipedia.org/wiki?curid=705" title="Politics of Angola">
Politics of Angola

Since the adoption of a new constitution in 2010, the politics of Angola takes place in a framework of a presidential republic, whereby the President of Angola is both head of state and head of government, and of a multi-party system. Executive power is exercised by the government. Legislative power is vested in the President, the government and parliament.
Angola changed from a one-party Marxist-Leninist system ruled by the Popular Movement for the Liberation of Angola (MPLA), in place since independence in 1975, to a multiparty democracy based on a new constitution adopted in 1992. That same year the first parliamentary and presidential elections were held. The MPLA won an absolute majority in the parliamentary elections. In the presidential elections, President José Eduardo dos Santos won the first round election with more than 49% of the vote to Jonas Savimbi's 40%. A runoff election would have been necessary, but never took place. The renewal of civil war immediately after the elections, which were considered as fraudulent by UNITA, and the collapse of the Lusaka Protocol, created a split situation. To a certain degree the new democratic institutions worked, notably the National Assembly, with the active participation of UNITA's and the FNLA's elected MPs - while José Eduardo dos Santos continued to exercise his functions without democratic legitimation. However the armed forces of the MPLA (now the official armed forces of the Angolan state) and of UNITA fought each other until the leader of UNITA, Jonas Savimbi, was killed in action in 2002.
From 2002 to 2010, the system as defined by the constitution of 1992 functioned in a relatively normal way. The executive branch of the government was composed of the President, the Prime Minister and Council of Ministers. The Council of Ministers, composed of all ministers and vice ministers, met regularly to discuss policy issues. Governors of the 18 provinces were appointed by and served at the pleasure of the president. The Constitutional Law of 1992 established the broad outlines of government structure and the rights and duties of citizens. The legal system was based on Portuguese and customary law but was weak and fragmented. Courts operated in only 12 of more than 140 municipalities. A Supreme Court served as the appellate tribunal; a Constitutional Court with powers of judicial review was never constituted despite statutory authorization. In practice, power was more and more concentrated in the hands of the President who, supported by an ever increasing staff, largely controlled parliament, government, and the judiciary.
The 26-year-long civil war has ravaged the country's political and social institutions. The UN estimates of 1.8 million internally displaced persons (IDPs), while generally the accepted figure for war-affected people is 4 million. Daily conditions of life throughout the country and specifically Luanda (population approximately 6 million) mirror the collapse of administrative infrastructure as well as many social institutions. The ongoing grave economic situation largely prevents any government support for social institutions. Hospitals are without medicines or basic equipment, schools are without books, and public employees often lack the basic supplies for their day-to-day work.
<h2>Executive branch.</h2>
The 2010 constitution grants the President almost absolute power. Elections for the National assembly are to take place every five years, and the President is automatically the leader of the winning party or coalition. It is for the President to appoint (and dismiss) all of the following:
The President is also provided a variety of powers, like defining the policy of the country. Even though it's not up to him/her to make laws (only to promulgate them and make edicts), the President is the leader of the winning party.
The only "relevant" post that is not directly appointed by the President is the Vice-President, which is the second in the winning party.
<h2>Legislative branch.</h2>
The National Assembly ("Assembleia Nacional") has 223 members, elected for a four-year term, 130 members by proportional representation, 90 members in provincial districts, and 3 members to represent Angolans abroad. The next general elections, due for 1997, have been rescheduled for 5 September 2008. The ruling party MPLA won 82% (191 seats in the National Assembly) and the main opposition party won only 10% (16 seats). The elections however have been described as only partly free but certainly not fair. A White Book on the elections in 2008 lists up all irregularities surrounding the Parliamentary elections of 2008.
<h2>Judicial branch.</h2>
Supreme Court (or "Tribunal da Relacao") judges of the Supreme Court are appointed by the president. The Constitutional Court, with the power of judicial review, contains 11 justices. Four are appointed by the President, four by the National Assembly, two by the Superior Council of the Judiciary, and one elected by the public.
<h2>Administrative divisions.</h2>
Angola has eighteen provinces (provincias, singular - provincia); Bengo, Benguela, Bie, Cabinda, Cuando Cubango, Cuanza Norte, Cuanza Sul, Cunene, Huambo, Huila, Luanda, Lunda Norte, Lunda Sul, Malanje, Moxico, Namibe, Uige, Zaire
<h2>Political pressure groups and leaders.</h2>
Front for the Liberation of the Enclave of Cabinda or FLEC (Henrique N'zita Tiago; António Bento Bembe)
<h2>International organization participation.</h2>
African, Caribbean and Pacific Group of States, AfDB, CEEAC, United Nations Economic Commission for Africa, FAO, Group of 77, IAEA, IBRD, ICAO, International Criminal Court (signatory), ICFTU, International Red Cross and Red Crescent Movement, International Development Association, IFAD, IFC, IFRCS, International Labour Organization, International Monetary Fund, International Maritime Organization, Interpol, IOC, International Organization for Migration, ISO (correspondent), ITU, Non-Aligned Council (temporary), UNCTAD, UNESCO, UNIDO, UPU, World Customs Organization, World Federation of Trade Unions, WHO, WIPO, WMO, WToO, WTrO

</doc>
<doc id="706" url="https://en.wikipedia.org/wiki?curid=706" title="Economy of Angola">
Economy of Angola

The Economy of Angola is one of the fastest-growing in the world, with reported annual average GDP growth of 11.1 percent from 2001 to 2010. It is still recovering from the Angolan Civil War that plagued the country from its independence in 1975 until 2002. Despite extensive oil and gas resources, diamonds, hydroelectric potential, and rich agricultural land, Angola remains poor, and a third of the population relies on subsistence agriculture. Since 2002, when the 27-year civil war ended, the nation has worked to repair and improve ravaged infrastructure and weakened political and social institutions. High international oil prices and rising oil production have contributed to the very strong economic growth since 1998, but corruption and public-sector mismanagement remain, particularly in the oil sector, which accounts for over 50 percent of GDP, over 90 percent of export revenue, and over 80 percent of government revenue.
<h2>History.</h2>
The Portuguese explorer Diogo Cão reached the Angolan coast in 1484, after which Portugal began to found trading posts and forts along the shore. Paulo Dias de Novais founded Sāo Paulo de Loanda (Luanda) in 1575. São Felipe de Benguella (Benguela) followed in 1587.
The principal early trade was in slaves. Portuguese merchants purchased the slaves from the local Imbangala and Mbundu peoples, notable slave hunters, and sold them to the sugarcane plantations in Brazil. Brazilian ships were frequent visitors to Luanda and Benguela and Angola functioned as a kind of colony of Brazil, with Brazilian Jesuits active in its religious and educational centers.
The Portuguese Empire was neglected during the period of the Iberian Union, which lasted from 1580 to 1640. The Dutch, bitter enemies of their former masters in Spain, invaded many Portuguese overseas possessions. During Portugal's separatist war against Spain, the Dutch occupied Luanda from 1640 to 1648, calling it "Fort Aardenburgh". The Dutch used the territory to supply their own slaves to the sugarcane plantations of Northeastern Brazil (Pernambuco, Olinda, Recife), which they had also seized from Portugal. John Maurice, Prince of Nassau-Siegen, conquered the Portuguese possessions of Saint George del Mina, Saint Thomas, and Luanda, Angola, on the west coast of Africa. Portugal recovered the territory between 1648 and 1650.
In the high plains, the Planalto, the most important native states were Bié and Bailundo, the latter being noted for its production of foodstuffs and rubber. Portugal expanded into their territory, but did not control much of the interior prior to the late 19th century.
The Portuguese started to develop townships, trading posts, logging camps and small processing factories. From 1764 onwards, there was a gradual change from a slave-based society to one based on production for domestic consumption and export. Following the independence of Brazil in 1822, the slave trade was formally abolished in 1836. However it did continue locally into the 20th century. In 1844, Angola's ports were opened to foreign shipping. 
By 1850, Luanda was one of the greatest and most developed Portuguese cities in the vast Portuguese Empire outside of Mainland Portugal, full of trading companies, exporting peanut oil, copal, timber, and cocoa. The principal exports of the post-slave economy in the 19th century were rubber, beeswax, and ivory. Maize, tobacco, dried meat and cassava flour also began to be locally produced. Prior to the First World War, exportation of coffee, palm kernels and oil, cattle, leather and hides, and salt fish joined the principal exports, with small quantities of gold and cotton also being produced. Grains, sugar, and rum were also produced for local consumption. The principal imports were foodstuffs, cotton goods, hardware, and British coal. Legislation against foreign traders was implemented in the 1890s. The territory's prosperity, however, continued to depend on plantations worked by labor "indentured" from the interior.
From the 1920s to the 1960s, strong economic growth, abundant natural resources and development of infrastructure, led to the arrival of even more Portuguese settlers. Petroleum was known to exist as early as the mid-19th century, but modern exploitation didn't begin until in 1955. Production began in the Cuanza basin in the 1950s, in the Congo basin in the 1960s, and in the exclave of Cabinda in 1968. The Portuguese government granted operating rights for Block Zero to the Cabinda Gulf Oil Company, a subsidiary of ChevronTexaco, in 1955. Oil production surpassed the exportation of coffee as Angola's largest export in 1973.
A leftist military-led coup d'état, started on April 25, 1974, in Lisbon, overthrew the Marcelo Caetano government in Portugal, and promised to hand over power to an independent Angolan government. Mobutu Sese Seko, the President of Zaire, met with António de Spínola, the transitional President of Portugal, on September 15, 1974 on Sal island in Cape Verde, crafting a plan to empower Holden Roberto of the National Liberation Front of Angola, Jonas Savimbi of UNITA, and Daniel Chipenda of the MPLA's eastern faction at the expense of MPLA leader Agostinho Neto while retaining the façade of national unity. Mobutu and Spínola wanted to present Chipenda as the MPLA head, Mobutu particularly preferring Chipenda over Neto because Chipenda supported autonomy for Cabinda. The Angolan exclave has immense petroleum reserves estimated at around 300 million tons (~300 kg) which Zaire, and thus the Mobutu government, depended on for economic survival. After independence thousands of white Portuguese left, most of them to Portugal and many travelling overland to South Africa. There was an immediate crisis because the indigenous African population lacked the skills and knowledge needed to run the country and maintain its well-developed infrastructure.
The Angolan government created Sonangol, a state-run oil company, in 1976. Two years later Sonangol received the rights to oil exploration and production in all of Angola. After independence from Portugal in 1975, Angola was ravaged by a horrific civil war between 1975 and 2002.
<h3>1990s.</h3>
United Nations Angola Verification Mission III and MONUA spent USD1.5 billion overseeing implementation of the Lusaka Protocol, a 1994 peace accord that ultimately failed to end the civil war. The protocol prohibited UNITA from buying foreign arms, a provision the United Nations largely did not enforce, so both sides continued to build up their stockpile. UNITA purchased weapons in 1996 and 1997 from private sources in Albania and Bulgaria, and from Zaire, South Africa, Republic of the Congo, Zambia, Togo, and Burkina Faso. In October 1997 the UN imposed travel sanctions on UNITA leaders, but the UN waited until July 1998 to limit UNITA's exportation of diamonds and freeze UNITA bank accounts. While the U.S. government gave USD250 million to UNITA between 1986 and 1991, UNITA made USD1.72 billion between 1994 and 1999 exporting diamonds, primarily through Zaire to Europe. At the same time the Angolan government received large amounts of weapons from the governments of Belarus, Brazil, Bulgaria, China, and South Africa. While no arms shipment to the government violated the protocol, no country informed the U.N. Register on Conventional Weapons as required.
Despite the increase in civil warfare in late 1998, the economy grew by an estimated 4% in 1999. The government introduced new currency denominations in 1999, including a 1 and 5 kwanza note.
<h3>2000s.</h3>
An economic reform effort was launched in 1998. Angola ranked 160 of 174 nations in the United Nations Human Development Index in 2000. In April 2000 Angola started an International Monetary Fund (IMF) Staff-Monitored Program (SMP). The program formally lapsed in June 2001, but the IMF remains engaged. In this context the Government of Angola has succeeded in unifying exchange rates and has raised fuel, electricity, and water rates. The Commercial Code, telecommunications law, and Foreign Investment Code are being modernized. A privatization effort, prepared with World Bank assistance, has begun with the BCI bank. Nevertheless, a legacy of fiscal mismanagement and corruption persists. The civil war internally displaced 3.8 million people, 32% of the population, by 2001. The security brought about by the 2002 peace settlement has led to the resettlement of 4 million displaced persons, thus resulting in large-scale increases in agriculture production.
Angola produced over of diamonds in 2003, and production was expected to grow to per year by 2007. In 2004 China's Eximbank approved a $2 billion line of credit to Angola to rebuild infrastructure. The economy grew 18% in 2005 and growth was expected to reach 26% in 2006 and stay above 10% for the rest of the decade.
The construction industry is taking advantage of the growing economy, with various housing projects stimulated by the government initiatives for example the "Angola Investe" program and the "Casa Feliz" or "Meña" projects. Not all public construction projects are functional. A case in point: Kilamba Kiaxi, where a whole new satellite town of Luanda, consisting of housing facilities for several hundreds of thousands of people, was completely uninhabited for over four years because of skyrocketing prices, but completely sold out after the government decreased the original price and created mortgage plans at around the election time thus made it affordable for middle-class people. 
ChevronTexaco started pumping from Block 14 in January 2000, but production decreased to in 2007 due to poor-quality oil. Angola joined the Organization of the Petroleum Exporting Countries on January 1, 2007.
Cabinda Gulf Oil Company found Malange-1, an oil reservoir in Block 14, on August 9, 2007.
<h2>Overview.</h2>
Despite its abundant natural resources, output per capita is among the world's lowest. Subsistence agriculture provides the main livelihood for 85% of the population. Oil production and the supporting activities are vital to the economy, contributing about 45% to GDP and 90% of exports. Growth is almost entirely driven by rising oil production which surpassed in late-2005 and which is expected to grow to by 2007. Control of the oil industry is consolidated in Sonangol Group, a conglomerate owned by the Angolan government. With revenues booming from oil exports, the government has started to implement ambitious development programs to build roads and other basic infrastructure for the nation.
In the last decade of the colonial period, Angola was a major African food exporter but now imports almost all its food. Severe wartime conditions, including extensive planting of landmines throughout the countryside, have brought agricultural activities to a near-standstill. Some efforts to recover have gone forward, however, notably in fisheries. Coffee production, though a fraction of its pre-1975 level, is sufficient for domestic needs and some exports. Expanding oil production is now almost half of GDP and 90% of exports, at . Diamonds provided much of the revenue for Jonas Savimbi's UNITA rebellion through illicit trade. Other rich resources await development: gold, forest products, fisheries, iron ore, coffee, and fruits.
This is a chart of trend of nominal gross domestic product of Angola at market prices using International Monetary Fund data; figures are in millions of units.
<h2>Foreign trade.</h2>
Exports in 2004 reached US$10,530,764,911. The vast majority of Angola's exports, 92% in 2004, are petroleum products. US$785 million worth of diamonds, 7.5% of exports, were sold abroad that year. Nearly all of Angola's oil goes to the United States, in 2006, making it the eighth largest supplier of oil to the United States, and to China, in 2006. In the first quarter of 2008, Angola became the main exporter of oil to China. The rest of its petroleum exports go to Europe and Latin America. U.S. companies account for more than half the investment in Angola, with Chevron-Texaco leading the way. The U.S. exports industrial goods and services, primarily oilfield equipment, mining equipment, chemicals, aircraft, and food, to Angola, while principally importing petroleum. Trade between Angola and South Africa exceeded USD 300 million in 2007. From the 2000s many Chinese have settled and started up businesses.
<h2>Resources.</h2>
<h3>Petroleum.</h3>
Angola produces and exports more petroleum than any other nation in sub-Saharan Africa, surpassing Nigeria in the 2000s. In January 2007 Angola became a member of OPEC. By 2010 production is expected to double the 2006 output level with development of deep-water offshore oil fields. Oil sales generated USD 1.71 billion in tax revenue in 2004 and now makes up 80% of the government's budget, a 5% increase from 2003, and 45% of GDP.
Chevron Corporation produces and receives , 27% of Angolan oil. Total S.A., Chevron Corporation, ExxonMobil, Eni, Petrobras, and BP also operate in the country.
Block Zero provides the majority of Angola's crude oil production with produced annually. The largest fields in Block Zero are Takula (Area A), Numbi (Area A), and Kokongo (Area B). Chevron operates in Block Zero with a 39.2% share. SONANGOL, the state oil company, Total, and Eni own the rest of the block. Chevron also operates Angola's first producing deepwater section, Block 14, with .
The United Nations has criticized the Angolan government for using torture, rape, summary executions, arbitrary detention, and disappearances, actions which Angolan government has justified on the need to maintain oil output.
Angola is the third-largest trading partner of the United States in Sub-Saharan Africa, largely because of its petroleum exports. The U.S. imports 7% of its oil from Angola, about three times as much as it imported from Kuwait just prior to the Gulf War in 1991. The U.S. Government has invested USD $4 billion in Angola's petroleum sector.
Oil makes up over 90% of Angola's exports.
<h3>Diamonds.</h3>
Angola is the third largest producer of diamonds in Africa and has only explored 40% of the diamond-rich territory within the country, but has had difficulty in attracting foreign investment because of corruption, human rights violations, and diamond smuggling. Production rose by 30% in 2006 and Endiama, the national diamond company of Angola, expects production to increase by 8% in 2007 to 10 million carats annually. The government is trying to attract foreign companies to the provinces of Bié, Malanje and Uíge.
The Angolan government loses $375 million annually from diamond smuggling. In 2003 the government began Operation Brilliant, an anti-smuggling investigation that arrested and deported 250,000 smugglers between 2003 and 2006. Rafael Marques, a journalist and human rights activist, described the diamond industry in his 2006 "Angola's Deadly Diamonds" report as plagued by "murders, beatings, arbitrary detentions and other human rights violations." Marques called on foreign countries to boycott Angola's "conflict diamonds". In December 2014, the Bureau of International Labor Affairs issued a "List of Goods Produced by Child Labor or Forced Labor" that classified Angola as one of the major diamond-producing African countries relying on both child labor and forced labor. The U.S. Department of Labor reported that "there is little publicly available information on [Angola's] efforts to enforce child labor law". Diamonds accounted for 1.48% of Angolan exports in 2014.
<h3>Iron.</h3>
Under Portuguese rule, Angola began mining iron in 1957, producing 1.2 million tons in 1967 and 6.2 million tons by 1971. In the early 1970s, 70% of Portuguese Angola's iron exports went to Western Europe and Japan. After independence in 1975, the Angolan Civil War (1975–2002) destroyed most of the territory's mining infrastructure. The redevelopment of the Angolan mining industry started in the late 2000s.

</doc>
<doc id="708" url="https://en.wikipedia.org/wiki?curid=708" title="Transport in Angola">
Transport in Angola

Transport in Angola comprises:
<h2>Railways.</h2>
There are three separate railway lines in Angola:
Reconstruction of these three lines began in 2005 and is expected to be completed by the end of the year 2012. The Benguela Railway already connects to the Democratic Republic of the Congo.
In April 2012, the Zambian Development Agency (ZDA) and an Angolan company signed a memorandum of understanding (MoU) to build a multi-product pipeline from Lobito to Lusaka, Zambia, to deliver various refined products to Zambia.
<h2>Pipelines.</h2>
Angola plans to build an oil refinery in Lobito in the coming years.
<h2>Ports and harbors.</h2>
The government plans to build a deep-water port at Barra do Dande, north of Luanda, in Bengo province near Caxito.
<h2>Airports.</h2>
<h3>History.</h3>
Angola had an estimated total of 43 airports as of 2004, of which 31 had paved runways as of 2005. There is an international airport at Luanda. International and domestic services are maintained by TAAG Angola Airlines, Aeroflot, British Airways, Brussels Airlines, Lufthansa, Air France, Air Namibia, Cubana, Ethiopian Airlines, Emirates, Delta Air Lines, Royal Air Maroc, Iberia, Hainan Airlines, Kenya Airways, South African Airways, TAP Air Portugal and several regional carriers. In 2003, domestic and international carriers carried 198,000 passengers. There are airstrips for domestic transport at Benguela, Cabinda, Huambo, Namibe, and Catumbela.
<h2>References.</h2>
"This article comes from the CIA World Factbook 2003."

</doc>
<doc id="709" url="https://en.wikipedia.org/wiki?curid=709" title="Angolan Armed Forces">
Angolan Armed Forces

The Angolan Armed Forces (Portuguese: "Forças Armadas Angolanas") or FAA are the military of Angola. 
The FAA include the General Staff of the Armed Forces and three components: the Army ("Exército"), the Navy ("Marinha de Guerra") and the National Air Force ("National Air Force"). Reported total manpower in 2013 was about 107,000.
The FAA is headed by Chief of the General Staff Geraldo Sachipengo Nunda since 2010, who reports to the Minister of National Defense, currently João Lourenço.
<h2>History.</h2>
The FAA succeeded to the previous Armed Forces for the Liberation of Angola (FAPLA) following the abortive Bicesse Accord with the National Union for the Total Independence of Angola (UNITA) in 1991. As part of the peace agreement, troops from both armies were to be demilitarized and then integrated. Integration was never completed as UNITA went back to war in 1992. Later, consequences for UNITA members in Luanda were harsh with FAPLA veterans persecuting their erstwhile opponents in certain areas and reports of vigilantism.
<h2>Army.</h2>
<h3>General description.</h3>
The Army ("Exército") is the land component of the FAA. It is organized in six military regions (Cabinda, Luanda, North, Center, East and South), with an infantry division being based in each one. Distributed by the six military regions / infantry divisions, there are 25 motorized infantry brigades, one tank brigade and one engineering brigade. The Army also includes an artillery regiment, the Military Artillery School, the Army Military Academy, an anti-aircraft defense group, a composite land artillery group, a military police regiment, a logistical transportation regiment and a field artillery brigade. The Army further includes the Special Forces Brigade (including Commandos and Special Operations units), but this unit is under the direct command of the General Staff of the FAA.
<h3>History.</h3>
On August 1, 1974 a few months after a military coup d'état had overthrown the Lisbon regime and proclaimed its intention of granting independence to Angola, the MPLA announced the formation of FAPLA, which replaced the EPLA. By 1976 FAPLA had been transformed from lightly armed guerrilla units into a national army capable of sustained field operations.
In 1990-91, the Army had ten military regions and an estimated 73+ 'brigades', each with a mean strength of 1,000 and comprising inf, tank, APC, artillery, and AA units as required. The Library of Congress said in 1990 that '[t]he regular army's 91,500 troops were organized into more than seventy brigades ranging from 750 to 1,200 men each and deployed throughout the ten military regions. Most regions were commanded by lieutenant colonels, with majors as deputy commanders, but some regions were commanded by majors. Each region consisted of one to four provinces, with one or more infantry brigades assigned to it. The brigades were generally dispersed in battalion or smaller unit formations to protect strategic terrain, urban centers, settlements, and critical infrastructure such as bridges and factories. Counterintelligence agents were assigned to all field units to thwart UNITA infiltration. The army's diverse combat capabilities were indicated by its many regular and motorised infantry brigades with organic or attached armor, artillery, and air defense units; two militia infantry brigades; four antiaircraft artillery brigades; ten tank battalions; and six artillery battalions. These forces were concentrated most heavily in places of strategic importance and recurring conflict: the oil-producing Cabinda Province, the area around the capital, and the southern provinces where UNITA and South African forces operated.'
It was reported in 2011 that the army was by far the largest of the services with about 120,000 men and women. The Angolan Army has around 29,000 "ghost workers" who remain enrolled in the ranks of the FAA and therefore receive a salary.
In 2013, the International Institute for Strategic Studies reported that the FAA had six divisions, the 1st, 5th, and 6th with two or three infantry brigades, and the 2nd, 3rd, and 4th with five to six infantry brigades. The 4th Division included a tank regiment. A separate tank brigade and special forces brigade were also reported.
As of 2011, the IISS reported the ground forces had 42 armoured/infantry regiments ('detachments/groups - strength varies') and 16 infantry 'brigades'. These probably comprised infantry, tanks, APC, artillery, and AA units as required. Major equipment included over 140 main battle tanks, 600 reconnaissance vehicles, over 920 AFVs, infantry fighting vehicles, 298 howitzers.
It was reported on May 3, 2007, that the Special Forces Brigade of the Angolan Armed Forces (FAA) located at Cabo Ledo region, northern Bengo Province, would host a 29th anniversary celebration for the entire armed forces. The brigade was reportedly formed on 5 May 1978 and under the command at the time of Colonel Paulo Falcao.
<h3>Army Equipment.</h3>
The Army operates a large amount of Russian, Soviet and ex-Warsaw pact hardware. A large amount of its equipment was acquired in the 1980s and 1990s most likely because of hostilities with neighbouring countries and its civil war which lasted from November 1975 until 2002. There is an interest from the Angolan Army for the Brazilian ASTROS II multiple rocket launcher.
<h4>Infantry Weapons.</h4>
Many of Angola's weapons are of Portuguese colonial and Warsaw Pact origin. Jane's Information Group lists the following as in service:
<h2>Air Force.</h2>
The National Air Force of Angola (FANA, "Força Aérea Nacional de Angola") is the air component of the FAA. It's organized in six aviation regiments, each including several squadrons. To each of the regiments correspond an air base. Besides the aviation regiments, there is also a Pilot Training School.
The Air Force's personnel total about 8,000; its equipment includes transport aircraft and six Russian-manufactured Sukhoi Su-27 fighter aircraft. In 2002 one was lost during the civil war with UNITA forces.
In 1991, the Air Force/Air Defense Forces had 8,000 personnel and 90 combat-capable aircraft, including 22 fighters, 59 fighter ground attack aircraft and 16 attack helicopters.
<h2>Navy.</h2>
The Angola Navy (MGA, "Marinha de Guerra de Angola") is the naval component of the FAA. It is organized in two naval zones (North and South), with naval bases in Luanda, Lobito and Namibe. It includes a Marines Brigade and a Marines School, based in Ambriz. The Navy numbers about 1,000 personnel and operates only a handful of small patrol craft and barges.
The Navy has been neglected and ignored as a military arm mainly due to the guerrilla struggle against the Portuguese and the nature of the civil war. From the early 1990s to the present the Angolan Navy has shrunk from around 4,200 personnel to around 1,000, resulting in the loss of skills and expertise needed to maintain equipment. In order to protect Angola’s 1 600 km long coastline, the Angolan Navy is undergoing modernisation but is still lacking in many ways. Portugal has been providing training through its Technical Military Cooperation (CTM) programme. The Navy is requesting procurement of a frigate, three corvettes, three offshore patrol vessel and additional fast patrol boats.
Most of the vessels in the navy's inventory dates back from the 1980s or earlier, and many of its ships are inoperable due to age and lack of maintenance. However the navy acquired new boats from Spain and France in the 1990s. Germany has delivered several Fast Attack Craft for border protection in 2011.
In September 2014 it was reported that the Angolan Navy would acquire seven Macaé-class patrol vessels from Brazil as part of a Technical Memorandum of Understanding (MoU) covering the production of the vessels as part of Angola’s Naval Power Development Programme (Pronaval). The military of Angola aims to modernize its naval capability, presumably due to a rise in maritime piracy within the Gulf of Guinea which may have an adverse effect on the country's economy.
The navy's current known inventory includes the following:
The navy also has several aircraft for maritime patrol:
<h2>Special forces.</h2>
The FAA include several types of special forces, namely the Commandos, the Special Operations and the Marines. The Angolan special forces follow the general model of the analogous Portuguese special forces, receiving a similar training.
The Commandos and the Special forces are part of the Special Forces Brigade (BRIFE, "Brigada de Forças Especiais"), based at Cabo Ledo, in the Bengo Province. The BRIFE includes two battalions of commandos, a battalion of special operations and sub-units of combat support and service support. The BRIFE also included the Special Actions Group (GAE, "Grupo de Ações Especiais"), which is presently inactive and that was dedicated to long range reconnaissance, covert and sabotage operations. In the Cabo Ledo base is also installed the Special Forces Training School (EFFE, "Escola de Formação de Forças Especiais"). Both the BRIFE and the EFFE are directly under the Directorate of Special Forces of the General Staff of the Armed Forces. 
The marines ("fuzileiros navais") constitute the Marines Brigade of the Angolan Navy. The Marines Brigade is not permanently dependent of the Directorate of Special Forces, but can detach their units and elements to be put under the command of that body for the conduction of exercises or real operations.
Since the disbandment of the Angolan Parachute Battalion in 2004, the FAA do not have a specialized paratrooper unit. However, elements of the commandos, special operations and marines are parachute qualified. 
<h2>Foreign deployments.</h2>
The FAPLA's main counterinsurgency effort was directed against UNITA in the southeast, and its conventional capabilities were demonstrated principally in the undeclared South African Border War. The FAPLA first performed its external assistance mission with the dispatch of 1,000 to 1,500 troops to São Tomé and Príncipe in 1977 to bolster the socialist regime of President Manuel Pinto da Costa. During the next several years, Angolan forces conducted joint exercises with their counterparts and exchanged technical operational visits. The Angolan expeditionary force was reduced to about 500 in early 1985.
The Angolan Armed Forces were controversially involved in training the armed forces of fellow Lusophone states Cape Verde and Guinea-Bissau. In the case of the latter, the 2012 Guinea-Bissau coup d'état was cited by the coup leaders as due to Angola's involvement in trying to "reform" the military in connivance with the civilian leadership.
A small number of FAA personnel are stationed in the Democratic Republic of the Congo (Kinshasa) and the Republic of the Congo (Brazzaville). A presence during the unrest in Ivory Coast, 2010–2011, were not officially confirmed. However, the "Frankfurter Allgemeine Zeitung", citing "Jeune Afrique", said that among President Gbagbo's guards were 92 personnel of President Dos Santos's Presidential Guard Unit. Angola is basically interested in the participation of the FAA operations of the African Union and has formed special units for this purpose.
David Birmingham, African Affairs, Vol. 77, No. 309 (Oct., 1978), pp. 554–564
<h2>Further reading.</h2>
Published by: Oxford University Press on behalf of The Royal African Society

</doc>
<doc id="710" url="https://en.wikipedia.org/wiki?curid=710" title="Foreign relations of Angola">
Foreign relations of Angola

The foreign relations of Angola are based on Angola's strong support of U.S. foreign policy as the Angolan economy is dependent on U.S. foreign aid.
From 1975 to 1989, Angola was aligned with the Eastern bloc, in particular the Soviet Union, Libya, and Cuba. Since then, it has focused on improving relationships with Western countries, cultivating links with other Portuguese-speaking countries, and asserting its own national interests in Central Africa through military and diplomatic intervention. In 1993, it established formal diplomatic relations with the United States. It has entered the Southern African Development Community as a vehicle for improving ties with its largely Anglophone neighbors to the south. Zimbabwe and Namibia joined Angola in its military intervention in the Democratic Republic of the Congo, where Angolan troops remain in support of the Joseph Kabila government. It also has intervened in the Republic of the Congo (Brazzaville) to support the existing government in that country.
Since 1998, Angola has successfully worked with the United Nations Security Council to impose and carry out sanctions on UNITA. More recently, it has extended those efforts to controls on conflict diamonds, the primary source of revenue for UNITA. At the same time, Angola has promoted the revival of the Community of Portuguese-Speaking Countries (CPLP) as a forum for cultural exchange and expanding ties with Portugal (its former ruler) and Brazil (which shares many cultural affinities with Angola) in particular.
<h2>Sub-Saharan Africa.</h2>
<h3>Cape Verde.</h3>
Cape Verde signed a friendship accord with Angola in December 1975, shortly after Angola gained its independence. Cape Verde and Guinea-Bissau served as stop-over points for Cuban troops on their way to Angola to fight UNITA rebels and South African troops. Prime Minister Pedro Pires sent FARP soldiers to Angola where they served as the personal bodyguards of Angolan President José Eduardo dos Santos.
<h3>Democratic Republic of the Congo.</h3>
Many thousands of Angolans fled the country after the civil war. More than 20,000 people were forced to leave the Democratic Republic of the Congo in 2009, an action the DR Congo said was in retaliation for regular expulsion of Congolese diamond miners who were in Angola illegally. Angola sent a delegation to DR Congo's capital Kinshasa and succeeded in stopping government-forced expulsions which had become a "tit-for-tat" immigration dispute. "Congo and Angola have agreed to suspend expulsions from both sides of the border," said Lambert Mende, DR Congo information minister, in October 2009. "We never challenged the expulsions themselves; we challenged the way they were being conducted — all the beating of people and looting their goods, even sometimes their clothes," Mende said.
<h3>Guinea-Bissau.</h3>
Following a request by the government of Guinea-Bissau, Angola sent there a contingent of about 300 troops meant to help putting an end to the political-military unrest in that country, and to reorganize the local military forces. In fact, these troops were perceived as a kind of Pretorian Guard for the ruling party, PAIGC. In the beginning of April 2012, when a new military Coup d'état was under preparation, the Angolan regime decided to withdraw its military mission from Guinea-Bissau.
<h3>Namibia.</h3>
Namibia borders Angola to the south. In 1999 Namibia signed a mutual defense pact with its northern neighbor Angola.
This affected the Angolan Civil War that had been ongoing since Angola's independence in 1975. Namibia's ruling party SWAPO sought to support the ruling party MPLA in Angola against the rebel movement UNITA, whose stronghold is in southern Angola, bordering to Namibia. The defence pact allowed Angolan troops to use Namibian territory when attacking Jonas Savimbi's UNITA.
<h3>Nigeria.</h3>
Angolan-Nigerian relations are primarily based on their roles as oil exporting nations. Both are members of the Organization of the Petroleum Exporting Countries, the African Union and other multilateral organizations.
<h3>South Africa.</h3>
Angola-South Africa relations are quite strong as the ruling parties in both nations, the African National Congress in South Africa and the MPLA in Angola, fought together during the Angolan Civil War and South African Border War. They fought against UNITA rebels, based in Angola, and the apartheid-era government in South Africa who supported them. Nelson Mandela mediated between the MPLA and UNITA factions during the last years of Angola's civil war.
<h3>Zimbabwe.</h3>
Angola-Zimbabwe relations have remained cordial since the birth of both states, Angola in 1975 and Zimbabwe in 1979, during the Cold War. While Angola's foreign policy shifted to a pro-U.S. stance based on substantial economic ties, under the rule of President Robert Mugabe Zimbabwe's ties with the West soured in the late 1990s.
<h2>Europe.</h2>
<h3>France.</h3>
Relations between the two countries have not always been cordial due to the former French government's policy of supporting militant separatists in Angola's Cabinda province and the international Angolagate scandal embarrassed both governments by exposing corruption and illicit arms deals. Following French President Nicolas Sarkozy's visit in 2008, relations have improved.
<h3>Portugal.</h3>
Angola-Portugal relations have significantly improved since the Angolan government abandoned communism and nominally embraced democracy in 1991, embracing a pro-U.S. and to a lesser degree pro-Europe foreign policy. Portugal ruled Angola for 400 years, colonizing the territory from 1483 until independence in 1975. Angola's war for independence did not end in a military victory for either side, but was suspended as a result of a coup in Portugal that replaced the Caetano regime.
<h3>Russia.</h3>
Russia has an embassy in Luanda. Angola has an embassy in Moscow and an honorary consulate in Saint Petersburg. Angola and the precursor to Russia, the Soviet Union, established relations upon Angola's independence.
The Defence Minister of Serbia, Dragan Šutanovac, stated in a 2011 meeting in Luanda that Serbia would negotiate with the Angolan military authorities for the construction of a new military hospital in Angola.
<h2>Americas.</h2>
<h3>Brazil.</h3>
Commercial and economic ties dominate the relations of each country. Parts of both countries were part of the Portuguese Empire from the early 16th century until Brazil's independence in 1822. As of November 2007, "trade between the two countries is booming as never before"
<h3>Cuba.</h3>
During Angola's civil war Cuban forces fought to install a Marxist–Leninist MPLA-PT government, against Western-backed UNITA and FLNA guerrillas and the South-African army.
<h3>Mexico.</h3>
Relations between Angola and Mexico have become of increasing priority due to the cultural similarities between the two nations. 
<h3>United States.</h3>
From the mid-1980s through at least 1992, the United States was the primary source of military and other support for the UNITA rebel movement, which was led from its creation through 2002 by Jonas Savimbi. The U.S. refused to recognize Angola diplomatically during this period.
Relations between the United States of America and the Republic of Angola (formerly the People's Republic of Angola) have warmed since Angola's ideological renunciation of Marxism before the 1992 elections.
<h2>Asia.</h2>
<h3>China.</h3>
Chinese Prime Minister Wen Jiabao visited Angola in June 2006, offering a US$9 billion loan for infrastructure improvements in return for petroleum. The PRC has invested heavily in Angola since the end of the civil war in 2002. João Manuel Bernardo, the current ambassador of Angola to China, visited the PRC in November 2007.
In February 2006, Angola surpassed Saudi Arabia to become the number one supplier of oil to China. 
<h3>Israel.</h3>
Angola-Israel relations, primarily based on trade and pro-United States foreign policies, are excellent. In March 2006, the trade volume between the two countries amounted to $400 million. The Israeli ambassador to Angola is Avraham Benjamin.[1] In 2005, President José Eduardo dos Santos visited Israel.
<h3>Japan.</h3>
Diplomatic relations between Japan and Angola were established in September 1976. Japan maintains an embassy at Luanda and Angola has an embassy in Tokyo. As of 2007, economic relations played "a fundamental role in the bilateral relations between the two governments". Japan has donated towards demining following the civil war.
<h3>Pakistan.</h3>
The Government of Angola called for the support of Pakistan for the candidature of Angola to the seat of non-permanent member of the UN Security Council, whose election is set for September this year, during the 69th session of the General Assembly of United Nations. On the fringes of the ceremony, the Angolan diplomat also met with officials in charge of the economic and commercial policy of Pakistan, to assess the business opportunities between the two states. It asked to discuss aspects related to the cooperation on several domains of common interest.
<h3>South Korea.</h3>
Establishment of diplomatic relations 6 January 1992. The number of South Koreans living in Angola in 2011 was 279.
<h3>Vietnam.</h3>
Angola-Vietnam relations were established in August 1971, four years before Angola gained its independence, when future President of Angola Agostinho Neto visited Vietnam. Angola and Vietnam have steadfast partners as both transitioned from Cold War-era foreign policies of international communism to pro-Western pragmatism following the fall of the Soviet Union.

</doc>
<doc id="711" url="https://en.wikipedia.org/wiki?curid=711" title="Albert Sidney Johnston">
Albert Sidney Johnston

Albert Sidney Johnston (February 2, 1803 – April 6, 1862) served as a general in three different armies: the Texian ("i.e.", Republic of Texas) Army, the United States Army, and the Confederate States Army. He saw extensive combat during his military career, fighting actions in the Texas War of Independence, the Mexican–American War, the Utah War, and the American Civil War.
Considered by Confederate President Jefferson Davis to be the finest general officer in the Confederacy before the emergence of Robert E. Lee, he was killed early in the Civil War at the Battle of Shiloh. Johnston was the highest-ranking officer, Union or Confederate, killed during the entire war. Davis believed the loss of Johnston "was the turning point of our fate".
Johnston was unrelated to Confederate general Joseph E. Johnston.
<h2>Early life and education.</h2>
Johnston was born in Washington, Kentucky, the youngest son of Dr. John and Abigail (Harris) Johnston. His father was a native of Salisbury, Connecticut. Although Albert Johnston was born in Kentucky, he lived much of his life in Texas, which he considered his home. He was first educated at Transylvania University in Lexington, where he met fellow student Jefferson Davis. Both were appointed to the United States Military Academy, Davis two years behind Johnston. In 1826 Johnston graduated eighth of 41 cadets in his class from West Point with a commission as a brevet second lieutenant in the 2nd U.S. Infantry.
Johnston was assigned to posts in New York and Missouri and served in the Black Hawk War in 1832 as chief of staff to Bvt. Brig. Gen. Henry Atkinson.
<h2>Marriage and family.</h2>
In 1829 he married Henrietta Preston, sister of Kentucky politician and future Civil War general William Preston. They had one son, William Preston Johnston, who became a colonel in the Confederate Army. The senior Johnston resigned his commission in 1834 in order to care for his dying wife in Kentucky, who succumbed two years later to tuberculosis.
After serving as Secretary of War for the Republic of Texas from 1838 to 1840, Johnston resigned and returned to Kentucky. In 1843, he married Eliza Griffin, his late wife's first cousin. The couple moved to Texas, where they settled on a large plantation in Brazoria County. Johnston named the property China Grove. Here they raised Johnston's two children from his first marriage and the first three children born to Eliza and him. (A sixth child was born later when they lived in Los Angeles).
<h2>Texas Army.</h2>
In 1836 Johnston moved to Texas. He enlisted as a private in the Texas Army during the Texas War of Independence against the Republic of Mexico. He was named Adjutant General as a colonel in the Republic of Texas Army on August 5, 1836. On January 31, 1837, he became senior brigadier general in command of the Texas Army.
On February 5, 1837, he fought in a duel with Texas Brig. Gen. Felix Huston, as they challenged each other for the command of the Texas Army; Johnston refused to fire on Huston and lost the position after he was wounded in the pelvis.
On December 22, 1838, Mirabeau B. Lamar, the second president of the Republic of Texas, appointed Johnston as Secretary of War. He provided for the defense of the Texas border against Mexican invasion, and in 1839 conducted a campaign against Indians in northern Texas. In February 1840, he resigned and returned to Kentucky.
<h2>United States Army.</h2>
Johnston returned to Texas during the Mexican–American War under General Zachary Taylor as a colonel of the 1st Texas Rifle Volunteers. The enlistments of his volunteers ran out just before the Battle of Monterrey. Johnston convinced a few volunteers to stay and fight as he served as the inspector general of volunteers and fought at the battles of Monterrey and Buena Vista.
He remained on his plantation after the war until he was appointed by President Zachary Taylor to the U.S. Army as a major and was made a paymaster in December 1849. He served in that role for more than five years, making six tours, and traveling more than annually on the Indian frontier of Texas. He served on the Texas frontier at Fort Mason and elsewhere in the West.
In 1855 President Franklin Pierce appointed him colonel of the new 2nd U.S. Cavalry (the unit that preceded the modern 5th U.S.), a new regiment, which he organized. On August 19, 1856, Gen. Persifor Smith, at the request of Kansas Territorial Governor Wilson Shannon, sent Col. Johnston with 1300 men composed of the 2d Cavalry Dragoons from Fort Riley, a battalion of the 6th Infantry and Capt. Howe's artillery company from Jefferson Barracks, to protect the territorial capital at Lecompton from an imminent attack by James Henry Lane and his abolitionist "Army of the North."
<h2>Utah War.</h2>
As a key figure in the Utah War, Johnston led U.S. troops who established a non-Mormon government in the formerly Mormon territory. He received a brevet promotion to brigadier general in 1857 for his service in Utah. He spent 1860 in Kentucky until December 21, when he sailed for California to take command of the Department of the Pacific.
<h2>Civil War.</h2>
At the outbreak of the American Civil War, Johnston was the commander of the U.S. Army Department of the Pacific in California. Like many regular army officers from the South, he was opposed to secession. But he resigned his commission soon after he heard of the secession of his adopted state of Texas. It was accepted by the War Department on May 6, 1861, effective May 3. On April 28 he moved to Los Angeles, the home of his wife's brother John Griffin. Considering staying in California with his wife and five children, Johnston remained there until May.
Soon, under suspicion by local Union officials, he evaded arrest and joined the Los Angeles Mounted Rifles as a private, leaving Warner's Ranch May 27. He participated in their trek across the southwestern deserts to Texas, crossing the Colorado River into the Confederate Territory of Arizona on July 4, 1861.
Early in the Civil War, Confederate President Jefferson Davis decided that the Confederacy would attempt to hold as much of its territory as possible, and therefore distributed military forces around its borders and coasts. In the summer of 1861, Davis appointed several generals to defend Confederate lines from the Mississippi River east to the Allegheny Mountains.
The most sensitive, and in many ways the most crucial areas, along the Mississippi River and in western Tennessee along the Tennessee and the Cumberland rivers were placed under the command of Maj. Gen. Leonidas Polk and Brig. Gen. Gideon J. Pillow. The latter had initially been in command in Tennessee as that State's top general. Their impolitic occupation of Columbus, Kentucky, on September 3, 1861, two days before Johnston arrived in the Confederacy's capital of Richmond, Virginia, after his cross–country journey, drove Kentucky from its stated neutrality. The majority of Kentuckians allied with the Union camp. Polk and Pillow's action gave Union Brig. Gen. Ulysses S. Grant an excuse to take control of the strategically located town of Paducah, Kentucky, without raising the ire of most Kentuckians and the pro-Union majority in the State legislature.
<h3>Confederate command in Western Theater.</h3>
On September 10, 1861, Johnston was assigned to command the huge area of the Confederacy west of the Allegheny Mountains, except for coastal areas. He became commander of the Confederacy's western armies in the area often called the Western Department or Western Military Department. Johnston's appointment as a full general by his friend and admirer Jefferson Davis already had been confirmed by the Confederate Senate on August 31, 1861. The appointment had been backdated to rank from May 30, 1861, making him the second highest ranking general in the Confederate States Army. Only Adjutant General and Inspector General Samuel Cooper ranked ahead of him. After his appointment, Johnston immediately headed for his new territory. He was permitted to call on governors of Arkansas, Tennessee and Mississippi for new troops, although this authority was largely stifled by politics, especially with respect to Mississippi. On September 13, 1861, Johnston ordered Brig. Gen. Felix Zollicoffer with 4,000 men to occupy Cumberland Gap in Kentucky in order to block Union troops from coming into eastern Tennessee. The Kentucky legislature had voted to side with the Union after the occupation of Columbus by Polk. By September 18, Johnston had Brig. Gen. Simon Bolivar Buckner with another 4,000 men blocking the railroad route to Tennessee at Bowling Green, Kentucky.
Johnston had fewer than 40,000 men spread throughout Kentucky, Tennessee, Arkansas and Missouri. Of these, 10,000 were in Missouri under Missouri State Guard Maj. Gen. Sterling Price. Johnston did not quickly gain many recruits when he first requested them from the governors, but his more serious problem was lacking sufficient arms and ammunition for the troops he already had. As the Confederate government concentrated efforts on the units in the East, they gave Johnston small numbers of reinforcements and minimal amounts of arms and material. Johnston maintained his defense by conducting raids and other measures to make it appear he had larger forces than he did, a strategy that worked for several months. Johnston's tactics had so annoyed and confused Union Brig. Gen. William Tecumseh Sherman in Kentucky that he became paranoid and mentally unstable. Sherman overestimated Johnston's forces, and had to be relieved by Brig. Gen. Don Carlos Buell on November 9, 1861.
<h3>Battle of Mill Springs.</h3>
Eastern Tennessee was held for the Confederacy by two unimpressive brigadier generals appointed by Jefferson Davis: Felix Zollicoffer, a brave but untrained and inexperienced officer, and soon-to-be Maj. Gen. George B. Crittenden, a former U.S. Army officer with apparent alcohol problems. While Crittenden was away in Richmond, Zollicoffer moved his forces to the north bank of the upper Cumberland River near Mill Springs (now Nancy, Kentucky), putting the river to his back and his forces into a trap. Zollicoffer decided it was impossible to obey orders to return to the other side of the river because of scarcity of transport and proximity of Union troops. When Union Brig. Gen. George H. Thomas moved against the Confederates, Crittenden decided to attack one of the two parts of Thomas's command at Logan's Cross Roads near Mill Springs before the Union forces could unite. At the Battle of Mill Springs on January 19, 1862, the ill-prepared Confederates, after a night march in the rain, attacked the Union force with some initial success. As the battle progressed, Zollicoffer was killed, Crittenden was unable to lead the Confederate force (he may have been intoxicated), and the Confederates were turned back and routed by a Union bayonet charge, suffering 533 casualties from their force of 4,000. The Confederate troops who escaped were assigned to other units as General Crittenden faced an investigation of his conduct.
After the Confederate defeat at the Mill Springs, Davis sent Johnston a brigade and a few other scattered reinforcements. He also assigned him Gen. P. G. T. Beauregard, who was supposed to attract recruits because of his victories early in the war, and act as a competent subordinate for Johnston. The brigade was led by Brig. Gen. John B. Floyd, considered incompetent. He took command at Fort Donelson as the senior general present just before Union Brig. Gen. Ulysses S. Grant attacked the fort. Historians believe the assignment of Beauregard to the west stimulated Union commanders to attack the forts before Beauregard could make a difference in the theater. Union officers heard that he was bringing 15 regiments with him, but this was an exaggeration of his forces.
<h3>Fort Henry, Fort Donelson, Nashville.</h3>
Based on the assumption that Kentucky neutrality would act as a shield against a direct invasion from the north, Tennessee initially had sent men to Virginia and concentrated defenses in the Mississippi Valley, circumstances that no longer applied in September 1861. Even before Johnston arrived in Tennessee, construction of two forts had been started to defend the Tennessee and the Cumberland rivers, which provided avenues into the State from the north. Both forts were located in Tennessee in order to respect Kentucky neutrality, but these were not in ideal locations. Fort Henry on the Tennessee River was in an unfavorable low–lying location, commanded by hills on the Kentucky side of the river. Fort Donelson on the Cumberland River, although in a better location, had a vulnerable land side and did not have enough heavy artillery to defend against gunboats.
Maj. Gen. Polk ignored the problems of the forts when he took command. After Johnston took command, Polk at first refused to comply with Johnston's order to send an engineer, Lt. Joseph K. Dixon, to inspect the forts. After Johnston asserted his authority, Polk had to allow Dixon to proceed. Dixon recommended that the forts be maintained and strengthened, although they were not in ideal locations, because much work had been done on them and the Confederates might not have time to build new ones. Johnston accepted his recommendations. Johnston wanted Major, later Lt. Gen., Alexander P. Stewart to command the forts but President Davis appointed Brig. Gen. Lloyd Tilghman as commander.
To prevent Polk from dissipating his forces by allowing some men to join a partisan group, Johnston ordered him to send Brig. Gen. Gideon Pillow and 5,000 men to Fort Donelson. Pillow took up a position at nearby Clarksville, Tennessee and did not move into the fort until February 7, 1862. Alerted by a Union reconnaissance on January 14, 1862, Johnston ordered Tilghman to fortify the high ground opposite Fort Henry, which Polk had failed to do despite Johnston's orders. Tilghman failed to act decisively on these orders, which in any event were too late to be adequately carried out.
Gen. Beauregard arrived at Johnston's headquarters at Bowling Green on February 4, 1862 and was given overall command of Polk's force at the western end of Johnston's line at Columbus, Kentucky. On February 6, 1862, Union Navy gunboats quickly reduced the defenses of ill-sited Fort Henry, inflicting 21 casualties on the small remaining Confederate force. Brig. Gen. Lloyd Tilghman surrendered the 94 remaining officers and men of his approximately 3,000-man force which had not been sent to Fort Donelson before U.S. Grant's force could even take up their positions. Johnston knew he could be trapped at Bowling Green if Fort Donelson fell, so he moved his force to Nashville, the capital of Tennessee and an increasingly important Confederate industrial center, beginning on February 11, 1862.
Johnston also reinforced Fort Donelson with 12,000 more men, including those under Floyd and Pillow, a curious decision in view of his thought that the Union gunboats alone might be able to take the fort. He did order the commanders of the fort to evacuate the troops if the fort could not be held. The senior generals sent to the fort to command the enlarged garrison, Gideon J. Pillow and John B. Floyd, squandered their chance to avoid having to surrender most of the garrison and on February 16, 1862, Brig. Gen. Simon Buckner, having been abandoned by Floyd and Pillow, surrendered Fort Donelson. Colonel Nathan Bedford Forrest escaped with his cavalry force of about 700 men before the surrender. The Confederates suffered about 1,500 casualties with an estimated 12,000 to 14,000 taken prisoner. Union casualties were 500 killed, 2,108 wounded, 224 missing.
Johnston, who had little choice in allowing Floyd and Pillow to take charge at Fort Donelson on the basis of seniority after he ordered them to add their forces to the garrison, took the blame and suffered calls for his removal because a full explanation to the press and public would have exposed the weakness of the Confederate position. His passive defensive performance while positioning himself in a forward position at Bowling Green, spreading his forces too thinly, not concentrating his forces in the face of Union advances, and appointing or relying upon inadequate or incompetent subordinates subjected him to criticism at the time and by later historians. The fall of the forts exposed Nashville to imminent attack, and it fell without resistance to Union forces under Brig. Gen. Buell on February 25, 1862, two days after Johnston had to pull his forces out in order to avoid having them captured as well.
<h3>Concentration at Corinth.</h3>
Johnston had various remaining military units scattered throughout his territory and retreating to the south to avoid being cut off. Johnston himself retreated with the force under his personal command, the Army of Central Kentucky, from the vicinity of Nashville. With Beauregard's help, Johnston decided to concentrate forces with those formerly under Polk and now already under Beauregard's command at the strategically located railroad crossroads of Corinth, Mississippi, which he reached by a circuitous route. Johnston kept the Union forces, now under the overall command of the ponderous Maj. Gen. Henry Halleck, confused and hesitant to move, allowing Johnston to reach his objective undetected. This delay allowed Jefferson Davis finally to send reinforcements from the garrisons of coastal cities and another highly rated but prickly general, Braxton Bragg, to help organize the western forces. Bragg at least calmed the nerves of Beauregard and Polk who had become agitated by their apparent dire situation in the face of numerically superior forces before the arrival of Johnston on March 24, 1862.
Johnston's army of 17,000 men gave the Confederates a combined force of about 40,000 to 44,669 men at Corinth. On March 29, 1862, Johnston officially took command of this combined force, which continued to use the Army of the Mississippi name under which it had been organized by Beauregard on March 5.
Johnston now planned to defeat the Union forces piecemeal before the various Union units in Kentucky and Tennessee under Grant with 40,000 men at nearby Pittsburg Landing, Tennessee, and the now Maj. Gen. Don Carlos Buell on his way from Nashville with 35,000 men, could unite against him. Johnston started his army in motion on April 3, 1862, intent on surprising Grant's force as soon as the next day, but they moved slowly due to their inexperience, bad roads and lack of adequate staff planning. Johnston's army was finally in position within a mile or two of Grant's force, and undetected, by the evening of April 5, 1862.
<h3>Battle of Shiloh and death.</h3>
Johnston launched a massive surprise attack with his concentrated forces against Grant at the Battle of Shiloh on April 6, 1862. As the Confederate forces overran the Union camps, Johnston seemed to be everywhere, personally leading and rallying troops up and down the line on his horse. At about 2:30 pm, while leading one of those charges against a Union camp near the "Peach Orchard," he was wounded, taking a bullet behind his right knee. He apparently did not think the wound was serious at the time, or even possibly did not feel it, and so he sent his personal physician away to attend to some wounded captured Union soldiers instead. It is possible that Johnston's duel in 1837 had caused nerve damage or numbness to his right leg and that he did not feel the wound to his leg as a result. The bullet had in fact clipped a part of his popliteal artery and his boot was filling up with blood.
Within a few minutes, Johnston was observed by his staff to be nearly fainting. Among his staff was Isham G. Harris, the Governor of Tennessee, who had ceased to make any real effort to function as governor after learning that Abraham Lincoln had appointed Andrew Johnson as military governor of Tennessee. Seeing Johnston slumping in his saddle and his face turning deathly pale, Harris asked: "General, are you wounded?" Johnston glanced down at his leg wound, then faced Harris and replied in a weak voice his last words: "Yes... and I fear seriously." Harris and other staff officers removed Johnston from his horse and carried him to a small ravine near the "Hornets Nest" and desperately tried to aid the general by trying to make a tourniquet for his leg wound, but little could be done by this point since he had already lost so much blood. He soon lost consciousness and bled to death a few minutes later. It is believed that Johnston may have lived for as long as one hour after receiving his fatal wound.
Harris and the other officers wrapped General Johnston's body in a blanket so as not to damage the troops' morale with the sight of the dead general. Johnston and his wounded horse, named Fire Eater, were taken to his field headquarters on the Corinth road, where his body remained in his tent until the Confederate Army withdrew to Corinth the next day, April 7, 1862, after failing to gain a decisive victory over the Union armies. From there, his body was taken to the home of Colonel William Inge, which had been his headquarters in Corinth. It was covered in the Confederate flag and lay in state for several hours.
It is probable that a Confederate soldier fired the fatal round. No Union soldiers were observed to have ever gotten behind Johnston during the fatal charge, while it is known that many Confederates were firing at the Union lines while Johnston charged well in advance of his soldiers.
Johnston was the highest-ranking fatality of the war on either side, and his death was a strong blow to the morale of the Confederacy. At the time, Jefferson Davis considered him the best general in the country.
<h2>Legacy and honors.</h2>
Johnston was survived by his wife Eliza and six children. His wife and five younger children, including one born after he went to war, chose to live out their days at home in Los Angeles with Eliza's brother, Dr. John Strother Griffin. Johnston's eldest son, Albert Sidney Jr. (born in Texas), had already followed him into the Confederate States Army. In 1863, after taking home leave in Los Angeles, Albert Jr. was on his way out of San Pedro harbor on a ferry. While a steamer was taking on passengers from the ferry, a wave swamped the smaller boat, causing its boilers to explode. Albert Jr. was killed in the accident.
Killed in action, General Johnston received the highest praise ever given by the Confederate government; accounts were published, on December 20, 1862, and thereafter, in the Los Angeles "Star" of his family's hometown. Johnston Street, Hancock Street, and Griffin Avenue, each in northeast Los Angeles, are named after the general and his family, who lived in the neighborhood.
Johnston was initially buried in New Orleans. In 1866, a joint resolution of the Texas Legislature was passed to have his body moved and reinterred at the Texas State Cemetery in Austin. The re-interment occurred in 1867. Forty years later, the state appointed Elisabet Ney to design a monument and sculpture of him to be erected at the grave site.
The Texas Historical Commission has erected a historical marker near the entrance of what was once Johnston's plantation. An adjacent marker was erected by the San Jacinto Chapter of the Daughters of The Republic of Texas and the Lee, Roberts, and Davis Chapter of the United Daughters of the Confederate States of America.
The University of Texas at Austin has recognized Johnston with a statue on the South Mall.

</doc>
<doc id="713" url="https://en.wikipedia.org/wiki?curid=713" title="Android (robot)">
Android (robot)

An android is a humanoid robot or synthetic organism designed to look and act like a human, especially one with a body having a flesh-like resemblance. Historically, androids remained completely within the domain of science fiction where they are frequently seen in film and television. Only recently have advancements in robot technology allowed the design of functional and realistic humanoid robots.
<h2>Etymology.</h2>
The word was coined from the Greek root ἀνδρ- 'man' (male, as opposed to anthrop- = human being) and the suffix "" 'having the form or likeness of'.
The "Oxford English Dictionary" traces the earliest use (as "Androides") to Ephraim Chambers' "Cyclopaedia," in reference to an automaton that St. Albertus Magnus allegedly created. The term "android" appears in US patents as early as 1863 in reference to miniature human-like toy automatons. The term "android" was used in a more modern sense by the French author Auguste Villiers de l'Isle-Adam in his work "Tomorrow's Eve" (1886). This story features an artificial humanlike robot named Hadaly. As said by the officer in the story, "In this age of Realien advancement, who knows what goes on in the mind of those responsible for these mechanical dolls." The term made an impact into English pulp science fiction starting from Jack Williamson's "The Cometeers" (1936) and the distinction between mechanical robots and fleshy androids was popularized by Edmond Hamilton's Captain Future (1940–1944).
Although Karel Čapek's robots in "R.U.R. (Rossum's Universal Robots)" (1921)—the play that introduced the word "robot" to the world—were organic artificial humans, the word "robot" has come to primarily refer to mechanical humans, animals, and other beings. The term "android" can mean either one of these, while a cyborg ("cybernetic organism" or "bionic man") would be a creature that is a combination of organic and mechanical parts.
The term "droid", popularized by George Lucas in the original "Star Wars" film and now used widely within science fiction, originated as an abridgment of "android", but has been used by Lucas and others to mean any robot, including distinctly non-human form machines like R2-D2. The word "android" was used in "" episode "What Are Little Girls Made Of?" The abbreviation "andy", coined as a pejorative by writer Philip K. Dick in his novel "Do Androids Dream of Electric Sheep?", has seen some further usage, such as within the TV series "Total Recall 2070".
Authors have used the term "android" in more diverse ways than "robot" or "cyborg". In some fictional works, the difference between a robot and android is only their appearance, with androids being made to look like humans on the outside but with robot-like internal mechanics. In other stories, authors have used the word "android" to mean a wholly organic, yet artificial, creation. Other fictional depictions of androids fall somewhere in between.
Eric G. Wilson, who defines androids as a "synthetic human being", distinguishes between three types of androids, based on their body's composition:
Although human morphology is not necessarily the ideal form for working robots, the fascination in developing robots that can mimic it can be found historically in the assimilation of two concepts: "simulacra" (devices that exhibit likeness) and "automata" (devices that have independence).
<h2>Projects.</h2>
Several projects aiming to create androids that look, and, to a certain degree, speak or act like a human being have been launched or are underway.
<h3>Japan.</h3>
The Intelligent Robotics Lab, directed by Hiroshi Ishiguro at Osaka University, and Kokoro Co., Ltd. have demonstrated the Actroid at Expo 2005 in Aichi Prefecture, Japan and released the Telenoid R1 in 2010. In 2006, Kokoro Co. developed a new "DER 2" android. The height of the human body part of DER2 is 165 cm. There are 47 mobile points. DER2 can not only change its expression but also move its hands and feet and twist its body. The "air servosystem" which Kokoro Co. developed originally is used for the actuator. As a result of having an actuator controlled precisely with air pressure via a servosystem, the movement is very fluid and there is very little noise. DER2 realized a slimmer body than that of the former version by using a smaller cylinder. Outwardly DER2 has a more beautiful proportion. Compared to the previous model, DER2 has thinner arms and a wider repertoire of expressions. Once programmed, it is able to choreograph its motions and gestures with its voice.
The Intelligent Mechatronics Lab, directed by Hiroshi Kobayashi at the Tokyo University of Science, has developed an android head called "Saya", which was exhibited at Robodex 2002 in Yokohama, Japan. There are several other initiatives around the world involving humanoid research and development at this time, which will hopefully introduce a broader spectrum of realized technology in the near future. Now Saya is "working" at the Science University of Tokyo as a guide.
The Waseda University (Japan) and NTT Docomo's manufacturers have succeeded in creating a shape-shifting robot "WD-2". It is capable of changing its face. At first, the creators decided the positions of the necessary points to express the outline, eyes, nose, and so on of a certain person. The robot expresses its face by moving all points to the decided positions, they say. The first version of the robot was first developed back in 2003. After that, a year later, they made a couple of major improvements to the design. The robot features an elastic mask made from the average head dummy. It uses a driving system with a 3DOF unit. The WD-2 robot can change its facial features by activating specific facial points on a mask, with each point possessing three degrees of freedom. This one has 17 facial points, for a total of 56 degrees of freedom. As for the materials they used, the WD-2's mask is fabricated with a highly elastic material called Septom, with bits of steel wool mixed in for added strength. Other technical features reveal a shaft driven behind the mask at the desired facial point, driven by a DC motor with a simple pulley and a slide screw. Apparently, the researchers can also modify the shape of the mask based on actual human faces. To "copy" a face, they need only a 3D scanner to determine the locations of an individual's 17 facial points. After that, they are then driven into position using a laptop and 56 motor control boards. In addition, the researchers also mention that the shifting robot can even display an individual's hair style and skin color if a photo of their face is projected onto the 3D Mask.
<h3>Singapore.</h3>
Prof Nadia Thalmann, a Nanyang Technological University scientist, directed efforts of the Institute for Media Innovation along with the School of Computer Engineering in the development of a social robot, Nadine. Nadine is powered by software similar to Apple’s Siri or Microsoft’s Cortana. Nadine may become a personal assistant in offices and homes in future, or she may become a companion for the young and the elderly.
Assoc Prof Gerald Seet from the School of Mechanical & Aerospace Engineering and the BeingThere Centre led a three-year R&D development in tele-presence robotics, creating EDGAR. A remote user can control EDGAR with the user’s face and expressions displayed on the robot’s face in real time. The robot also mimics their upper body movements.
<h3>South Korea.</h3>
KITECH researched and developed EveR-1, an android interpersonal communications model capable of emulating human emotional expression via facial "musculature" and capable of rudimentary conversation, having a vocabulary of around 400 words. She is tall and weighs , matching the average figure of a Korean woman in her twenties. EveR-1's name derives from the Biblical Eve, plus the letter "r" for "robot". EveR-1's advanced computing processing power enables speech recognition and vocal synthesis, at the same time processing lip synchronization and visual recognition by 90-degree micro-CCD cameras with face recognition technology. An independent microchip inside her artificial brain handles gesture expression, body coordination, and emotion expression. Her whole body is made of highly advanced synthetic jelly silicon and with 60 artificial joints in her face, neck, and lower body; she is able to demonstrate realistic facial expressions and sing while simultaneously dancing. In South Korea, the Ministry of Information and Communication has an ambitious plan to put a robot in every household by 2020. Several robot cities have been planned for the country: the first will be built in 2016 at a cost of 500 billion won, of which 50 billion is direct government investment. The new robot city will feature research and development centers for manufacturers and part suppliers, as well as exhibition halls and a stadium for robot competitions. The country's new Robotics Ethics Charter will establish ground rules and laws for human interaction with robots in the future, setting standards for robotics users and manufacturers, as well as guidelines on ethical standards to be programmed into robots to prevent human abuse of robots and vice versa.
<h3>United States.</h3>
Walt Disney and a staff of Imagineers created Great Moments with Mr. Lincoln that debuted at the 1964 New York World's Fair.
Hanson Robotics, Inc., of Texas and KAIST produced an android portrait of Albert Einstein, using Hanson's facial android technology mounted on KAIST's life-size walking bipedal robot body. This Einstein android, also called "Albert Hubo", thus represents the first full-body walking android in history (see video at). Hanson Robotics, the FedEx Institute of Technology, and the University of Texas at Arlington also developed the android portrait of sci-fi author Philip K. Dick (creator of "Do Androids Dream of Electric Sheep?", the basis for the film "Blade Runner"), with full conversational capabilities that incorporated thousands of pages of the author's works. In 2005, the PKD android won a first place artificial intelligence award from AAAI.
<h2>Use in fiction.</h2>
Androids are a staple of science fiction. Isaac Asimov pioneered the fictionalization of the science of robotics and artificial intelligence, notably in his 1950s series "I, Robot". One thing common to most fictional androids is that the real-life technological challenges associated with creating thoroughly human-like robots—such as the creation of strong artificial intelligence—are assumed to have been solved. Fictional androids are often depicted as mentally and physically equal or superior to humans—moving, thinking and speaking as fluidly as them.
The tension between the nonhuman substance and the human appearance—or even human ambitions—of androids is the dramatic impetus behind most of their fictional depictions. Some android heroes seek, like Pinocchio, to become human, as in the films "Bicentennial Man", "Hollywood", "Enthiran" and "A.I. Artificial Intelligence", or Data in "". Others, as in the film "Westworld", rebel against abuse by careless humans. Android hunter Deckard in "Do Androids Dream of Electric Sheep?" and its film adaptation "Blade Runner" discovers that his targets are, in some ways, more human than he is. Android stories, therefore, are not essentially stories "about" androids; they are stories about the human condition and what it means to be human.
One aspect of writing about the meaning of humanity is to use discrimination against androids as a mechanism for exploring racism in society, as in "Blade Runner". Perhaps the clearest example of this is John Brunner's 1968 novel "Into the Slave Nebula", where the blue-skinned android slaves are explicitly shown to be fully human. More recently, the androids Bishop and Annalee Call in the films "Aliens" and "Alien Resurrection" are used as vehicles for exploring how humans deal with the presence of an "Other".
Female androids, or "gynoids", are often seen in science fiction, and can be viewed as a continuation of the long tradition of men attempting to create the stereotypical "perfect woman". Examples include the Greek myth of "Pygmalion" and the female robot Maria in Fritz Lang's "Metropolis". Some gynoids, like Pris in "Blade Runner", are designed as sex-objects, with the intent of "pleasing men's violent sexual desires," or as submissive, servile companions, such as in "The Stepford Wives". Fiction about gynoids has therefore been described as reinforcing "essentialist ideas of femininity", although others have suggested that the treatment of androids is a way of exploring racism and misogyny in society.
The 2015 Japanese film "Sayonara", starring Geminoid F, was promoted as "the first movie to feature an android performing opposite a human actor".

</doc>
